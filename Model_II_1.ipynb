{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "## Import tensorflow package for modeling\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Min-max normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## Plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Initializing module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "## Copy module\n",
    "import copy\n",
    "\n",
    "## Used to calculate the training time\n",
    "import time\n",
    "\n",
    "## Set the GUP environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the display\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True, threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = pd.read_csv(\"DINKLE_demand.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Month_date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Mean</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>11</td>\n",
       "      <td>43.08</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>12</td>\n",
       "      <td>55.33</td>\n",
       "      <td>50.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>13</td>\n",
       "      <td>47.00</td>\n",
       "      <td>109.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>14</td>\n",
       "      <td>28.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>15</td>\n",
       "      <td>39.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>75.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>9</td>\n",
       "      <td>542.58</td>\n",
       "      <td>984.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>10</td>\n",
       "      <td>440.58</td>\n",
       "      <td>504.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "      <td>430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>11</td>\n",
       "      <td>428.25</td>\n",
       "      <td>504.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>12</td>\n",
       "      <td>432.92</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>13</td>\n",
       "      <td>310.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1472.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1035 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Number  Month_date  Month    Mean    t-4    t-3    t-2    t-1  \\\n",
       "0     CC110108002300  2013-05-01     11   43.08   20.0   50.0  109.5    0.0   \n",
       "1     CC110108002300  2013-06-01     12   55.33   50.0  109.5    0.0    0.0   \n",
       "2     CC110108002300  2013-07-01     13   47.00  109.5    0.0    0.0   79.0   \n",
       "3     CC110108002300  2013-08-01     14   28.75    0.0    0.0   79.0   93.5   \n",
       "4     CC110108002300  2013-09-01     15   39.92    0.0   79.0   93.5    0.0   \n",
       "...              ...         ...    ...     ...    ...    ...    ...    ...   \n",
       "1030  CC110106004900  2020-03-01      9  542.58  984.0  504.0  504.0  732.0   \n",
       "1031  CC110106004900  2020-04-01     10  440.58  504.0  504.0  732.0    0.0   \n",
       "1032  CC110106004900  2020-05-01     11  428.25  504.0  732.0    0.0  531.5   \n",
       "1033  CC110106004900  2020-06-01     12  432.92  732.0    0.0  531.5  372.0   \n",
       "1034  CC110106004900  2020-07-01     13  310.92    0.0  531.5  372.0  430.0   \n",
       "\n",
       "          t    t+1     t+2  \n",
       "0       0.0   79.0    93.5  \n",
       "1      79.0   93.5     0.0  \n",
       "2      93.5    0.0     0.0  \n",
       "3       0.0    0.0    67.0  \n",
       "4       0.0   67.0    75.5  \n",
       "...     ...    ...     ...  \n",
       "1030    0.0  531.5   372.0  \n",
       "1031  531.5  372.0   430.0  \n",
       "1032  372.0  430.0   532.0  \n",
       "1033  430.0  532.0     0.0  \n",
       "1034  532.0    0.0  1472.0  \n",
       "\n",
       "[1035 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read data\n",
    "demand_x = demand.iloc[:,:-1]\n",
    "demand_y = pd.DataFrame(demand.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_y = demand_y[~((demand_x[\"t-4\"]==0) & (demand_x[\"t-3\"]==0) & (demand_x[\"t-2\"]==0) & (demand_x[\"t-1\"]==0) & (demand_x[\"t\"]==0) & (demand_x[\"t+1\"]==0))]\n",
    "demand_x = demand_x[~((demand_x[\"t-4\"]==0) & (demand_x[\"t-3\"]==0) & (demand_x[\"t-2\"]==0) & (demand_x[\"t-1\"]==0) & (demand_x[\"t\"]==0) & (demand_x[\"t+1\"]==0))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_x.reset_index(drop=True, inplace=True)\n",
    "demand_y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add new column \"Number\" to demand_y\n",
    "demand_y.insert(0, \"Number\", demand_x[\"Number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Month_date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Mean</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "      <th>t+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>11</td>\n",
       "      <td>43.08</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>12</td>\n",
       "      <td>55.33</td>\n",
       "      <td>50.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>13</td>\n",
       "      <td>47.00</td>\n",
       "      <td>109.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>14</td>\n",
       "      <td>28.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>15</td>\n",
       "      <td>39.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>9</td>\n",
       "      <td>542.58</td>\n",
       "      <td>984.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>10</td>\n",
       "      <td>440.58</td>\n",
       "      <td>504.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>11</td>\n",
       "      <td>428.25</td>\n",
       "      <td>504.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "      <td>430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>12</td>\n",
       "      <td>432.92</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>13</td>\n",
       "      <td>310.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1033 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Number  Month_date  Month    Mean    t-4    t-3    t-2    t-1  \\\n",
       "0     CC110108002300  2013-05-01     11   43.08   20.0   50.0  109.5    0.0   \n",
       "1     CC110108002300  2013-06-01     12   55.33   50.0  109.5    0.0    0.0   \n",
       "2     CC110108002300  2013-07-01     13   47.00  109.5    0.0    0.0   79.0   \n",
       "3     CC110108002300  2013-08-01     14   28.75    0.0    0.0   79.0   93.5   \n",
       "4     CC110108002300  2013-09-01     15   39.92    0.0   79.0   93.5    0.0   \n",
       "...              ...         ...    ...     ...    ...    ...    ...    ...   \n",
       "1028  CC110106004900  2020-03-01      9  542.58  984.0  504.0  504.0  732.0   \n",
       "1029  CC110106004900  2020-04-01     10  440.58  504.0  504.0  732.0    0.0   \n",
       "1030  CC110106004900  2020-05-01     11  428.25  504.0  732.0    0.0  531.5   \n",
       "1031  CC110106004900  2020-06-01     12  432.92  732.0    0.0  531.5  372.0   \n",
       "1032  CC110106004900  2020-07-01     13  310.92    0.0  531.5  372.0  430.0   \n",
       "\n",
       "          t    t+1  \n",
       "0       0.0   79.0  \n",
       "1      79.0   93.5  \n",
       "2      93.5    0.0  \n",
       "3       0.0    0.0  \n",
       "4       0.0   67.0  \n",
       "...     ...    ...  \n",
       "1028    0.0  531.5  \n",
       "1029  531.5  372.0  \n",
       "1030  372.0  430.0  \n",
       "1031  430.0  532.0  \n",
       "1032  532.0    0.0  \n",
       "\n",
       "[1033 rows x 10 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2013-05-01\n",
       "1       2013-06-01\n",
       "2       2013-07-01\n",
       "3       2013-08-01\n",
       "4       2013-09-01\n",
       "           ...    \n",
       "1028    2020-03-01\n",
       "1029    2020-04-01\n",
       "1030    2020-05-01\n",
       "1031    2020-06-01\n",
       "1032    2020-07-01\n",
       "Name: Month_date, Length: 1033, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Store the date data\n",
    "date = demand_x.iloc[:,1]\n",
    "\n",
    "## Delete the date data from the demand_x \n",
    "demand_x.pop(\"Month_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Month</th>\n",
       "      <th>Mean</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "      <th>t+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>11</td>\n",
       "      <td>43.08</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>12</td>\n",
       "      <td>55.33</td>\n",
       "      <td>50.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>13</td>\n",
       "      <td>47.00</td>\n",
       "      <td>109.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>14</td>\n",
       "      <td>28.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC110108002300</td>\n",
       "      <td>15</td>\n",
       "      <td>39.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>9</td>\n",
       "      <td>542.58</td>\n",
       "      <td>984.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>10</td>\n",
       "      <td>440.58</td>\n",
       "      <td>504.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>11</td>\n",
       "      <td>428.25</td>\n",
       "      <td>504.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "      <td>430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>12</td>\n",
       "      <td>432.92</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>CC110106004900</td>\n",
       "      <td>13</td>\n",
       "      <td>310.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.5</td>\n",
       "      <td>372.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1033 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Number  Month    Mean    t-4    t-3    t-2    t-1      t    t+1\n",
       "0     CC110108002300     11   43.08   20.0   50.0  109.5    0.0    0.0   79.0\n",
       "1     CC110108002300     12   55.33   50.0  109.5    0.0    0.0   79.0   93.5\n",
       "2     CC110108002300     13   47.00  109.5    0.0    0.0   79.0   93.5    0.0\n",
       "3     CC110108002300     14   28.75    0.0    0.0   79.0   93.5    0.0    0.0\n",
       "4     CC110108002300     15   39.92    0.0   79.0   93.5    0.0    0.0   67.0\n",
       "...              ...    ...     ...    ...    ...    ...    ...    ...    ...\n",
       "1028  CC110106004900      9  542.58  984.0  504.0  504.0  732.0    0.0  531.5\n",
       "1029  CC110106004900     10  440.58  504.0  504.0  732.0    0.0  531.5  372.0\n",
       "1030  CC110106004900     11  428.25  504.0  732.0    0.0  531.5  372.0  430.0\n",
       "1031  CC110106004900     12  432.92  732.0    0.0  531.5  372.0  430.0  532.0\n",
       "1032  CC110106004900     13  310.92    0.0  531.5  372.0  430.0  532.0    0.0\n",
       "\n",
       "[1033 rows x 9 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the label encoder \n",
    "labelencoder = LabelEncoder()\n",
    "demand_x_encode = copy.deepcopy(demand_x)\n",
    "demand_y_encode = copy.deepcopy(demand_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode the material number\n",
    "demand_x_encode[\"Number\"]=labelencoder.fit_transform(demand_x_encode[\"Number\"])\n",
    "demand_y_encode[\"Number\"]=labelencoder.transform(demand_y_encode[\"Number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CC110105002300' 'CC110106001800' 'CC110106004900' 'CC110108002300'\n",
      " 'CC110108002800' 'CC110108004300' 'CC110108004500' 'CC110108004700'\n",
      " 'CC110208001800' 'CC110208002500' 'CC110208003600' 'CC110210002800']\n"
     ]
    }
   ],
   "source": [
    "## Print out each meaning of code\n",
    "material_num = [i for i in range(len(demand_x_encode[\"Number\"].unique()))]\n",
    "print(labelencoder.inverse_transform(material_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into the training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(demand_x_encode, demand_y_encode, data_des,number_encode):\n",
    " \n",
    "    block_x_train, block_y_train, block_x_test, block_y_test = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    for i in range(data_des.shape[0]):\n",
    "    # for i in range(1):\n",
    "        selected_material_x = demand_x_encode[demand_x_encode[\"Number\"]==number_encode[i]]\n",
    "        selected_material_y = demand_y_encode[demand_y_encode[\"Number\"]==number_encode[i]]\n",
    "        selected_material_x.reset_index(drop=True, inplace=True)\n",
    "        selected_material_y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        selected_index = np.random.randint(selected_material_x.shape[0], size=data_des.iloc[i,3])\n",
    "\n",
    "        block_x_train = np.append(block_x_train, selected_material_x.iloc[selected_index,:][:data_des.iloc[i,4]]).reshape([-1,selected_material_x.shape[1]])\n",
    "        block_y_train = np.append(block_y_train, selected_material_y.iloc[selected_index,:][:data_des.iloc[i,4]]).reshape([-1,selected_material_y.shape[1]])\n",
    "\n",
    "        block_x_test = np.append(block_x_test, selected_material_x.iloc[selected_index,:][data_des.iloc[i,4]:]).reshape([-1,selected_material_x.shape[1]])\n",
    "        block_y_test = np.append(block_y_test, selected_material_y.iloc[selected_index,:][data_des.iloc[i,4]:]).reshape([-1,selected_material_y.shape[1]])\n",
    "        \n",
    "    return (block_x_train, block_y_train, block_x_test, block_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out some info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_cacl(pred_value, actual_value):\n",
    "    \n",
    "#     yo, loss, tape = network.forward()\n",
    "    performance = []\n",
    "    performance.append(torch.mean(torch.abs(pred_value - actual_value)))\n",
    "    performance.append(torch.mean(torch.abs((pred_value - actual_value) / actual_value))) \n",
    "    performance.append(torch.sqrt(torch.mean((pred_value - actual_value)**2)))\n",
    "    \n",
    "    for i in range(2000,3001,1000):\n",
    "        correct_times = torch.nonzero(torch.abs(pred_value - actual_value) <= i)\n",
    "        accuracy = correct_times.shape[0]/pred_value.shape[0]\n",
    "        performance.append(accuracy)\n",
    "                       \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(name, pred_value, actual_value,block_index):\n",
    "    \n",
    "#     fig, ax = plt.subplots(2,2,figsize=(20,10), sharex=True, sharey=True)\n",
    "    fig, ax = plt.subplots(1,figsize=(20,10), sharex=True, sharey=True)\n",
    "#     ax.set_xlim(0,pred_value.shape[0])  \n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.plot(pred_value, label=\"LLAAT\")\n",
    "    ax.plot(actual_value, label=\"Actual\")\n",
    "    ax.set_title(\"Forecasted performance for l=%d\" %(1))\n",
    "    ax.legend()\n",
    "        \n",
    "    #fig.text(0.5, 0, \"Stage of training\", ha='center', fontsize=20)\n",
    "    #fig.text(0, 0.5, \"Copper price value\", va='center', rotation='vertical')\n",
    "\n",
    "    fig.suptitle(\"In the %s process in the M=%d window\"%(name, block_index))\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(\"In the %s process in the M=%d window.png\"%(name, block_index),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adopted_node(network,block_index):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "#     ax.set_xticklabels([i for i in range(network.nb_node_acceptable.shape[0]+5)])\n",
    "    \n",
    "    ax.set_title(\"Total amount of adopted hidden nodes in the training process in the M=%d window\"%(block_index))\n",
    "    ax.plot(network.nb_node_acceptable,\"-o\")\n",
    "\n",
    "    ax.set_xlabel(\"Stage of training\")\n",
    "    ax.set_ylabel(\"Hidden nodes\")\n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    fig.savefig(\"hidden nodes in the training process in the M=%d window\"%(block_index),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_table(evaluation_results, block_index, name, performance, nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node):\n",
    "\n",
    "    print(performance[3])\n",
    "    print(type(performance[3]))\n",
    "    \n",
    "    new_result = pd.DataFrame({\n",
    "\n",
    "        \"Window_index\":block_index,\n",
    "        \"Stage\":name,\n",
    "        \"MAE\" : performance[0].item(),\n",
    "        \"MAPE\" : \"%.2f\"%(performance[1]*100).item(),\n",
    "        \"RMSE\" : performance[2].item(),\n",
    "        \"Accuracy(2000)\" : [round(performance[3]*100,2)],\n",
    "        \"Accuracy(3000)\" : [round(performance[4]*100,2)],\n",
    "        \"Step4\":nb_step4,\n",
    "        \"Step6.1\":nb_step6_1,\n",
    "        \"Step6.2\":nb_step6_2,\n",
    "        \"Time\":time,\n",
    "        \"Adopted_hidden_node\":adopted_hidden_node\n",
    "    })\n",
    "\n",
    "    evaluation_results = evaluation_results.append(new_result, ignore_index=True)\n",
    "    \n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test, y_test, start, end, block_index, evaluation_results_train, evaluation_results_test):\n",
    "\n",
    "    ## Training_Step\n",
    "    print(\"<<Training step>>\")\n",
    "    print(\"The training time(s):\",end - start)\n",
    "    time = end - start\n",
    "    yo, loss= network.forward()\n",
    "    \n",
    "    pre_train = yo.data.cpu()\n",
    "    true_train = network.y.data.cpu()\n",
    "    \n",
    "    pred_value_train = torch.FloatTensor(sc.inverse_transform(pre_train))\n",
    "    actual_value_train = torch.FloatTensor(sc.inverse_transform(true_train))\n",
    "    accuracy_train = accuracy_cacl(pred_value_train,actual_value_train)\n",
    "\n",
    "    pred_value_test = torch.FloatTensor(sc.inverse_transform(network.forecast(x_test).data.cpu()))\n",
    "    accuracy_test = accuracy_cacl(pred_value_test, y_test)\n",
    "    \n",
    "    total_time = nb_step4 + nb_step6_1 + nb_step6_2\n",
    "    print(\"<<The percentage of each step>>\")\n",
    "    print(\"Step 4: %.2f%%\"%((nb_step4/total_time)*100))\n",
    "    print(\"Step 6.1: %.2f%%\"%((nb_step6_1/total_time)*100))\n",
    "    print(\"Step 6.2: %.2f%%\"%((nb_step6_2/total_time)*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"Total frequency of cramming occurrences:\",nb_step6_2)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"The amount of hidden node that be pruned:\",network.nb_node_pruned)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    adopted_hidden_node = network.nb_node_acceptable[-1].item()\n",
    "    print(\"The amount of adopted hidden nodes:\",network.nb_node_acceptable[-1].item())\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in training step>>\")\n",
    "    print(\"The MAE for l = 1: %.2f\" %(accuracy_train[0]))\n",
    "    print(\"The MAPE for l = 1: %.2f%%\" %(accuracy_train[1]))\n",
    "    print(\"The RMSE for l = 1: %.2f\" %(accuracy_train[2]))\n",
    "    print(\"The accuracy(2000) for l = 1: %.2f%%\" %(accuracy_train[3]*100))\n",
    "    print(\"The accuracy(3000) for l = 1: %.2f%%\" %(accuracy_train[4]*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in inferencing step>>\")\n",
    "    print(\"The MAE for l = 1: %.1f\" %(accuracy_test[0]))\n",
    "    print(\"The MAPE for l = 1: %.1f%%\" %(accuracy_test[1]))\n",
    "    print(\"The RMSE for l = 1: %.1f\" %(accuracy_test[2]))\n",
    "    print(\"The accuracy(2000) for l = 1: %.1f%%\" %(accuracy_test[3]*100))\n",
    "    print(\"The accuracy(3000) for l = 1: %.1f%%\" %(accuracy_test[4]*100))\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    \n",
    "    evaluation_table_train = evaluation_table(evaluation_results_train, block_index, \"Training\", accuracy_train,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "    evaluation_table_test = evaluation_table(evaluation_results_test, block_index, \"Inferencing\", accuracy_test,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "    pre_LDSS = sc.inverse_transform(network.forecast(x_test).data.cpu())\n",
    "    pd.DataFrame(pre_LDSS).to_csv(\"pre_LDSS_%d.csv\"%(block_index), index=False)\n",
    "    \n",
    "    if block_index%5==0:\n",
    "        plot_result(\"training\",pred_value_train, actual_value_train,block_index)\n",
    "        plot_result(\"inferencing\",pred_value_test, y_test,block_index)\n",
    "        plot_adopted_node(network,block_index)\n",
    "    \n",
    "    return(evaluation_table_train, evaluation_table_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use min-max normalization to scale the data to the range from 1 to 0\n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_neuro, x_train_scaled, y_train_scaled):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(x_train_scaled.shape[1], nb_neuro).cuda()\n",
    "        self.linear2 = torch.nn.Linear(nb_neuro, 1).cuda()\n",
    "        \n",
    "        \n",
    "        # Stop criteria - threshold\n",
    "        self.threshold_for_error = 0.12\n",
    "        self.threshold_for_lr = 1e-4\n",
    "        \n",
    "        # Input data \n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "        \n",
    "        # Learning rate\n",
    "        self.learning_rate = 1e-3\n",
    "        \n",
    "        # Whether the network is acceptable, default as False\n",
    "        self.acceptable = False\n",
    "        \n",
    "        # Some record for experiment\n",
    "        self.nb_node_pruned = 0\n",
    "        self.nb_node_acceptable=torch.IntTensor([nb_neuro])\n",
    "        \n",
    "        self.limit = nb_neuro\n",
    "        \n",
    "    ## Forecast the test data\n",
    "    def forecast(self, x_test):\n",
    "    \n",
    "        x_test = torch.FloatTensor(x_test).cuda()\n",
    "        activation_value = self.linear1(x_test).clamp(min=0)\n",
    "        forecast_value = self.linear2(activation_value)\n",
    "       \n",
    "        return forecast_value\n",
    "\n",
    "    ## Reset the x and y data\n",
    "    def setData(self, x_train_scaled, y_train_scaled):\n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "    \n",
    "    ## Add the new data to the x and y data\n",
    "    def addData(self, new_x_train, new_y_train):\n",
    "\n",
    "        self.x = torch.cat([self.x, new_x_train.reshape(1,-1).cuda()],0)\n",
    "        self.y = torch.cat([self.y, new_y_train.reshape(-1,1).cuda()],0)\n",
    "    \n",
    "    ## forward operation\n",
    "    def forward(self, reg_strength=0):\n",
    "       \n",
    "        y1 = self.linear1(self.x).clamp(min=0)\n",
    "        yo = self.linear2(y1)\n",
    "\n",
    "        # performance measure\n",
    "        param_val= torch.sum(torch.pow(self.linear2.bias.data,2))+torch.sum(torch.pow(self.linear2.weight.data,2))+torch.sum(torch.pow(self.linear1.bias.data,2))+torch.sum(torch.pow(self.linear1.weight.data,2))\n",
    "        reg_term= reg_strength/((self.linear2.bias.data.shape[0]*(self.linear2.weight.data.shape[1]+1)) +(self.linear1.bias.data.shape[0]*(self.linear1.weight.data.shape[1]+1)))*param_val\n",
    "        loss = torch.nn.functional.mse_loss(yo,self.y)+reg_term\n",
    "        loss = loss.cuda()\n",
    "        return(yo, loss)\n",
    "\n",
    "    # backward operation\n",
    "    def backward_Adadelta(self,loss):    \n",
    "\n",
    "        optimizer = optim.Adadelta(self.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializing(network, initial_x, initial_y):\n",
    "    print(\"Initializing module\")\n",
    "    ## Find each minimum output value y\n",
    "    min_y = torch.min(initial_y, axis=0)\n",
    "    ## Subtract min_y from each y\n",
    "    res_y = initial_y-min_y.values\n",
    "    \n",
    "    ## Use linear regression to find the initial W1,b1,Wo,bo\n",
    "    reg = LinearRegression().fit(initial_x, res_y)\n",
    "    \n",
    "    ## Set up the initial parameter of the network\n",
    "    network.linear1.weight = torch.nn.Parameter(torch.FloatTensor(reg.coef_).cuda())\n",
    "    network.linear1.bias = torch.nn.Parameter(torch.FloatTensor(reg.intercept_).cuda())\n",
    "    network.linear2.weight=torch.nn.Parameter(torch.FloatTensor([[1]]).cuda())\n",
    "    network.linear2.bias = torch.nn.Parameter(torch.FloatTensor(min_y.values).cuda())\n",
    "    \n",
    "#     print(reg.coef_)\n",
    "#     print(reg.intercept_)\n",
    "\n",
    "    ## Set up the acceptable of the initial network as True\n",
    "    network.acceptable =True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting(network, x_train_scaled, y_train_scaled):\n",
    "    \n",
    "    print(\"<<Selecting module>>\")\n",
    "    loss = []\n",
    "    temp_network = copy.deepcopy(network)\n",
    "    \n",
    "    ## Put each data into network to calculate the loss value\n",
    "    for i in range(x_train_scaled.shape[0]):\n",
    "        temp_network.setData(x_train_scaled[i].reshape(1,-1), y_train_scaled[i].reshape(-1,1))\n",
    "        loss.append((temp_network.forward()[1].item(),i))\n",
    "#         print(network.state_dict())\n",
    "#         print(temp_network.y)\n",
    "#         print(\"-\"*20)\n",
    "#         print(temp_network.forward()[1])\n",
    "#         print(\"-\"*20)\n",
    "#     ## Sort the data according to the loss value from smallest to largest, and save the data index in sorted_index\n",
    "    sorted_index = [sorted_data[1] for sorted_data in sorted(loss, key = lambda x:x[0])]\n",
    "    \n",
    "    \n",
    "    ## Print out some info for debug\n",
    "    print(\"The loss value of k:\",loss[sorted_index[0]])\n",
    "    print(\"The second_loss value of k:\",loss[sorted_index[1]])\n",
    "    print(\"Selecting module finish!\")\n",
    "#     print(\"Loss\",loss)\n",
    "#     print(network.state_dict())\n",
    "    \n",
    "    return sorted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def matching(network):\n",
    "\n",
    "#     times_enlarge=0\n",
    "#     times_shrink=0\n",
    "    \n",
    "#     print(\"<<Matching module>>\")\n",
    "#     print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "#     ## Set up the learning rate of the network\n",
    "#     network.learning_rate = 1e-3\n",
    "#     network.acceptable = False\n",
    "#     initial_network = copy.deepcopy(network)\n",
    "\n",
    "#     yo, loss = network.forward()\n",
    "    \n",
    "#     if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "#         print(\"Matching finished (firstly) - the network is acceptable\")\n",
    "#         network.acceptable = True\n",
    "# #         print(\"Matching firstly finished - the network is acceptable\")\n",
    "#         print(\"Number of enlarge:\",times_enlarge)\n",
    "#         print(\"Number of shrink:\",times_shrink)\n",
    "#         return(network)\n",
    "    \n",
    "#     else:\n",
    "    \n",
    "#         while True:\n",
    "\n",
    "#             yo, loss = network.forward()\n",
    "#             network_pre = copy.deepcopy(network)\n",
    "#             loss_pre = loss\n",
    "            \n",
    "#             # Backward and check the loss performance of the network with new learning rate\n",
    "#             network.backward_Adadelta(loss)\n",
    "#             yo, loss = network.forward()\n",
    "\n",
    "#             # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "#             if loss <= loss_pre and torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "       \n",
    "#                 network.acceptable = True\n",
    "#                 print(\"Matching finished - the network is acceptable\")\n",
    "#                 print(\"Number of enlarge:\",times_enlarge)\n",
    "#                 print(\"Number of shrink:\",times_shrink)\n",
    "#                 return(network)\n",
    "\n",
    "#             elif loss <= loss_pre:\n",
    "                \n",
    "#                 times_enlarge+=1\n",
    "#                 network.learning_rate *= 1.2\n",
    "\n",
    "#             else:         \n",
    "\n",
    "#                 # Identify whether the current learning rate is less than the threshold\n",
    "#                 if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "#                     # If true, set the acceptable of the network as false and return it\n",
    "#                     network.acceptable = False\n",
    "#                     print(\"Matching finished - the network is Unacceptable\")\n",
    "#                     print(\"Number of enlarge:\",times_enlarge)\n",
    "#                     print(\"Number of shrink:\",times_shrink)\n",
    "#                     return(initial_network)\n",
    "\n",
    "#                 # On the contrary, restore w and adjust the learning rate\n",
    "#                 else:\n",
    "                    \n",
    "#                     # Restore the papameter of the network\n",
    "#                     network = copy.deepcopy(network_pre)\n",
    "#                     times_shrink+=1\n",
    "#                     network.learning_rate *= 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    \n",
    "    print(\"<<Matching module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "    yo, loss = network.forward()\n",
    "    \n",
    "    if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "        network.acceptable = True\n",
    "        print(\"Matching(o) first finished - the network is acceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(10000):\n",
    "            \n",
    "            yo, loss = network.forward()\n",
    "            network_pre = copy.deepcopy(network)\n",
    "            loss_pre = loss\n",
    "\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "            network.backward_Adadelta(loss)\n",
    "            yo, loss = network.forward()\n",
    "\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "            if loss <= loss_pre and torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "                # If true, multiply the learning rate by 1.2\n",
    "                network.acceptable = True\n",
    "                print(\"Matching finished - the network is acceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "            elif loss <= loss_pre:\n",
    "                \n",
    "                times_enlarge+=1\n",
    "                network.learning_rate *= 1.2\n",
    "\n",
    "\n",
    "            else:         \n",
    "\n",
    "                # Identify whether the current learning rate is less than the threshold\n",
    "                if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                    # If true, set the acceptable of the network as false and return it\n",
    "                    network.acceptable = False\n",
    "                    print(\"Matching finished - the network is Unacceptable\")\n",
    "                    print(\"Number of enlarge:\",times_enlarge)\n",
    "                    print(\"Number of shrink:\",times_shrink)\n",
    "                    return(initial_network)\n",
    "\n",
    "                # On the contrary, restore w and adjust the learning rate\n",
    "                else:\n",
    "\n",
    "                    # Restore the papameter of the network\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    times_shrink+=1\n",
    "                    network.learning_rate *= 0.7\n",
    "                \n",
    "        network.acceptable = False\n",
    "        print(\"Matching的第%d回合\"%(i+1))\n",
    "        print(\"Matching finished - the network is Unacceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(initial_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching for reorganizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_for_reorganizing(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    \n",
    "    print(\"<<Matching module for reorganizing>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "    yo, loss = network.forward()\n",
    "    \n",
    "    if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "        network.acceptable = True\n",
    "        print(\"Matching(o) first finished - the network is acceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(500):\n",
    "            \n",
    "            yo, loss = network.forward()\n",
    "            network_pre = copy.deepcopy(network)\n",
    "            loss_pre = loss\n",
    "\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "            network.backward_Adadelta(loss)\n",
    "            yo, loss = network.forward()\n",
    "\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "            if loss <= loss_pre and torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "                # If true, multiply the learning rate by 1.2\n",
    "                network.acceptable = True\n",
    "                print(\"Matching finished(o) - the network is acceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "            elif loss <= loss_pre:\n",
    "                \n",
    "                times_enlarge+=1\n",
    "                network.learning_rate *= 1.2\n",
    "\n",
    "\n",
    "            else:         \n",
    "\n",
    "                # Identify whether the current learning rate is less than the threshold\n",
    "                if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                    # If true, set the acceptable of the network as false and return it\n",
    "                    network.acceptable = False\n",
    "                    print(\"Matching finished(o) - the network is Unacceptable\")\n",
    "                    print(\"Number of enlarge:\",times_enlarge)\n",
    "                    print(\"Number of shrink:\",times_shrink)\n",
    "                    return(initial_network)\n",
    "\n",
    "                # On the contrary, restore w and adjust the learning rate\n",
    "                else:\n",
    "\n",
    "                    # Restore the papameter of the network\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    times_shrink+=1\n",
    "                    network.learning_rate *= 0.7\n",
    "                \n",
    "        network.acceptable = False\n",
    "        print(\"Matching的第%d回合\"%(i+1))\n",
    "        print(\"Matching finished - the network is Unacceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(initial_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramming module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramming(network):\n",
    "    \n",
    "   \n",
    "    print(\"<<Cramming module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Find unsatisfied data:K\n",
    "    yo, loss = network.forward()\n",
    "    undesired_index = torch.nonzero(torch.abs(yo-network.y) > network.threshold_for_error+0.001, as_tuple =False)\n",
    "\n",
    "    ## Print out the undesired_index for debug\n",
    "    print(\"不滿足個數：\",undesired_index.shape[0])\n",
    "    print(\"The index of the undesired data:\",undesired_index)\n",
    "\n",
    "    \n",
    "    if undesired_index.shape[0] == 1:\n",
    "        \n",
    "        # Unsatisfied situation\n",
    "        ## Find the index of the unsatisfied data\n",
    "        k_data_num = undesired_index[0][0]\n",
    "\n",
    "        undesired_data = torch.reshape(network.x[k_data_num,:], [1,-1])\n",
    "\n",
    "        ## Remove the data that does not meet the error term\n",
    "        left_data = network.x[:k_data_num,:]\n",
    "        right_data = network.x[k_data_num+1:,:]\n",
    "        remain_tensor = torch.cat([left_data, right_data], 0)\n",
    "\n",
    "\n",
    "        ## Use the random method to find out the gamma and zeta\n",
    "        while True:\n",
    "\n",
    "            ## Find m-vector gamma: r\n",
    "            ## Use the random method to generate the gamma that can make the conditions met\n",
    "            gamma = torch.rand(size=[1,network.x.shape[1]]).cuda()\n",
    "            subtract_undesired_data = torch.sub(remain_tensor, undesired_data)\n",
    "            matmul_value = torch.mm(gamma,torch.t(subtract_undesired_data))\n",
    "\n",
    "            if torch.all(matmul_value != 0):\n",
    "                break\n",
    "\n",
    "        while True:\n",
    "\n",
    "            ## Find the tiny value: zeta\n",
    "            ## Use the random method to generate the zeta that can make the conditions met\n",
    "            zeta = torch.rand(size=[1]).cuda()\n",
    "\n",
    "            if torch.all(torch.mul(torch.add(zeta,matmul_value),torch.sub(zeta,matmul_value))<0):\n",
    "                break\n",
    "\n",
    "       \n",
    "\n",
    "        k_l = undesired_index[0][1]\n",
    "        \n",
    "        ## The weight of input layer to hidden layer I\n",
    "        w10 = gamma\n",
    "        w11 = gamma\n",
    "        w12 = gamma\n",
    "\n",
    "        W1_new = torch.cat([w10,w11,w12],0)\n",
    "        \n",
    "\n",
    "        ## The bias of input layer to hidden layer I\n",
    "        matual_value = torch.mm(gamma,torch.t(undesired_data))\n",
    "       \n",
    "        \n",
    "        b10 = torch.sub(zeta,matual_value)\n",
    "        b11 = -1*matual_value\n",
    "        b12 = torch.sub(-1*zeta,matual_value)\n",
    "        b1_new = torch.reshape(torch.cat([b10,b11,b12],0),[3])\n",
    "\n",
    "\n",
    "\n",
    "        ## The weight of hidden layer I to output layer\n",
    "        gap = network.y[k_data_num, k_l]-yo[k_data_num, k_l]\n",
    "\n",
    "        wo0_value = gap/zeta\n",
    "        wo1_value = (-2*gap)/zeta\n",
    "        wo2_value = gap/zeta\n",
    "\n",
    "        Wo_new = torch.reshape(torch.cat([wo0_value,wo1_value,wo2_value],0),[1,-1])\n",
    "\n",
    "        ## Add new neuroes to the network\n",
    "        network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight.data, W1_new]))\n",
    "        network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias.data, b1_new]))\n",
    "        network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight.data, Wo_new],1))\n",
    "\n",
    "\n",
    "        yo, loss = network.forward()\n",
    "        \n",
    "        ## Determine if cramming is successful and print out the corresponding information\n",
    "        if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "            network.acceptable = True \n",
    "            print(\"Cramming success!\")\n",
    "\n",
    "        else:\n",
    "            print(\"Cramming failed!\")\n",
    "    \n",
    "    else:\n",
    "        print(\"條件不合，不能Cramming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizing(network):\n",
    "\n",
    "    print(\"<<Regularizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    ## Record the number of executions\n",
    "    times_enlarge = 0\n",
    "    times_shrink = 0\n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "\n",
    "    ## Set epoch to 100\n",
    "    for i in range(100):\n",
    "\n",
    "        ## Store the parameter of the network\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "        loss_pre = loss\n",
    "\n",
    "\n",
    "        ## Backward operation to obtain w'\n",
    "        network.backward_Adadelta(loss)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "        \n",
    "        ## Confirm whether the adjusted loss value is smaller than the current one\n",
    "        if loss <= loss_pre:\n",
    "            \n",
    "            ## Identify that all forecast value has met the error term\n",
    "            if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "                \n",
    "                ## If true, multiply the learning rate by 1.2\n",
    "                network.learning_rate *= 1.2\n",
    "                times_enlarge += 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                ## Else, restore w and end the process\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                print(\"Regularizing結束-因為沒有顧好預測誤差\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "        # If the adjusted loss value is not smaller than the current one\n",
    "        else:\n",
    "\n",
    "            ## If the learning rate is greater than the threshold for learning rate\n",
    "            if network.learning_rate > network.threshold_for_lr:\n",
    "                \n",
    "                ## Restore the w and multiply the learning rate by 0.7\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                network.learning_rate *= 0.7\n",
    "                times_shrink += 1\n",
    "\n",
    "             ## If the learning rate is smaller than the threshold for learning rate\n",
    "            else:\n",
    "                \n",
    "                ## Restore the w\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                print(\"Regularizing結束-Learning不能這麼小\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "    print(\"第\\\"%d\\\"回合Regularizing module完畢\"%(i+1))\n",
    "    print(\"Number of enlarge:\",times_enlarge)\n",
    "    print(\"Number of shrink:\",times_shrink)\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganizing(network):\n",
    "    print(\"<<Reorganizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    limit = 4\n",
    "    if network.linear1.bias.shape[0] <= limit:\n",
    "        network = regularizing(network)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        ## Set up the k = 1, and p = the number of hidden node\n",
    "        k = 1\n",
    "    #     p = network.W1.shape[1]\n",
    "        p = network.linear1.weight.data.shape[0]\n",
    "\n",
    "        while True:\n",
    "\n",
    "            ## If k > p, end of Process\n",
    "            if k > p or p<=limit:\n",
    "\n",
    "                print(\"Reorganizing result: The final number of neuro is \",p)\n",
    "                return(network)\n",
    "\n",
    "            ## Else, Process is ongoing\n",
    "            else:\n",
    "\n",
    "                ## Using the regularizing module to adjust the network\n",
    "                network = regularizing(network)\n",
    "\n",
    "                ## Store the network and w\n",
    "                network_pre = copy.deepcopy(network)\n",
    "\n",
    "                ## Set up the acceptable of the network as false\n",
    "                network.acceptable = False\n",
    "                \n",
    "            \n",
    "                ## Ignore the K hidden node\n",
    "                network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight[:k-1],network.linear1.weight[k:]],0))\n",
    "                network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias[:k-1],network.linear1.bias[k:]]))\n",
    "                network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight[:,:k-1],network.linear2.weight[:,k:]],1))\n",
    "\n",
    "                \n",
    "                ## Using the matching module to adjust the network\n",
    "                network = matching_for_reorganizing(network)\n",
    "\n",
    "                print(\"是不是可以不要這個hidden node:\",network.acceptable)\n",
    "\n",
    "                ## If the resulting network is acceptable, this means that the k hidden node can be removed\n",
    "                if network.acceptable:\n",
    "\n",
    "                    print(\"Drop out the nero number: %d / %d\" %(k, p))\n",
    "                    network.nb_node_pruned += 1\n",
    "                    ## p--\n",
    "                    p-=1\n",
    "\n",
    "                ## Else, it means that the k hidden node cannot be removed\n",
    "                else:\n",
    "\n",
    "                    ## Restore the network and w\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    print(\"Cannot drop out the nero number: %d / %d\" %(k, p))\n",
    "\n",
    "                    ## k++\n",
    "                    k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_encode = [data_des.iloc[i,0] for i in range(data_des.shape[0])]\n",
    "number_encode = labelencoder.transform(number_encode)\n",
    "\n",
    "x_sets_train, y_sets_train, x_sets_test, y_sets_test = [],[],[],[]\n",
    "\n",
    "for _ in range(15):\n",
    "    \n",
    "    block_x_train, block_y_train, block_x_test, block_y_test = get_data(demand_x_encode, demand_y_encode, data_des,number_encode)\n",
    "    \n",
    "    block_y_train = block_y_train[:,1:]\n",
    "    block_y_test = block_y_test[:,1:]\n",
    "    \n",
    "    zip_list = list(zip(block_x_train.tolist(), block_y_train.tolist()))\n",
    "    random.shuffle(zip_list)\n",
    "    demand_x_shuffle, demand_y_shuffle = zip(*zip_list)\n",
    "    demand_x_shuffle, demand_y_shuffle = np.array(demand_x_shuffle), np.array(demand_y_shuffle)\n",
    "    \n",
    "    x_sets_train.append(demand_x_shuffle)\n",
    "    y_sets_train.append(demand_y_shuffle)\n",
    "    x_sets_test.append(block_x_test)\n",
    "    y_sets_test.append(block_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_sets_train (210, 10)\n",
      "y_sets_train (210, 4)\n",
      "x_sets_test (90, 10)\n",
      "y_sets_test (90, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_sets_train\",x_sets_train[0].shape)\n",
    "print(\"y_sets_train\",y_sets_train[0].shape)\n",
    "print(\"x_sets_test\",x_sets_test[0].shape)\n",
    "print(\"y_sets_test\",y_sets_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 318.  ,    0.  ,  325.77,    0.  ,    0.  ,   16.26,    1.  ,\n",
       "          0.  ,    0.  ,    5.  ,    0.  ,    0.  ,  226.  ,   87.39,\n",
       "          0.  ,    0.  ,   13.  ,    0.  ,    0.  ,    0.  ,    0.  ,\n",
       "          0.  ,    0.  ,    0.  ,   55.  ,    0.  ,    0.  ,    0.  ,\n",
       "          0.  ,   34.  ,    0.  ,    0.  ,    0.  ,    0.  ,   64.5 ,\n",
       "          0.  ,    0.  ,    0.  ,    0.  ,   35.  ,    0.  ,    0.  ,\n",
       "        332.5 ,    0.  ,    4.48,    0.  ,    0.  ,    0.  ,    0.  ,\n",
       "          0.  ,    0.  ,    0.  ,    0.  ,  636.  ,    0.  ,    0.  ,\n",
       "         15.  ,    0.  ,    3.5 ,  195.  ,    0.  ,    0.  ,    0.  ,\n",
       "          0.  ,   23.5 ,  490.37,    0.  ,   10.  ,    0.  ,    0.  ,\n",
       "          0.  ,    0.  ,    0.  ,    0.  ,  206.  ,  120.43,    0.  ,\n",
       "          0.  ,    0.  ,  180.  ,    0.  ,    0.  ,    0.  ,   85.6 ,\n",
       "          0.  ,    0.  ,    0.  ,    0.  ,  226.  ,    0.  ,    0.  ,\n",
       "          0.  ,   38.  ,  384.  ,    0.  ,    0.  ,  759.75,   22.3 ,\n",
       "          0.  ,    0.  ,  152.67,    0.  ,    0.  ,   92.5 ,   66.5 ,\n",
       "       1189.5 ,    0.  ,    4.5 ,    0.  ,    0.  ,    0.  ,    0.  ,\n",
       "          0.  ,    0.  ,  779.  ,  403.  ,   41.5 ,  839.5 ,   51.  ,\n",
       "          0.  ,  238.  ,  105.  ,    0.  ,    0.  ,    0.  ,    0.  ,\n",
       "        200.  ,    0.  ,  826.  ,  106.2 ,   71.  ,    0.  ,  287.67,\n",
       "          0.  ,    0.  ,    0.  ,    2.  ,  314.  ,  277.  ,    0.  ,\n",
       "         44.  ,    6.7 ,    0.  ,   25.08,   67.  ,   32.6 ,    0.  ,\n",
       "          0.  ,   10.  ,  105.  ,    0.  ,    0.  ,    0.  ,  152.67,\n",
       "          0.  ,    0.  ,    0.  ,    0.  ,   55.  ,  149.  ,  420.  ,\n",
       "          0.  ,    0.  ,  175.5 ,    0.  ,  228.  ,    0.  ,    0.  ,\n",
       "          0.  ,    0.  ,    0.  ,    0.  ,    4.  ,    0.  ,  580.5 ,\n",
       "         87.  ,  139.  ,    0.  ,  113.5 ,  190.  ,   10.5 ,  359.  ,\n",
       "        465.  ,  490.37,    0.  ,   79.2 ,    0.  ,    0.  ,    0.  ,\n",
       "         22.3 ,  154.  ,    0.  , 1083.  ,    0.  ,    0.  ,    0.  ,\n",
       "       1541.5 ,   33.  ,  349.  ,  177.  ,    0.  ,   99.  ,    0.  ,\n",
       "          0.  ,   98.  ,    0.  ,    0.  ,  236.  ,    0.  ,    0.  ])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sets_train[0][:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The <<1>> Block\n",
      "Initializing module\n",
      "<<Initializing後看一下差異>>\n",
      "tensor([[204.9738],\n",
      "        [ 24.5769],\n",
      "        [ 63.0873],\n",
      "        [  0.0000],\n",
      "        [ 13.2758],\n",
      "        [ 43.8584],\n",
      "        [ 20.7761],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [ 13.5682],\n",
      "        [  0.0000],\n",
      "        [ 56.4698],\n",
      "        [ 56.7930],\n",
      "        [  5.6984],\n",
      "        [ 58.2159],\n",
      "        [  3.2013],\n",
      "        [ 12.5351],\n",
      "        [ 98.4614],\n",
      "        [145.1876]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "現在訓練到第幾筆資料: 12\n",
      "剩餘X 資料 torch.Size([191, 10])\n",
      "剩餘Y 資料 torch.Size([191, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 0)\n",
      "The second_loss value of k: (0.0, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([20, 1])\n",
      "<<預測值>>\n",
      "tensor([[113.0262],\n",
      "        [ 24.5769],\n",
      "        [262.6827],\n",
      "        [  0.0000],\n",
      "        [ 13.2758],\n",
      "        [ 60.1184],\n",
      "        [ 21.7761],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [ 18.5682],\n",
      "        [  0.0000],\n",
      "        [ 56.4698],\n",
      "        [169.2070],\n",
      "        [ 81.6916],\n",
      "        [ 58.2159],\n",
      "        [  3.2013],\n",
      "        [  0.4649],\n",
      "        [ 98.4614],\n",
      "        [145.1876],\n",
      "        [  0.0000]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[204.9738],\n",
      "        [ 24.5769],\n",
      "        [ 63.0873],\n",
      "        [  0.0000],\n",
      "        [ 13.2758],\n",
      "        [ 43.8584],\n",
      "        [ 20.7761],\n",
      "        [  0.0000],\n",
      "        [  0.0000],\n",
      "        [ 13.5682],\n",
      "        [  0.0000],\n",
      "        [ 56.4698],\n",
      "        [ 56.7930],\n",
      "        [  5.6984],\n",
      "        [ 58.2159],\n",
      "        [  3.2013],\n",
      "        [ 12.5351],\n",
      "        [ 98.4614],\n",
      "        [145.1876],\n",
      "        [  0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4504.5581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 82\n",
      "Number of shrink: 18\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[206.4115],\n",
      "        [  6.6158],\n",
      "        [ 41.1909],\n",
      "        [  0.7233],\n",
      "        [  0.7233],\n",
      "        [ 18.8026],\n",
      "        [ 17.0062],\n",
      "        [  0.7233],\n",
      "        [  0.7233],\n",
      "        [  8.8224],\n",
      "        [  0.7233],\n",
      "        [ 13.3560],\n",
      "        [  6.4310],\n",
      "        [  1.8771],\n",
      "        [  0.7233],\n",
      "        [  0.7233],\n",
      "        [ 13.7233],\n",
      "        [ 80.9944],\n",
      "        [151.5141],\n",
      "        [  0.7233]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 0.3411214351654053\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 13\n",
      "剩餘X 資料 torch.Size([190, 10])\n",
      "剩餘Y 資料 torch.Size([190, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.014370730146765709, 166)\n",
      "The second_loss value of k: (0.5231595635414124, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引166，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([21, 1])\n",
      "<<預測值>>\n",
      "tensor([[   111.5885],\n",
      "        [     6.6158],\n",
      "        [   284.5791],\n",
      "        [    -0.7233],\n",
      "        [    -0.7233],\n",
      "        [    35.0626],\n",
      "        [    18.0062],\n",
      "        [    -0.7233],\n",
      "        [    -0.7233],\n",
      "        [    13.8224],\n",
      "        [    -0.7233],\n",
      "        [    13.3560],\n",
      "        [   219.5690],\n",
      "        [    85.5129],\n",
      "        [    -0.7233],\n",
      "        [    -0.7233],\n",
      "        [    -0.7233],\n",
      "        [    80.9944],\n",
      "        [   151.5141],\n",
      "        [    -0.7233],\n",
      "        [     0.1199]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  206.4115],\n",
      "        [    6.6158],\n",
      "        [   41.1909],\n",
      "        [    0.7233],\n",
      "        [    0.7233],\n",
      "        [   18.8026],\n",
      "        [   17.0062],\n",
      "        [    0.7233],\n",
      "        [    0.7233],\n",
      "        [    8.8224],\n",
      "        [    0.7233],\n",
      "        [   13.3560],\n",
      "        [    6.4310],\n",
      "        [    1.8771],\n",
      "        [    0.7233],\n",
      "        [    0.7233],\n",
      "        [   13.7233],\n",
      "        [   80.9944],\n",
      "        [  151.5141],\n",
      "        [    0.7233],\n",
      "        [    0.1199]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(3571.3882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 80\n",
      "Number of shrink: 20\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  201.4748],\n",
      "        [    0.0944],\n",
      "        [   26.8771],\n",
      "        [    0.9530],\n",
      "        [    0.9530],\n",
      "        [    5.1134],\n",
      "        [   16.4949],\n",
      "        [    0.9530],\n",
      "        [    0.9530],\n",
      "        [    6.5783],\n",
      "        [    0.9530],\n",
      "        [   13.6982],\n",
      "        [    5.4740],\n",
      "        [    3.1116],\n",
      "        [    0.9530],\n",
      "        [    4.7150],\n",
      "        [   13.9530],\n",
      "        [   56.8728],\n",
      "        [  162.0576],\n",
      "        [    0.9530],\n",
      "        [    0.9530]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 0.6744492053985596\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 14\n",
      "剩餘X 資料 torch.Size([189, 10])\n",
      "剩餘Y 資料 torch.Size([189, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.9081432223320007, 0)\n",
      "The second_loss value of k: (0.9081432223320007, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([22, 1])\n",
      "<<預測值>>\n",
      "tensor([[   116.5252],\n",
      "        [     0.0944],\n",
      "        [   298.8929],\n",
      "        [    -0.9530],\n",
      "        [    -0.9530],\n",
      "        [    21.3734],\n",
      "        [    17.4949],\n",
      "        [    -0.9530],\n",
      "        [    -0.9530],\n",
      "        [    11.5783],\n",
      "        [    -0.9530],\n",
      "        [    13.6982],\n",
      "        [   220.5260],\n",
      "        [    84.2784],\n",
      "        [    -0.9530],\n",
      "        [     4.7150],\n",
      "        [    -0.9530],\n",
      "        [    56.8728],\n",
      "        [   162.0576],\n",
      "        [    -0.9530],\n",
      "        [    -0.9530],\n",
      "        [    -0.9530]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  201.4748],\n",
      "        [    0.0944],\n",
      "        [   26.8771],\n",
      "        [    0.9530],\n",
      "        [    0.9530],\n",
      "        [    5.1134],\n",
      "        [   16.4949],\n",
      "        [    0.9530],\n",
      "        [    0.9530],\n",
      "        [    6.5783],\n",
      "        [    0.9530],\n",
      "        [   13.6982],\n",
      "        [    5.4740],\n",
      "        [    3.1116],\n",
      "        [    0.9530],\n",
      "        [    4.7150],\n",
      "        [   13.9530],\n",
      "        [   56.8728],\n",
      "        [  162.0576],\n",
      "        [    0.9530],\n",
      "        [    0.9530],\n",
      "        [    0.9530]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(3254.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[200.9302],\n",
      "        [  0.9691],\n",
      "        [ 25.1598],\n",
      "        [  0.9691],\n",
      "        [  0.9691],\n",
      "        [  1.0859],\n",
      "        [ 17.7335],\n",
      "        [  0.9691],\n",
      "        [  0.9691],\n",
      "        [  5.4489],\n",
      "        [  0.9691],\n",
      "        [ 10.6619],\n",
      "        [  4.7069],\n",
      "        [  2.4578],\n",
      "        [  0.6078],\n",
      "        [  0.9691],\n",
      "        [ 13.9691],\n",
      "        [ 47.8344],\n",
      "        [164.0231],\n",
      "        [  0.9691],\n",
      "        [  0.9691],\n",
      "        [  0.9691]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.076059103012085\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 15\n",
      "剩餘X 資料 torch.Size([188, 10])\n",
      "剩餘Y 資料 torch.Size([188, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.939091145992279, 0)\n",
      "The second_loss value of k: (0.939091145992279, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([23, 1])\n",
      "<<預測值>>\n",
      "tensor([[117.0698],\n",
      "        [ -0.9691],\n",
      "        [300.6102],\n",
      "        [ -0.9691],\n",
      "        [ -0.9691],\n",
      "        [ 15.1741],\n",
      "        [ 18.7335],\n",
      "        [ -0.9691],\n",
      "        [ -0.9691],\n",
      "        [ 10.4489],\n",
      "        [ -0.9691],\n",
      "        [ 10.6619],\n",
      "        [221.2931],\n",
      "        [ 84.9322],\n",
      "        [ -0.6078],\n",
      "        [ -0.9691],\n",
      "        [ -0.9691],\n",
      "        [ 47.8344],\n",
      "        [164.0231],\n",
      "        [ -0.9691],\n",
      "        [ -0.9691],\n",
      "        [ -0.9691],\n",
      "        [ -0.9691]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[200.9302],\n",
      "        [  0.9691],\n",
      "        [ 25.1598],\n",
      "        [  0.9691],\n",
      "        [  0.9691],\n",
      "        [  1.0859],\n",
      "        [ 17.7335],\n",
      "        [  0.9691],\n",
      "        [  0.9691],\n",
      "        [  5.4489],\n",
      "        [  0.9691],\n",
      "        [ 10.6619],\n",
      "        [  4.7069],\n",
      "        [  2.4578],\n",
      "        [  0.6078],\n",
      "        [  0.9691],\n",
      "        [ 13.9691],\n",
      "        [ 47.8344],\n",
      "        [164.0231],\n",
      "        [  0.9691],\n",
      "        [  0.9691],\n",
      "        [  0.9691],\n",
      "        [  0.9691]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(3082.2048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  200.1708],\n",
      "        [    0.9027],\n",
      "        [   21.7178],\n",
      "        [    0.9027],\n",
      "        [    0.9027],\n",
      "        [    4.4070],\n",
      "        [   18.5694],\n",
      "        [    0.9027],\n",
      "        [    0.9027],\n",
      "        [    5.9287],\n",
      "        [    0.9027],\n",
      "        [   10.3676],\n",
      "        [    3.6958],\n",
      "        [    2.6924],\n",
      "        [    0.0001],\n",
      "        [    0.9027],\n",
      "        [   13.9026],\n",
      "        [   43.3069],\n",
      "        [  165.6729],\n",
      "        [    0.9027],\n",
      "        [    0.9027],\n",
      "        [    0.9027],\n",
      "        [    0.9027]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.3833227157592773\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 16\n",
      "剩餘X 資料 torch.Size([187, 10])\n",
      "剩餘Y 資料 torch.Size([187, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.8147773146629333, 0)\n",
      "The second_loss value of k: (0.8147773146629333, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([24, 1])\n",
      "<<預測值>>\n",
      "tensor([[   117.8292],\n",
      "        [    -0.9027],\n",
      "        [   304.0522],\n",
      "        [    -0.9027],\n",
      "        [    -0.9027],\n",
      "        [    11.8530],\n",
      "        [    19.5694],\n",
      "        [    -0.9027],\n",
      "        [    -0.9027],\n",
      "        [    10.9287],\n",
      "        [    -0.9027],\n",
      "        [    10.3676],\n",
      "        [   222.3042],\n",
      "        [    84.6976],\n",
      "        [    -0.0001],\n",
      "        [    -0.9027],\n",
      "        [    -0.9027],\n",
      "        [    43.3069],\n",
      "        [   165.6729],\n",
      "        [    -0.9027],\n",
      "        [    -0.9027],\n",
      "        [    -0.9027],\n",
      "        [    -0.9027],\n",
      "        [    -0.9027]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  200.1708],\n",
      "        [    0.9027],\n",
      "        [   21.7178],\n",
      "        [    0.9027],\n",
      "        [    0.9027],\n",
      "        [    4.4070],\n",
      "        [   18.5694],\n",
      "        [    0.9027],\n",
      "        [    0.9027],\n",
      "        [    5.9287],\n",
      "        [    0.9027],\n",
      "        [   10.3676],\n",
      "        [    3.6958],\n",
      "        [    2.6924],\n",
      "        [    0.0001],\n",
      "        [    0.9027],\n",
      "        [   13.9026],\n",
      "        [   43.3069],\n",
      "        [  165.6729],\n",
      "        [    0.9027],\n",
      "        [    0.9027],\n",
      "        [    0.9027],\n",
      "        [    0.9027],\n",
      "        [    0.9027]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2941.4106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  199.7248],\n",
      "        [    0.8623],\n",
      "        [   21.5665],\n",
      "        [    0.8623],\n",
      "        [    0.8623],\n",
      "        [    6.5683],\n",
      "        [   19.0758],\n",
      "        [    0.8623],\n",
      "        [    0.8623],\n",
      "        [    5.5975],\n",
      "        [    0.8623],\n",
      "        [   11.1093],\n",
      "        [    3.4673],\n",
      "        [    2.5229],\n",
      "        [    0.5216],\n",
      "        [    0.0170],\n",
      "        [   13.8623],\n",
      "        [   39.2305],\n",
      "        [  166.6195],\n",
      "        [    0.8623],\n",
      "        [    0.8623],\n",
      "        [    0.8623],\n",
      "        [    0.8623],\n",
      "        [    0.8623]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.6697437763214111\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 17\n",
      "剩餘X 資料 torch.Size([186, 10])\n",
      "剩餘Y 資料 torch.Size([186, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.7436350584030151, 0)\n",
      "The second_loss value of k: (0.7436350584030151, 7)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([25, 1])\n",
      "<<預測值>>\n",
      "tensor([[   118.2752],\n",
      "        [    -0.8623],\n",
      "        [   304.2035],\n",
      "        [    -0.8623],\n",
      "        [    -0.8623],\n",
      "        [     9.6917],\n",
      "        [    20.0758],\n",
      "        [    -0.8623],\n",
      "        [    -0.8623],\n",
      "        [    10.5975],\n",
      "        [    -0.8623],\n",
      "        [    11.1093],\n",
      "        [   222.5327],\n",
      "        [    84.8671],\n",
      "        [     0.5216],\n",
      "        [    -0.0170],\n",
      "        [    -0.8623],\n",
      "        [    39.2305],\n",
      "        [   166.6195],\n",
      "        [    -0.8623],\n",
      "        [    -0.8623],\n",
      "        [    -0.8623],\n",
      "        [    -0.8623],\n",
      "        [    -0.8623],\n",
      "        [    -0.8623]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  199.7248],\n",
      "        [    0.8623],\n",
      "        [   21.5665],\n",
      "        [    0.8623],\n",
      "        [    0.8623],\n",
      "        [    6.5683],\n",
      "        [   19.0758],\n",
      "        [    0.8623],\n",
      "        [    0.8623],\n",
      "        [    5.5975],\n",
      "        [    0.8623],\n",
      "        [   11.1093],\n",
      "        [    3.4673],\n",
      "        [    2.5229],\n",
      "        [    0.5216],\n",
      "        [    0.0170],\n",
      "        [   13.8623],\n",
      "        [   39.2305],\n",
      "        [  166.6195],\n",
      "        [    0.8623],\n",
      "        [    0.8623],\n",
      "        [    0.8623],\n",
      "        [    0.8623],\n",
      "        [    0.8623],\n",
      "        [    0.8623]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2817.5090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  199.5519],\n",
      "        [    0.8325],\n",
      "        [   20.7285],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    8.2367],\n",
      "        [   19.4506],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    5.9024],\n",
      "        [    0.8325],\n",
      "        [   10.3941],\n",
      "        [    3.1260],\n",
      "        [    2.3458],\n",
      "        [    1.0218],\n",
      "        [    0.1577],\n",
      "        [   13.8325],\n",
      "        [   36.9426],\n",
      "        [  167.1483],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    0.8325]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.9534409046173096\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 18\n",
      "剩餘X 資料 torch.Size([185, 10])\n",
      "剩餘Y 資料 torch.Size([185, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.6929989457130432, 6)\n",
      "The second_loss value of k: (0.6929989457130432, 7)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([26, 1])\n",
      "<<預測值>>\n",
      "tensor([[   118.4481],\n",
      "        [    -0.8325],\n",
      "        [   305.0415],\n",
      "        [    -0.8325],\n",
      "        [    -0.8325],\n",
      "        [     8.0233],\n",
      "        [    20.4506],\n",
      "        [    -0.8325],\n",
      "        [    -0.8325],\n",
      "        [    10.9024],\n",
      "        [    -0.8325],\n",
      "        [    10.3941],\n",
      "        [   222.8740],\n",
      "        [    85.0442],\n",
      "        [     1.0218],\n",
      "        [     0.1577],\n",
      "        [    -0.8325],\n",
      "        [    36.9426],\n",
      "        [   167.1483],\n",
      "        [    -0.8325],\n",
      "        [    -0.8325],\n",
      "        [    -0.8325],\n",
      "        [    -0.8325],\n",
      "        [    -0.8325],\n",
      "        [    -0.8325],\n",
      "        [    -0.8325]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  199.5519],\n",
      "        [    0.8325],\n",
      "        [   20.7285],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    8.2367],\n",
      "        [   19.4506],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    5.9024],\n",
      "        [    0.8325],\n",
      "        [   10.3941],\n",
      "        [    3.1260],\n",
      "        [    2.3458],\n",
      "        [    1.0218],\n",
      "        [    0.1577],\n",
      "        [   13.8325],\n",
      "        [   36.9426],\n",
      "        [  167.1483],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    0.8325],\n",
      "        [    0.8325]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2706.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[199.2479],\n",
      "        [  0.8078],\n",
      "        [ 20.1613],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  9.2393],\n",
      "        [ 20.0456],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  5.8840],\n",
      "        [  0.8078],\n",
      "        [  9.8012],\n",
      "        [  3.1362],\n",
      "        [  2.4108],\n",
      "        [  0.5223],\n",
      "        [  1.8998],\n",
      "        [ 13.8078],\n",
      "        [ 35.7333],\n",
      "        [167.5853],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  0.8078]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.239258050918579\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 19\n",
      "剩餘X 資料 torch.Size([184, 10])\n",
      "剩餘Y 資料 torch.Size([184, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.6524968147277832, 6)\n",
      "The second_loss value of k: (0.6524968147277832, 8)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([27, 1])\n",
      "<<預測值>>\n",
      "tensor([[118.7521],\n",
      "        [ -0.8078],\n",
      "        [305.6087],\n",
      "        [ -0.8078],\n",
      "        [ -0.8078],\n",
      "        [  7.0207],\n",
      "        [ 21.0456],\n",
      "        [ -0.8078],\n",
      "        [ -0.8078],\n",
      "        [ 10.8840],\n",
      "        [ -0.8078],\n",
      "        [  9.8012],\n",
      "        [222.8638],\n",
      "        [ 84.9792],\n",
      "        [  0.5223],\n",
      "        [  1.8998],\n",
      "        [ -0.8078],\n",
      "        [ 35.7333],\n",
      "        [167.5853],\n",
      "        [ -0.8078],\n",
      "        [ -0.8078],\n",
      "        [ -0.8078],\n",
      "        [ -0.8078],\n",
      "        [ -0.8078],\n",
      "        [ -0.8078],\n",
      "        [ -0.8078],\n",
      "        [ -0.8078]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[199.2479],\n",
      "        [  0.8078],\n",
      "        [ 20.1613],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  9.2393],\n",
      "        [ 20.0456],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  5.8840],\n",
      "        [  0.8078],\n",
      "        [  9.8012],\n",
      "        [  3.1362],\n",
      "        [  2.4108],\n",
      "        [  0.5223],\n",
      "        [  1.8998],\n",
      "        [ 13.8078],\n",
      "        [ 35.7333],\n",
      "        [167.5853],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  0.8078],\n",
      "        [  0.8078]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2603.8933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[198.8533],\n",
      "        [  0.7864],\n",
      "        [ 20.2268],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  9.6736],\n",
      "        [ 20.9527],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  5.7484],\n",
      "        [  0.7864],\n",
      "        [  9.8080],\n",
      "        [  2.8725],\n",
      "        [  2.4111],\n",
      "        [  0.7716],\n",
      "        [  2.0654],\n",
      "        [ 13.7864],\n",
      "        [ 35.3027],\n",
      "        [167.8710],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.5218241214752197\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 20\n",
      "剩餘X 資料 torch.Size([183, 10])\n",
      "剩餘Y 資料 torch.Size([183, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.6184934377670288, 7)\n",
      "The second_loss value of k: (0.6184934377670288, 9)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引7，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([28, 1])\n",
      "<<預測值>>\n",
      "tensor([[119.1467],\n",
      "        [ -0.7864],\n",
      "        [305.5432],\n",
      "        [ -0.7864],\n",
      "        [ -0.7864],\n",
      "        [  6.5864],\n",
      "        [ 21.9527],\n",
      "        [ -0.7864],\n",
      "        [ -0.7864],\n",
      "        [ 10.7484],\n",
      "        [ -0.7864],\n",
      "        [  9.8080],\n",
      "        [223.1275],\n",
      "        [ 84.9789],\n",
      "        [  0.7716],\n",
      "        [  2.0654],\n",
      "        [ -0.7864],\n",
      "        [ 35.3027],\n",
      "        [167.8710],\n",
      "        [ -0.7864],\n",
      "        [ -0.7864],\n",
      "        [ -0.7864],\n",
      "        [ -0.7864],\n",
      "        [ -0.7864],\n",
      "        [ -0.7864],\n",
      "        [ -0.7864],\n",
      "        [ -0.7864],\n",
      "        [ -0.7864]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[198.8533],\n",
      "        [  0.7864],\n",
      "        [ 20.2268],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  9.6736],\n",
      "        [ 20.9527],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  5.7484],\n",
      "        [  0.7864],\n",
      "        [  9.8080],\n",
      "        [  2.8725],\n",
      "        [  2.4111],\n",
      "        [  0.7716],\n",
      "        [  2.0654],\n",
      "        [ 13.7864],\n",
      "        [ 35.3027],\n",
      "        [167.8710],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864],\n",
      "        [  0.7864]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2509.2434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[198.6914],\n",
      "        [  0.7653],\n",
      "        [ 20.2070],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [ 10.2104],\n",
      "        [ 21.8743],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  5.8587],\n",
      "        [  0.7653],\n",
      "        [  8.8632],\n",
      "        [  2.8576],\n",
      "        [  2.4181],\n",
      "        [  0.9245],\n",
      "        [  0.5063],\n",
      "        [ 13.7653],\n",
      "        [ 35.2478],\n",
      "        [167.8753],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.808058977127075\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 21\n",
      "剩餘X 資料 torch.Size([182, 10])\n",
      "剩餘Y 資料 torch.Size([182, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.5857047438621521, 8)\n",
      "The second_loss value of k: (0.5857047438621521, 11)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引8，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([29, 1])\n",
      "<<預測值>>\n",
      "tensor([[119.3086],\n",
      "        [ -0.7653],\n",
      "        [305.5630],\n",
      "        [ -0.7653],\n",
      "        [ -0.7653],\n",
      "        [  6.0496],\n",
      "        [ 22.8743],\n",
      "        [ -0.7653],\n",
      "        [ -0.7653],\n",
      "        [ 10.8587],\n",
      "        [ -0.7653],\n",
      "        [  8.8632],\n",
      "        [223.1424],\n",
      "        [ 84.9719],\n",
      "        [  0.9245],\n",
      "        [  0.5063],\n",
      "        [ -0.7653],\n",
      "        [ 35.2478],\n",
      "        [167.8753],\n",
      "        [ -0.7653],\n",
      "        [ -0.7653],\n",
      "        [ -0.7653],\n",
      "        [ -0.7653],\n",
      "        [ -0.7653],\n",
      "        [ -0.7653],\n",
      "        [ -0.7653],\n",
      "        [ -0.7653],\n",
      "        [ -0.7653],\n",
      "        [ -0.7653]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[198.6914],\n",
      "        [  0.7653],\n",
      "        [ 20.2070],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [ 10.2104],\n",
      "        [ 21.8743],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  5.8587],\n",
      "        [  0.7653],\n",
      "        [  8.8632],\n",
      "        [  2.8576],\n",
      "        [  2.4181],\n",
      "        [  0.9245],\n",
      "        [  0.5063],\n",
      "        [ 13.7653],\n",
      "        [ 35.2478],\n",
      "        [167.8753],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653],\n",
      "        [  0.7653]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2421.4043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[198.2930],\n",
      "        [  0.7424],\n",
      "        [ 19.6396],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [ 10.6638],\n",
      "        [ 22.8974],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  5.4757],\n",
      "        [  0.7424],\n",
      "        [  9.4465],\n",
      "        [  2.8085],\n",
      "        [  2.5107],\n",
      "        [  0.6325],\n",
      "        [  1.6855],\n",
      "        [ 13.7424],\n",
      "        [ 35.0049],\n",
      "        [168.1411],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.09414005279541\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 22\n",
      "剩餘X 資料 torch.Size([181, 10])\n",
      "剩餘Y 資料 torch.Size([181, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.55110764503479, 10)\n",
      "The second_loss value of k: (0.55110764503479, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引10，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([30, 1])\n",
      "<<預測值>>\n",
      "tensor([[119.7070],\n",
      "        [ -0.7424],\n",
      "        [306.1304],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424],\n",
      "        [  5.5962],\n",
      "        [ 23.8974],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424],\n",
      "        [ 10.4757],\n",
      "        [ -0.7424],\n",
      "        [  9.4465],\n",
      "        [223.1915],\n",
      "        [ 84.8793],\n",
      "        [  0.6325],\n",
      "        [  1.6855],\n",
      "        [ -0.7424],\n",
      "        [ 35.0049],\n",
      "        [168.1411],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424],\n",
      "        [ -0.7424]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[198.2930],\n",
      "        [  0.7424],\n",
      "        [ 19.6396],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [ 10.6638],\n",
      "        [ 22.8974],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  5.4757],\n",
      "        [  0.7424],\n",
      "        [  9.4465],\n",
      "        [  2.8085],\n",
      "        [  2.5107],\n",
      "        [  0.6325],\n",
      "        [  1.6855],\n",
      "        [ 13.7424],\n",
      "        [ 35.0049],\n",
      "        [168.1411],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424],\n",
      "        [  0.7424]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2339.1831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[198.2139],\n",
      "        [  0.7245],\n",
      "        [ 20.2221],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [ 11.2348],\n",
      "        [ 23.7155],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  5.6692],\n",
      "        [  0.7245],\n",
      "        [  9.7661],\n",
      "        [  2.6614],\n",
      "        [  2.4559],\n",
      "        [  0.8045],\n",
      "        [  1.9192],\n",
      "        [ 13.7245],\n",
      "        [ 34.3549],\n",
      "        [168.0173],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.382655382156372\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 23\n",
      "剩餘X 資料 torch.Size([180, 10])\n",
      "剩餘Y 資料 torch.Size([180, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.5248280763626099, 11)\n",
      "The second_loss value of k: (0.5248280763626099, 14)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引11，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([31, 1])\n",
      "<<預測值>>\n",
      "tensor([[119.7861],\n",
      "        [ -0.7245],\n",
      "        [305.5479],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [  5.0252],\n",
      "        [ 24.7155],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [ 10.6692],\n",
      "        [ -0.7245],\n",
      "        [  9.7661],\n",
      "        [223.3386],\n",
      "        [ 84.9341],\n",
      "        [  0.8045],\n",
      "        [  1.9192],\n",
      "        [ -0.7245],\n",
      "        [ 34.3549],\n",
      "        [168.0173],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245],\n",
      "        [ -0.7245]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[198.2139],\n",
      "        [  0.7245],\n",
      "        [ 20.2221],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [ 11.2348],\n",
      "        [ 23.7155],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  5.6692],\n",
      "        [  0.7245],\n",
      "        [  9.7661],\n",
      "        [  2.6614],\n",
      "        [  2.4559],\n",
      "        [  0.8045],\n",
      "        [  1.9192],\n",
      "        [ 13.7245],\n",
      "        [ 34.3549],\n",
      "        [168.0173],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245],\n",
      "        [  0.7245]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2262.5532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[197.9585],\n",
      "        [  0.7044],\n",
      "        [ 20.1044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [ 11.6828],\n",
      "        [ 24.6273],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  5.3723],\n",
      "        [  0.7044],\n",
      "        [  9.9429],\n",
      "        [  2.9050],\n",
      "        [  2.6345],\n",
      "        [  0.6358],\n",
      "        [  0.4745],\n",
      "        [ 13.7044],\n",
      "        [ 34.0492],\n",
      "        [168.1416],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.670234203338623\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 24\n",
      "剩餘X 資料 torch.Size([179, 10])\n",
      "剩餘Y 資料 torch.Size([179, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.49624165892601013, 13)\n",
      "The second_loss value of k: (0.49624165892601013, 16)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引13，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([32, 1])\n",
      "<<預測值>>\n",
      "tensor([[120.0415],\n",
      "        [ -0.7044],\n",
      "        [305.6656],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [  4.5772],\n",
      "        [ 25.6273],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ 10.3723],\n",
      "        [ -0.7044],\n",
      "        [  9.9429],\n",
      "        [223.0950],\n",
      "        [ 84.7555],\n",
      "        [  0.6358],\n",
      "        [  0.4745],\n",
      "        [ -0.7044],\n",
      "        [ 34.0492],\n",
      "        [168.1416],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044],\n",
      "        [ -0.7044]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[197.9585],\n",
      "        [  0.7044],\n",
      "        [ 20.1044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [ 11.6828],\n",
      "        [ 24.6273],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  5.3723],\n",
      "        [  0.7044],\n",
      "        [  9.9429],\n",
      "        [  2.9050],\n",
      "        [  2.6345],\n",
      "        [  0.6358],\n",
      "        [  0.4745],\n",
      "        [ 13.7044],\n",
      "        [ 34.0492],\n",
      "        [168.1416],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044],\n",
      "        [  0.7044]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2190.8330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[197.6132],\n",
      "        [  0.4561],\n",
      "        [ 20.4001],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [ 12.0383],\n",
      "        [ 25.5112],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  5.6916],\n",
      "        [  0.6853],\n",
      "        [  8.9781],\n",
      "        [  2.9508],\n",
      "        [  2.6003],\n",
      "        [  0.4077],\n",
      "        [  0.6350],\n",
      "        [ 13.6853],\n",
      "        [ 33.9381],\n",
      "        [168.3343],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.956515312194824\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 25\n",
      "剩餘X 資料 torch.Size([178, 10])\n",
      "剩餘Y 資料 torch.Size([178, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.46961501240730286, 15)\n",
      "The second_loss value of k: (0.46961501240730286, 16)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引15，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([33, 1])\n",
      "<<預測值>>\n",
      "tensor([[120.3868],\n",
      "        [ -0.4561],\n",
      "        [305.3699],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [  4.2217],\n",
      "        [ 26.5112],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ 10.6916],\n",
      "        [ -0.6853],\n",
      "        [  8.9781],\n",
      "        [223.0492],\n",
      "        [ 84.7896],\n",
      "        [  0.4077],\n",
      "        [  0.6350],\n",
      "        [ -0.6853],\n",
      "        [ 33.9381],\n",
      "        [168.3343],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853],\n",
      "        [ -0.6853]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[197.6132],\n",
      "        [  0.4561],\n",
      "        [ 20.4001],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [ 12.0383],\n",
      "        [ 25.5112],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  5.6916],\n",
      "        [  0.6853],\n",
      "        [  8.9781],\n",
      "        [  2.9508],\n",
      "        [  2.6003],\n",
      "        [  0.4077],\n",
      "        [  0.6350],\n",
      "        [ 13.6853],\n",
      "        [ 33.9381],\n",
      "        [168.3343],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853],\n",
      "        [  0.6853]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2123.5317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 74\n",
      "Number of shrink: 26\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[197.4004],\n",
      "        [  0.1984],\n",
      "        [ 20.4220],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [ 12.4462],\n",
      "        [ 26.3085],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  5.5467],\n",
      "        [  0.6683],\n",
      "        [  9.3878],\n",
      "        [  2.8215],\n",
      "        [  2.5654],\n",
      "        [  0.8460],\n",
      "        [  1.2746],\n",
      "        [ 13.6683],\n",
      "        [ 33.5927],\n",
      "        [168.3963],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683],\n",
      "        [  0.6683]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.243555784225464\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 26\n",
      "剩餘X 資料 torch.Size([177, 10])\n",
      "剩餘Y 資料 torch.Size([177, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.012878785841166973, 15)\n",
      "The second_loss value of k: (0.44663649797439575, 16)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引15，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([34, 1])\n",
      "<<預測值>>\n",
      "tensor([[   120.5996],\n",
      "        [     0.1984],\n",
      "        [   305.3480],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [     3.8138],\n",
      "        [    27.3085],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    10.5467],\n",
      "        [    -0.6683],\n",
      "        [     9.3878],\n",
      "        [   223.1785],\n",
      "        [    84.8246],\n",
      "        [     0.8460],\n",
      "        [     1.2746],\n",
      "        [    -0.6683],\n",
      "        [    33.5927],\n",
      "        [   168.3963],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.6683],\n",
      "        [    -0.1135]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  197.4004],\n",
      "        [    0.1984],\n",
      "        [   20.4220],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [   12.4462],\n",
      "        [   26.3085],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    5.5467],\n",
      "        [    0.6683],\n",
      "        [    9.3878],\n",
      "        [    2.8215],\n",
      "        [    2.5654],\n",
      "        [    0.8460],\n",
      "        [    1.2746],\n",
      "        [   13.6683],\n",
      "        [   33.5927],\n",
      "        [  168.3963],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.6683],\n",
      "        [    0.1135]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2060.2339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[197.4160],\n",
      "        [  0.6120],\n",
      "        [ 20.1306],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [ 12.8981],\n",
      "        [ 26.9973],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  5.3707],\n",
      "        [  0.6536],\n",
      "        [  9.0917],\n",
      "        [  2.7342],\n",
      "        [  2.4920],\n",
      "        [  0.6846],\n",
      "        [  0.6865],\n",
      "        [ 13.6536],\n",
      "        [ 33.6727],\n",
      "        [168.2302],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.5617]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.528030633926392\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 27\n",
      "剩餘X 資料 torch.Size([176, 10])\n",
      "剩餘Y 資料 torch.Size([176, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.42720431089401245, 15)\n",
      "The second_loss value of k: (0.42720431089401245, 16)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引15，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([35, 1])\n",
      "<<預測值>>\n",
      "tensor([[120.5840],\n",
      "        [  0.6120],\n",
      "        [305.6394],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [  3.3619],\n",
      "        [ 27.9973],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ 10.3707],\n",
      "        [ -0.6536],\n",
      "        [  9.0917],\n",
      "        [223.2658],\n",
      "        [ 84.8980],\n",
      "        [  0.6846],\n",
      "        [  0.6865],\n",
      "        [ -0.6536],\n",
      "        [ 33.6727],\n",
      "        [168.2302],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [ -0.6536],\n",
      "        [  0.5617],\n",
      "        [ -0.6536]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[197.4160],\n",
      "        [  0.6120],\n",
      "        [ 20.1306],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [ 12.8981],\n",
      "        [ 26.9973],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  5.3707],\n",
      "        [  0.6536],\n",
      "        [  9.0917],\n",
      "        [  2.7342],\n",
      "        [  2.4920],\n",
      "        [  0.6846],\n",
      "        [  0.6865],\n",
      "        [ 13.6536],\n",
      "        [ 33.6727],\n",
      "        [168.2302],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.6536],\n",
      "        [  0.5617],\n",
      "        [  0.6536]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2000.8732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[197.2435],\n",
      "        [  1.0392],\n",
      "        [ 20.4561],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [ 13.2006],\n",
      "        [ 27.5396],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  5.3051],\n",
      "        [  0.6416],\n",
      "        [  9.0985],\n",
      "        [  2.8193],\n",
      "        [  2.4934],\n",
      "        [  0.7938],\n",
      "        [  1.1727],\n",
      "        [ 13.6416],\n",
      "        [ 33.2801],\n",
      "        [168.3055],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  0.6416],\n",
      "        [  1.1460],\n",
      "        [  0.6416]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.812285900115967\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 28\n",
      "剩餘X 資料 torch.Size([175, 10])\n",
      "剩餘Y 資料 torch.Size([175, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.03222820535302162, 135)\n",
      "The second_loss value of k: (0.41167888045310974, 15)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引135，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([36, 1])\n",
      "<<預測值>>\n",
      "tensor([[   120.7565],\n",
      "        [     1.0392],\n",
      "        [   305.3139],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [     3.0594],\n",
      "        [    28.5396],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    10.3051],\n",
      "        [    -0.6416],\n",
      "        [     9.0985],\n",
      "        [   223.1807],\n",
      "        [    84.8966],\n",
      "        [     0.7938],\n",
      "        [     1.1727],\n",
      "        [    -0.6416],\n",
      "        [    33.2801],\n",
      "        [   168.3055],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [    -0.6416],\n",
      "        [     1.1460],\n",
      "        [    -0.6416],\n",
      "        [    -0.1795]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  197.2435],\n",
      "        [    1.0392],\n",
      "        [   20.4561],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [   13.2006],\n",
      "        [   27.5396],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    5.3051],\n",
      "        [    0.6416],\n",
      "        [    9.0985],\n",
      "        [    2.8193],\n",
      "        [    2.4934],\n",
      "        [    0.7938],\n",
      "        [    1.1727],\n",
      "        [   13.6416],\n",
      "        [   33.2801],\n",
      "        [  168.3055],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    0.6416],\n",
      "        [    1.1460],\n",
      "        [    0.6416],\n",
      "        [    0.1795]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1944.8416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 74\n",
      "Number of shrink: 26\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.9815],\n",
      "        [  1.2647],\n",
      "        [ 20.1230],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [ 13.4861],\n",
      "        [ 27.9766],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  5.2787],\n",
      "        [  0.6300],\n",
      "        [  9.1807],\n",
      "        [  2.8066],\n",
      "        [  2.4554],\n",
      "        [  0.7919],\n",
      "        [  0.9638],\n",
      "        [ 13.6300],\n",
      "        [ 32.9639],\n",
      "        [168.5818],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  1.5591],\n",
      "        [  0.6300],\n",
      "        [  0.2653]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.098989009857178\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 29\n",
      "剩餘X 資料 torch.Size([174, 10])\n",
      "剩餘Y 資料 torch.Size([174, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.39685311913490295, 15)\n",
      "The second_loss value of k: (0.39685311913490295, 16)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引15，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([37, 1])\n",
      "<<預測值>>\n",
      "tensor([[   121.0185],\n",
      "        [     1.2647],\n",
      "        [   305.6470],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [     2.7739],\n",
      "        [    28.9766],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    10.2787],\n",
      "        [    -0.6300],\n",
      "        [     9.1807],\n",
      "        [   223.1934],\n",
      "        [    84.9346],\n",
      "        [     0.7919],\n",
      "        [     0.9638],\n",
      "        [    -0.6300],\n",
      "        [    32.9639],\n",
      "        [   168.5818],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [    -0.6300],\n",
      "        [     1.5591],\n",
      "        [    -0.6300],\n",
      "        [     0.2653],\n",
      "        [    -0.6300]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.9815],\n",
      "        [  1.2647],\n",
      "        [ 20.1230],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [ 13.4861],\n",
      "        [ 27.9766],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  5.2787],\n",
      "        [  0.6300],\n",
      "        [  9.1807],\n",
      "        [  2.8066],\n",
      "        [  2.4554],\n",
      "        [  0.7919],\n",
      "        [  0.9638],\n",
      "        [ 13.6300],\n",
      "        [ 32.9639],\n",
      "        [168.5818],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  0.6300],\n",
      "        [  1.5591],\n",
      "        [  0.6300],\n",
      "        [  0.2653],\n",
      "        [  0.6300]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1891.9866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 74\n",
      "Number of shrink: 26\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.9829],\n",
      "        [  1.4316],\n",
      "        [ 20.1274],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [ 13.9415],\n",
      "        [ 28.2993],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  5.3532],\n",
      "        [  0.6202],\n",
      "        [  8.9057],\n",
      "        [  2.8442],\n",
      "        [  2.4348],\n",
      "        [  0.5878],\n",
      "        [  1.7094],\n",
      "        [ 13.6202],\n",
      "        [ 32.5372],\n",
      "        [168.5499],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  1.7093],\n",
      "        [  0.6202],\n",
      "        [  0.5204],\n",
      "        [  0.6202]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.385836362838745\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 30\n",
      "剩餘X 資料 torch.Size([173, 10])\n",
      "剩餘Y 資料 torch.Size([173, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3846098780632019, 15)\n",
      "The second_loss value of k: (0.3846098780632019, 17)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引15，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([38, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.0171],\n",
      "        [  1.4316],\n",
      "        [305.6426],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [  2.3185],\n",
      "        [ 29.2993],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ 10.3532],\n",
      "        [ -0.6202],\n",
      "        [  8.9057],\n",
      "        [223.1558],\n",
      "        [ 84.9552],\n",
      "        [  0.5878],\n",
      "        [  1.7094],\n",
      "        [ -0.6202],\n",
      "        [ 32.5372],\n",
      "        [168.5499],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202],\n",
      "        [  1.7093],\n",
      "        [ -0.6202],\n",
      "        [  0.5204],\n",
      "        [ -0.6202],\n",
      "        [ -0.6202]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.9829],\n",
      "        [  1.4316],\n",
      "        [ 20.1274],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [ 13.9415],\n",
      "        [ 28.2993],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  5.3532],\n",
      "        [  0.6202],\n",
      "        [  8.9057],\n",
      "        [  2.8442],\n",
      "        [  2.4348],\n",
      "        [  0.5878],\n",
      "        [  1.7094],\n",
      "        [ 13.6202],\n",
      "        [ 32.5372],\n",
      "        [168.5499],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  0.6202],\n",
      "        [  1.7093],\n",
      "        [  0.6202],\n",
      "        [  0.5204],\n",
      "        [  0.6202],\n",
      "        [  0.6202]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1841.9684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.8963],\n",
      "        [  1.5219],\n",
      "        [ 20.3339],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [ 14.2338],\n",
      "        [ 28.5697],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  5.3166],\n",
      "        [  0.6124],\n",
      "        [  8.9472],\n",
      "        [  2.8401],\n",
      "        [  2.4005],\n",
      "        [  0.6325],\n",
      "        [  1.4228],\n",
      "        [ 13.6124],\n",
      "        [ 32.0571],\n",
      "        [168.6281],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  1.9410],\n",
      "        [  0.6124],\n",
      "        [  0.7468],\n",
      "        [  0.6124],\n",
      "        [  0.6124]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.668479681015015\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 31\n",
      "剩餘X 資料 torch.Size([172, 10])\n",
      "剩餘Y 資料 torch.Size([172, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.375089168548584, 16)\n",
      "The second_loss value of k: (0.375089168548584, 19)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引16，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([39, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.1037],\n",
      "        [  1.5219],\n",
      "        [305.4361],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [  2.0262],\n",
      "        [ 29.5697],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ 10.3166],\n",
      "        [ -0.6124],\n",
      "        [  8.9472],\n",
      "        [223.1599],\n",
      "        [ 84.9895],\n",
      "        [  0.6325],\n",
      "        [  1.4228],\n",
      "        [ -0.6124],\n",
      "        [ 32.0571],\n",
      "        [168.6281],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [  1.9410],\n",
      "        [ -0.6124],\n",
      "        [  0.7468],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124],\n",
      "        [ -0.6124]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.8963],\n",
      "        [  1.5219],\n",
      "        [ 20.3339],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [ 14.2338],\n",
      "        [ 28.5697],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  5.3166],\n",
      "        [  0.6124],\n",
      "        [  8.9472],\n",
      "        [  2.8401],\n",
      "        [  2.4005],\n",
      "        [  0.6325],\n",
      "        [  1.4228],\n",
      "        [ 13.6124],\n",
      "        [ 32.0571],\n",
      "        [168.6281],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  1.9410],\n",
      "        [  0.6124],\n",
      "        [  0.7468],\n",
      "        [  0.6124],\n",
      "        [  0.6124],\n",
      "        [  0.6124]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1794.5813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 74\n",
      "Number of shrink: 26\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.7146],\n",
      "        [  1.6772],\n",
      "        [ 19.8922],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [ 14.4651],\n",
      "        [ 28.8419],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  5.3660],\n",
      "        [  0.6042],\n",
      "        [  8.7432],\n",
      "        [  2.7819],\n",
      "        [  2.3599],\n",
      "        [  0.6399],\n",
      "        [  1.8505],\n",
      "        [ 13.6042],\n",
      "        [ 31.9165],\n",
      "        [168.8430],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  2.0752],\n",
      "        [  0.6042],\n",
      "        [  0.9845],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.949841499328613\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 32\n",
      "剩餘X 資料 torch.Size([171, 10])\n",
      "剩餘Y 資料 torch.Size([171, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3650401532649994, 18)\n",
      "The second_loss value of k: (0.3650401532649994, 20)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引18，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([40, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.2854],\n",
      "        [  1.6772],\n",
      "        [305.8778],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [  1.7949],\n",
      "        [ 29.8419],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ 10.3660],\n",
      "        [ -0.6042],\n",
      "        [  8.7432],\n",
      "        [223.2181],\n",
      "        [ 85.0301],\n",
      "        [  0.6399],\n",
      "        [  1.8505],\n",
      "        [ -0.6042],\n",
      "        [ 31.9165],\n",
      "        [168.8430],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [  2.0752],\n",
      "        [ -0.6042],\n",
      "        [  0.9845],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042],\n",
      "        [ -0.6042]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.7146],\n",
      "        [  1.6772],\n",
      "        [ 19.8922],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [ 14.4651],\n",
      "        [ 28.8419],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  5.3660],\n",
      "        [  0.6042],\n",
      "        [  8.7432],\n",
      "        [  2.7819],\n",
      "        [  2.3599],\n",
      "        [  0.6399],\n",
      "        [  1.8505],\n",
      "        [ 13.6042],\n",
      "        [ 31.9165],\n",
      "        [168.8430],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  2.0752],\n",
      "        [  0.6042],\n",
      "        [  0.9845],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042],\n",
      "        [  0.6042]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1749.6083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.7686],\n",
      "        [  1.6369],\n",
      "        [ 20.1356],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [ 14.8042],\n",
      "        [ 29.0291],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  5.1826],\n",
      "        [  0.5975],\n",
      "        [  8.5810],\n",
      "        [  2.6950],\n",
      "        [  2.2863],\n",
      "        [  0.5377],\n",
      "        [  1.1544],\n",
      "        [ 13.5975],\n",
      "        [ 31.5057],\n",
      "        [168.7776],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  2.1556],\n",
      "        [  0.5975],\n",
      "        [  1.1091],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.232943058013916\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 33\n",
      "剩餘X 資料 torch.Size([170, 10])\n",
      "剩餘Y 資料 torch.Size([170, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.35700201988220215, 19)\n",
      "The second_loss value of k: (0.35700201988220215, 22)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引19，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([41, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.2313],\n",
      "        [  1.6369],\n",
      "        [305.6344],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [  1.4558],\n",
      "        [ 30.0291],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ 10.1826],\n",
      "        [ -0.5975],\n",
      "        [  8.5810],\n",
      "        [223.3050],\n",
      "        [ 85.1037],\n",
      "        [  0.5377],\n",
      "        [  1.1544],\n",
      "        [ -0.5975],\n",
      "        [ 31.5057],\n",
      "        [168.7776],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [  2.1556],\n",
      "        [ -0.5975],\n",
      "        [  1.1091],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975],\n",
      "        [ -0.5975]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.7686],\n",
      "        [  1.6369],\n",
      "        [ 20.1356],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [ 14.8042],\n",
      "        [ 29.0291],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  5.1826],\n",
      "        [  0.5975],\n",
      "        [  8.5810],\n",
      "        [  2.6950],\n",
      "        [  2.2863],\n",
      "        [  0.5377],\n",
      "        [  1.1544],\n",
      "        [ 13.5975],\n",
      "        [ 31.5057],\n",
      "        [168.7776],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  2.1556],\n",
      "        [  0.5975],\n",
      "        [  1.1091],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975],\n",
      "        [  0.5975]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1706.8448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6736],\n",
      "        [  1.7160],\n",
      "        [ 20.0760],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9475],\n",
      "        [ 29.1727],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2411],\n",
      "        [  0.5920],\n",
      "        [  8.6822],\n",
      "        [  2.7299],\n",
      "        [  2.3148],\n",
      "        [  0.5592],\n",
      "        [  1.2674],\n",
      "        [ 13.5920],\n",
      "        [ 31.2679],\n",
      "        [168.8821],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.3008],\n",
      "        [  0.5920],\n",
      "        [  1.2274],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.515381574630737\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 34\n",
      "剩餘X 資料 torch.Size([169, 10])\n",
      "剩餘Y 資料 torch.Size([169, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.35048234462738037, 21)\n",
      "The second_loss value of k: (0.35048234462738037, 22)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引21，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([42, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3265],\n",
      "        [  1.7160],\n",
      "        [305.6940],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3125],\n",
      "        [ 30.1727],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2411],\n",
      "        [ -0.5920],\n",
      "        [  8.6822],\n",
      "        [223.2701],\n",
      "        [ 85.0751],\n",
      "        [  0.5592],\n",
      "        [  1.2674],\n",
      "        [ -0.5920],\n",
      "        [ 31.2679],\n",
      "        [168.8821],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.3008],\n",
      "        [ -0.5920],\n",
      "        [  1.2274],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6736],\n",
      "        [  1.7160],\n",
      "        [ 20.0760],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9475],\n",
      "        [ 29.1727],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2411],\n",
      "        [  0.5920],\n",
      "        [  8.6822],\n",
      "        [  2.7299],\n",
      "        [  2.3148],\n",
      "        [  0.5592],\n",
      "        [  1.2674],\n",
      "        [ 13.5920],\n",
      "        [ 31.2679],\n",
      "        [168.8821],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.3008],\n",
      "        [  0.5920],\n",
      "        [  1.2274],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1666.1437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 7\n",
      "Number of shrink: 11\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.6317267417907715\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 35\n",
      "剩餘X 資料 torch.Size([168, 10])\n",
      "剩餘Y 資料 torch.Size([168, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 21)\n",
      "The second_loss value of k: (0.3504432737827301, 22)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引21，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([43, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1627.4022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.7247326374053955\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 36\n",
      "剩餘X 資料 torch.Size([167, 10])\n",
      "剩餘Y 資料 torch.Size([167, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 21)\n",
      "The second_loss value of k: (0.3504432737827301, 29)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引21，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([44, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1590.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.817155122756958\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 37\n",
      "剩餘X 資料 torch.Size([166, 10])\n",
      "剩餘Y 資料 torch.Size([166, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 28)\n",
      "The second_loss value of k: (0.3504432737827301, 29)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引28，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([45, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1555.0889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.909012794494629\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 38\n",
      "剩餘X 資料 torch.Size([165, 10])\n",
      "剩餘Y 資料 torch.Size([165, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 28)\n",
      "The second_loss value of k: (0.3504432737827301, 29)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引28，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([46, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1521.2903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.0021538734436035\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 39\n",
      "剩餘X 資料 torch.Size([164, 10])\n",
      "剩餘Y 資料 torch.Size([164, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 28)\n",
      "The second_loss value of k: (0.3504432737827301, 34)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引28，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([47, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1488.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.094155550003052\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 40\n",
      "剩餘X 資料 torch.Size([163, 10])\n",
      "剩餘Y 資料 torch.Size([163, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 33)\n",
      "The second_loss value of k: (0.3504432737827301, 39)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引33，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([48, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1457.9177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.186612367630005\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 41\n",
      "剩餘X 資料 torch.Size([162, 10])\n",
      "剩餘Y 資料 torch.Size([162, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 38)\n",
      "The second_loss value of k: (0.3504432737827301, 39)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引38，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([49, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1428.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.278637409210205\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 42\n",
      "剩餘X 資料 torch.Size([161, 10])\n",
      "剩餘Y 資料 torch.Size([161, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 38)\n",
      "The second_loss value of k: (0.3504432737827301, 39)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引38，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([50, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1399.6150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.369648456573486\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 43\n",
      "剩餘X 資料 torch.Size([160, 10])\n",
      "剩餘Y 資料 torch.Size([160, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 38)\n",
      "The second_loss value of k: (0.3504432737827301, 43)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引38，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([51, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1372.1785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.461756467819214\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 44\n",
      "剩餘X 資料 torch.Size([159, 10])\n",
      "剩餘Y 資料 torch.Size([159, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 42)\n",
      "The second_loss value of k: (0.3504432737827301, 45)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引42，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([52, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1345.7972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.553243160247803\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 45\n",
      "剩餘X 資料 torch.Size([158, 10])\n",
      "剩餘Y 資料 torch.Size([158, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 44)\n",
      "The second_loss value of k: (0.3504432737827301, 45)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引44，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([53, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1320.4113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.644094705581665\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 46\n",
      "剩餘X 資料 torch.Size([157, 10])\n",
      "剩餘Y 資料 torch.Size([157, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 44)\n",
      "The second_loss value of k: (0.3504432737827301, 51)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引44，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([54, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1295.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.734388589859009\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 47\n",
      "剩餘X 資料 torch.Size([156, 10])\n",
      "剩餘Y 資料 torch.Size([156, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 50)\n",
      "The second_loss value of k: (0.3504432737827301, 54)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引50，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([55, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1272.4091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.82518744468689\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 48\n",
      "剩餘X 資料 torch.Size([155, 10])\n",
      "剩餘Y 資料 torch.Size([155, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 53)\n",
      "The second_loss value of k: (0.3504432737827301, 57)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引53，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([56, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1249.6938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.916638612747192\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 49\n",
      "剩餘X 資料 torch.Size([154, 10])\n",
      "剩餘Y 資料 torch.Size([154, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 56)\n",
      "The second_loss value of k: (0.3504432737827301, 57)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引56，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([57, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1227.7755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.005708456039429\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 50\n",
      "剩餘X 資料 torch.Size([153, 10])\n",
      "剩餘Y 資料 torch.Size([153, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 56)\n",
      "The second_loss value of k: (0.3504432737827301, 68)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引56，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([58, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1206.6130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.0954008102417\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 51\n",
      "剩餘X 資料 torch.Size([152, 10])\n",
      "剩餘Y 資料 torch.Size([152, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 67)\n",
      "The second_loss value of k: (0.3504432737827301, 68)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引67，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([59, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1186.1678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.183778047561646\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 52\n",
      "剩餘X 資料 torch.Size([151, 10])\n",
      "剩餘Y 資料 torch.Size([151, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 67)\n",
      "The second_loss value of k: (0.3504432737827301, 70)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引67，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([60, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1166.4042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.286107778549194\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 53\n",
      "剩餘X 資料 torch.Size([150, 10])\n",
      "剩餘Y 資料 torch.Size([150, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 69)\n",
      "The second_loss value of k: (0.3504432737827301, 77)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引69，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([61, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1147.2886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.424729824066162\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 54\n",
      "剩餘X 資料 torch.Size([149, 10])\n",
      "剩餘Y 資料 torch.Size([149, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 76)\n",
      "The second_loss value of k: (0.3504432737827301, 80)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引76，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([62, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1128.7896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.563688039779663\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 55\n",
      "剩餘X 資料 torch.Size([148, 10])\n",
      "剩餘Y 資料 torch.Size([148, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 79)\n",
      "The second_loss value of k: (0.3504432737827301, 82)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引79，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([63, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1110.8779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.697412014007568\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 56\n",
      "剩餘X 資料 torch.Size([147, 10])\n",
      "剩餘Y 資料 torch.Size([147, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 81)\n",
      "The second_loss value of k: (0.3504432737827301, 85)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引81，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([64, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1093.5259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.79219913482666\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 57\n",
      "剩餘X 資料 torch.Size([146, 10])\n",
      "剩餘Y 資料 torch.Size([146, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 84)\n",
      "The second_loss value of k: (0.3504432737827301, 85)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引84，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([65, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1076.7078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.883519649505615\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 58\n",
      "剩餘X 資料 torch.Size([145, 10])\n",
      "剩餘Y 資料 torch.Size([145, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 84)\n",
      "The second_loss value of k: (0.3504432737827301, 87)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引84，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([66, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1060.3994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.973976612091064\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 59\n",
      "剩餘X 資料 torch.Size([144, 10])\n",
      "剩餘Y 資料 torch.Size([144, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 86)\n",
      "The second_loss value of k: (0.3504432737827301, 93)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引86，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([67, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1044.5776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.064276456832886\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 60\n",
      "剩餘X 資料 torch.Size([143, 10])\n",
      "剩餘Y 資料 torch.Size([143, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504432737827301, 92)\n",
      "The second_loss value of k: (0.3504432737827301, 96)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引92，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([68, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3444],\n",
      "        [  1.7325],\n",
      "        [305.7045],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3250],\n",
      "        [ 30.1744],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2604],\n",
      "        [ -0.5920],\n",
      "        [  8.6472],\n",
      "        [223.2879],\n",
      "        [ 85.0881],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ -0.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2911],\n",
      "        [ -0.5920],\n",
      "        [  1.2315],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6556],\n",
      "        [  1.7325],\n",
      "        [ 20.0655],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9350],\n",
      "        [ 29.1744],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2604],\n",
      "        [  0.5920],\n",
      "        [  8.6472],\n",
      "        [  2.7121],\n",
      "        [  2.3019],\n",
      "        [  0.5982],\n",
      "        [  1.3930],\n",
      "        [ 13.5920],\n",
      "        [ 31.2852],\n",
      "        [168.9020],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2911],\n",
      "        [  0.5920],\n",
      "        [  1.2315],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1029.2216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 8\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6554],\n",
      "        [  1.7359],\n",
      "        [ 20.0627],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9348],\n",
      "        [ 29.1747],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2581],\n",
      "        [  0.5920],\n",
      "        [  8.6374],\n",
      "        [  2.7142],\n",
      "        [  2.3018],\n",
      "        [  0.6036],\n",
      "        [  1.4280],\n",
      "        [ 13.5920],\n",
      "        [ 31.2893],\n",
      "        [168.9021],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2884],\n",
      "        [  0.5920],\n",
      "        [  1.2326],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.159674406051636\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 61\n",
      "剩餘X 資料 torch.Size([142, 10])\n",
      "剩餘Y 資料 torch.Size([142, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504323959350586, 95)\n",
      "The second_loss value of k: (0.3504323959350586, 101)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引95，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([69, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3446],\n",
      "        [  1.7359],\n",
      "        [305.7073],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  1.3252],\n",
      "        [ 30.1747],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ 10.2581],\n",
      "        [ -0.5920],\n",
      "        [  8.6374],\n",
      "        [223.2858],\n",
      "        [ 85.0882],\n",
      "        [  0.6036],\n",
      "        [  1.4280],\n",
      "        [ -0.5920],\n",
      "        [ 31.2893],\n",
      "        [168.9021],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [  2.2884],\n",
      "        [ -0.5920],\n",
      "        [  1.2326],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920],\n",
      "        [ -0.5920]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6554],\n",
      "        [  1.7359],\n",
      "        [ 20.0627],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [ 14.9348],\n",
      "        [ 29.1747],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  5.2581],\n",
      "        [  0.5920],\n",
      "        [  8.6374],\n",
      "        [  2.7142],\n",
      "        [  2.3018],\n",
      "        [  0.6036],\n",
      "        [  1.4280],\n",
      "        [ 13.5920],\n",
      "        [ 31.2893],\n",
      "        [168.9021],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  2.2884],\n",
      "        [  0.5920],\n",
      "        [  1.2326],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920],\n",
      "        [  0.5920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1014.3102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 8\n",
      "Number of shrink: 11\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7377],\n",
      "        [ 20.0848],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9361],\n",
      "        [ 29.1757],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2589],\n",
      "        [  0.5919],\n",
      "        [  8.6085],\n",
      "        [  2.7216],\n",
      "        [  2.3016],\n",
      "        [  0.6194],\n",
      "        [  1.4389],\n",
      "        [ 13.5919],\n",
      "        [ 31.2856],\n",
      "        [168.9006],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2804],\n",
      "        [  0.5919],\n",
      "        [  1.2344],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.273191213607788\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 62\n",
      "剩餘X 資料 torch.Size([141, 10])\n",
      "剩餘Y 資料 torch.Size([141, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3504002094268799, 100)\n",
      "The second_loss value of k: (0.3504002094268799, 105)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引100，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([70, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3443],\n",
      "        [  1.7377],\n",
      "        [305.6852],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  1.3239],\n",
      "        [ 30.1757],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ 10.2589],\n",
      "        [ -0.5919],\n",
      "        [  8.6085],\n",
      "        [223.2784],\n",
      "        [ 85.0884],\n",
      "        [  0.6194],\n",
      "        [  1.4389],\n",
      "        [ -0.5919],\n",
      "        [ 31.2856],\n",
      "        [168.9006],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  2.2804],\n",
      "        [ -0.5919],\n",
      "        [  1.2344],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7377],\n",
      "        [ 20.0848],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9361],\n",
      "        [ 29.1757],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2589],\n",
      "        [  0.5919],\n",
      "        [  8.6085],\n",
      "        [  2.7216],\n",
      "        [  2.3016],\n",
      "        [  0.6194],\n",
      "        [  1.4389],\n",
      "        [ 13.5919],\n",
      "        [ 31.2856],\n",
      "        [168.9006],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2804],\n",
      "        [  0.5919],\n",
      "        [  1.2344],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(999.8246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 2\n",
      "Number of shrink: 8\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6563],\n",
      "        [  1.7375],\n",
      "        [ 20.0887],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1758],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2575],\n",
      "        [  0.5919],\n",
      "        [  8.6047],\n",
      "        [  2.7228],\n",
      "        [  2.3016],\n",
      "        [  0.6215],\n",
      "        [  1.4372],\n",
      "        [ 13.5919],\n",
      "        [ 31.2846],\n",
      "        [168.8998],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2793],\n",
      "        [  0.5919],\n",
      "        [  1.2346],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.366475582122803\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 63\n",
      "剩餘X 資料 torch.Size([140, 10])\n",
      "剩餘Y 資料 torch.Size([140, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.35039597749710083, 104)\n",
      "The second_loss value of k: (0.35039597749710083, 123)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引104，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([71, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3437],\n",
      "        [  1.7375],\n",
      "        [305.6813],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  1.3233],\n",
      "        [ 30.1758],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ 10.2575],\n",
      "        [ -0.5919],\n",
      "        [  8.6047],\n",
      "        [223.2772],\n",
      "        [ 85.0884],\n",
      "        [  0.6215],\n",
      "        [  1.4372],\n",
      "        [ -0.5919],\n",
      "        [ 31.2846],\n",
      "        [168.8998],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  2.2793],\n",
      "        [ -0.5919],\n",
      "        [  1.2346],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6563],\n",
      "        [  1.7375],\n",
      "        [ 20.0887],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1758],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2575],\n",
      "        [  0.5919],\n",
      "        [  8.6047],\n",
      "        [  2.7228],\n",
      "        [  2.3016],\n",
      "        [  0.6215],\n",
      "        [  1.4372],\n",
      "        [ 13.5919],\n",
      "        [ 31.2846],\n",
      "        [168.8998],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2793],\n",
      "        [  0.5919],\n",
      "        [  1.2346],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(985.7474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6563],\n",
      "        [  1.7375],\n",
      "        [ 20.0887],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1758],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2575],\n",
      "        [  0.5919],\n",
      "        [  8.6047],\n",
      "        [  2.7228],\n",
      "        [  2.3016],\n",
      "        [  0.6215],\n",
      "        [  1.4372],\n",
      "        [ 13.5919],\n",
      "        [ 31.2846],\n",
      "        [168.8998],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2793],\n",
      "        [  0.5919],\n",
      "        [  1.2346],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.453836917877197\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 64\n",
      "剩餘X 資料 torch.Size([139, 10])\n",
      "剩餘Y 資料 torch.Size([139, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.35039597749710083, 122)\n",
      "The second_loss value of k: (0.35039597749710083, 123)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引122，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([72, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3437],\n",
      "        [  1.7375],\n",
      "        [305.6813],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  1.3233],\n",
      "        [ 30.1758],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ 10.2575],\n",
      "        [ -0.5919],\n",
      "        [  8.6047],\n",
      "        [223.2772],\n",
      "        [ 85.0884],\n",
      "        [  0.6215],\n",
      "        [  1.4372],\n",
      "        [ -0.5919],\n",
      "        [ 31.2846],\n",
      "        [168.8998],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  2.2793],\n",
      "        [ -0.5919],\n",
      "        [  1.2346],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6563],\n",
      "        [  1.7375],\n",
      "        [ 20.0887],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1758],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2575],\n",
      "        [  0.5919],\n",
      "        [  8.6047],\n",
      "        [  2.7228],\n",
      "        [  2.3016],\n",
      "        [  0.6215],\n",
      "        [  1.4372],\n",
      "        [ 13.5919],\n",
      "        [ 31.2846],\n",
      "        [168.8998],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2793],\n",
      "        [  0.5919],\n",
      "        [  1.2346],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(972.0614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6561],\n",
      "        [  1.7377],\n",
      "        [ 20.0886],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9365],\n",
      "        [ 29.1758],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2577],\n",
      "        [  0.5919],\n",
      "        [  8.6043],\n",
      "        [  2.7229],\n",
      "        [  2.3015],\n",
      "        [  0.6217],\n",
      "        [  1.4387],\n",
      "        [ 13.5919],\n",
      "        [ 31.2848],\n",
      "        [168.9001],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2792],\n",
      "        [  0.5919],\n",
      "        [  1.2346],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.544293880462646\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 65\n",
      "剩餘X 資料 torch.Size([138, 10])\n",
      "剩餘Y 資料 torch.Size([138, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.3503955602645874, 122)\n",
      "The second_loss value of k: (0.3503955602645874, 131)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引122，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([73, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3439],\n",
      "        [  1.7377],\n",
      "        [305.6814],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  1.3235],\n",
      "        [ 30.1758],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ 10.2577],\n",
      "        [ -0.5919],\n",
      "        [  8.6043],\n",
      "        [223.2771],\n",
      "        [ 85.0885],\n",
      "        [  0.6217],\n",
      "        [  1.4387],\n",
      "        [ -0.5919],\n",
      "        [ 31.2848],\n",
      "        [168.9001],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  2.2792],\n",
      "        [ -0.5919],\n",
      "        [  1.2346],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6561],\n",
      "        [  1.7377],\n",
      "        [ 20.0886],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9365],\n",
      "        [ 29.1758],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2577],\n",
      "        [  0.5919],\n",
      "        [  8.6043],\n",
      "        [  2.7229],\n",
      "        [  2.3015],\n",
      "        [  0.6217],\n",
      "        [  1.4387],\n",
      "        [ 13.5919],\n",
      "        [ 31.2848],\n",
      "        [168.9001],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2792],\n",
      "        [  0.5919],\n",
      "        [  1.2346],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(958.7503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 7\n",
      "Number of shrink: 11\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7384],\n",
      "        [ 20.0903],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1763],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2578],\n",
      "        [  0.5919],\n",
      "        [  8.6044],\n",
      "        [  2.7245],\n",
      "        [  2.3014],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ 13.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2797],\n",
      "        [  0.5919],\n",
      "        [  1.2352],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.65570878982544\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 66\n",
      "剩餘X 資料 torch.Size([137, 10])\n",
      "剩餘Y 資料 torch.Size([137, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.35038504004478455, 130)\n",
      "The second_loss value of k: (0.35038504004478455, 132)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引130，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([74, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3443],\n",
      "        [  1.7384],\n",
      "        [305.6797],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  1.3233],\n",
      "        [ 30.1763],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ 10.2578],\n",
      "        [ -0.5919],\n",
      "        [  8.6044],\n",
      "        [223.2755],\n",
      "        [ 85.0886],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ -0.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  2.2797],\n",
      "        [ -0.5919],\n",
      "        [  1.2352],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7384],\n",
      "        [ 20.0903],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1763],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2578],\n",
      "        [  0.5919],\n",
      "        [  8.6044],\n",
      "        [  2.7245],\n",
      "        [  2.3014],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ 13.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2797],\n",
      "        [  0.5919],\n",
      "        [  1.2352],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(945.7987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7384],\n",
      "        [ 20.0903],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1763],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2578],\n",
      "        [  0.5919],\n",
      "        [  8.6044],\n",
      "        [  2.7245],\n",
      "        [  2.3014],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ 13.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2797],\n",
      "        [  0.5919],\n",
      "        [  1.2352],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.742667436599731\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 67\n",
      "剩餘X 資料 torch.Size([136, 10])\n",
      "剩餘Y 資料 torch.Size([136, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.35038504004478455, 131)\n",
      "The second_loss value of k: (0.35038504004478455, 134)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引131，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([75, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3443],\n",
      "        [  1.7384],\n",
      "        [305.6797],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  1.3233],\n",
      "        [ 30.1763],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ 10.2578],\n",
      "        [ -0.5919],\n",
      "        [  8.6044],\n",
      "        [223.2755],\n",
      "        [ 85.0886],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ -0.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  2.2797],\n",
      "        [ -0.5919],\n",
      "        [  1.2352],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7384],\n",
      "        [ 20.0903],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1763],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2578],\n",
      "        [  0.5919],\n",
      "        [  8.6044],\n",
      "        [  2.7245],\n",
      "        [  2.3014],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ 13.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2797],\n",
      "        [  0.5919],\n",
      "        [  1.2352],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(933.1927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7384],\n",
      "        [ 20.0903],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1763],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2578],\n",
      "        [  0.5919],\n",
      "        [  8.6044],\n",
      "        [  2.7245],\n",
      "        [  2.3014],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ 13.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2797],\n",
      "        [  0.5919],\n",
      "        [  1.2352],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.828596115112305\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 68\n",
      "剩餘X 資料 torch.Size([135, 10])\n",
      "剩餘Y 資料 torch.Size([135, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.35038504004478455, 133)\n",
      "The second_loss value of k: (0.35038504004478455, 134)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引133，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([76, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3443],\n",
      "        [  1.7384],\n",
      "        [305.6797],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  1.3233],\n",
      "        [ 30.1763],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ 10.2578],\n",
      "        [ -0.5919],\n",
      "        [  8.6044],\n",
      "        [223.2755],\n",
      "        [ 85.0886],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ -0.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  2.2797],\n",
      "        [ -0.5919],\n",
      "        [  1.2352],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7384],\n",
      "        [ 20.0903],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1763],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2578],\n",
      "        [  0.5919],\n",
      "        [  8.6044],\n",
      "        [  2.7245],\n",
      "        [  2.3014],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ 13.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2797],\n",
      "        [  0.5919],\n",
      "        [  1.2352],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(920.9185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7384],\n",
      "        [ 20.0903],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1763],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2578],\n",
      "        [  0.5919],\n",
      "        [  8.6044],\n",
      "        [  2.7245],\n",
      "        [  2.3014],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ 13.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2797],\n",
      "        [  0.5919],\n",
      "        [  1.2352],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.915102243423462\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 69\n",
      "剩餘X 資料 torch.Size([134, 10])\n",
      "剩餘Y 資料 torch.Size([134, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.35038504004478455, 133)\n",
      "The second_loss value of k: (2.6183807849884033, 84)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引133，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([77, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3443],\n",
      "        [  1.7384],\n",
      "        [305.6797],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  1.3233],\n",
      "        [ 30.1763],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ 10.2578],\n",
      "        [ -0.5919],\n",
      "        [  8.6044],\n",
      "        [223.2755],\n",
      "        [ 85.0886],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ -0.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  2.2797],\n",
      "        [ -0.5919],\n",
      "        [  1.2352],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7384],\n",
      "        [ 20.0903],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1763],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2578],\n",
      "        [  0.5919],\n",
      "        [  8.6044],\n",
      "        [  2.7245],\n",
      "        [  2.3014],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ 13.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2797],\n",
      "        [  0.5919],\n",
      "        [  1.2352],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(908.9631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7384],\n",
      "        [ 20.0903],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1763],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2578],\n",
      "        [  0.5919],\n",
      "        [  8.6044],\n",
      "        [  2.7245],\n",
      "        [  2.3014],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ 13.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2797],\n",
      "        [  0.5919],\n",
      "        [  1.2352],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.000165939331055\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 70\n",
      "剩餘X 資料 torch.Size([133, 10])\n",
      "剩餘Y 資料 torch.Size([133, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (2.6183807849884033, 84)\n",
      "The second_loss value of k: (6.718118190765381, 76)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引84，y= tensor([10.])\n",
      "目前模型的Data狀態 torch.Size([78, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3443],\n",
      "        [  1.7384],\n",
      "        [305.6797],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  1.3233],\n",
      "        [ 30.1763],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ 10.2578],\n",
      "        [ -0.5919],\n",
      "        [  8.6044],\n",
      "        [223.2755],\n",
      "        [ 85.0886],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ -0.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  2.2797],\n",
      "        [ -0.5919],\n",
      "        [  1.2352],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [ -0.5919],\n",
      "        [  8.3819]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[196.6557],\n",
      "        [  1.7384],\n",
      "        [ 20.0903],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [ 14.9367],\n",
      "        [ 29.1763],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  5.2578],\n",
      "        [  0.5919],\n",
      "        [  8.6044],\n",
      "        [  2.7245],\n",
      "        [  2.3014],\n",
      "        [  0.6269],\n",
      "        [  1.4417],\n",
      "        [ 13.5919],\n",
      "        [ 31.2835],\n",
      "        [168.9003],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  2.2797],\n",
      "        [  0.5919],\n",
      "        [  1.2352],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  0.5919],\n",
      "        [  1.6181]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(897.3433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.6177],\n",
      "        [    1.7739],\n",
      "        [   19.8195],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [   15.0985],\n",
      "        [   29.2794],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    5.2108],\n",
      "        [    0.5861],\n",
      "        [    8.5336],\n",
      "        [    2.7307],\n",
      "        [    2.4033],\n",
      "        [    0.6619],\n",
      "        [    1.5032],\n",
      "        [   13.5861],\n",
      "        [   31.1866],\n",
      "        [  168.9575],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    2.3278],\n",
      "        [    0.5861],\n",
      "        [    1.3242],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.1410]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.278340816497803\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 71\n",
      "剩餘X 資料 torch.Size([132, 10])\n",
      "剩餘Y 資料 torch.Size([132, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (6.688108444213867, 76)\n",
      "The second_loss value of k: (7.4569597244262695, 39)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引76，y= tensor([2.])\n",
      "目前模型的Data狀態 torch.Size([79, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.3823],\n",
      "        [  1.7739],\n",
      "        [305.9505],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [  1.1615],\n",
      "        [ 30.2794],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ 10.2108],\n",
      "        [ -0.5861],\n",
      "        [  8.5336],\n",
      "        [223.2693],\n",
      "        [ 84.9867],\n",
      "        [  0.6619],\n",
      "        [  1.5032],\n",
      "        [ -0.5861],\n",
      "        [ 31.1866],\n",
      "        [168.9575],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [  2.3278],\n",
      "        [ -0.5861],\n",
      "        [  1.3242],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [ -0.5861],\n",
      "        [  9.8590],\n",
      "        [ -0.5861]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.6177],\n",
      "        [    1.7739],\n",
      "        [   19.8195],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [   15.0985],\n",
      "        [   29.2794],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    5.2108],\n",
      "        [    0.5861],\n",
      "        [    8.5336],\n",
      "        [    2.7307],\n",
      "        [    2.4033],\n",
      "        [    0.6619],\n",
      "        [    1.5032],\n",
      "        [   13.5861],\n",
      "        [   31.1866],\n",
      "        [  168.9575],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    2.3278],\n",
      "        [    0.5861],\n",
      "        [    1.3242],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.5861],\n",
      "        [    0.1410],\n",
      "        [    2.5861]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(886.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 70\n",
      "Number of shrink: 30\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.5788],\n",
      "        [    1.8125],\n",
      "        [   19.9362],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [   15.2219],\n",
      "        [   29.3725],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    5.2506],\n",
      "        [    0.5811],\n",
      "        [    8.4325],\n",
      "        [    2.6911],\n",
      "        [    2.3470],\n",
      "        [    0.6818],\n",
      "        [    1.5138],\n",
      "        [   13.5811],\n",
      "        [   31.0076],\n",
      "        [  168.9918],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    2.3786],\n",
      "        [    0.5811],\n",
      "        [    1.4054],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.0283],\n",
      "        [    2.5811]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.557423830032349\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 72\n",
      "剩餘X 資料 torch.Size([131, 10])\n",
      "剩餘Y 資料 torch.Size([131, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (7.24177885055542, 39)\n",
      "The second_loss value of k: (16.65529441833496, 19)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引39，y= tensor([226.])\n",
      "目前模型的Data狀態 torch.Size([80, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.4212],\n",
      "        [  1.8125],\n",
      "        [305.8338],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [  1.0381],\n",
      "        [ 30.3725],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ 10.2506],\n",
      "        [ -0.5811],\n",
      "        [  8.4325],\n",
      "        [223.3089],\n",
      "        [ 85.0430],\n",
      "        [  0.6818],\n",
      "        [  1.5138],\n",
      "        [ -0.5811],\n",
      "        [ 31.0076],\n",
      "        [168.9918],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [  2.3786],\n",
      "        [ -0.5811],\n",
      "        [  1.4054],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [ -0.5811],\n",
      "        [  9.9717],\n",
      "        [ -0.5811],\n",
      "        [223.3089]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.5788],\n",
      "        [    1.8125],\n",
      "        [   19.9362],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [   15.2219],\n",
      "        [   29.3725],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    5.2506],\n",
      "        [    0.5811],\n",
      "        [    8.4325],\n",
      "        [    2.6911],\n",
      "        [    2.3470],\n",
      "        [    0.6818],\n",
      "        [    1.5138],\n",
      "        [   13.5811],\n",
      "        [   31.0076],\n",
      "        [  168.9918],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    2.3786],\n",
      "        [    0.5811],\n",
      "        [    1.4054],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.5811],\n",
      "        [    0.0283],\n",
      "        [    2.5811],\n",
      "        [    2.6911]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(874.9860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.4892],\n",
      "        [    1.8067],\n",
      "        [   20.0038],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [   15.3357],\n",
      "        [   29.4373],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    5.2881],\n",
      "        [    0.5745],\n",
      "        [    8.3551],\n",
      "        [    1.3600],\n",
      "        [    1.9288],\n",
      "        [    0.6342],\n",
      "        [    1.3278],\n",
      "        [   13.5745],\n",
      "        [   30.9221],\n",
      "        [  169.1062],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    2.3982],\n",
      "        [    0.5745],\n",
      "        [    1.4437],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.1040],\n",
      "        [    2.5745],\n",
      "        [    1.3600]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.832916975021362\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 73\n",
      "剩餘X 資料 torch.Size([130, 10])\n",
      "剩餘Y 資料 torch.Size([130, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (16.601306915283203, 19)\n",
      "The second_loss value of k: (25.54766845703125, 13)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引19，y= tensor([3.5000])\n",
      "目前模型的Data狀態 torch.Size([81, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.5108],\n",
      "        [  1.8067],\n",
      "        [305.7662],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [  0.9243],\n",
      "        [ 30.4373],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ 10.2881],\n",
      "        [ -0.5745],\n",
      "        [  8.3551],\n",
      "        [224.6400],\n",
      "        [ 85.4612],\n",
      "        [  0.6342],\n",
      "        [  1.3278],\n",
      "        [ -0.5745],\n",
      "        [ 30.9221],\n",
      "        [169.1062],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [  2.3982],\n",
      "        [ -0.5745],\n",
      "        [  1.4437],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ -0.5745],\n",
      "        [ 10.1040],\n",
      "        [ -0.5745],\n",
      "        [224.6400],\n",
      "        [ -0.5745]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.4892],\n",
      "        [    1.8067],\n",
      "        [   20.0038],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [   15.3357],\n",
      "        [   29.4373],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    5.2881],\n",
      "        [    0.5745],\n",
      "        [    8.3551],\n",
      "        [    1.3600],\n",
      "        [    1.9288],\n",
      "        [    0.6342],\n",
      "        [    1.3278],\n",
      "        [   13.5745],\n",
      "        [   30.9221],\n",
      "        [  169.1062],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    2.3982],\n",
      "        [    0.5745],\n",
      "        [    1.4437],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.5745],\n",
      "        [    0.1040],\n",
      "        [    2.5745],\n",
      "        [    1.3600],\n",
      "        [    4.0745]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(864.3094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.4865],\n",
      "        [    1.8326],\n",
      "        [   19.7210],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [   15.4467],\n",
      "        [   29.4697],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    5.2788],\n",
      "        [    0.5686],\n",
      "        [    8.4623],\n",
      "        [    1.3759],\n",
      "        [    1.9381],\n",
      "        [    0.5357],\n",
      "        [    1.6884],\n",
      "        [   13.5686],\n",
      "        [   30.8880],\n",
      "        [  169.1171],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    2.4649],\n",
      "        [    0.5686],\n",
      "        [    1.4707],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.0009],\n",
      "        [    2.5686],\n",
      "        [    1.3759],\n",
      "        [    4.0686]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.109577178955078\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 74\n",
      "剩餘X 資料 torch.Size([129, 10])\n",
      "剩餘Y 資料 torch.Size([129, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (25.488008499145508, 13)\n",
      "The second_loss value of k: (25.690349578857422, 51)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引13，y= tensor([4.4800])\n",
      "目前模型的Data狀態 torch.Size([82, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.5135],\n",
      "        [  1.8326],\n",
      "        [306.0490],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [  0.8133],\n",
      "        [ 30.4697],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ 10.2788],\n",
      "        [ -0.5686],\n",
      "        [  8.4623],\n",
      "        [224.6241],\n",
      "        [ 85.4519],\n",
      "        [  0.5357],\n",
      "        [  1.6884],\n",
      "        [ -0.5686],\n",
      "        [ 30.8880],\n",
      "        [169.1171],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [  2.4649],\n",
      "        [ -0.5686],\n",
      "        [  1.4707],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686],\n",
      "        [  9.9991],\n",
      "        [ -0.5686],\n",
      "        [224.6241],\n",
      "        [ -0.5686],\n",
      "        [ -0.5686]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.4865],\n",
      "        [    1.8326],\n",
      "        [   19.7210],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [   15.4467],\n",
      "        [   29.4697],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    5.2788],\n",
      "        [    0.5686],\n",
      "        [    8.4623],\n",
      "        [    1.3759],\n",
      "        [    1.9381],\n",
      "        [    0.5357],\n",
      "        [    1.6884],\n",
      "        [   13.5686],\n",
      "        [   30.8880],\n",
      "        [  169.1171],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    2.4649],\n",
      "        [    0.5686],\n",
      "        [    1.4707],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.5686],\n",
      "        [    0.0009],\n",
      "        [    2.5686],\n",
      "        [    1.3759],\n",
      "        [    4.0686],\n",
      "        [    5.0486]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(854.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.4411],\n",
      "        [    1.8298],\n",
      "        [   19.6314],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [   15.5246],\n",
      "        [   29.4972],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    5.2158],\n",
      "        [    0.5624],\n",
      "        [    8.3657],\n",
      "        [    1.3952],\n",
      "        [    1.9248],\n",
      "        [    0.5896],\n",
      "        [    1.6883],\n",
      "        [   13.5624],\n",
      "        [   30.8186],\n",
      "        [  169.1810],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    2.4658],\n",
      "        [    0.5624],\n",
      "        [    1.4980],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.1285],\n",
      "        [    2.5624],\n",
      "        [    1.3952],\n",
      "        [    4.0624],\n",
      "        [    5.0424]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.386278867721558\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 75\n",
      "剩餘X 資料 torch.Size([128, 10])\n",
      "剩餘Y 資料 torch.Size([128, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (25.628089904785156, 50)\n",
      "The second_loss value of k: (52.742733001708984, 76)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引50，y= tensor([4.5000])\n",
      "目前模型的Data狀態 torch.Size([83, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.5589],\n",
      "        [  1.8298],\n",
      "        [306.1385],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [  0.7354],\n",
      "        [ 30.4972],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ 10.2158],\n",
      "        [ -0.5624],\n",
      "        [  8.3657],\n",
      "        [224.6048],\n",
      "        [ 85.4652],\n",
      "        [  0.5896],\n",
      "        [  1.6883],\n",
      "        [ -0.5624],\n",
      "        [ 30.8186],\n",
      "        [169.1810],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [  2.4658],\n",
      "        [ -0.5624],\n",
      "        [  1.4980],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ 10.1285],\n",
      "        [ -0.5624],\n",
      "        [224.6048],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624],\n",
      "        [ -0.5624]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.4411],\n",
      "        [    1.8298],\n",
      "        [   19.6314],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [   15.5246],\n",
      "        [   29.4972],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    5.2158],\n",
      "        [    0.5624],\n",
      "        [    8.3657],\n",
      "        [    1.3952],\n",
      "        [    1.9248],\n",
      "        [    0.5896],\n",
      "        [    1.6883],\n",
      "        [   13.5624],\n",
      "        [   30.8186],\n",
      "        [  169.1810],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    2.4658],\n",
      "        [    0.5624],\n",
      "        [    1.4980],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.5624],\n",
      "        [    0.1285],\n",
      "        [    2.5624],\n",
      "        [    1.3952],\n",
      "        [    4.0624],\n",
      "        [    5.0424],\n",
      "        [    5.0624]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(844.0318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.4196],\n",
      "        [    1.8038],\n",
      "        [   19.7689],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [   15.6075],\n",
      "        [   29.5246],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    5.2877],\n",
      "        [    0.5576],\n",
      "        [    8.4117],\n",
      "        [    1.3682],\n",
      "        [    1.9058],\n",
      "        [    0.5950],\n",
      "        [    1.3208],\n",
      "        [   13.5576],\n",
      "        [   30.6316],\n",
      "        [  169.2048],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    2.5107],\n",
      "        [    0.5576],\n",
      "        [    1.5113],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.1221],\n",
      "        [    2.5576],\n",
      "        [    1.3682],\n",
      "        [    4.0576],\n",
      "        [    5.0376],\n",
      "        [    5.0576]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.663073301315308\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 76\n",
      "剩餘X 資料 torch.Size([127, 10])\n",
      "剩餘Y 資料 torch.Size([127, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (52.6727294921875, 75)\n",
      "The second_loss value of k: (57.6240119934082, 68)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引75，y= tensor([6.7000])\n",
      "目前模型的Data狀態 torch.Size([84, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.5804],\n",
      "        [  1.8038],\n",
      "        [306.0011],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [  0.6525],\n",
      "        [ 30.5246],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ 10.2877],\n",
      "        [ -0.5576],\n",
      "        [  8.4117],\n",
      "        [224.6318],\n",
      "        [ 85.4842],\n",
      "        [  0.5950],\n",
      "        [  1.3208],\n",
      "        [ -0.5576],\n",
      "        [ 30.6316],\n",
      "        [169.2048],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [  2.5107],\n",
      "        [ -0.5576],\n",
      "        [  1.5113],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ 10.1221],\n",
      "        [ -0.5576],\n",
      "        [224.6318],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576],\n",
      "        [ -0.5576]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.4196],\n",
      "        [    1.8038],\n",
      "        [   19.7689],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [   15.6075],\n",
      "        [   29.5246],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    5.2877],\n",
      "        [    0.5576],\n",
      "        [    8.4117],\n",
      "        [    1.3682],\n",
      "        [    1.9058],\n",
      "        [    0.5950],\n",
      "        [    1.3208],\n",
      "        [   13.5576],\n",
      "        [   30.6316],\n",
      "        [  169.2048],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    2.5107],\n",
      "        [    0.5576],\n",
      "        [    1.5113],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.5576],\n",
      "        [    0.1221],\n",
      "        [    2.5576],\n",
      "        [    1.3682],\n",
      "        [    4.0576],\n",
      "        [    5.0376],\n",
      "        [    5.0576],\n",
      "        [    7.2576]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(834.5809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.4178],\n",
      "        [    1.8109],\n",
      "        [   19.6332],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [   15.7091],\n",
      "        [   29.5589],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    5.2581],\n",
      "        [    0.5514],\n",
      "        [    8.3113],\n",
      "        [    1.4167],\n",
      "        [    1.9278],\n",
      "        [    0.4531],\n",
      "        [    1.4021],\n",
      "        [   13.5514],\n",
      "        [   30.6046],\n",
      "        [  169.2104],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    2.5232],\n",
      "        [    0.5514],\n",
      "        [    1.5547],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.0093],\n",
      "        [    2.5514],\n",
      "        [    1.4167],\n",
      "        [    4.0514],\n",
      "        [    5.0314],\n",
      "        [    5.0514],\n",
      "        [    7.2514]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.939346551895142\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 77\n",
      "剩餘X 資料 torch.Size([126, 10])\n",
      "剩餘Y 資料 torch.Size([126, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (57.0846061706543, 68)\n",
      "The second_loss value of k: (64.87081909179688, 43)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引68，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([85, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.5823],\n",
      "        [  1.8109],\n",
      "        [306.1367],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [  0.5509],\n",
      "        [ 30.5589],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ 10.2581],\n",
      "        [ -0.5514],\n",
      "        [  8.3113],\n",
      "        [224.5833],\n",
      "        [ 85.4622],\n",
      "        [  0.4531],\n",
      "        [  1.4021],\n",
      "        [ -0.5514],\n",
      "        [ 30.6046],\n",
      "        [169.2104],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [  2.5232],\n",
      "        [ -0.5514],\n",
      "        [  1.5547],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [  9.9907],\n",
      "        [ -0.5514],\n",
      "        [224.5833],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [ -0.5514],\n",
      "        [  7.5554]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.4178],\n",
      "        [    1.8109],\n",
      "        [   19.6332],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [   15.7091],\n",
      "        [   29.5589],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    5.2581],\n",
      "        [    0.5514],\n",
      "        [    8.3113],\n",
      "        [    1.4167],\n",
      "        [    1.9278],\n",
      "        [    0.4531],\n",
      "        [    1.4021],\n",
      "        [   13.5514],\n",
      "        [   30.6046],\n",
      "        [  169.2104],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    2.5232],\n",
      "        [    0.5514],\n",
      "        [    1.5547],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.5514],\n",
      "        [    0.0093],\n",
      "        [    2.5514],\n",
      "        [    1.4167],\n",
      "        [    4.0514],\n",
      "        [    5.0314],\n",
      "        [    5.0514],\n",
      "        [    7.2514],\n",
      "        [    7.5554]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(825.4000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.4275],\n",
      "        [    1.8241],\n",
      "        [   19.6472],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [   15.6507],\n",
      "        [   29.5066],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    5.3010],\n",
      "        [    0.5435],\n",
      "        [    8.2974],\n",
      "        [    1.3830],\n",
      "        [    1.9447],\n",
      "        [    0.4996],\n",
      "        [    1.4588],\n",
      "        [   13.5435],\n",
      "        [   30.7148],\n",
      "        [  169.1866],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    2.5237],\n",
      "        [    0.5435],\n",
      "        [    1.5637],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.0512],\n",
      "        [    2.5435],\n",
      "        [    1.3830],\n",
      "        [    4.0435],\n",
      "        [    5.0235],\n",
      "        [    5.0435],\n",
      "        [    7.2435],\n",
      "        [    7.4906]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.2163667678833\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 78\n",
      "剩餘X 資料 torch.Size([125, 10])\n",
      "剩餘Y 資料 torch.Size([125, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (65.32762908935547, 43)\n",
      "The second_loss value of k: (111.16583251953125, 23)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引43，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([86, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.5725],\n",
      "        [  1.8241],\n",
      "        [306.1228],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [  0.6093],\n",
      "        [ 30.5066],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ 10.3010],\n",
      "        [ -0.5435],\n",
      "        [  8.2974],\n",
      "        [224.6170],\n",
      "        [ 85.4453],\n",
      "        [  0.4996],\n",
      "        [  1.4588],\n",
      "        [ -0.5435],\n",
      "        [ 30.7148],\n",
      "        [169.1866],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [  2.5237],\n",
      "        [ -0.5435],\n",
      "        [  1.5637],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ 10.0512],\n",
      "        [ -0.5435],\n",
      "        [224.6170],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [ -0.5435],\n",
      "        [  7.4906],\n",
      "        [  8.0826]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.4275],\n",
      "        [    1.8241],\n",
      "        [   19.6472],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [   15.6507],\n",
      "        [   29.5066],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    5.3010],\n",
      "        [    0.5435],\n",
      "        [    8.2974],\n",
      "        [    1.3830],\n",
      "        [    1.9447],\n",
      "        [    0.4996],\n",
      "        [    1.4588],\n",
      "        [   13.5435],\n",
      "        [   30.7148],\n",
      "        [  169.1866],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    2.5237],\n",
      "        [    0.5435],\n",
      "        [    1.5637],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.5435],\n",
      "        [    0.0512],\n",
      "        [    2.5435],\n",
      "        [    1.3830],\n",
      "        [    4.0435],\n",
      "        [    5.0235],\n",
      "        [    5.0435],\n",
      "        [    7.2435],\n",
      "        [    7.4906],\n",
      "        [    8.0826]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(816.5208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.4217],\n",
      "        [    1.8198],\n",
      "        [   20.3027],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [   15.7920],\n",
      "        [   29.7237],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    3.1642],\n",
      "        [    0.5327],\n",
      "        [    5.3971],\n",
      "        [    1.3877],\n",
      "        [    1.6766],\n",
      "        [    0.3673],\n",
      "        [    1.3492],\n",
      "        [   13.5327],\n",
      "        [   31.1620],\n",
      "        [  169.1970],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    1.9085],\n",
      "        [    0.5327],\n",
      "        [    1.9931],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.1316],\n",
      "        [    2.5327],\n",
      "        [    1.3877],\n",
      "        [    4.0327],\n",
      "        [    5.0127],\n",
      "        [    5.0327],\n",
      "        [    7.2327],\n",
      "        [    7.5076],\n",
      "        [    2.8043]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.4918954372406\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 79\n",
      "剩餘X 資料 torch.Size([124, 10])\n",
      "剩餘Y 資料 torch.Size([124, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (110.93779754638672, 23)\n",
      "The second_loss value of k: (114.32633972167969, 29)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引23，y= tensor([10.])\n",
      "目前模型的Data狀態 torch.Size([87, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.5783],\n",
      "        [  1.8198],\n",
      "        [305.4673],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [  0.4680],\n",
      "        [ 30.7237],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [  8.1642],\n",
      "        [ -0.5327],\n",
      "        [  5.3971],\n",
      "        [224.6123],\n",
      "        [ 85.7134],\n",
      "        [  0.3673],\n",
      "        [  1.3492],\n",
      "        [ -0.5327],\n",
      "        [ 31.1620],\n",
      "        [169.1970],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [  1.9085],\n",
      "        [ -0.5327],\n",
      "        [  1.9931],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [  9.8684],\n",
      "        [ -0.5327],\n",
      "        [224.6123],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [ -0.5327],\n",
      "        [  7.5076],\n",
      "        [  2.8043],\n",
      "        [ -0.5327]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.4217],\n",
      "        [    1.8198],\n",
      "        [   20.3027],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [   15.7920],\n",
      "        [   29.7237],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    3.1642],\n",
      "        [    0.5327],\n",
      "        [    5.3971],\n",
      "        [    1.3877],\n",
      "        [    1.6766],\n",
      "        [    0.3673],\n",
      "        [    1.3492],\n",
      "        [   13.5327],\n",
      "        [   31.1620],\n",
      "        [  169.1970],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    1.9085],\n",
      "        [    0.5327],\n",
      "        [    1.9931],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.5327],\n",
      "        [    0.1316],\n",
      "        [    2.5327],\n",
      "        [    1.3877],\n",
      "        [    4.0327],\n",
      "        [    5.0127],\n",
      "        [    5.0327],\n",
      "        [    7.2327],\n",
      "        [    7.5076],\n",
      "        [    2.8043],\n",
      "        [   10.5327]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(807.8738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 8\n",
      "Number of shrink: 11\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.4131],\n",
      "        [    1.8353],\n",
      "        [   20.2375],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [   15.7865],\n",
      "        [   29.7250],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    3.1538],\n",
      "        [    0.5326],\n",
      "        [    5.4559],\n",
      "        [    1.3927],\n",
      "        [    1.6783],\n",
      "        [    0.3966],\n",
      "        [    1.4942],\n",
      "        [   13.5326],\n",
      "        [   31.1752],\n",
      "        [  169.2078],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    1.9289],\n",
      "        [    0.5326],\n",
      "        [    1.9961],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.0598],\n",
      "        [    2.5326],\n",
      "        [    1.3927],\n",
      "        [    4.0326],\n",
      "        [    5.0126],\n",
      "        [    5.0326],\n",
      "        [    7.2326],\n",
      "        [    7.5075],\n",
      "        [    2.8659],\n",
      "        [   10.5326]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.600161075592041\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 80\n",
      "剩餘X 資料 torch.Size([123, 10])\n",
      "剩餘Y 資料 torch.Size([123, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (114.1789321899414, 28)\n",
      "The second_loss value of k: (121.71936798095703, 100)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引28，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([88, 1])\n",
      "<<預測值>>\n",
      "tensor([[121.5869],\n",
      "        [  1.8353],\n",
      "        [305.5324],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [  0.4735],\n",
      "        [ 30.7250],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [  8.1538],\n",
      "        [ -0.5326],\n",
      "        [  5.4559],\n",
      "        [224.6073],\n",
      "        [ 85.7117],\n",
      "        [  0.3966],\n",
      "        [  1.4942],\n",
      "        [ -0.5326],\n",
      "        [ 31.1752],\n",
      "        [169.2078],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [  1.9289],\n",
      "        [ -0.5326],\n",
      "        [  1.9961],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [  9.9402],\n",
      "        [ -0.5326],\n",
      "        [224.6073],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [ -0.5326],\n",
      "        [  7.5075],\n",
      "        [  2.8659],\n",
      "        [ -0.5326],\n",
      "        [ 10.6855]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.4131],\n",
      "        [    1.8353],\n",
      "        [   20.2375],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [   15.7865],\n",
      "        [   29.7250],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    3.1538],\n",
      "        [    0.5326],\n",
      "        [    5.4559],\n",
      "        [    1.3927],\n",
      "        [    1.6783],\n",
      "        [    0.3966],\n",
      "        [    1.4942],\n",
      "        [   13.5326],\n",
      "        [   31.1752],\n",
      "        [  169.2078],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    1.9289],\n",
      "        [    0.5326],\n",
      "        [    1.9961],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.5326],\n",
      "        [    0.0598],\n",
      "        [    2.5326],\n",
      "        [    1.3927],\n",
      "        [    4.0326],\n",
      "        [    5.0126],\n",
      "        [    5.0326],\n",
      "        [    7.2326],\n",
      "        [    7.5075],\n",
      "        [    2.8659],\n",
      "        [   10.5326],\n",
      "        [   10.6855]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(799.9894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.3034],\n",
      "        [    1.7349],\n",
      "        [   18.0697],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [   16.2555],\n",
      "        [   29.9884],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    3.0087],\n",
      "        [    0.5150],\n",
      "        [    5.2175],\n",
      "        [    4.0700],\n",
      "        [    2.2948],\n",
      "        [    0.6836],\n",
      "        [    0.6585],\n",
      "        [   13.5150],\n",
      "        [   31.1819],\n",
      "        [  169.4606],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    1.9752],\n",
      "        [    0.5150],\n",
      "        [    2.1476],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.1633],\n",
      "        [    2.5150],\n",
      "        [    4.0700],\n",
      "        [    4.0150],\n",
      "        [    4.9950],\n",
      "        [    5.0150],\n",
      "        [    7.2150],\n",
      "        [    7.5417],\n",
      "        [    2.3040],\n",
      "        [   10.5150],\n",
      "        [    7.5901]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.877661943435669\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 81\n",
      "剩餘X 資料 torch.Size([122, 10])\n",
      "剩餘Y 資料 torch.Size([122, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (121.33010864257812, 99)\n",
      "The second_loss value of k: (281.97662353515625, 117)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引99，y= tensor([10.5000])\n",
      "目前模型的Data狀態 torch.Size([89, 1])\n",
      "<<預測值>>\n",
      "tensor([[   121.6966],\n",
      "        [     1.7349],\n",
      "        [   307.7003],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [     0.0045],\n",
      "        [    30.9884],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [     8.0087],\n",
      "        [    -0.5150],\n",
      "        [     5.2175],\n",
      "        [   221.9300],\n",
      "        [    85.0952],\n",
      "        [     0.6836],\n",
      "        [     0.6585],\n",
      "        [    -0.5150],\n",
      "        [    31.1819],\n",
      "        [   169.4606],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [     1.9752],\n",
      "        [    -0.5150],\n",
      "        [     2.1476],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    10.1633],\n",
      "        [    -0.5150],\n",
      "        [   221.9300],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [    -0.5150],\n",
      "        [     7.5417],\n",
      "        [     2.3040],\n",
      "        [    -0.5150],\n",
      "        [     7.5901],\n",
      "        [    -0.5150]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.3034],\n",
      "        [    1.7349],\n",
      "        [   18.0697],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [   16.2555],\n",
      "        [   29.9884],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    3.0087],\n",
      "        [    0.5150],\n",
      "        [    5.2175],\n",
      "        [    4.0700],\n",
      "        [    2.2948],\n",
      "        [    0.6836],\n",
      "        [    0.6585],\n",
      "        [   13.5150],\n",
      "        [   31.1819],\n",
      "        [  169.4606],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    1.9752],\n",
      "        [    0.5150],\n",
      "        [    2.1476],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.5150],\n",
      "        [    0.1633],\n",
      "        [    2.5150],\n",
      "        [    4.0700],\n",
      "        [    4.0150],\n",
      "        [    4.9950],\n",
      "        [    5.0150],\n",
      "        [    7.2150],\n",
      "        [    7.5417],\n",
      "        [    2.3040],\n",
      "        [   10.5150],\n",
      "        [    7.5901],\n",
      "        [   11.0150]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(791.8712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 74\n",
      "Number of shrink: 26\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  196.3448],\n",
      "        [    1.6562],\n",
      "        [   17.3434],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [   16.5451],\n",
      "        [   30.0528],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    3.1141],\n",
      "        [    0.5060],\n",
      "        [    5.2025],\n",
      "        [    3.8570],\n",
      "        [    2.1902],\n",
      "        [    0.7111],\n",
      "        [    0.4325],\n",
      "        [   13.5060],\n",
      "        [   31.1607],\n",
      "        [  169.4625],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    1.9670],\n",
      "        [    0.5060],\n",
      "        [    2.1363],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.1645],\n",
      "        [    2.5060],\n",
      "        [    3.8570],\n",
      "        [    4.0060],\n",
      "        [    4.9860],\n",
      "        [    5.0060],\n",
      "        [    7.2060],\n",
      "        [    7.5263],\n",
      "        [    2.3506],\n",
      "        [   10.5060],\n",
      "        [    7.3322],\n",
      "        [   11.0060]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.152313470840454\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 82\n",
      "剩餘X 資料 torch.Size([121, 10])\n",
      "剩餘Y 資料 torch.Size([121, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (275.1026916503906, 116)\n",
      "The second_loss value of k: (416.1594543457031, 32)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引116，y= tensor([99.])\n",
      "目前模型的Data狀態 torch.Size([90, 1])\n",
      "<<預測值>>\n",
      "tensor([[   121.6552],\n",
      "        [     1.6562],\n",
      "        [   308.4265],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.2851],\n",
      "        [    31.0528],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [     8.1141],\n",
      "        [    -0.5060],\n",
      "        [     5.2025],\n",
      "        [   222.1430],\n",
      "        [    85.1998],\n",
      "        [     0.7111],\n",
      "        [     0.4325],\n",
      "        [    -0.5060],\n",
      "        [    31.1607],\n",
      "        [   169.4625],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [     1.9670],\n",
      "        [    -0.5060],\n",
      "        [     2.1363],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    10.1645],\n",
      "        [    -0.5060],\n",
      "        [   222.1430],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [    -0.5060],\n",
      "        [     7.5263],\n",
      "        [     2.3506],\n",
      "        [    -0.5060],\n",
      "        [     7.3322],\n",
      "        [    -0.5060],\n",
      "        [    82.4138]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  196.3448],\n",
      "        [    1.6562],\n",
      "        [   17.3434],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [   16.5451],\n",
      "        [   30.0528],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    3.1141],\n",
      "        [    0.5060],\n",
      "        [    5.2025],\n",
      "        [    3.8570],\n",
      "        [    2.1902],\n",
      "        [    0.7111],\n",
      "        [    0.4325],\n",
      "        [   13.5060],\n",
      "        [   31.1607],\n",
      "        [  169.4625],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    1.9670],\n",
      "        [    0.5060],\n",
      "        [    2.1363],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.5060],\n",
      "        [    0.1645],\n",
      "        [    2.5060],\n",
      "        [    3.8570],\n",
      "        [    4.0060],\n",
      "        [    4.9860],\n",
      "        [    5.0060],\n",
      "        [    7.2060],\n",
      "        [    7.5263],\n",
      "        [    2.3506],\n",
      "        [   10.5060],\n",
      "        [    7.3322],\n",
      "        [   11.0060],\n",
      "        [   16.5862]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(786.0606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[200.8830],\n",
      "        [  1.1703],\n",
      "        [ 14.2828],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [ 16.7155],\n",
      "        [ 31.3768],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  4.6352],\n",
      "        [  0.4555],\n",
      "        [  4.9981],\n",
      "        [  2.8759],\n",
      "        [  1.3472],\n",
      "        [  0.4555],\n",
      "        [  3.4333],\n",
      "        [ 13.4555],\n",
      "        [ 29.1512],\n",
      "        [164.0615],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  2.3738],\n",
      "        [  0.4555],\n",
      "        [  2.5180],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  1.6919],\n",
      "        [  2.4555],\n",
      "        [  2.8759],\n",
      "        [  3.9555],\n",
      "        [  4.9355],\n",
      "        [  4.9555],\n",
      "        [  7.1555],\n",
      "        [  7.9979],\n",
      "        [  2.4016],\n",
      "        [ 10.4555],\n",
      "        [  5.8903],\n",
      "        [ 10.9555],\n",
      "        [ 13.7996]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.425420999526978\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 83\n",
      "剩餘X 資料 torch.Size([120, 10])\n",
      "剩餘Y 資料 torch.Size([120, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (342.8703308105469, 32)\n",
      "The second_loss value of k: (652.0642700195312, 71)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引32，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([91, 1])\n",
      "<<預測值>>\n",
      "tensor([[117.1170],\n",
      "        [  1.1703],\n",
      "        [311.4872],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ 32.3768],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [  9.6352],\n",
      "        [ -0.4555],\n",
      "        [  4.9981],\n",
      "        [223.1241],\n",
      "        [ 86.0428],\n",
      "        [ -0.4555],\n",
      "        [  3.4333],\n",
      "        [ -0.4555],\n",
      "        [ 29.1512],\n",
      "        [164.0615],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [  2.3738],\n",
      "        [ -0.4555],\n",
      "        [  2.5180],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [  8.3081],\n",
      "        [ -0.4555],\n",
      "        [223.1241],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [ -0.4555],\n",
      "        [  7.9979],\n",
      "        [  2.4016],\n",
      "        [ -0.4555],\n",
      "        [  5.8903],\n",
      "        [ -0.4555],\n",
      "        [ 85.2004],\n",
      "        [ 18.5168]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[200.8830],\n",
      "        [  1.1703],\n",
      "        [ 14.2828],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [ 16.7155],\n",
      "        [ 31.3768],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  4.6352],\n",
      "        [  0.4555],\n",
      "        [  4.9981],\n",
      "        [  2.8759],\n",
      "        [  1.3472],\n",
      "        [  0.4555],\n",
      "        [  3.4333],\n",
      "        [ 13.4555],\n",
      "        [ 29.1512],\n",
      "        [164.0615],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  2.3738],\n",
      "        [  0.4555],\n",
      "        [  2.5180],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  0.4555],\n",
      "        [  1.6919],\n",
      "        [  2.4555],\n",
      "        [  2.8759],\n",
      "        [  3.9555],\n",
      "        [  4.9355],\n",
      "        [  4.9555],\n",
      "        [  7.1555],\n",
      "        [  7.9979],\n",
      "        [  2.4016],\n",
      "        [ 10.4555],\n",
      "        [  5.8903],\n",
      "        [ 10.9555],\n",
      "        [ 13.7996],\n",
      "        [ 18.5168]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(778.7194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  201.6075],\n",
      "        [    0.0471],\n",
      "        [   17.8438],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [   16.6508],\n",
      "        [   32.7684],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    3.8031],\n",
      "        [    0.3908],\n",
      "        [    4.5387],\n",
      "        [    2.9725],\n",
      "        [    0.4005],\n",
      "        [    0.6401],\n",
      "        [    0.3908],\n",
      "        [   13.3908],\n",
      "        [   21.8415],\n",
      "        [  163.5344],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    2.3077],\n",
      "        [    0.3908],\n",
      "        [    2.0207],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3123],\n",
      "        [    2.3908],\n",
      "        [    2.9725],\n",
      "        [    3.8908],\n",
      "        [    4.8708],\n",
      "        [    4.8908],\n",
      "        [    7.0908],\n",
      "        [    8.6180],\n",
      "        [    0.9868],\n",
      "        [   10.3908],\n",
      "        [    4.0977],\n",
      "        [   10.8908],\n",
      "        [   10.4137],\n",
      "        [   11.7174]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.698655605316162\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 84\n",
      "剩餘X 資料 torch.Size([119, 10])\n",
      "剩餘Y 資料 torch.Size([119, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (625.1079711914062, 85)\n",
      "The second_loss value of k: (648.7622680664062, 70)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引85，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([92, 1])\n",
      "<<預測值>>\n",
      "tensor([[   116.3925],\n",
      "        [    -0.0471],\n",
      "        [   307.9262],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    33.7684],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [     8.8031],\n",
      "        [    -0.3908],\n",
      "        [     4.5387],\n",
      "        [   223.0275],\n",
      "        [    86.9895],\n",
      "        [     0.6401],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    21.8415],\n",
      "        [   163.5344],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [     2.3077],\n",
      "        [    -0.3908],\n",
      "        [     2.0207],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    10.3123],\n",
      "        [    -0.3908],\n",
      "        [   223.0275],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [    -0.3908],\n",
      "        [     8.6180],\n",
      "        [     0.9868],\n",
      "        [    -0.3908],\n",
      "        [     4.0977],\n",
      "        [    -0.3908],\n",
      "        [    88.5863],\n",
      "        [    11.7174],\n",
      "        [    25.0022]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  201.6075],\n",
      "        [    0.0471],\n",
      "        [   17.8438],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [   16.6508],\n",
      "        [   32.7684],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    3.8031],\n",
      "        [    0.3908],\n",
      "        [    4.5387],\n",
      "        [    2.9725],\n",
      "        [    0.4005],\n",
      "        [    0.6401],\n",
      "        [    0.3908],\n",
      "        [   13.3908],\n",
      "        [   21.8415],\n",
      "        [  163.5344],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    2.3077],\n",
      "        [    0.3908],\n",
      "        [    2.0207],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3908],\n",
      "        [    0.3123],\n",
      "        [    2.3908],\n",
      "        [    2.9725],\n",
      "        [    3.8908],\n",
      "        [    4.8708],\n",
      "        [    4.8908],\n",
      "        [    7.0908],\n",
      "        [    8.6180],\n",
      "        [    0.9868],\n",
      "        [   10.3908],\n",
      "        [    4.0977],\n",
      "        [   10.8908],\n",
      "        [   10.4137],\n",
      "        [   11.7174],\n",
      "        [   25.0022]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(772.7762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  201.2324],\n",
      "        [    0.3500],\n",
      "        [   20.6754],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [   16.6100],\n",
      "        [   33.7659],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    4.1337],\n",
      "        [    0.3500],\n",
      "        [    3.4625],\n",
      "        [    2.7171],\n",
      "        [    0.0803],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [   13.3500],\n",
      "        [   17.4469],\n",
      "        [  164.0987],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    2.1962],\n",
      "        [    0.3500],\n",
      "        [    1.9169],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    1.0464],\n",
      "        [    2.3500],\n",
      "        [    2.7171],\n",
      "        [    3.8500],\n",
      "        [    4.8300],\n",
      "        [    4.8500],\n",
      "        [    7.0500],\n",
      "        [    9.0177],\n",
      "        [    0.3500],\n",
      "        [   10.3500],\n",
      "        [    3.5871],\n",
      "        [   10.8500],\n",
      "        [    8.1620],\n",
      "        [    7.5099],\n",
      "        [   23.4499]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.966403722763062\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 85\n",
      "剩餘X 資料 torch.Size([118, 10])\n",
      "剩餘Y 資料 torch.Size([118, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (646.6845092773438, 70)\n",
      "The second_loss value of k: (667.498046875, 116)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引70，y= tensor([25.0800])\n",
      "目前模型的Data狀態 torch.Size([93, 1])\n",
      "<<預測值>>\n",
      "tensor([[116.7676],\n",
      "        [ -0.3500],\n",
      "        [305.0946],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ 34.7659],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [  9.1337],\n",
      "        [ -0.3500],\n",
      "        [  3.4625],\n",
      "        [223.2829],\n",
      "        [ 87.3097],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ 17.4469],\n",
      "        [164.0987],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [  2.1962],\n",
      "        [ -0.3500],\n",
      "        [  1.9169],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [  8.9536],\n",
      "        [ -0.3500],\n",
      "        [223.2829],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [  9.0177],\n",
      "        [ -0.3500],\n",
      "        [ -0.3500],\n",
      "        [  3.5871],\n",
      "        [ -0.3500],\n",
      "        [ 90.8380],\n",
      "        [  7.5099],\n",
      "        [ 23.4499],\n",
      "        [ -0.3500]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  201.2324],\n",
      "        [    0.3500],\n",
      "        [   20.6754],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [   16.6100],\n",
      "        [   33.7659],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    4.1337],\n",
      "        [    0.3500],\n",
      "        [    3.4625],\n",
      "        [    2.7171],\n",
      "        [    0.0803],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [   13.3500],\n",
      "        [   17.4469],\n",
      "        [  164.0987],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    2.1962],\n",
      "        [    0.3500],\n",
      "        [    1.9169],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    0.3500],\n",
      "        [    1.0464],\n",
      "        [    2.3500],\n",
      "        [    2.7171],\n",
      "        [    3.8500],\n",
      "        [    4.8300],\n",
      "        [    4.8500],\n",
      "        [    7.0500],\n",
      "        [    9.0177],\n",
      "        [    0.3500],\n",
      "        [   10.3500],\n",
      "        [    3.5871],\n",
      "        [   10.8500],\n",
      "        [    8.1620],\n",
      "        [    7.5099],\n",
      "        [   23.4499],\n",
      "        [   25.4300]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(769.5259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 74\n",
      "Number of shrink: 26\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  201.2347],\n",
      "        [    0.1938],\n",
      "        [   19.0489],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [   16.5883],\n",
      "        [   34.4942],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    5.2070],\n",
      "        [    0.3283],\n",
      "        [    4.2457],\n",
      "        [    1.9558],\n",
      "        [    0.1248],\n",
      "        [    0.3283],\n",
      "        [    0.6345],\n",
      "        [   13.3283],\n",
      "        [   16.7628],\n",
      "        [  164.0546],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    2.8937],\n",
      "        [    0.3283],\n",
      "        [    2.3873],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.2019],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.0707],\n",
      "        [    2.3283],\n",
      "        [    1.9558],\n",
      "        [    3.8283],\n",
      "        [    4.8083],\n",
      "        [    4.8283],\n",
      "        [    7.0283],\n",
      "        [    9.2326],\n",
      "        [    0.6243],\n",
      "        [   10.3283],\n",
      "        [    3.4808],\n",
      "        [   10.8283],\n",
      "        [    6.8136],\n",
      "        [    6.7467],\n",
      "        [   23.4241],\n",
      "        [   25.4083]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 14.235161066055298\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 86\n",
      "剩餘X 資料 torch.Size([117, 10])\n",
      "剩餘Y 資料 torch.Size([117, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (660.3668212890625, 115)\n",
      "The second_loss value of k: (686.93408203125, 34)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引115，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([94, 1])\n",
      "<<預測值>>\n",
      "tensor([[   116.7653],\n",
      "        [     0.1938],\n",
      "        [   306.7211],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    35.4942],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    10.2070],\n",
      "        [    -0.3283],\n",
      "        [     4.2457],\n",
      "        [   224.0442],\n",
      "        [    87.5148],\n",
      "        [    -0.3283],\n",
      "        [     0.6345],\n",
      "        [    -0.3283],\n",
      "        [    16.7628],\n",
      "        [   164.0546],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [     2.8937],\n",
      "        [    -0.3283],\n",
      "        [     2.3873],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.2019],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [     9.9293],\n",
      "        [    -0.3283],\n",
      "        [   224.0442],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [    -0.3283],\n",
      "        [     9.2326],\n",
      "        [     0.6243],\n",
      "        [    -0.3283],\n",
      "        [     3.4808],\n",
      "        [    -0.3283],\n",
      "        [    92.1864],\n",
      "        [     6.7467],\n",
      "        [    23.4241],\n",
      "        [    -0.3283],\n",
      "        [    25.6976]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  201.2347],\n",
      "        [    0.1938],\n",
      "        [   19.0489],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [   16.5883],\n",
      "        [   34.4942],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    5.2070],\n",
      "        [    0.3283],\n",
      "        [    4.2457],\n",
      "        [    1.9558],\n",
      "        [    0.1248],\n",
      "        [    0.3283],\n",
      "        [    0.6345],\n",
      "        [   13.3283],\n",
      "        [   16.7628],\n",
      "        [  164.0546],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    2.8937],\n",
      "        [    0.3283],\n",
      "        [    2.3873],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.2019],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.3283],\n",
      "        [    0.0707],\n",
      "        [    2.3283],\n",
      "        [    1.9558],\n",
      "        [    3.8283],\n",
      "        [    4.8083],\n",
      "        [    4.8283],\n",
      "        [    7.0283],\n",
      "        [    9.2326],\n",
      "        [    0.6243],\n",
      "        [   10.3283],\n",
      "        [    3.4808],\n",
      "        [   10.8283],\n",
      "        [    6.8136],\n",
      "        [    6.7467],\n",
      "        [   23.4241],\n",
      "        [   25.4083],\n",
      "        [   25.6976]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(767.5950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  201.4265],\n",
      "        [    0.0672],\n",
      "        [   21.2280],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [   16.5592],\n",
      "        [   35.1379],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    4.6993],\n",
      "        [    0.2992],\n",
      "        [    5.3162],\n",
      "        [    1.8507],\n",
      "        [    0.0385],\n",
      "        [    0.2992],\n",
      "        [    0.4771],\n",
      "        [   13.2992],\n",
      "        [   13.0263],\n",
      "        [  163.9022],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    3.3670],\n",
      "        [    0.2992],\n",
      "        [    2.2119],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2837],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.4715],\n",
      "        [    2.2992],\n",
      "        [    1.8507],\n",
      "        [    3.7992],\n",
      "        [    4.7792],\n",
      "        [    4.7992],\n",
      "        [    6.9992],\n",
      "        [    9.4789],\n",
      "        [    1.2643],\n",
      "        [   10.2992],\n",
      "        [    3.3476],\n",
      "        [   10.7992],\n",
      "        [    5.3230],\n",
      "        [    3.1601],\n",
      "        [   22.3101],\n",
      "        [   25.3792],\n",
      "        [   24.1914]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 14.503767967224121\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 87\n",
      "剩餘X 資料 torch.Size([116, 10])\n",
      "剩餘Y 資料 torch.Size([116, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (645.9827880859375, 44)\n",
      "The second_loss value of k: (697.768310546875, 34)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引44，y= tensor([66.5000])\n",
      "目前模型的Data狀態 torch.Size([95, 1])\n",
      "<<預測值>>\n",
      "tensor([[   116.5735],\n",
      "        [    -0.0672],\n",
      "        [   304.5420],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    36.1379],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [     9.6993],\n",
      "        [    -0.2992],\n",
      "        [     5.3162],\n",
      "        [   224.1493],\n",
      "        [    87.3515],\n",
      "        [    -0.2992],\n",
      "        [     0.4771],\n",
      "        [    -0.2992],\n",
      "        [    13.0263],\n",
      "        [   163.9022],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [     3.3670],\n",
      "        [    -0.2992],\n",
      "        [     2.2119],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [     0.2837],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    10.4715],\n",
      "        [    -0.2992],\n",
      "        [   224.1493],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [    -0.2992],\n",
      "        [     9.4789],\n",
      "        [     1.2643],\n",
      "        [    -0.2992],\n",
      "        [     3.3476],\n",
      "        [    -0.2992],\n",
      "        [    93.6770],\n",
      "        [     3.1601],\n",
      "        [    22.3101],\n",
      "        [    -0.2992],\n",
      "        [    24.1914],\n",
      "        [    91.9162]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  201.4265],\n",
      "        [    0.0672],\n",
      "        [   21.2280],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [   16.5592],\n",
      "        [   35.1379],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    4.6993],\n",
      "        [    0.2992],\n",
      "        [    5.3162],\n",
      "        [    1.8507],\n",
      "        [    0.0385],\n",
      "        [    0.2992],\n",
      "        [    0.4771],\n",
      "        [   13.2992],\n",
      "        [   13.0263],\n",
      "        [  163.9022],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    3.3670],\n",
      "        [    0.2992],\n",
      "        [    2.2119],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2837],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.2992],\n",
      "        [    0.4715],\n",
      "        [    2.2992],\n",
      "        [    1.8507],\n",
      "        [    3.7992],\n",
      "        [    4.7792],\n",
      "        [    4.7992],\n",
      "        [    6.9992],\n",
      "        [    9.4789],\n",
      "        [    1.2643],\n",
      "        [   10.2992],\n",
      "        [    3.3476],\n",
      "        [   10.7992],\n",
      "        [    5.3230],\n",
      "        [    3.1601],\n",
      "        [   22.3101],\n",
      "        [   25.3792],\n",
      "        [   24.1914],\n",
      "        [   25.4162]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(764.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  204.7377],\n",
      "        [    0.2608],\n",
      "        [   20.0055],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [   16.5208],\n",
      "        [   36.2114],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.1324],\n",
      "        [    0.2608],\n",
      "        [    4.9543],\n",
      "        [    6.1128],\n",
      "        [    0.0748],\n",
      "        [    0.2608],\n",
      "        [    0.6151],\n",
      "        [   13.2608],\n",
      "        [   11.3612],\n",
      "        [  159.9861],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    4.0861],\n",
      "        [    0.2608],\n",
      "        [    3.0722],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    1.4671],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.7039],\n",
      "        [    2.2608],\n",
      "        [    6.1128],\n",
      "        [    3.7608],\n",
      "        [    4.7408],\n",
      "        [    4.7608],\n",
      "        [    6.9608],\n",
      "        [    9.7962],\n",
      "        [    0.2608],\n",
      "        [   10.2608],\n",
      "        [    0.2608],\n",
      "        [   10.7608],\n",
      "        [    3.1093],\n",
      "        [    1.8134],\n",
      "        [   21.9276],\n",
      "        [   25.3408],\n",
      "        [   23.8730],\n",
      "        [   18.0126]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 14.801332950592041\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 88\n",
      "剩餘X 資料 torch.Size([115, 10])\n",
      "剩餘Y 資料 torch.Size([115, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (582.8257446289062, 34)\n",
      "The second_loss value of k: (791.1719360351562, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引34，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([96, 1])\n",
      "<<預測值>>\n",
      "tensor([[   113.2623],\n",
      "        [    -0.2608],\n",
      "        [   305.7645],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    37.2114],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [     5.1324],\n",
      "        [    -0.2608],\n",
      "        [     4.9543],\n",
      "        [   219.8872],\n",
      "        [    87.3152],\n",
      "        [    -0.2608],\n",
      "        [     0.6151],\n",
      "        [    -0.2608],\n",
      "        [    11.3612],\n",
      "        [   159.9861],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [     4.0861],\n",
      "        [    -0.2608],\n",
      "        [     3.0722],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [     1.4671],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    10.7039],\n",
      "        [    -0.2608],\n",
      "        [   219.8872],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [     9.7962],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    -0.2608],\n",
      "        [    95.8907],\n",
      "        [     1.8134],\n",
      "        [    21.9276],\n",
      "        [    -0.2608],\n",
      "        [    23.8730],\n",
      "        [    84.5126],\n",
      "        [    24.1418]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  204.7377],\n",
      "        [    0.2608],\n",
      "        [   20.0055],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [   16.5208],\n",
      "        [   36.2114],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.1324],\n",
      "        [    0.2608],\n",
      "        [    4.9543],\n",
      "        [    6.1128],\n",
      "        [    0.0748],\n",
      "        [    0.2608],\n",
      "        [    0.6151],\n",
      "        [   13.2608],\n",
      "        [   11.3612],\n",
      "        [  159.9861],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    4.0861],\n",
      "        [    0.2608],\n",
      "        [    3.0722],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    1.4671],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.2608],\n",
      "        [    0.7039],\n",
      "        [    2.2608],\n",
      "        [    6.1128],\n",
      "        [    3.7608],\n",
      "        [    4.7408],\n",
      "        [    4.7608],\n",
      "        [    6.9608],\n",
      "        [    9.7962],\n",
      "        [    0.2608],\n",
      "        [   10.2608],\n",
      "        [    0.2608],\n",
      "        [   10.7608],\n",
      "        [    3.1093],\n",
      "        [    1.8134],\n",
      "        [   21.9276],\n",
      "        [   25.3408],\n",
      "        [   23.8730],\n",
      "        [   18.0126],\n",
      "        [   24.1418]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(760.1901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  209.3363],\n",
      "        [    0.2185],\n",
      "        [   16.7172],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [   16.4785],\n",
      "        [   36.1352],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.7919],\n",
      "        [    0.2185],\n",
      "        [    4.4895],\n",
      "        [    4.7156],\n",
      "        [    0.1782],\n",
      "        [    0.2185],\n",
      "        [    1.2713],\n",
      "        [   13.2185],\n",
      "        [    9.6234],\n",
      "        [  154.9621],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    2.9932],\n",
      "        [    0.2185],\n",
      "        [    1.8098],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.4870],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.6744],\n",
      "        [    2.2185],\n",
      "        [    4.7156],\n",
      "        [    3.7185],\n",
      "        [    4.6985],\n",
      "        [    4.7185],\n",
      "        [    6.9185],\n",
      "        [    9.8201],\n",
      "        [    0.2185],\n",
      "        [   10.2185],\n",
      "        [    0.2185],\n",
      "        [   10.7185],\n",
      "        [    2.2851],\n",
      "        [    0.5602],\n",
      "        [   21.7327],\n",
      "        [   25.2985],\n",
      "        [   23.6063],\n",
      "        [   15.0822],\n",
      "        [   20.6459]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.104278326034546\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 89\n",
      "剩餘X 資料 torch.Size([114, 10])\n",
      "剩餘Y 資料 torch.Size([114, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (696.3134765625, 6)\n",
      "The second_loss value of k: (999.0079956054688, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([97, 1])\n",
      "<<預測值>>\n",
      "tensor([[   108.6637],\n",
      "        [    -0.2185],\n",
      "        [   309.0528],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    37.1352],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [     4.2081],\n",
      "        [    -0.2185],\n",
      "        [     4.4895],\n",
      "        [   221.2844],\n",
      "        [    87.5682],\n",
      "        [    -0.2185],\n",
      "        [     1.2713],\n",
      "        [    -0.2185],\n",
      "        [     9.6234],\n",
      "        [   154.9621],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [     2.9932],\n",
      "        [    -0.2185],\n",
      "        [     1.8098],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [     0.4870],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    10.6744],\n",
      "        [    -0.2185],\n",
      "        [   221.2844],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [     9.8201],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    -0.2185],\n",
      "        [    96.7149],\n",
      "        [     0.5602],\n",
      "        [    21.7327],\n",
      "        [    -0.2185],\n",
      "        [    23.6063],\n",
      "        [    81.5822],\n",
      "        [    20.6459],\n",
      "        [    26.3878]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  209.3363],\n",
      "        [    0.2185],\n",
      "        [   16.7172],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [   16.4785],\n",
      "        [   36.1352],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.7919],\n",
      "        [    0.2185],\n",
      "        [    4.4895],\n",
      "        [    4.7156],\n",
      "        [    0.1782],\n",
      "        [    0.2185],\n",
      "        [    1.2713],\n",
      "        [   13.2185],\n",
      "        [    9.6234],\n",
      "        [  154.9621],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    2.9932],\n",
      "        [    0.2185],\n",
      "        [    1.8098],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.4870],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.2185],\n",
      "        [    0.6744],\n",
      "        [    2.2185],\n",
      "        [    4.7156],\n",
      "        [    3.7185],\n",
      "        [    4.6985],\n",
      "        [    4.7185],\n",
      "        [    6.9185],\n",
      "        [    9.8201],\n",
      "        [    0.2185],\n",
      "        [   10.2185],\n",
      "        [    0.2185],\n",
      "        [   10.7185],\n",
      "        [    2.2851],\n",
      "        [    0.5602],\n",
      "        [   21.7327],\n",
      "        [   25.2985],\n",
      "        [   23.6063],\n",
      "        [   15.0822],\n",
      "        [   20.6459],\n",
      "        [   26.3878]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(757.6678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  208.5843],\n",
      "        [    0.1682],\n",
      "        [   18.8727],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [   16.4282],\n",
      "        [   35.9678],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    5.1682],\n",
      "        [    0.1682],\n",
      "        [    5.2555],\n",
      "        [    2.8152],\n",
      "        [    0.0610],\n",
      "        [    0.1682],\n",
      "        [    0.0828],\n",
      "        [   13.1682],\n",
      "        [    6.0533],\n",
      "        [  156.8755],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    3.0743],\n",
      "        [    0.1682],\n",
      "        [    1.2480],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.4387],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.4839],\n",
      "        [    2.1682],\n",
      "        [    2.8152],\n",
      "        [    3.6682],\n",
      "        [    4.6482],\n",
      "        [    4.6682],\n",
      "        [    6.8682],\n",
      "        [    9.7418],\n",
      "        [    0.1682],\n",
      "        [   10.1682],\n",
      "        [    0.1682],\n",
      "        [   10.6682],\n",
      "        [    1.1294],\n",
      "        [    0.1682],\n",
      "        [   20.3474],\n",
      "        [   25.2482],\n",
      "        [   21.8254],\n",
      "        [    9.0158],\n",
      "        [   19.3130],\n",
      "        [    1.0271]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.393633127212524\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 90\n",
      "剩餘X 資料 torch.Size([113, 10])\n",
      "剩餘Y 資料 torch.Size([113, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1015.4788818359375, 1)\n",
      "The second_loss value of k: (1073.7564697265625, 68)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([98, 1])\n",
      "<<預測值>>\n",
      "tensor([[   109.4157],\n",
      "        [    -0.1682],\n",
      "        [   306.8973],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    36.9678],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [     5.2555],\n",
      "        [   223.1848],\n",
      "        [    87.4510],\n",
      "        [    -0.1682],\n",
      "        [    -0.0828],\n",
      "        [    -0.1682],\n",
      "        [     6.0533],\n",
      "        [   156.8755],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [     3.0743],\n",
      "        [    -0.1682],\n",
      "        [     1.2480],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [     0.4387],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    10.4839],\n",
      "        [    -0.1682],\n",
      "        [   223.1848],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [     9.7418],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    -0.1682],\n",
      "        [    97.8706],\n",
      "        [    -0.1682],\n",
      "        [    20.3474],\n",
      "        [    -0.1682],\n",
      "        [    21.8254],\n",
      "        [    75.5158],\n",
      "        [    19.3130],\n",
      "        [     1.0271],\n",
      "        [    31.8666]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  208.5843],\n",
      "        [    0.1682],\n",
      "        [   18.8727],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [   16.4282],\n",
      "        [   35.9678],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    5.1682],\n",
      "        [    0.1682],\n",
      "        [    5.2555],\n",
      "        [    2.8152],\n",
      "        [    0.0610],\n",
      "        [    0.1682],\n",
      "        [    0.0828],\n",
      "        [   13.1682],\n",
      "        [    6.0533],\n",
      "        [  156.8755],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    3.0743],\n",
      "        [    0.1682],\n",
      "        [    1.2480],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.4387],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.1682],\n",
      "        [    0.4839],\n",
      "        [    2.1682],\n",
      "        [    2.8152],\n",
      "        [    3.6682],\n",
      "        [    4.6482],\n",
      "        [    4.6682],\n",
      "        [    6.8682],\n",
      "        [    9.7418],\n",
      "        [    0.1682],\n",
      "        [   10.1682],\n",
      "        [    0.1682],\n",
      "        [   10.6682],\n",
      "        [    1.1294],\n",
      "        [    0.1682],\n",
      "        [   20.3474],\n",
      "        [   25.2482],\n",
      "        [   21.8254],\n",
      "        [    9.0158],\n",
      "        [   19.3130],\n",
      "        [    1.0271],\n",
      "        [   31.8666]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(752.5649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  208.5755],\n",
      "        [    0.0941],\n",
      "        [   15.6207],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [   16.3541],\n",
      "        [   36.5326],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    5.0941],\n",
      "        [    0.0941],\n",
      "        [    2.6974],\n",
      "        [    2.8676],\n",
      "        [    0.0549],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [   13.0941],\n",
      "        [    5.8159],\n",
      "        [  157.2641],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    2.3071],\n",
      "        [    0.0941],\n",
      "        [    0.3539],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [   10.0941],\n",
      "        [    2.0941],\n",
      "        [    2.8676],\n",
      "        [    3.5941],\n",
      "        [    4.5741],\n",
      "        [    4.5941],\n",
      "        [    6.7941],\n",
      "        [    9.6378],\n",
      "        [    0.0941],\n",
      "        [   10.0941],\n",
      "        [    0.0941],\n",
      "        [   10.5941],\n",
      "        [    0.6725],\n",
      "        [    0.0941],\n",
      "        [   20.0342],\n",
      "        [   25.1741],\n",
      "        [   21.9158],\n",
      "        [    8.6401],\n",
      "        [   18.4358],\n",
      "        [    1.1861],\n",
      "        [    0.9252]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.665247678756714\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 91\n",
      "剩餘X 資料 torch.Size([112, 10])\n",
      "剩餘Y 資料 torch.Size([112, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1068.9041748046875, 67)\n",
      "The second_loss value of k: (1095.219482421875, 105)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引67，y= tensor([32.6000])\n",
      "目前模型的Data狀態 torch.Size([99, 1])\n",
      "<<預測值>>\n",
      "tensor([[   109.4245],\n",
      "        [    -0.0941],\n",
      "        [   310.1493],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    37.5326],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [     2.6974],\n",
      "        [   223.1324],\n",
      "        [    87.3351],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [     5.8159],\n",
      "        [   157.2641],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [     2.3071],\n",
      "        [    -0.0941],\n",
      "        [     0.3539],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [   223.1324],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [     9.6378],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    -0.0941],\n",
      "        [    99.6725],\n",
      "        [    -0.0941],\n",
      "        [    20.0342],\n",
      "        [    -0.0941],\n",
      "        [    21.9158],\n",
      "        [    75.1401],\n",
      "        [    18.4358],\n",
      "        [     1.1861],\n",
      "        [     0.9252],\n",
      "        [    -0.0941]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  208.5755],\n",
      "        [    0.0941],\n",
      "        [   15.6207],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [   16.3541],\n",
      "        [   36.5326],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    5.0941],\n",
      "        [    0.0941],\n",
      "        [    2.6974],\n",
      "        [    2.8676],\n",
      "        [    0.0549],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [   13.0941],\n",
      "        [    5.8159],\n",
      "        [  157.2641],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    2.3071],\n",
      "        [    0.0941],\n",
      "        [    0.3539],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [    0.0941],\n",
      "        [   10.0941],\n",
      "        [    2.0941],\n",
      "        [    2.8676],\n",
      "        [    3.5941],\n",
      "        [    4.5741],\n",
      "        [    4.5941],\n",
      "        [    6.7941],\n",
      "        [    9.6378],\n",
      "        [    0.0941],\n",
      "        [   10.0941],\n",
      "        [    0.0941],\n",
      "        [   10.5941],\n",
      "        [    0.6725],\n",
      "        [    0.0941],\n",
      "        [   20.0342],\n",
      "        [   25.1741],\n",
      "        [   21.9158],\n",
      "        [    8.6401],\n",
      "        [   18.4358],\n",
      "        [    1.1861],\n",
      "        [    0.9252],\n",
      "        [   32.6941]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(746.0484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  208.6752],\n",
      "        [    0.0734],\n",
      "        [   15.4034],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [   16.3334],\n",
      "        [   36.6189],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    5.0734],\n",
      "        [    0.0734],\n",
      "        [    2.2110],\n",
      "        [    2.8667],\n",
      "        [    0.1064],\n",
      "        [    0.0734],\n",
      "        [    0.0027],\n",
      "        [   13.0734],\n",
      "        [    5.7916],\n",
      "        [  157.1411],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    2.3346],\n",
      "        [    0.0734],\n",
      "        [    0.5484],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [   10.0734],\n",
      "        [    2.0734],\n",
      "        [    2.8667],\n",
      "        [    3.5734],\n",
      "        [    4.5534],\n",
      "        [    4.5734],\n",
      "        [    6.7734],\n",
      "        [    9.4807],\n",
      "        [    0.0734],\n",
      "        [   10.0734],\n",
      "        [    0.0734],\n",
      "        [   10.5734],\n",
      "        [    0.9611],\n",
      "        [    0.0734],\n",
      "        [   19.8175],\n",
      "        [   25.1534],\n",
      "        [   21.7799],\n",
      "        [    8.0909],\n",
      "        [   18.3263],\n",
      "        [    0.6333],\n",
      "        [    0.8077],\n",
      "        [   32.6734]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.934669971466064\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 92\n",
      "剩餘X 資料 torch.Size([111, 10])\n",
      "剩餘Y 資料 torch.Size([111, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1093.8521728515625, 104)\n",
      "The second_loss value of k: (1160.9991455078125, 4)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引104，y= tensor([33.])\n",
      "目前模型的Data狀態 torch.Size([100, 1])\n",
      "<<預測值>>\n",
      "tensor([[   109.3248],\n",
      "        [    -0.0734],\n",
      "        [   310.3665],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    37.6189],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [     2.2110],\n",
      "        [   223.1333],\n",
      "        [    87.2836],\n",
      "        [    -0.0734],\n",
      "        [     0.0027],\n",
      "        [    -0.0734],\n",
      "        [     5.7916],\n",
      "        [   157.1411],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [     2.3346],\n",
      "        [    -0.0734],\n",
      "        [     0.5484],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [   223.1333],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [     9.4807],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734],\n",
      "        [    99.9611],\n",
      "        [    -0.0734],\n",
      "        [    19.8175],\n",
      "        [    -0.0734],\n",
      "        [    21.7799],\n",
      "        [    74.5909],\n",
      "        [    18.3263],\n",
      "        [     0.6333],\n",
      "        [     0.8077],\n",
      "        [    -0.0734],\n",
      "        [    -0.0734]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  208.6752],\n",
      "        [    0.0734],\n",
      "        [   15.4034],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [   16.3334],\n",
      "        [   36.6189],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    5.0734],\n",
      "        [    0.0734],\n",
      "        [    2.2110],\n",
      "        [    2.8667],\n",
      "        [    0.1064],\n",
      "        [    0.0734],\n",
      "        [    0.0027],\n",
      "        [   13.0734],\n",
      "        [    5.7916],\n",
      "        [  157.1411],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    2.3346],\n",
      "        [    0.0734],\n",
      "        [    0.5484],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [    0.0734],\n",
      "        [   10.0734],\n",
      "        [    2.0734],\n",
      "        [    2.8667],\n",
      "        [    3.5734],\n",
      "        [    4.5534],\n",
      "        [    4.5734],\n",
      "        [    6.7734],\n",
      "        [    9.4807],\n",
      "        [    0.0734],\n",
      "        [   10.0734],\n",
      "        [    0.0734],\n",
      "        [   10.5734],\n",
      "        [    0.9611],\n",
      "        [    0.0734],\n",
      "        [   19.8175],\n",
      "        [   25.1534],\n",
      "        [   21.7799],\n",
      "        [    8.0909],\n",
      "        [   18.3263],\n",
      "        [    0.6333],\n",
      "        [    0.8077],\n",
      "        [   32.6734],\n",
      "        [   33.0734]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(749.1501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  208.3060],\n",
      "        [    0.0556],\n",
      "        [   14.8895],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [   16.3156],\n",
      "        [   36.7330],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    5.0556],\n",
      "        [    0.0556],\n",
      "        [    2.7072],\n",
      "        [    2.6201],\n",
      "        [    0.0076],\n",
      "        [    0.0556],\n",
      "        [    0.7826],\n",
      "        [   13.0556],\n",
      "        [    5.6728],\n",
      "        [  157.5419],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    2.6619],\n",
      "        [    0.0556],\n",
      "        [    0.7147],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [   10.0556],\n",
      "        [    2.0556],\n",
      "        [    2.6201],\n",
      "        [    3.5556],\n",
      "        [    4.5356],\n",
      "        [    4.5556],\n",
      "        [    6.7556],\n",
      "        [    9.3422],\n",
      "        [    0.0556],\n",
      "        [   10.0556],\n",
      "        [    0.0556],\n",
      "        [   10.5556],\n",
      "        [    1.2055],\n",
      "        [    0.0556],\n",
      "        [   19.7193],\n",
      "        [   25.1356],\n",
      "        [   21.6055],\n",
      "        [    8.3510],\n",
      "        [   18.6710],\n",
      "        [    1.4023],\n",
      "        [    1.1198],\n",
      "        [   32.6556],\n",
      "        [   33.0556]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 16.204126119613647\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 93\n",
      "剩餘X 資料 torch.Size([110, 10])\n",
      "剩餘Y 資料 torch.Size([110, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1159.781982421875, 4)\n",
      "The second_loss value of k: (1228.8931884765625, 8)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引4，y= tensor([34.])\n",
      "目前模型的Data狀態 torch.Size([101, 1])\n",
      "<<預測值>>\n",
      "tensor([[   109.6940],\n",
      "        [    -0.0556],\n",
      "        [   310.8805],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    37.7330],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [     2.7072],\n",
      "        [   223.3799],\n",
      "        [    87.3824],\n",
      "        [    -0.0556],\n",
      "        [     0.7826],\n",
      "        [    -0.0556],\n",
      "        [     5.6728],\n",
      "        [   157.5419],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [     2.6619],\n",
      "        [    -0.0556],\n",
      "        [     0.7147],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [   223.3799],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [     9.3422],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [   100.2055],\n",
      "        [    -0.0556],\n",
      "        [    19.7193],\n",
      "        [    -0.0556],\n",
      "        [    21.6055],\n",
      "        [    74.8510],\n",
      "        [    18.6710],\n",
      "        [     1.4023],\n",
      "        [     1.1198],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556],\n",
      "        [    -0.0556]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  208.3060],\n",
      "        [    0.0556],\n",
      "        [   14.8895],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [   16.3156],\n",
      "        [   36.7330],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    5.0556],\n",
      "        [    0.0556],\n",
      "        [    2.7072],\n",
      "        [    2.6201],\n",
      "        [    0.0076],\n",
      "        [    0.0556],\n",
      "        [    0.7826],\n",
      "        [   13.0556],\n",
      "        [    5.6728],\n",
      "        [  157.5419],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    2.6619],\n",
      "        [    0.0556],\n",
      "        [    0.7147],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [    0.0556],\n",
      "        [   10.0556],\n",
      "        [    2.0556],\n",
      "        [    2.6201],\n",
      "        [    3.5556],\n",
      "        [    4.5356],\n",
      "        [    4.5556],\n",
      "        [    6.7556],\n",
      "        [    9.3422],\n",
      "        [    0.0556],\n",
      "        [   10.0556],\n",
      "        [    0.0556],\n",
      "        [   10.5556],\n",
      "        [    1.2055],\n",
      "        [    0.0556],\n",
      "        [   19.7193],\n",
      "        [   25.1356],\n",
      "        [   21.6055],\n",
      "        [    8.3510],\n",
      "        [   18.6710],\n",
      "        [    1.4023],\n",
      "        [    1.1198],\n",
      "        [   32.6556],\n",
      "        [   33.0556],\n",
      "        [   34.0556]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(752.8689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  208.3021],\n",
      "        [    0.0349],\n",
      "        [   14.3417],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [   16.2949],\n",
      "        [   36.8263],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    5.0349],\n",
      "        [    0.0349],\n",
      "        [    2.6028],\n",
      "        [    2.5658],\n",
      "        [    0.0326],\n",
      "        [    0.0349],\n",
      "        [    0.8125],\n",
      "        [   13.0349],\n",
      "        [    5.7319],\n",
      "        [  157.5466],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    2.8194],\n",
      "        [    0.0349],\n",
      "        [    0.9131],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [   10.0349],\n",
      "        [    2.0349],\n",
      "        [    2.5658],\n",
      "        [    3.5349],\n",
      "        [    4.5149],\n",
      "        [    4.5349],\n",
      "        [    6.7349],\n",
      "        [    9.1787],\n",
      "        [    0.0349],\n",
      "        [   10.0349],\n",
      "        [    0.0349],\n",
      "        [   10.5349],\n",
      "        [    1.4831],\n",
      "        [    0.0349],\n",
      "        [   19.5888],\n",
      "        [   25.1149],\n",
      "        [   21.5041],\n",
      "        [    7.9862],\n",
      "        [   18.5980],\n",
      "        [    1.2822],\n",
      "        [    0.8003],\n",
      "        [   32.6349],\n",
      "        [   33.0349],\n",
      "        [   34.0349]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 16.474120616912842\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 94\n",
      "剩餘X 資料 torch.Size([109, 10])\n",
      "剩餘Y 資料 torch.Size([109, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1227.4442138671875, 7)\n",
      "The second_loss value of k: (1446.6536865234375, 32)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引7，y= tensor([35.])\n",
      "目前模型的Data狀態 torch.Size([102, 1])\n",
      "<<預測值>>\n",
      "tensor([[   109.6979],\n",
      "        [    -0.0349],\n",
      "        [   311.4283],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    37.8263],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [     2.6028],\n",
      "        [   223.4342],\n",
      "        [    87.4226],\n",
      "        [    -0.0349],\n",
      "        [     0.8125],\n",
      "        [    -0.0349],\n",
      "        [     5.7319],\n",
      "        [   157.5466],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [     2.8194],\n",
      "        [    -0.0349],\n",
      "        [     0.9131],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [   223.4342],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [     9.1787],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [   100.4831],\n",
      "        [    -0.0349],\n",
      "        [    19.5888],\n",
      "        [    -0.0349],\n",
      "        [    21.5041],\n",
      "        [    74.4862],\n",
      "        [    18.5980],\n",
      "        [     1.2822],\n",
      "        [     0.8003],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349],\n",
      "        [    -0.0349]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  208.3021],\n",
      "        [    0.0349],\n",
      "        [   14.3417],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [   16.2949],\n",
      "        [   36.8263],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    5.0349],\n",
      "        [    0.0349],\n",
      "        [    2.6028],\n",
      "        [    2.5658],\n",
      "        [    0.0326],\n",
      "        [    0.0349],\n",
      "        [    0.8125],\n",
      "        [   13.0349],\n",
      "        [    5.7319],\n",
      "        [  157.5466],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    2.8194],\n",
      "        [    0.0349],\n",
      "        [    0.9131],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [    0.0349],\n",
      "        [   10.0349],\n",
      "        [    2.0349],\n",
      "        [    2.5658],\n",
      "        [    3.5349],\n",
      "        [    4.5149],\n",
      "        [    4.5349],\n",
      "        [    6.7349],\n",
      "        [    9.1787],\n",
      "        [    0.0349],\n",
      "        [   10.0349],\n",
      "        [    0.0349],\n",
      "        [   10.5349],\n",
      "        [    1.4831],\n",
      "        [    0.0349],\n",
      "        [   19.5888],\n",
      "        [   25.1149],\n",
      "        [   21.5041],\n",
      "        [    7.9862],\n",
      "        [   18.5980],\n",
      "        [    1.2822],\n",
      "        [    0.8003],\n",
      "        [   32.6349],\n",
      "        [   33.0349],\n",
      "        [   34.0349],\n",
      "        [   35.0349]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(757.1417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 74\n",
      "Number of shrink: 26\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  208.3741],\n",
      "        [    0.0155],\n",
      "        [   14.6742],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [   16.2755],\n",
      "        [   36.9334],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    5.0155],\n",
      "        [    0.0155],\n",
      "        [    2.7717],\n",
      "        [    2.6545],\n",
      "        [    0.0500],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [   13.0155],\n",
      "        [    5.2517],\n",
      "        [  157.4100],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    3.0575],\n",
      "        [    0.0155],\n",
      "        [    1.0660],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [   10.0155],\n",
      "        [    2.0155],\n",
      "        [    2.6545],\n",
      "        [    3.5155],\n",
      "        [    4.4955],\n",
      "        [    4.5155],\n",
      "        [    6.7155],\n",
      "        [    9.0219],\n",
      "        [    0.0155],\n",
      "        [   10.0155],\n",
      "        [    0.0155],\n",
      "        [   10.5155],\n",
      "        [    1.7384],\n",
      "        [    0.0155],\n",
      "        [   19.2723],\n",
      "        [   25.0955],\n",
      "        [   21.1351],\n",
      "        [    7.7688],\n",
      "        [   18.6124],\n",
      "        [    1.3131],\n",
      "        [    0.8276],\n",
      "        [   32.6155],\n",
      "        [   33.0155],\n",
      "        [   34.0155],\n",
      "        [   35.0155]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 16.742684841156006\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 95\n",
      "剩餘X 資料 torch.Size([108, 10])\n",
      "剩餘Y 資料 torch.Size([108, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1445.1759033203125, 31)\n",
      "The second_loss value of k: (1517.888671875, 5)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引31，y= tensor([38.])\n",
      "目前模型的Data狀態 torch.Size([103, 1])\n",
      "<<預測值>>\n",
      "tensor([[   109.6259],\n",
      "        [    -0.0155],\n",
      "        [   311.0958],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    37.9334],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [     2.7717],\n",
      "        [   223.3455],\n",
      "        [    87.3400],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [     5.2517],\n",
      "        [   157.4100],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [     3.0575],\n",
      "        [    -0.0155],\n",
      "        [     1.0660],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [   223.3455],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [     9.0219],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [   100.7384],\n",
      "        [    -0.0155],\n",
      "        [    19.2723],\n",
      "        [    -0.0155],\n",
      "        [    21.1351],\n",
      "        [    74.2688],\n",
      "        [    18.6124],\n",
      "        [     1.3131],\n",
      "        [     0.8276],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155],\n",
      "        [    -0.0155]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  208.3741],\n",
      "        [    0.0155],\n",
      "        [   14.6742],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [   16.2755],\n",
      "        [   36.9334],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    5.0155],\n",
      "        [    0.0155],\n",
      "        [    2.7717],\n",
      "        [    2.6545],\n",
      "        [    0.0500],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [   13.0155],\n",
      "        [    5.2517],\n",
      "        [  157.4100],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    3.0575],\n",
      "        [    0.0155],\n",
      "        [    1.0660],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [    0.0155],\n",
      "        [   10.0155],\n",
      "        [    2.0155],\n",
      "        [    2.6545],\n",
      "        [    3.5155],\n",
      "        [    4.4955],\n",
      "        [    4.5155],\n",
      "        [    6.7155],\n",
      "        [    9.0219],\n",
      "        [    0.0155],\n",
      "        [   10.0155],\n",
      "        [    0.0155],\n",
      "        [   10.5155],\n",
      "        [    1.7384],\n",
      "        [    0.0155],\n",
      "        [   19.2723],\n",
      "        [   25.0955],\n",
      "        [   21.1351],\n",
      "        [    7.7688],\n",
      "        [   18.6124],\n",
      "        [    1.3131],\n",
      "        [    0.8276],\n",
      "        [   32.6155],\n",
      "        [   33.0155],\n",
      "        [   34.0155],\n",
      "        [   35.0155],\n",
      "        [   38.0155]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(763.4301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  208.1518],\n",
      "        [    0.0058],\n",
      "        [   14.5472],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [   16.2542],\n",
      "        [   36.9664],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    4.9942],\n",
      "        [    0.0058],\n",
      "        [    2.1680],\n",
      "        [    2.4824],\n",
      "        [    0.0728],\n",
      "        [    0.0058],\n",
      "        [    0.6779],\n",
      "        [   12.9942],\n",
      "        [    5.5504],\n",
      "        [  157.6267],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    3.0575],\n",
      "        [    0.0058],\n",
      "        [    1.2956],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    9.9942],\n",
      "        [    1.9942],\n",
      "        [    2.4824],\n",
      "        [    3.4942],\n",
      "        [    4.4742],\n",
      "        [    4.4942],\n",
      "        [    6.6942],\n",
      "        [    8.8329],\n",
      "        [    0.0058],\n",
      "        [    9.9942],\n",
      "        [    0.0058],\n",
      "        [   10.4942],\n",
      "        [    1.8568],\n",
      "        [    0.0058],\n",
      "        [   19.1130],\n",
      "        [   25.0742],\n",
      "        [   21.0917],\n",
      "        [    7.8454],\n",
      "        [   18.7771],\n",
      "        [    1.7023],\n",
      "        [    0.7794],\n",
      "        [   32.5942],\n",
      "        [   32.9942],\n",
      "        [   33.9942],\n",
      "        [   34.9942],\n",
      "        [   37.9942]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 17.01160454750061\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 96\n",
      "剩餘X 資料 torch.Size([107, 10])\n",
      "剩餘Y 資料 torch.Size([107, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1520.99853515625, 5)\n",
      "The second_loss value of k: (1545.1622314453125, 66)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引5，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([104, 1])\n",
      "<<預測值>>\n",
      "tensor([[  109.8482],\n",
      "        [    0.0058],\n",
      "        [  311.2228],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [   37.9664],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    2.1680],\n",
      "        [  223.5176],\n",
      "        [   87.3172],\n",
      "        [    0.0058],\n",
      "        [    0.6779],\n",
      "        [    0.0058],\n",
      "        [    5.5504],\n",
      "        [  157.6267],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    3.0575],\n",
      "        [    0.0058],\n",
      "        [    1.2956],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [  223.5176],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    8.8329],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [  100.8568],\n",
      "        [    0.0058],\n",
      "        [   19.1130],\n",
      "        [    0.0058],\n",
      "        [   21.0917],\n",
      "        [   74.3454],\n",
      "        [   18.7771],\n",
      "        [    1.7023],\n",
      "        [    0.7794],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [   39.0000]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  208.1518],\n",
      "        [    0.0058],\n",
      "        [   14.5472],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [   16.2542],\n",
      "        [   36.9664],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    4.9942],\n",
      "        [    0.0058],\n",
      "        [    2.1680],\n",
      "        [    2.4824],\n",
      "        [    0.0728],\n",
      "        [    0.0058],\n",
      "        [    0.6779],\n",
      "        [   12.9942],\n",
      "        [    5.5504],\n",
      "        [  157.6267],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    3.0575],\n",
      "        [    0.0058],\n",
      "        [    1.2956],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    0.0058],\n",
      "        [    9.9942],\n",
      "        [    1.9942],\n",
      "        [    2.4824],\n",
      "        [    3.4942],\n",
      "        [    4.4742],\n",
      "        [    4.4942],\n",
      "        [    6.6942],\n",
      "        [    8.8329],\n",
      "        [    0.0058],\n",
      "        [    9.9942],\n",
      "        [    0.0058],\n",
      "        [   10.4942],\n",
      "        [    1.8568],\n",
      "        [    0.0058],\n",
      "        [   19.1130],\n",
      "        [   25.0742],\n",
      "        [   21.0917],\n",
      "        [    7.8454],\n",
      "        [   18.7771],\n",
      "        [    1.7023],\n",
      "        [    0.7794],\n",
      "        [   32.5942],\n",
      "        [   32.9942],\n",
      "        [   33.9942],\n",
      "        [   34.9942],\n",
      "        [   37.9942],\n",
      "        [   39.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(770.3232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  208.9562],\n",
      "        [    0.0513],\n",
      "        [   16.0869],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [   16.2087],\n",
      "        [   34.5448],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    4.9487],\n",
      "        [    0.0513],\n",
      "        [    3.9457],\n",
      "        [    2.9951],\n",
      "        [    0.0509],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [   12.9487],\n",
      "        [    2.4919],\n",
      "        [  157.4430],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.4971],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    9.9487],\n",
      "        [    1.9487],\n",
      "        [    2.9951],\n",
      "        [    3.4487],\n",
      "        [    4.4287],\n",
      "        [    4.4487],\n",
      "        [    6.6487],\n",
      "        [    8.2681],\n",
      "        [    0.0513],\n",
      "        [    9.9487],\n",
      "        [    0.0513],\n",
      "        [   10.4487],\n",
      "        [    1.3689],\n",
      "        [    0.0513],\n",
      "        [   18.7073],\n",
      "        [   25.0287],\n",
      "        [   19.9804],\n",
      "        [    9.3087],\n",
      "        [   17.7047],\n",
      "        [    0.5919],\n",
      "        [    0.5909],\n",
      "        [   32.5487],\n",
      "        [   32.9487],\n",
      "        [   33.9487],\n",
      "        [   34.9487],\n",
      "        [   37.9487],\n",
      "        [   36.4733]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 17.280394792556763\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 97\n",
      "剩餘X 資料 torch.Size([106, 10])\n",
      "剩餘Y 資料 torch.Size([106, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1394.302734375, 65)\n",
      "The second_loss value of k: (1707.846435546875, 5)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引65，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([105, 1])\n",
      "<<預測值>>\n",
      "tensor([[  109.0438],\n",
      "        [    0.0513],\n",
      "        [  309.6831],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [   35.5448],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    3.9457],\n",
      "        [  223.0049],\n",
      "        [   87.3391],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    2.4919],\n",
      "        [  157.4430],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.4971],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [  223.0049],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    8.2681],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [   97.6311],\n",
      "        [    0.0513],\n",
      "        [   18.7073],\n",
      "        [    0.0513],\n",
      "        [   19.9804],\n",
      "        [   75.8087],\n",
      "        [   17.7047],\n",
      "        [    0.5919],\n",
      "        [    0.5909],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [   36.4733],\n",
      "        [   37.3404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  208.9562],\n",
      "        [    0.0513],\n",
      "        [   16.0869],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [   16.2087],\n",
      "        [   34.5448],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    4.9487],\n",
      "        [    0.0513],\n",
      "        [    3.9457],\n",
      "        [    2.9951],\n",
      "        [    0.0509],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [   12.9487],\n",
      "        [    2.4919],\n",
      "        [  157.4430],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.4971],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    0.0513],\n",
      "        [    9.9487],\n",
      "        [    1.9487],\n",
      "        [    2.9951],\n",
      "        [    3.4487],\n",
      "        [    4.4287],\n",
      "        [    4.4487],\n",
      "        [    6.6487],\n",
      "        [    8.2681],\n",
      "        [    0.0513],\n",
      "        [    9.9487],\n",
      "        [    0.0513],\n",
      "        [   10.4487],\n",
      "        [    1.3689],\n",
      "        [    0.0513],\n",
      "        [   18.7073],\n",
      "        [   25.0287],\n",
      "        [   19.9804],\n",
      "        [    9.3087],\n",
      "        [   17.7047],\n",
      "        [    0.5919],\n",
      "        [    0.5909],\n",
      "        [   32.5487],\n",
      "        [   32.9487],\n",
      "        [   33.9487],\n",
      "        [   34.9487],\n",
      "        [   37.9487],\n",
      "        [   36.4733],\n",
      "        [   37.3404]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(774.6183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  210.0274],\n",
      "        [    0.1339],\n",
      "        [   23.1971],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [   16.1261],\n",
      "        [   31.5544],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    4.8661],\n",
      "        [    0.1339],\n",
      "        [    7.4122],\n",
      "        [    3.9726],\n",
      "        [    0.1759],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [   12.8661],\n",
      "        [    0.1339],\n",
      "        [  157.5916],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    9.8661],\n",
      "        [    1.8661],\n",
      "        [    3.9726],\n",
      "        [    3.3661],\n",
      "        [    4.3461],\n",
      "        [    4.3661],\n",
      "        [    6.5661],\n",
      "        [    7.5206],\n",
      "        [    0.1339],\n",
      "        [    9.8661],\n",
      "        [    0.1339],\n",
      "        [   10.3661],\n",
      "        [    3.8475],\n",
      "        [    0.1339],\n",
      "        [   15.0024],\n",
      "        [   24.9461],\n",
      "        [   14.3724],\n",
      "        [   11.7978],\n",
      "        [   17.1883],\n",
      "        [    0.1339],\n",
      "        [    1.1657],\n",
      "        [   32.4661],\n",
      "        [   32.8661],\n",
      "        [   33.8661],\n",
      "        [   34.8661],\n",
      "        [   37.8661],\n",
      "        [   33.0631],\n",
      "        [   26.5427]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 17.548595428466797\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 98\n",
      "剩餘X 資料 torch.Size([105, 10])\n",
      "剩餘Y 資料 torch.Size([105, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1695.361083984375, 5)\n",
      "The second_loss value of k: (1711.155517578125, 44)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引5，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([106, 1])\n",
      "<<預測值>>\n",
      "tensor([[  107.9726],\n",
      "        [    0.1339],\n",
      "        [  302.5729],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [   32.5544],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    7.4122],\n",
      "        [  222.0274],\n",
      "        [   87.2141],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [  157.5916],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [  222.0274],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    7.5206],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [   95.1525],\n",
      "        [    0.1339],\n",
      "        [   15.0024],\n",
      "        [    0.1339],\n",
      "        [   14.3724],\n",
      "        [   78.2978],\n",
      "        [   17.1883],\n",
      "        [    0.1339],\n",
      "        [    1.1657],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [   33.0631],\n",
      "        [   26.5427],\n",
      "        [   41.1748]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  210.0274],\n",
      "        [    0.1339],\n",
      "        [   23.1971],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [   16.1261],\n",
      "        [   31.5544],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    4.8661],\n",
      "        [    0.1339],\n",
      "        [    7.4122],\n",
      "        [    3.9726],\n",
      "        [    0.1759],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [   12.8661],\n",
      "        [    0.1339],\n",
      "        [  157.5916],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    0.1339],\n",
      "        [    9.8661],\n",
      "        [    1.8661],\n",
      "        [    3.9726],\n",
      "        [    3.3661],\n",
      "        [    4.3461],\n",
      "        [    4.3661],\n",
      "        [    6.5661],\n",
      "        [    7.5206],\n",
      "        [    0.1339],\n",
      "        [    9.8661],\n",
      "        [    0.1339],\n",
      "        [   10.3661],\n",
      "        [    3.8475],\n",
      "        [    0.1339],\n",
      "        [   15.0024],\n",
      "        [   24.9461],\n",
      "        [   14.3724],\n",
      "        [   11.7978],\n",
      "        [   17.1883],\n",
      "        [    0.1339],\n",
      "        [    1.1657],\n",
      "        [   32.4661],\n",
      "        [   32.8661],\n",
      "        [   33.8661],\n",
      "        [   34.8661],\n",
      "        [   37.8661],\n",
      "        [   33.0631],\n",
      "        [   26.5427],\n",
      "        [   41.1748]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(777.3629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  210.5846],\n",
      "        [    0.1933],\n",
      "        [   21.2232],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [   16.0667],\n",
      "        [   28.9455],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    4.8067],\n",
      "        [    0.1933],\n",
      "        [    9.4169],\n",
      "        [    3.0685],\n",
      "        [    0.0602],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [   12.8067],\n",
      "        [    0.1933],\n",
      "        [  158.4568],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    9.8067],\n",
      "        [    1.8067],\n",
      "        [    3.0685],\n",
      "        [    3.3067],\n",
      "        [    4.2867],\n",
      "        [    4.3067],\n",
      "        [    6.5067],\n",
      "        [    6.9018],\n",
      "        [    0.1933],\n",
      "        [    9.8067],\n",
      "        [    0.1933],\n",
      "        [   10.3067],\n",
      "        [    6.3069],\n",
      "        [    0.1933],\n",
      "        [   14.4638],\n",
      "        [   24.8867],\n",
      "        [   12.9626],\n",
      "        [   11.3498],\n",
      "        [   15.1522],\n",
      "        [    0.1933],\n",
      "        [    1.2641],\n",
      "        [   32.4067],\n",
      "        [   32.8067],\n",
      "        [   33.8067],\n",
      "        [   34.8067],\n",
      "        [   37.8067],\n",
      "        [   30.4576],\n",
      "        [   24.0507],\n",
      "        [   40.4383]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 17.81742763519287\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 99\n",
      "剩餘X 資料 torch.Size([104, 10])\n",
      "剩餘Y 資料 torch.Size([104, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1635.1029052734375, 66)\n",
      "The second_loss value of k: (1706.2423095703125, 43)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引66，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([107, 1])\n",
      "<<預測值>>\n",
      "tensor([[  107.4154],\n",
      "        [    0.1933],\n",
      "        [  304.5468],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [   29.9455],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    9.4169],\n",
      "        [  222.9315],\n",
      "        [   87.4502],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [  158.4568],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [  222.9315],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    6.9018],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [   92.6931],\n",
      "        [    0.1933],\n",
      "        [   14.4638],\n",
      "        [    0.1933],\n",
      "        [   12.9626],\n",
      "        [   77.8498],\n",
      "        [   15.1522],\n",
      "        [    0.1933],\n",
      "        [    1.2641],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [   30.4576],\n",
      "        [   24.0507],\n",
      "        [   40.4383],\n",
      "        [   40.4364]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  210.5846],\n",
      "        [    0.1933],\n",
      "        [   21.2232],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [   16.0667],\n",
      "        [   28.9455],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    4.8067],\n",
      "        [    0.1933],\n",
      "        [    9.4169],\n",
      "        [    3.0685],\n",
      "        [    0.0602],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [   12.8067],\n",
      "        [    0.1933],\n",
      "        [  158.4568],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    0.1933],\n",
      "        [    9.8067],\n",
      "        [    1.8067],\n",
      "        [    3.0685],\n",
      "        [    3.3067],\n",
      "        [    4.2867],\n",
      "        [    4.3067],\n",
      "        [    6.5067],\n",
      "        [    6.9018],\n",
      "        [    0.1933],\n",
      "        [    9.8067],\n",
      "        [    0.1933],\n",
      "        [   10.3067],\n",
      "        [    6.3069],\n",
      "        [    0.1933],\n",
      "        [   14.4638],\n",
      "        [   24.8867],\n",
      "        [   12.9626],\n",
      "        [   11.3498],\n",
      "        [   15.1522],\n",
      "        [    0.1933],\n",
      "        [    1.2641],\n",
      "        [   32.4067],\n",
      "        [   32.8067],\n",
      "        [   33.8067],\n",
      "        [   34.8067],\n",
      "        [   37.8067],\n",
      "        [   30.4576],\n",
      "        [   24.0507],\n",
      "        [   40.4383],\n",
      "        [   40.4364]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(783.3724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[210.3029],\n",
      "        [  0.2555],\n",
      "        [ 24.9170],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [ 16.0045],\n",
      "        [ 25.6906],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  4.7445],\n",
      "        [  0.2555],\n",
      "        [  6.3957],\n",
      "        [  1.1198],\n",
      "        [  7.2413],\n",
      "        [  0.2555],\n",
      "        [  1.4797],\n",
      "        [ 12.7445],\n",
      "        [  0.2555],\n",
      "        [160.7283],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  9.7445],\n",
      "        [  1.7445],\n",
      "        [  1.1198],\n",
      "        [  3.2445],\n",
      "        [  4.2245],\n",
      "        [  4.2445],\n",
      "        [  6.4445],\n",
      "        [  6.2093],\n",
      "        [  0.2555],\n",
      "        [  9.7445],\n",
      "        [  0.2555],\n",
      "        [ 10.2445],\n",
      "        [  9.3443],\n",
      "        [  0.2555],\n",
      "        [ 12.8157],\n",
      "        [ 24.8245],\n",
      "        [ 11.1430],\n",
      "        [  8.3038],\n",
      "        [ 12.5898],\n",
      "        [  0.2555],\n",
      "        [  0.4596],\n",
      "        [ 32.3445],\n",
      "        [ 32.7445],\n",
      "        [ 33.7445],\n",
      "        [ 34.7445],\n",
      "        [ 37.7445],\n",
      "        [ 27.6087],\n",
      "        [ 20.7829],\n",
      "        [ 39.1292],\n",
      "        [ 36.2559]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 18.087177515029907\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 100\n",
      "剩餘X 資料 torch.Size([103, 10])\n",
      "剩餘Y 資料 torch.Size([103, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1485.743896484375, 75)\n",
      "The second_loss value of k: (1701.1077880859375, 43)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引75，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([108, 1])\n",
      "<<預測值>>\n",
      "tensor([[  107.6971],\n",
      "        [    0.2555],\n",
      "        [  300.8530],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [   26.6906],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    6.3957],\n",
      "        [  224.8802],\n",
      "        [   80.1487],\n",
      "        [    0.2555],\n",
      "        [    1.4797],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [  160.7283],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [  224.8802],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    6.2093],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [   89.6557],\n",
      "        [    0.2555],\n",
      "        [   12.8157],\n",
      "        [    0.2555],\n",
      "        [   11.1430],\n",
      "        [   74.8038],\n",
      "        [   12.5898],\n",
      "        [    0.2555],\n",
      "        [    0.4596],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [    0.2555],\n",
      "        [   27.6087],\n",
      "        [   20.7829],\n",
      "        [   39.1292],\n",
      "        [   36.2559],\n",
      "        [   38.5453]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[210.3029],\n",
      "        [  0.2555],\n",
      "        [ 24.9170],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [ 16.0045],\n",
      "        [ 25.6906],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  4.7445],\n",
      "        [  0.2555],\n",
      "        [  6.3957],\n",
      "        [  1.1198],\n",
      "        [  7.2413],\n",
      "        [  0.2555],\n",
      "        [  1.4797],\n",
      "        [ 12.7445],\n",
      "        [  0.2555],\n",
      "        [160.7283],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  0.2555],\n",
      "        [  9.7445],\n",
      "        [  1.7445],\n",
      "        [  1.1198],\n",
      "        [  3.2445],\n",
      "        [  4.2245],\n",
      "        [  4.2445],\n",
      "        [  6.4445],\n",
      "        [  6.2093],\n",
      "        [  0.2555],\n",
      "        [  9.7445],\n",
      "        [  0.2555],\n",
      "        [ 10.2445],\n",
      "        [  9.3443],\n",
      "        [  0.2555],\n",
      "        [ 12.8157],\n",
      "        [ 24.8245],\n",
      "        [ 11.1430],\n",
      "        [  8.3038],\n",
      "        [ 12.5898],\n",
      "        [  0.2555],\n",
      "        [  0.4596],\n",
      "        [ 32.3445],\n",
      "        [ 32.7445],\n",
      "        [ 33.7445],\n",
      "        [ 34.7445],\n",
      "        [ 37.7445],\n",
      "        [ 27.6087],\n",
      "        [ 20.7829],\n",
      "        [ 39.1292],\n",
      "        [ 36.2559],\n",
      "        [ 38.5453]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(786.5170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[209.9401],\n",
      "        [  0.3354],\n",
      "        [ 23.9564],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [ 15.9246],\n",
      "        [ 21.4585],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  4.6646],\n",
      "        [  0.3354],\n",
      "        [  9.5709],\n",
      "        [  0.3962],\n",
      "        [  6.2072],\n",
      "        [  0.3354],\n",
      "        [  6.4000],\n",
      "        [ 12.6646],\n",
      "        [  0.3354],\n",
      "        [162.9332],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  9.6646],\n",
      "        [  1.6646],\n",
      "        [  0.3962],\n",
      "        [  3.1646],\n",
      "        [  4.1446],\n",
      "        [  4.1646],\n",
      "        [  6.3646],\n",
      "        [  5.2570],\n",
      "        [  0.3354],\n",
      "        [  9.6646],\n",
      "        [  0.3354],\n",
      "        [ 10.1646],\n",
      "        [ 14.5241],\n",
      "        [  0.3354],\n",
      "        [ 12.6079],\n",
      "        [ 24.7446],\n",
      "        [  9.7475],\n",
      "        [ 10.7468],\n",
      "        [ 11.1984],\n",
      "        [  0.3354],\n",
      "        [  1.0989],\n",
      "        [ 32.2646],\n",
      "        [ 32.6646],\n",
      "        [ 33.6646],\n",
      "        [ 34.6646],\n",
      "        [ 37.6646],\n",
      "        [ 23.2898],\n",
      "        [ 18.4143],\n",
      "        [ 37.4923],\n",
      "        [ 34.7205],\n",
      "        [ 33.1651]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 18.355222940444946\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 101\n",
      "剩餘X 資料 torch.Size([102, 10])\n",
      "剩餘Y 資料 torch.Size([102, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1451.825927734375, 27)\n",
      "The second_loss value of k: (1694.5224609375, 43)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引27，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([109, 1])\n",
      "<<預測值>>\n",
      "tensor([[108.0599],\n",
      "        [  0.3354],\n",
      "        [301.8136],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [ 22.4585],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  9.5709],\n",
      "        [225.6038],\n",
      "        [ 81.1828],\n",
      "        [  0.3354],\n",
      "        [  6.4000],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [162.9332],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [225.6038],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  5.2570],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [ 84.4759],\n",
      "        [  0.3354],\n",
      "        [ 12.6079],\n",
      "        [  0.3354],\n",
      "        [  9.7475],\n",
      "        [ 77.2468],\n",
      "        [ 11.1984],\n",
      "        [  0.3354],\n",
      "        [  1.0989],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [ 23.2898],\n",
      "        [ 18.4143],\n",
      "        [ 37.4923],\n",
      "        [ 34.7205],\n",
      "        [ 33.1651],\n",
      "        [ 38.1028]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[209.9401],\n",
      "        [  0.3354],\n",
      "        [ 23.9564],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [ 15.9246],\n",
      "        [ 21.4585],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  4.6646],\n",
      "        [  0.3354],\n",
      "        [  9.5709],\n",
      "        [  0.3962],\n",
      "        [  6.2072],\n",
      "        [  0.3354],\n",
      "        [  6.4000],\n",
      "        [ 12.6646],\n",
      "        [  0.3354],\n",
      "        [162.9332],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  0.3354],\n",
      "        [  9.6646],\n",
      "        [  1.6646],\n",
      "        [  0.3962],\n",
      "        [  3.1646],\n",
      "        [  4.1446],\n",
      "        [  4.1646],\n",
      "        [  6.3646],\n",
      "        [  5.2570],\n",
      "        [  0.3354],\n",
      "        [  9.6646],\n",
      "        [  0.3354],\n",
      "        [ 10.1646],\n",
      "        [ 14.5241],\n",
      "        [  0.3354],\n",
      "        [ 12.6079],\n",
      "        [ 24.7446],\n",
      "        [  9.7475],\n",
      "        [ 10.7468],\n",
      "        [ 11.1984],\n",
      "        [  0.3354],\n",
      "        [  1.0989],\n",
      "        [ 32.2646],\n",
      "        [ 32.6646],\n",
      "        [ 33.6646],\n",
      "        [ 34.6646],\n",
      "        [ 37.6646],\n",
      "        [ 23.2898],\n",
      "        [ 18.4143],\n",
      "        [ 37.4923],\n",
      "        [ 34.7205],\n",
      "        [ 33.1651],\n",
      "        [ 38.1028]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(788.0948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[211.1713],\n",
      "        [  0.4378],\n",
      "        [ 25.0539],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [ 15.8222],\n",
      "        [ 16.3275],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  4.5622],\n",
      "        [  0.4378],\n",
      "        [  8.0867],\n",
      "        [  1.5962],\n",
      "        [  6.1870],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [ 12.5622],\n",
      "        [  0.4378],\n",
      "        [163.8627],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  9.5622],\n",
      "        [  1.5622],\n",
      "        [  1.5962],\n",
      "        [  3.0622],\n",
      "        [  4.0422],\n",
      "        [  4.0622],\n",
      "        [  6.2622],\n",
      "        [  4.0944],\n",
      "        [  0.4378],\n",
      "        [  9.5622],\n",
      "        [  0.4378],\n",
      "        [ 10.0622],\n",
      "        [ 20.2105],\n",
      "        [  0.4378],\n",
      "        [ 11.0718],\n",
      "        [ 24.6422],\n",
      "        [  7.4154],\n",
      "        [ 12.1974],\n",
      "        [  7.4883],\n",
      "        [  0.4378],\n",
      "        [  1.3099],\n",
      "        [ 32.1622],\n",
      "        [ 32.5622],\n",
      "        [ 33.5622],\n",
      "        [ 34.5622],\n",
      "        [ 37.5622],\n",
      "        [ 18.0233],\n",
      "        [ 14.2888],\n",
      "        [ 35.9006],\n",
      "        [ 32.3739],\n",
      "        [ 26.6516],\n",
      "        [ 30.9657]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 18.62332820892334\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 102\n",
      "剩餘X 資料 torch.Size([101, 10])\n",
      "剩餘Y 資料 torch.Size([101, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1599.5721435546875, 16)\n",
      "The second_loss value of k: (1686.102294921875, 42)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引16，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([110, 1])\n",
      "<<預測值>>\n",
      "tensor([[106.8287],\n",
      "        [  0.4378],\n",
      "        [300.7161],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [ 17.3275],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  8.0867],\n",
      "        [224.4038],\n",
      "        [ 81.2029],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [163.8627],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [224.4038],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  4.0944],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [ 78.7895],\n",
      "        [  0.4378],\n",
      "        [ 11.0718],\n",
      "        [  0.4378],\n",
      "        [  7.4154],\n",
      "        [ 78.6974],\n",
      "        [  7.4883],\n",
      "        [  0.4378],\n",
      "        [  1.3099],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [ 18.0233],\n",
      "        [ 14.2888],\n",
      "        [ 35.9006],\n",
      "        [ 32.3739],\n",
      "        [ 26.6516],\n",
      "        [ 30.9657],\n",
      "        [ 39.9947]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[211.1713],\n",
      "        [  0.4378],\n",
      "        [ 25.0539],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [ 15.8222],\n",
      "        [ 16.3275],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  4.5622],\n",
      "        [  0.4378],\n",
      "        [  8.0867],\n",
      "        [  1.5962],\n",
      "        [  6.1870],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [ 12.5622],\n",
      "        [  0.4378],\n",
      "        [163.8627],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  0.4378],\n",
      "        [  9.5622],\n",
      "        [  1.5622],\n",
      "        [  1.5962],\n",
      "        [  3.0622],\n",
      "        [  4.0422],\n",
      "        [  4.0622],\n",
      "        [  6.2622],\n",
      "        [  4.0944],\n",
      "        [  0.4378],\n",
      "        [  9.5622],\n",
      "        [  0.4378],\n",
      "        [ 10.0622],\n",
      "        [ 20.2105],\n",
      "        [  0.4378],\n",
      "        [ 11.0718],\n",
      "        [ 24.6422],\n",
      "        [  7.4154],\n",
      "        [ 12.1974],\n",
      "        [  7.4883],\n",
      "        [  0.4378],\n",
      "        [  1.3099],\n",
      "        [ 32.1622],\n",
      "        [ 32.5622],\n",
      "        [ 33.5622],\n",
      "        [ 34.5622],\n",
      "        [ 37.5622],\n",
      "        [ 18.0233],\n",
      "        [ 14.2888],\n",
      "        [ 35.9006],\n",
      "        [ 32.3739],\n",
      "        [ 26.6516],\n",
      "        [ 30.9657],\n",
      "        [ 39.9947]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(787.5983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[212.9147],\n",
      "        [  0.5093],\n",
      "        [ 24.4651],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [ 15.7507],\n",
      "        [ 12.8372],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  4.4907],\n",
      "        [  0.5093],\n",
      "        [  3.8873],\n",
      "        [  6.4075],\n",
      "        [  6.5002],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [ 12.4907],\n",
      "        [  0.5093],\n",
      "        [163.3958],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  9.4907],\n",
      "        [  1.4907],\n",
      "        [  6.4075],\n",
      "        [  2.9907],\n",
      "        [  3.9707],\n",
      "        [  3.9907],\n",
      "        [  6.1907],\n",
      "        [  3.2912],\n",
      "        [  0.5093],\n",
      "        [  9.4907],\n",
      "        [  0.5093],\n",
      "        [  9.9907],\n",
      "        [ 23.8400],\n",
      "        [  0.5093],\n",
      "        [  9.9685],\n",
      "        [ 24.5707],\n",
      "        [  6.2832],\n",
      "        [ 11.1086],\n",
      "        [  4.6372],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [ 32.0907],\n",
      "        [ 32.4907],\n",
      "        [ 33.4907],\n",
      "        [ 34.4907],\n",
      "        [ 37.4907],\n",
      "        [ 14.3928],\n",
      "        [ 12.3995],\n",
      "        [ 35.0258],\n",
      "        [ 31.3372],\n",
      "        [ 22.1834],\n",
      "        [ 26.0787],\n",
      "        [ 36.1788]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 18.891674757003784\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 103\n",
      "剩餘X 資料 torch.Size([100, 10])\n",
      "剩餘Y 資料 torch.Size([100, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1534.50390625, 48)\n",
      "The second_loss value of k: (1680.239013671875, 41)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引48，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([111, 1])\n",
      "<<預測值>>\n",
      "tensor([[105.0853],\n",
      "        [  0.5093],\n",
      "        [301.3048],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [ 13.8372],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  3.8873],\n",
      "        [219.5925],\n",
      "        [ 80.8898],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [163.3958],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [219.5925],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  3.2912],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [ 75.1600],\n",
      "        [  0.5093],\n",
      "        [  9.9685],\n",
      "        [  0.5093],\n",
      "        [  6.2832],\n",
      "        [ 77.6086],\n",
      "        [  4.6372],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [ 14.3928],\n",
      "        [ 12.3995],\n",
      "        [ 35.0258],\n",
      "        [ 31.3372],\n",
      "        [ 22.1834],\n",
      "        [ 26.0787],\n",
      "        [ 36.1788],\n",
      "        [ 39.1727]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[212.9147],\n",
      "        [  0.5093],\n",
      "        [ 24.4651],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [ 15.7507],\n",
      "        [ 12.8372],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  4.4907],\n",
      "        [  0.5093],\n",
      "        [  3.8873],\n",
      "        [  6.4075],\n",
      "        [  6.5002],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [ 12.4907],\n",
      "        [  0.5093],\n",
      "        [163.3958],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [  9.4907],\n",
      "        [  1.4907],\n",
      "        [  6.4075],\n",
      "        [  2.9907],\n",
      "        [  3.9707],\n",
      "        [  3.9907],\n",
      "        [  6.1907],\n",
      "        [  3.2912],\n",
      "        [  0.5093],\n",
      "        [  9.4907],\n",
      "        [  0.5093],\n",
      "        [  9.9907],\n",
      "        [ 23.8400],\n",
      "        [  0.5093],\n",
      "        [  9.9685],\n",
      "        [ 24.5707],\n",
      "        [  6.2832],\n",
      "        [ 11.1086],\n",
      "        [  4.6372],\n",
      "        [  0.5093],\n",
      "        [  0.5093],\n",
      "        [ 32.0907],\n",
      "        [ 32.4907],\n",
      "        [ 33.4907],\n",
      "        [ 34.4907],\n",
      "        [ 37.4907],\n",
      "        [ 14.3928],\n",
      "        [ 12.3995],\n",
      "        [ 35.0258],\n",
      "        [ 31.3372],\n",
      "        [ 22.1834],\n",
      "        [ 26.0787],\n",
      "        [ 36.1788],\n",
      "        [ 39.1727]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(789.1171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[212.1285],\n",
      "        [  0.5751],\n",
      "        [ 21.5706],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [ 15.6849],\n",
      "        [  9.4048],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  4.4249],\n",
      "        [  0.5751],\n",
      "        [  5.0885],\n",
      "        [  4.9658],\n",
      "        [  5.5517],\n",
      "        [  0.5751],\n",
      "        [  4.2701],\n",
      "        [ 12.4249],\n",
      "        [  0.5751],\n",
      "        [165.8994],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  9.4249],\n",
      "        [  1.4249],\n",
      "        [  4.9658],\n",
      "        [  2.9249],\n",
      "        [  3.9049],\n",
      "        [  3.9249],\n",
      "        [  6.1249],\n",
      "        [  2.5213],\n",
      "        [  3.3776],\n",
      "        [  9.4249],\n",
      "        [  0.5751],\n",
      "        [  9.9249],\n",
      "        [ 27.8946],\n",
      "        [  0.5751],\n",
      "        [ 10.1279],\n",
      "        [ 24.5049],\n",
      "        [  5.7648],\n",
      "        [ 13.6622],\n",
      "        [  3.4878],\n",
      "        [  0.5751],\n",
      "        [  1.5985],\n",
      "        [ 32.0249],\n",
      "        [ 32.4249],\n",
      "        [ 33.4249],\n",
      "        [ 34.4249],\n",
      "        [ 37.4249],\n",
      "        [ 10.9018],\n",
      "        [ 11.7004],\n",
      "        [ 33.7742],\n",
      "        [ 30.3214],\n",
      "        [ 17.8444],\n",
      "        [ 21.3158],\n",
      "        [ 33.9168],\n",
      "        [ 36.0485]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 19.16002321243286\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 104\n",
      "剩餘X 資料 torch.Size([99, 10])\n",
      "剩餘Y 資料 torch.Size([99, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1674.8458251953125, 41)\n",
      "The second_loss value of k: (1717.90234375, 58)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引41，y= tensor([41.5000])\n",
      "目前模型的Data狀態 torch.Size([112, 1])\n",
      "<<預測值>>\n",
      "tensor([[105.8715],\n",
      "        [  0.5751],\n",
      "        [304.1994],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [ 10.4048],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  5.0885],\n",
      "        [221.0342],\n",
      "        [ 81.8383],\n",
      "        [  0.5751],\n",
      "        [  4.2701],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [165.8994],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [221.0342],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  2.5213],\n",
      "        [  3.3776],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [ 71.1054],\n",
      "        [  0.5751],\n",
      "        [ 10.1279],\n",
      "        [  0.5751],\n",
      "        [  5.7648],\n",
      "        [ 80.1622],\n",
      "        [  3.4878],\n",
      "        [  0.5751],\n",
      "        [  1.5985],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [ 10.9018],\n",
      "        [ 11.7004],\n",
      "        [ 33.7742],\n",
      "        [ 30.3214],\n",
      "        [ 17.8444],\n",
      "        [ 21.3158],\n",
      "        [ 33.9168],\n",
      "        [ 36.0485],\n",
      "        [  0.5751]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[212.1285],\n",
      "        [  0.5751],\n",
      "        [ 21.5706],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [ 15.6849],\n",
      "        [  9.4048],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  4.4249],\n",
      "        [  0.5751],\n",
      "        [  5.0885],\n",
      "        [  4.9658],\n",
      "        [  5.5517],\n",
      "        [  0.5751],\n",
      "        [  4.2701],\n",
      "        [ 12.4249],\n",
      "        [  0.5751],\n",
      "        [165.8994],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  0.5751],\n",
      "        [  9.4249],\n",
      "        [  1.4249],\n",
      "        [  4.9658],\n",
      "        [  2.9249],\n",
      "        [  3.9049],\n",
      "        [  3.9249],\n",
      "        [  6.1249],\n",
      "        [  2.5213],\n",
      "        [  3.3776],\n",
      "        [  9.4249],\n",
      "        [  0.5751],\n",
      "        [  9.9249],\n",
      "        [ 27.8946],\n",
      "        [  0.5751],\n",
      "        [ 10.1279],\n",
      "        [ 24.5049],\n",
      "        [  5.7648],\n",
      "        [ 13.6622],\n",
      "        [  3.4878],\n",
      "        [  0.5751],\n",
      "        [  1.5985],\n",
      "        [ 32.0249],\n",
      "        [ 32.4249],\n",
      "        [ 33.4249],\n",
      "        [ 34.4249],\n",
      "        [ 37.4249],\n",
      "        [ 10.9018],\n",
      "        [ 11.7004],\n",
      "        [ 33.7742],\n",
      "        [ 30.3214],\n",
      "        [ 17.8444],\n",
      "        [ 21.3158],\n",
      "        [ 33.9168],\n",
      "        [ 36.0485],\n",
      "        [ 40.9249]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(792.1746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[212.7867],\n",
      "        [  0.6095],\n",
      "        [ 22.3617],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [ 15.6505],\n",
      "        [  7.5637],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  4.3905],\n",
      "        [  0.6095],\n",
      "        [  3.4369],\n",
      "        [  5.6933],\n",
      "        [  5.4586],\n",
      "        [  0.6095],\n",
      "        [  1.1508],\n",
      "        [ 12.3905],\n",
      "        [  0.6095],\n",
      "        [166.0187],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  9.3905],\n",
      "        [  1.3905],\n",
      "        [  5.6933],\n",
      "        [  2.8905],\n",
      "        [  3.8705],\n",
      "        [  3.8905],\n",
      "        [  6.0905],\n",
      "        [  2.1231],\n",
      "        [  1.3476],\n",
      "        [  9.3905],\n",
      "        [  0.6095],\n",
      "        [  9.8905],\n",
      "        [ 29.8910],\n",
      "        [  0.6095],\n",
      "        [  9.5442],\n",
      "        [ 24.4705],\n",
      "        [  5.1061],\n",
      "        [ 13.0694],\n",
      "        [  1.7601],\n",
      "        [  0.6095],\n",
      "        [  1.1164],\n",
      "        [ 31.9905],\n",
      "        [ 32.3905],\n",
      "        [ 33.3905],\n",
      "        [ 34.3905],\n",
      "        [ 37.3905],\n",
      "        [  9.0984],\n",
      "        [ 10.5649],\n",
      "        [ 33.1395],\n",
      "        [ 29.3893],\n",
      "        [ 15.6103],\n",
      "        [ 18.8663],\n",
      "        [ 32.5207],\n",
      "        [ 34.4760],\n",
      "        [ 40.8905]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 19.430195093154907\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 105\n",
      "剩餘X 資料 torch.Size([98, 10])\n",
      "剩餘Y 資料 torch.Size([98, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1583.320068359375, 57)\n",
      "The second_loss value of k: (1696.6776123046875, 7)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引57，y= tensor([67.])\n",
      "目前模型的Data狀態 torch.Size([113, 1])\n",
      "<<預測值>>\n",
      "tensor([[105.2133],\n",
      "        [  0.6095],\n",
      "        [303.4083],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  8.5637],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  3.4369],\n",
      "        [220.3067],\n",
      "        [ 81.9314],\n",
      "        [  0.6095],\n",
      "        [  1.1508],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [166.0187],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [220.3067],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  2.1231],\n",
      "        [  1.3476],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [ 69.1090],\n",
      "        [  0.6095],\n",
      "        [  9.5442],\n",
      "        [  0.6095],\n",
      "        [  5.1061],\n",
      "        [ 79.5694],\n",
      "        [  1.7601],\n",
      "        [  0.6095],\n",
      "        [  1.1164],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  9.0984],\n",
      "        [ 10.5649],\n",
      "        [ 33.1395],\n",
      "        [ 29.3893],\n",
      "        [ 15.6103],\n",
      "        [ 18.8663],\n",
      "        [ 32.5207],\n",
      "        [ 34.4760],\n",
      "        [  0.6095],\n",
      "        [106.7910]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[212.7867],\n",
      "        [  0.6095],\n",
      "        [ 22.3617],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [ 15.6505],\n",
      "        [  7.5637],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  4.3905],\n",
      "        [  0.6095],\n",
      "        [  3.4369],\n",
      "        [  5.6933],\n",
      "        [  5.4586],\n",
      "        [  0.6095],\n",
      "        [  1.1508],\n",
      "        [ 12.3905],\n",
      "        [  0.6095],\n",
      "        [166.0187],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  0.6095],\n",
      "        [  9.3905],\n",
      "        [  1.3905],\n",
      "        [  5.6933],\n",
      "        [  2.8905],\n",
      "        [  3.8705],\n",
      "        [  3.8905],\n",
      "        [  6.0905],\n",
      "        [  2.1231],\n",
      "        [  1.3476],\n",
      "        [  9.3905],\n",
      "        [  0.6095],\n",
      "        [  9.8905],\n",
      "        [ 29.8910],\n",
      "        [  0.6095],\n",
      "        [  9.5442],\n",
      "        [ 24.4705],\n",
      "        [  5.1061],\n",
      "        [ 13.0694],\n",
      "        [  1.7601],\n",
      "        [  0.6095],\n",
      "        [  1.1164],\n",
      "        [ 31.9905],\n",
      "        [ 32.3905],\n",
      "        [ 33.3905],\n",
      "        [ 34.3905],\n",
      "        [ 37.3905],\n",
      "        [  9.0984],\n",
      "        [ 10.5649],\n",
      "        [ 33.1395],\n",
      "        [ 29.3893],\n",
      "        [ 15.6103],\n",
      "        [ 18.8663],\n",
      "        [ 32.5207],\n",
      "        [ 34.4760],\n",
      "        [ 40.8905],\n",
      "        [ 39.7910]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(797.4965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[212.7073],\n",
      "        [  0.6729],\n",
      "        [ 24.2397],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [ 15.5871],\n",
      "        [  4.5388],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  4.3271],\n",
      "        [  0.6729],\n",
      "        [  7.5523],\n",
      "        [  6.1731],\n",
      "        [  5.4282],\n",
      "        [  0.6729],\n",
      "        [  5.4421],\n",
      "        [ 12.3271],\n",
      "        [  0.6729],\n",
      "        [166.8622],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  9.3271],\n",
      "        [  1.3271],\n",
      "        [  6.1731],\n",
      "        [  2.8271],\n",
      "        [  3.8071],\n",
      "        [  3.8271],\n",
      "        [  6.0271],\n",
      "        [  1.3744],\n",
      "        [  3.0153],\n",
      "        [  9.3271],\n",
      "        [  0.6729],\n",
      "        [  9.8271],\n",
      "        [ 34.5304],\n",
      "        [  0.6729],\n",
      "        [  9.9324],\n",
      "        [ 24.4071],\n",
      "        [  4.5685],\n",
      "        [ 13.9624],\n",
      "        [  1.1813],\n",
      "        [  0.6729],\n",
      "        [  1.7680],\n",
      "        [ 31.9271],\n",
      "        [ 32.3271],\n",
      "        [ 33.3271],\n",
      "        [ 34.3271],\n",
      "        [ 37.3271],\n",
      "        [  6.1214],\n",
      "        [  9.8557],\n",
      "        [ 31.2582],\n",
      "        [ 27.9677],\n",
      "        [ 11.8500],\n",
      "        [ 14.7143],\n",
      "        [ 30.7071],\n",
      "        [ 31.2639],\n",
      "        [ 40.8271],\n",
      "        [ 34.7861]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 19.6988742351532\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 106\n",
      "剩餘X 資料 torch.Size([97, 10])\n",
      "剩餘Y 資料 torch.Size([97, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1479.8773193359375, 7)\n",
      "The second_loss value of k: (1635.0494384765625, 49)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引7，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([114, 1])\n",
      "<<預測值>>\n",
      "tensor([[105.2927],\n",
      "        [  0.6729],\n",
      "        [301.5303],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  5.5388],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  7.5523],\n",
      "        [219.8269],\n",
      "        [ 81.9618],\n",
      "        [  0.6729],\n",
      "        [  5.4421],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [166.8622],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [219.8269],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  1.3744],\n",
      "        [  3.0153],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [ 64.4696],\n",
      "        [  0.6729],\n",
      "        [  9.9324],\n",
      "        [  0.6729],\n",
      "        [  4.5685],\n",
      "        [ 80.4624],\n",
      "        [  1.1813],\n",
      "        [  0.6729],\n",
      "        [  1.7680],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  6.1214],\n",
      "        [  9.8557],\n",
      "        [ 31.2582],\n",
      "        [ 27.9677],\n",
      "        [ 11.8500],\n",
      "        [ 14.7143],\n",
      "        [ 30.7071],\n",
      "        [ 31.2639],\n",
      "        [  0.6729],\n",
      "        [101.7861],\n",
      "        [ 38.4692]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[212.7073],\n",
      "        [  0.6729],\n",
      "        [ 24.2397],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [ 15.5871],\n",
      "        [  4.5388],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  4.3271],\n",
      "        [  0.6729],\n",
      "        [  7.5523],\n",
      "        [  6.1731],\n",
      "        [  5.4282],\n",
      "        [  0.6729],\n",
      "        [  5.4421],\n",
      "        [ 12.3271],\n",
      "        [  0.6729],\n",
      "        [166.8622],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  0.6729],\n",
      "        [  9.3271],\n",
      "        [  1.3271],\n",
      "        [  6.1731],\n",
      "        [  2.8271],\n",
      "        [  3.8071],\n",
      "        [  3.8271],\n",
      "        [  6.0271],\n",
      "        [  1.3744],\n",
      "        [  3.0153],\n",
      "        [  9.3271],\n",
      "        [  0.6729],\n",
      "        [  9.8271],\n",
      "        [ 34.5304],\n",
      "        [  0.6729],\n",
      "        [  9.9324],\n",
      "        [ 24.4071],\n",
      "        [  4.5685],\n",
      "        [ 13.9624],\n",
      "        [  1.1813],\n",
      "        [  0.6729],\n",
      "        [  1.7680],\n",
      "        [ 31.9271],\n",
      "        [ 32.3271],\n",
      "        [ 33.3271],\n",
      "        [ 34.3271],\n",
      "        [ 37.3271],\n",
      "        [  6.1214],\n",
      "        [  9.8557],\n",
      "        [ 31.2582],\n",
      "        [ 27.9677],\n",
      "        [ 11.8500],\n",
      "        [ 14.7143],\n",
      "        [ 30.7071],\n",
      "        [ 31.2639],\n",
      "        [ 40.8271],\n",
      "        [ 34.7861],\n",
      "        [ 38.4692]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(798.8712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[213.8015],\n",
      "        [  0.7460],\n",
      "        [ 25.5284],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [ 15.5140],\n",
      "        [  2.3371],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  4.2540],\n",
      "        [  0.7460],\n",
      "        [  9.8279],\n",
      "        [  5.4523],\n",
      "        [ 13.6029],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [ 12.2540],\n",
      "        [  0.7460],\n",
      "        [165.6582],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  9.2540],\n",
      "        [  1.2540],\n",
      "        [  5.4523],\n",
      "        [  2.7540],\n",
      "        [  3.7340],\n",
      "        [  3.7540],\n",
      "        [  5.9540],\n",
      "        [  0.7460],\n",
      "        [  1.6547],\n",
      "        [  9.2540],\n",
      "        [  0.7460],\n",
      "        [  9.7540],\n",
      "        [ 38.7237],\n",
      "        [  0.7460],\n",
      "        [ 10.9940],\n",
      "        [ 24.3340],\n",
      "        [  5.3781],\n",
      "        [ 15.7201],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [ 31.8540],\n",
      "        [ 32.2540],\n",
      "        [ 33.2540],\n",
      "        [ 34.2540],\n",
      "        [ 37.2540],\n",
      "        [  3.9891],\n",
      "        [ 12.0313],\n",
      "        [ 29.1699],\n",
      "        [ 25.3446],\n",
      "        [  9.1775],\n",
      "        [ 11.7717],\n",
      "        [ 29.8420],\n",
      "        [ 28.5091],\n",
      "        [ 40.7540],\n",
      "        [ 29.6549],\n",
      "        [ 33.6910]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 19.966652154922485\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 107\n",
      "剩餘X 資料 torch.Size([96, 10])\n",
      "剩餘Y 資料 torch.Size([96, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1500.4830322265625, 48)\n",
      "The second_loss value of k: (1845.714599609375, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引48，y= tensor([106.2000])\n",
      "目前模型的Data狀態 torch.Size([115, 1])\n",
      "<<預測值>>\n",
      "tensor([[104.1985],\n",
      "        [  0.7460],\n",
      "        [300.2416],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  3.3371],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  9.8279],\n",
      "        [220.5477],\n",
      "        [ 73.7871],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [165.6582],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [220.5477],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  1.6547],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [ 60.2763],\n",
      "        [  0.7460],\n",
      "        [ 10.9940],\n",
      "        [  0.7460],\n",
      "        [  5.3781],\n",
      "        [ 82.2201],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  3.9891],\n",
      "        [ 12.0313],\n",
      "        [ 29.1699],\n",
      "        [ 25.3446],\n",
      "        [  9.1775],\n",
      "        [ 11.7717],\n",
      "        [ 29.8420],\n",
      "        [ 28.5091],\n",
      "        [  0.7460],\n",
      "        [ 96.6549],\n",
      "        [ 33.6910],\n",
      "        [144.9361]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[213.8015],\n",
      "        [  0.7460],\n",
      "        [ 25.5284],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [ 15.5140],\n",
      "        [  2.3371],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  4.2540],\n",
      "        [  0.7460],\n",
      "        [  9.8279],\n",
      "        [  5.4523],\n",
      "        [ 13.6029],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [ 12.2540],\n",
      "        [  0.7460],\n",
      "        [165.6582],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  9.2540],\n",
      "        [  1.2540],\n",
      "        [  5.4523],\n",
      "        [  2.7540],\n",
      "        [  3.7340],\n",
      "        [  3.7540],\n",
      "        [  5.9540],\n",
      "        [  0.7460],\n",
      "        [  1.6547],\n",
      "        [  9.2540],\n",
      "        [  0.7460],\n",
      "        [  9.7540],\n",
      "        [ 38.7237],\n",
      "        [  0.7460],\n",
      "        [ 10.9940],\n",
      "        [ 24.3340],\n",
      "        [  5.3781],\n",
      "        [ 15.7201],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [  0.7460],\n",
      "        [ 31.8540],\n",
      "        [ 32.2540],\n",
      "        [ 33.2540],\n",
      "        [ 34.2540],\n",
      "        [ 37.2540],\n",
      "        [  3.9891],\n",
      "        [ 12.0313],\n",
      "        [ 29.1699],\n",
      "        [ 25.3446],\n",
      "        [  9.1775],\n",
      "        [ 11.7717],\n",
      "        [ 29.8420],\n",
      "        [ 28.5091],\n",
      "        [ 40.7540],\n",
      "        [ 29.6549],\n",
      "        [ 33.6910],\n",
      "        [ 38.7361]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(799.2158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  213.5084],\n",
      "        [    0.8103],\n",
      "        [   35.3727],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [   15.4497],\n",
      "        [    0.1897],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    4.1897],\n",
      "        [    0.8103],\n",
      "        [   15.2765],\n",
      "        [    4.9752],\n",
      "        [   11.8066],\n",
      "        [    0.8103],\n",
      "        [    3.5226],\n",
      "        [   12.1897],\n",
      "        [    0.8103],\n",
      "        [  166.8239],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    9.1897],\n",
      "        [    1.1897],\n",
      "        [    4.9752],\n",
      "        [    2.6897],\n",
      "        [    3.6697],\n",
      "        [    3.6897],\n",
      "        [    5.8897],\n",
      "        [    0.8103],\n",
      "        [    1.9690],\n",
      "        [    9.1897],\n",
      "        [    0.8103],\n",
      "        [    9.6897],\n",
      "        [   43.4091],\n",
      "        [    0.8103],\n",
      "        [    9.4433],\n",
      "        [   24.2697],\n",
      "        [    2.2783],\n",
      "        [   16.0939],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    1.3467],\n",
      "        [   31.7897],\n",
      "        [   32.1897],\n",
      "        [   33.1897],\n",
      "        [   34.1897],\n",
      "        [   37.1897],\n",
      "        [    0.8617],\n",
      "        [    6.1399],\n",
      "        [   27.3030],\n",
      "        [   22.6979],\n",
      "        [    5.2127],\n",
      "        [    7.3882],\n",
      "        [   28.3065],\n",
      "        [   25.2401],\n",
      "        [   40.6897],\n",
      "        [   24.7429],\n",
      "        [   31.3256],\n",
      "        [   26.6908]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 20.235064268112183\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 108\n",
      "剩餘X 資料 torch.Size([95, 10])\n",
      "剩餘Y 資料 torch.Size([95, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1535.794677734375, 1)\n",
      "The second_loss value of k: (1865.3509521484375, 54)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([116, 1])\n",
      "<<預測值>>\n",
      "tensor([[104.4916],\n",
      "        [  0.8103],\n",
      "        [290.3973],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [ 15.2765],\n",
      "        [221.0248],\n",
      "        [ 75.5834],\n",
      "        [  0.8103],\n",
      "        [  3.5226],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [166.8239],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [221.0248],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  1.9690],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [ 55.5909],\n",
      "        [  0.8103],\n",
      "        [  9.4433],\n",
      "        [  0.8103],\n",
      "        [  2.2783],\n",
      "        [ 82.5939],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  1.3467],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8103],\n",
      "        [  0.8617],\n",
      "        [  6.1399],\n",
      "        [ 27.3030],\n",
      "        [ 22.6979],\n",
      "        [  5.2127],\n",
      "        [  7.3882],\n",
      "        [ 28.3065],\n",
      "        [ 25.2401],\n",
      "        [  0.8103],\n",
      "        [ 91.7429],\n",
      "        [ 31.3256],\n",
      "        [132.8908],\n",
      "        [ 39.1892]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  213.5084],\n",
      "        [    0.8103],\n",
      "        [   35.3727],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [   15.4497],\n",
      "        [    0.1897],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    4.1897],\n",
      "        [    0.8103],\n",
      "        [   15.2765],\n",
      "        [    4.9752],\n",
      "        [   11.8066],\n",
      "        [    0.8103],\n",
      "        [    3.5226],\n",
      "        [   12.1897],\n",
      "        [    0.8103],\n",
      "        [  166.8239],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    9.1897],\n",
      "        [    1.1897],\n",
      "        [    4.9752],\n",
      "        [    2.6897],\n",
      "        [    3.6697],\n",
      "        [    3.6897],\n",
      "        [    5.8897],\n",
      "        [    0.8103],\n",
      "        [    1.9690],\n",
      "        [    9.1897],\n",
      "        [    0.8103],\n",
      "        [    9.6897],\n",
      "        [   43.4091],\n",
      "        [    0.8103],\n",
      "        [    9.4433],\n",
      "        [   24.2697],\n",
      "        [    2.2783],\n",
      "        [   16.0939],\n",
      "        [    0.8103],\n",
      "        [    0.8103],\n",
      "        [    1.3467],\n",
      "        [   31.7897],\n",
      "        [   32.1897],\n",
      "        [   33.1897],\n",
      "        [   34.1897],\n",
      "        [   37.1897],\n",
      "        [    0.8617],\n",
      "        [    6.1399],\n",
      "        [   27.3030],\n",
      "        [   22.6979],\n",
      "        [    5.2127],\n",
      "        [    7.3882],\n",
      "        [   28.3065],\n",
      "        [   25.2401],\n",
      "        [   40.6897],\n",
      "        [   24.7429],\n",
      "        [   31.3256],\n",
      "        [   26.6908],\n",
      "        [   39.1892]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(799.4478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  214.3839],\n",
      "        [    0.8580],\n",
      "        [   37.2299],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [   15.4020],\n",
      "        [    0.1420],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    4.1420],\n",
      "        [    0.8580],\n",
      "        [   14.2711],\n",
      "        [    5.8783],\n",
      "        [   11.6331],\n",
      "        [    0.8580],\n",
      "        [    4.6242],\n",
      "        [   12.1420],\n",
      "        [    0.8580],\n",
      "        [  166.4228],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    9.1420],\n",
      "        [    1.1420],\n",
      "        [    5.8783],\n",
      "        [    2.6420],\n",
      "        [    3.6220],\n",
      "        [    3.6420],\n",
      "        [    5.8420],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    9.1420],\n",
      "        [    0.8580],\n",
      "        [    9.6420],\n",
      "        [   46.8418],\n",
      "        [    0.8580],\n",
      "        [    9.4621],\n",
      "        [   24.2220],\n",
      "        [    2.2347],\n",
      "        [   16.4077],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    1.3181],\n",
      "        [   31.7420],\n",
      "        [   32.1420],\n",
      "        [   33.1420],\n",
      "        [   34.1420],\n",
      "        [   37.1420],\n",
      "        [    0.8580],\n",
      "        [    6.2348],\n",
      "        [   26.0417],\n",
      "        [   21.5960],\n",
      "        [    2.2827],\n",
      "        [    4.1474],\n",
      "        [   26.7616],\n",
      "        [   22.8406],\n",
      "        [   40.6420],\n",
      "        [   21.1662],\n",
      "        [   29.3990],\n",
      "        [   23.9821],\n",
      "        [   36.4260]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 20.502686500549316\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 109\n",
      "剩餘X 資料 torch.Size([94, 10])\n",
      "剩餘Y 資料 torch.Size([94, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1644.534423828125, 24)\n",
      "The second_loss value of k: (1826.4342041015625, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引24，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([117, 1])\n",
      "<<預測值>>\n",
      "tensor([[103.6161],\n",
      "        [  0.8580],\n",
      "        [288.5401],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [ 14.2711],\n",
      "        [220.1217],\n",
      "        [ 75.7569],\n",
      "        [  0.8580],\n",
      "        [  4.6242],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [166.4228],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [220.1217],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [ 52.1582],\n",
      "        [  0.8580],\n",
      "        [  9.4621],\n",
      "        [  0.8580],\n",
      "        [  2.2347],\n",
      "        [ 82.9077],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  1.3181],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  0.8580],\n",
      "        [  6.2348],\n",
      "        [ 26.0417],\n",
      "        [ 21.5960],\n",
      "        [  2.2827],\n",
      "        [  4.1474],\n",
      "        [ 26.7616],\n",
      "        [ 22.8406],\n",
      "        [  0.8580],\n",
      "        [ 88.1662],\n",
      "        [ 29.3990],\n",
      "        [130.1821],\n",
      "        [ 36.4260],\n",
      "        [ 40.5529]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  214.3839],\n",
      "        [    0.8580],\n",
      "        [   37.2299],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [   15.4020],\n",
      "        [    0.1420],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    4.1420],\n",
      "        [    0.8580],\n",
      "        [   14.2711],\n",
      "        [    5.8783],\n",
      "        [   11.6331],\n",
      "        [    0.8580],\n",
      "        [    4.6242],\n",
      "        [   12.1420],\n",
      "        [    0.8580],\n",
      "        [  166.4228],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    9.1420],\n",
      "        [    1.1420],\n",
      "        [    5.8783],\n",
      "        [    2.6420],\n",
      "        [    3.6220],\n",
      "        [    3.6420],\n",
      "        [    5.8420],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    9.1420],\n",
      "        [    0.8580],\n",
      "        [    9.6420],\n",
      "        [   46.8418],\n",
      "        [    0.8580],\n",
      "        [    9.4621],\n",
      "        [   24.2220],\n",
      "        [    2.2347],\n",
      "        [   16.4077],\n",
      "        [    0.8580],\n",
      "        [    0.8580],\n",
      "        [    1.3181],\n",
      "        [   31.7420],\n",
      "        [   32.1420],\n",
      "        [   33.1420],\n",
      "        [   34.1420],\n",
      "        [   37.1420],\n",
      "        [    0.8580],\n",
      "        [    6.2348],\n",
      "        [   26.0417],\n",
      "        [   21.5960],\n",
      "        [    2.2827],\n",
      "        [    4.1474],\n",
      "        [   26.7616],\n",
      "        [   22.8406],\n",
      "        [   40.6420],\n",
      "        [   21.1662],\n",
      "        [   29.3990],\n",
      "        [   23.9821],\n",
      "        [   36.4260],\n",
      "        [   40.5529]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(803.7775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  213.9638],\n",
      "        [    0.9267],\n",
      "        [   36.9504],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [   15.3333],\n",
      "        [    0.0733],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    4.0733],\n",
      "        [    0.9267],\n",
      "        [   16.6637],\n",
      "        [    4.1438],\n",
      "        [   10.3577],\n",
      "        [    0.9267],\n",
      "        [    1.5081],\n",
      "        [   12.0733],\n",
      "        [    0.9267],\n",
      "        [  168.5569],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    9.0733],\n",
      "        [    1.0733],\n",
      "        [    4.1438],\n",
      "        [    2.5733],\n",
      "        [    3.5533],\n",
      "        [    3.5733],\n",
      "        [    5.7733],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    9.0733],\n",
      "        [    0.9267],\n",
      "        [    9.5733],\n",
      "        [   50.8878],\n",
      "        [    0.9267],\n",
      "        [   10.3521],\n",
      "        [   24.1533],\n",
      "        [    2.6635],\n",
      "        [   11.5298],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    1.6350],\n",
      "        [   31.6733],\n",
      "        [   32.0733],\n",
      "        [   33.0733],\n",
      "        [   34.0733],\n",
      "        [   37.0733],\n",
      "        [    0.9267],\n",
      "        [    7.4502],\n",
      "        [   23.8259],\n",
      "        [   19.8882],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [   26.1953],\n",
      "        [   20.0702],\n",
      "        [   40.5733],\n",
      "        [   16.6848],\n",
      "        [   26.8224],\n",
      "        [   21.9166],\n",
      "        [   33.1756],\n",
      "        [   35.5098]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 20.767106771469116\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 110\n",
      "剩餘X 資料 torch.Size([93, 10])\n",
      "剩餘Y 資料 torch.Size([93, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1670.4952392578125, 1)\n",
      "The second_loss value of k: (1760.152099609375, 21)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([118, 1])\n",
      "<<預測值>>\n",
      "tensor([[104.0362],\n",
      "        [  0.9267],\n",
      "        [288.8196],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [ 16.6637],\n",
      "        [221.8562],\n",
      "        [ 77.0323],\n",
      "        [  0.9267],\n",
      "        [  1.5081],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [168.5569],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [221.8562],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [ 48.1122],\n",
      "        [  0.9267],\n",
      "        [ 10.3521],\n",
      "        [  0.9267],\n",
      "        [  2.6635],\n",
      "        [ 78.0298],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  1.6350],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [  7.4502],\n",
      "        [ 23.8259],\n",
      "        [ 19.8882],\n",
      "        [  0.9267],\n",
      "        [  0.9267],\n",
      "        [ 26.1953],\n",
      "        [ 20.0702],\n",
      "        [  0.9267],\n",
      "        [ 83.6848],\n",
      "        [ 26.8224],\n",
      "        [128.1166],\n",
      "        [ 33.1756],\n",
      "        [ 35.5098],\n",
      "        [ 40.8717]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  213.9638],\n",
      "        [    0.9267],\n",
      "        [   36.9504],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [   15.3333],\n",
      "        [    0.0733],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    4.0733],\n",
      "        [    0.9267],\n",
      "        [   16.6637],\n",
      "        [    4.1438],\n",
      "        [   10.3577],\n",
      "        [    0.9267],\n",
      "        [    1.5081],\n",
      "        [   12.0733],\n",
      "        [    0.9267],\n",
      "        [  168.5569],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    9.0733],\n",
      "        [    1.0733],\n",
      "        [    4.1438],\n",
      "        [    2.5733],\n",
      "        [    3.5533],\n",
      "        [    3.5733],\n",
      "        [    5.7733],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    9.0733],\n",
      "        [    0.9267],\n",
      "        [    9.5733],\n",
      "        [   50.8878],\n",
      "        [    0.9267],\n",
      "        [   10.3521],\n",
      "        [   24.1533],\n",
      "        [    2.6635],\n",
      "        [   11.5298],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [    1.6350],\n",
      "        [   31.6733],\n",
      "        [   32.0733],\n",
      "        [   33.0733],\n",
      "        [   34.0733],\n",
      "        [   37.0733],\n",
      "        [    0.9267],\n",
      "        [    7.4502],\n",
      "        [   23.8259],\n",
      "        [   19.8882],\n",
      "        [    0.9267],\n",
      "        [    0.9267],\n",
      "        [   26.1953],\n",
      "        [   20.0702],\n",
      "        [   40.5733],\n",
      "        [   16.6848],\n",
      "        [   26.8224],\n",
      "        [   21.9166],\n",
      "        [   33.1756],\n",
      "        [   35.5098],\n",
      "        [   40.8717]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(806.0310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  214.4158],\n",
      "        [    0.9953],\n",
      "        [   40.4510],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [   15.2647],\n",
      "        [    0.0047],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    4.0047],\n",
      "        [    0.9953],\n",
      "        [   15.7402],\n",
      "        [    4.6080],\n",
      "        [    9.9369],\n",
      "        [    0.9953],\n",
      "        [    2.0937],\n",
      "        [   12.0047],\n",
      "        [    0.9953],\n",
      "        [  167.5603],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    9.0047],\n",
      "        [    1.0047],\n",
      "        [    4.6080],\n",
      "        [    2.5047],\n",
      "        [    3.4847],\n",
      "        [    3.5047],\n",
      "        [    5.7047],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    9.0047],\n",
      "        [    0.9953],\n",
      "        [    9.5047],\n",
      "        [   53.7392],\n",
      "        [    0.9953],\n",
      "        [   10.9399],\n",
      "        [   24.0847],\n",
      "        [    3.6503],\n",
      "        [   12.1454],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    1.0501],\n",
      "        [   31.6047],\n",
      "        [   32.0047],\n",
      "        [   33.0047],\n",
      "        [   34.0047],\n",
      "        [   37.0047],\n",
      "        [    0.9953],\n",
      "        [    9.9510],\n",
      "        [   22.0736],\n",
      "        [   19.0540],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [   25.9631],\n",
      "        [   18.3234],\n",
      "        [   40.5047],\n",
      "        [   12.7273],\n",
      "        [   25.0117],\n",
      "        [   21.3442],\n",
      "        [   30.9373],\n",
      "        [   32.6340],\n",
      "        [   38.7238]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 21.03997826576233\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 111\n",
      "剩餘X 資料 torch.Size([92, 10])\n",
      "剩餘Y 資料 torch.Size([92, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1567.4862060546875, 20)\n",
      "The second_loss value of k: (1681.7232666015625, 28)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引20，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([119, 1])\n",
      "<<預測值>>\n",
      "tensor([[103.5842],\n",
      "        [  0.9953],\n",
      "        [285.3189],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [ 15.7402],\n",
      "        [221.3920],\n",
      "        [ 77.4531],\n",
      "        [  0.9953],\n",
      "        [  2.0937],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [167.5603],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [221.3920],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [ 45.2608],\n",
      "        [  0.9953],\n",
      "        [ 10.9399],\n",
      "        [  0.9953],\n",
      "        [  3.6503],\n",
      "        [ 78.6454],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  1.0501],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [  9.9510],\n",
      "        [ 22.0736],\n",
      "        [ 19.0540],\n",
      "        [  0.9953],\n",
      "        [  0.9953],\n",
      "        [ 25.9631],\n",
      "        [ 18.3234],\n",
      "        [  0.9953],\n",
      "        [ 79.7273],\n",
      "        [ 25.0117],\n",
      "        [127.5442],\n",
      "        [ 30.9373],\n",
      "        [ 32.6340],\n",
      "        [ 38.7238],\n",
      "        [ 39.5915]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  214.4158],\n",
      "        [    0.9953],\n",
      "        [   40.4510],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [   15.2647],\n",
      "        [    0.0047],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    4.0047],\n",
      "        [    0.9953],\n",
      "        [   15.7402],\n",
      "        [    4.6080],\n",
      "        [    9.9369],\n",
      "        [    0.9953],\n",
      "        [    2.0937],\n",
      "        [   12.0047],\n",
      "        [    0.9953],\n",
      "        [  167.5603],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    9.0047],\n",
      "        [    1.0047],\n",
      "        [    4.6080],\n",
      "        [    2.5047],\n",
      "        [    3.4847],\n",
      "        [    3.5047],\n",
      "        [    5.7047],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    9.0047],\n",
      "        [    0.9953],\n",
      "        [    9.5047],\n",
      "        [   53.7392],\n",
      "        [    0.9953],\n",
      "        [   10.9399],\n",
      "        [   24.0847],\n",
      "        [    3.6503],\n",
      "        [   12.1454],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [    1.0501],\n",
      "        [   31.6047],\n",
      "        [   32.0047],\n",
      "        [   33.0047],\n",
      "        [   34.0047],\n",
      "        [   37.0047],\n",
      "        [    0.9953],\n",
      "        [    9.9510],\n",
      "        [   22.0736],\n",
      "        [   19.0540],\n",
      "        [    0.9953],\n",
      "        [    0.9953],\n",
      "        [   25.9631],\n",
      "        [   18.3234],\n",
      "        [   40.5047],\n",
      "        [   12.7273],\n",
      "        [   25.0117],\n",
      "        [   21.3442],\n",
      "        [   30.9373],\n",
      "        [   32.6340],\n",
      "        [   38.7238],\n",
      "        [   39.5915]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(808.2706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  213.9120],\n",
      "        [    1.0681],\n",
      "        [   39.5148],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [   15.1919],\n",
      "        [    0.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    3.9318],\n",
      "        [    1.0681],\n",
      "        [   17.3584],\n",
      "        [    3.8648],\n",
      "        [    9.1582],\n",
      "        [    1.0681],\n",
      "        [    7.1583],\n",
      "        [   11.9319],\n",
      "        [    1.0681],\n",
      "        [  168.4104],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    8.9319],\n",
      "        [    0.9319],\n",
      "        [    3.8648],\n",
      "        [    2.4318],\n",
      "        [    3.4118],\n",
      "        [    3.4318],\n",
      "        [    5.6318],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    8.9319],\n",
      "        [    1.0681],\n",
      "        [    9.4319],\n",
      "        [   56.8938],\n",
      "        [    1.0681],\n",
      "        [   11.9655],\n",
      "        [   24.0119],\n",
      "        [    4.5105],\n",
      "        [   13.5126],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    2.4022],\n",
      "        [   31.5318],\n",
      "        [   31.9319],\n",
      "        [   32.9319],\n",
      "        [   33.9319],\n",
      "        [   36.9319],\n",
      "        [    1.0681],\n",
      "        [   12.1351],\n",
      "        [   20.4846],\n",
      "        [   18.5449],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [   25.1946],\n",
      "        [   16.1967],\n",
      "        [   40.4319],\n",
      "        [    8.9828],\n",
      "        [   23.1431],\n",
      "        [   21.1283],\n",
      "        [   28.3988],\n",
      "        [   29.7958],\n",
      "        [   36.9814],\n",
      "        [   37.2757]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 21.364043712615967\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 112\n",
      "剩餘X 資料 torch.Size([91, 10])\n",
      "剩餘Y 資料 torch.Size([91, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1480.966064453125, 27)\n",
      "The second_loss value of k: (1843.143798828125, 50)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引27，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([120, 1])\n",
      "<<預測值>>\n",
      "tensor([[104.0881],\n",
      "        [  1.0681],\n",
      "        [286.2552],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [ 17.3584],\n",
      "        [222.1352],\n",
      "        [ 78.2318],\n",
      "        [  1.0681],\n",
      "        [  7.1583],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [168.4104],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [222.1352],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [ 42.1062],\n",
      "        [  1.0681],\n",
      "        [ 11.9655],\n",
      "        [  1.0681],\n",
      "        [  4.5105],\n",
      "        [ 80.0126],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  2.4022],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [ 12.1351],\n",
      "        [ 20.4846],\n",
      "        [ 18.5449],\n",
      "        [  1.0681],\n",
      "        [  1.0681],\n",
      "        [ 25.1946],\n",
      "        [ 16.1967],\n",
      "        [  1.0681],\n",
      "        [ 75.9828],\n",
      "        [ 23.1431],\n",
      "        [127.3283],\n",
      "        [ 28.3988],\n",
      "        [ 29.7958],\n",
      "        [ 36.9814],\n",
      "        [ 37.2757],\n",
      "        [ 38.4833]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  213.9120],\n",
      "        [    1.0681],\n",
      "        [   39.5148],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [   15.1919],\n",
      "        [    0.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    3.9318],\n",
      "        [    1.0681],\n",
      "        [   17.3584],\n",
      "        [    3.8648],\n",
      "        [    9.1582],\n",
      "        [    1.0681],\n",
      "        [    7.1583],\n",
      "        [   11.9319],\n",
      "        [    1.0681],\n",
      "        [  168.4104],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    8.9319],\n",
      "        [    0.9319],\n",
      "        [    3.8648],\n",
      "        [    2.4318],\n",
      "        [    3.4118],\n",
      "        [    3.4318],\n",
      "        [    5.6318],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    8.9319],\n",
      "        [    1.0681],\n",
      "        [    9.4319],\n",
      "        [   56.8938],\n",
      "        [    1.0681],\n",
      "        [   11.9655],\n",
      "        [   24.0119],\n",
      "        [    4.5105],\n",
      "        [   13.5126],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [    2.4022],\n",
      "        [   31.5318],\n",
      "        [   31.9319],\n",
      "        [   32.9319],\n",
      "        [   33.9319],\n",
      "        [   36.9319],\n",
      "        [    1.0681],\n",
      "        [   12.1351],\n",
      "        [   20.4846],\n",
      "        [   18.5449],\n",
      "        [    1.0681],\n",
      "        [    1.0681],\n",
      "        [   25.1946],\n",
      "        [   16.1967],\n",
      "        [   40.4319],\n",
      "        [    8.9828],\n",
      "        [   23.1431],\n",
      "        [   21.1283],\n",
      "        [   28.3988],\n",
      "        [   29.7958],\n",
      "        [   36.9814],\n",
      "        [   37.2757],\n",
      "        [   38.4833]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(809.5792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  214.4725],\n",
      "        [    1.1391],\n",
      "        [   39.3740],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [   15.1209],\n",
      "        [    0.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    3.8609],\n",
      "        [    1.1391],\n",
      "        [   19.1087],\n",
      "        [    4.3520],\n",
      "        [    8.5896],\n",
      "        [    1.1391],\n",
      "        [    5.3826],\n",
      "        [   11.8609],\n",
      "        [    1.1391],\n",
      "        [  168.2085],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    8.8609],\n",
      "        [    0.8609],\n",
      "        [    4.3520],\n",
      "        [    2.3609],\n",
      "        [    3.3409],\n",
      "        [    3.3609],\n",
      "        [    5.5609],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    8.8609],\n",
      "        [    1.1391],\n",
      "        [    9.3609],\n",
      "        [   60.3790],\n",
      "        [    1.1391],\n",
      "        [   12.8037],\n",
      "        [   23.9409],\n",
      "        [    5.0556],\n",
      "        [   13.7512],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    2.3481],\n",
      "        [   31.4609],\n",
      "        [   31.8609],\n",
      "        [   32.8609],\n",
      "        [   33.8609],\n",
      "        [   36.8609],\n",
      "        [    1.1391],\n",
      "        [   13.5815],\n",
      "        [   18.9100],\n",
      "        [   17.8874],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [   23.9821],\n",
      "        [   13.8309],\n",
      "        [   40.3609],\n",
      "        [    5.0160],\n",
      "        [   21.1490],\n",
      "        [   19.7306],\n",
      "        [   25.6033],\n",
      "        [   26.7644],\n",
      "        [   35.2588],\n",
      "        [   34.8491],\n",
      "        [   35.7920]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 21.641168117523193\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 113\n",
      "剩餘X 資料 torch.Size([90, 10])\n",
      "剩餘Y 資料 torch.Size([90, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1837.05810546875, 49)\n",
      "The second_loss value of k: (2486.11083984375, 36)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引49，y= tensor([44.])\n",
      "目前模型的Data狀態 torch.Size([121, 1])\n",
      "<<預測值>>\n",
      "tensor([[103.5275],\n",
      "        [  1.1391],\n",
      "        [286.3960],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [ 19.1087],\n",
      "        [221.6480],\n",
      "        [ 78.8004],\n",
      "        [  1.1391],\n",
      "        [  5.3826],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [168.2085],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [221.6480],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [ 38.6210],\n",
      "        [  1.1391],\n",
      "        [ 12.8037],\n",
      "        [  1.1391],\n",
      "        [  5.0556],\n",
      "        [ 80.2512],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  2.3481],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [ 13.5815],\n",
      "        [ 18.9100],\n",
      "        [ 17.8874],\n",
      "        [  1.1391],\n",
      "        [  1.1391],\n",
      "        [ 23.9821],\n",
      "        [ 13.8309],\n",
      "        [  1.1391],\n",
      "        [ 72.0160],\n",
      "        [ 21.1490],\n",
      "        [125.9306],\n",
      "        [ 25.6033],\n",
      "        [ 26.7644],\n",
      "        [ 35.2588],\n",
      "        [ 34.8491],\n",
      "        [ 35.7920],\n",
      "        [  1.1391]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  214.4725],\n",
      "        [    1.1391],\n",
      "        [   39.3740],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [   15.1209],\n",
      "        [    0.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    3.8609],\n",
      "        [    1.1391],\n",
      "        [   19.1087],\n",
      "        [    4.3520],\n",
      "        [    8.5896],\n",
      "        [    1.1391],\n",
      "        [    5.3826],\n",
      "        [   11.8609],\n",
      "        [    1.1391],\n",
      "        [  168.2085],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    8.8609],\n",
      "        [    0.8609],\n",
      "        [    4.3520],\n",
      "        [    2.3609],\n",
      "        [    3.3409],\n",
      "        [    3.3609],\n",
      "        [    5.5609],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    8.8609],\n",
      "        [    1.1391],\n",
      "        [    9.3609],\n",
      "        [   60.3790],\n",
      "        [    1.1391],\n",
      "        [   12.8037],\n",
      "        [   23.9409],\n",
      "        [    5.0556],\n",
      "        [   13.7512],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [    2.3481],\n",
      "        [   31.4609],\n",
      "        [   31.8609],\n",
      "        [   32.8609],\n",
      "        [   33.8609],\n",
      "        [   36.8609],\n",
      "        [    1.1391],\n",
      "        [   13.5815],\n",
      "        [   18.9100],\n",
      "        [   17.8874],\n",
      "        [    1.1391],\n",
      "        [    1.1391],\n",
      "        [   23.9821],\n",
      "        [   13.8309],\n",
      "        [   40.3609],\n",
      "        [    5.0160],\n",
      "        [   21.1490],\n",
      "        [   19.7306],\n",
      "        [   25.6033],\n",
      "        [   26.7644],\n",
      "        [   35.2588],\n",
      "        [   34.8491],\n",
      "        [   35.7920],\n",
      "        [   42.8609]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(813.1762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  214.9359],\n",
      "        [    1.1905],\n",
      "        [   39.3092],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [   15.0695],\n",
      "        [    0.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    3.8095],\n",
      "        [    1.1905],\n",
      "        [   17.6620],\n",
      "        [    4.5920],\n",
      "        [    8.1739],\n",
      "        [    1.1905],\n",
      "        [    4.7555],\n",
      "        [   11.8095],\n",
      "        [    1.1905],\n",
      "        [  167.7410],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    8.8095],\n",
      "        [    0.8095],\n",
      "        [    4.5920],\n",
      "        [    2.3095],\n",
      "        [    3.2895],\n",
      "        [    3.3095],\n",
      "        [    5.5095],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    8.8095],\n",
      "        [    1.1905],\n",
      "        [    9.3095],\n",
      "        [   62.3404],\n",
      "        [    1.1905],\n",
      "        [   13.2610],\n",
      "        [   23.8895],\n",
      "        [    5.8160],\n",
      "        [   14.5701],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.8714],\n",
      "        [   31.4095],\n",
      "        [   31.8095],\n",
      "        [   32.8095],\n",
      "        [   33.8095],\n",
      "        [   36.8095],\n",
      "        [    1.1905],\n",
      "        [   15.4263],\n",
      "        [   17.9357],\n",
      "        [   17.5624],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [   23.3430],\n",
      "        [   12.4966],\n",
      "        [   40.3095],\n",
      "        [    2.6846],\n",
      "        [   19.9909],\n",
      "        [   20.3071],\n",
      "        [   24.0177],\n",
      "        [   25.1036],\n",
      "        [   34.0135],\n",
      "        [   33.3925],\n",
      "        [   34.2093],\n",
      "        [   42.8095]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 21.90791654586792\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 114\n",
      "剩餘X 資料 torch.Size([89, 10])\n",
      "剩餘Y 資料 torch.Size([89, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (2480.98193359375, 36)\n",
      "The second_loss value of k: (2895.45751953125, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引36，y= tensor([51.])\n",
      "目前模型的Data狀態 torch.Size([122, 1])\n",
      "<<預測值>>\n",
      "tensor([[103.0641],\n",
      "        [  1.1905],\n",
      "        [286.4608],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [ 17.6620],\n",
      "        [221.4080],\n",
      "        [ 79.2161],\n",
      "        [  1.1905],\n",
      "        [  4.7555],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [167.7410],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [221.4080],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [ 36.6596],\n",
      "        [  1.1905],\n",
      "        [ 13.2610],\n",
      "        [  1.1905],\n",
      "        [  5.8160],\n",
      "        [ 81.0701],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.8714],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [ 15.4263],\n",
      "        [ 17.9357],\n",
      "        [ 17.5624],\n",
      "        [  1.1905],\n",
      "        [  1.1905],\n",
      "        [ 23.3430],\n",
      "        [ 12.4966],\n",
      "        [  1.1905],\n",
      "        [ 69.6846],\n",
      "        [ 19.9909],\n",
      "        [126.5071],\n",
      "        [ 24.0177],\n",
      "        [ 25.1036],\n",
      "        [ 34.0135],\n",
      "        [ 33.3925],\n",
      "        [ 34.2093],\n",
      "        [  1.1905],\n",
      "        [  1.1905]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  214.9359],\n",
      "        [    1.1905],\n",
      "        [   39.3092],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [   15.0695],\n",
      "        [    0.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    3.8095],\n",
      "        [    1.1905],\n",
      "        [   17.6620],\n",
      "        [    4.5920],\n",
      "        [    8.1739],\n",
      "        [    1.1905],\n",
      "        [    4.7555],\n",
      "        [   11.8095],\n",
      "        [    1.1905],\n",
      "        [  167.7410],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    8.8095],\n",
      "        [    0.8095],\n",
      "        [    4.5920],\n",
      "        [    2.3095],\n",
      "        [    3.2895],\n",
      "        [    3.3095],\n",
      "        [    5.5095],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    8.8095],\n",
      "        [    1.1905],\n",
      "        [    9.3095],\n",
      "        [   62.3404],\n",
      "        [    1.1905],\n",
      "        [   13.2610],\n",
      "        [   23.8895],\n",
      "        [    5.8160],\n",
      "        [   14.5701],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [    1.8714],\n",
      "        [   31.4095],\n",
      "        [   31.8095],\n",
      "        [   32.8095],\n",
      "        [   33.8095],\n",
      "        [   36.8095],\n",
      "        [    1.1905],\n",
      "        [   15.4263],\n",
      "        [   17.9357],\n",
      "        [   17.5624],\n",
      "        [    1.1905],\n",
      "        [    1.1905],\n",
      "        [   23.3430],\n",
      "        [   12.4966],\n",
      "        [   40.3095],\n",
      "        [    2.6846],\n",
      "        [   19.9909],\n",
      "        [   20.3071],\n",
      "        [   24.0177],\n",
      "        [   25.1036],\n",
      "        [   34.0135],\n",
      "        [   33.3925],\n",
      "        [   34.2093],\n",
      "        [   42.8095],\n",
      "        [   49.8095]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(824.1161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[215.0510],\n",
      "        [  1.2372],\n",
      "        [ 38.6644],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [ 15.0228],\n",
      "        [  0.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  3.7628],\n",
      "        [  1.2372],\n",
      "        [ 17.5206],\n",
      "        [  4.2282],\n",
      "        [  7.7642],\n",
      "        [  1.2372],\n",
      "        [  6.2434],\n",
      "        [ 11.7628],\n",
      "        [  1.2372],\n",
      "        [167.7221],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  8.7628],\n",
      "        [  0.7628],\n",
      "        [  4.2282],\n",
      "        [  2.2628],\n",
      "        [  3.2428],\n",
      "        [  3.2628],\n",
      "        [  5.4628],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  8.7628],\n",
      "        [  1.2372],\n",
      "        [  9.2628],\n",
      "        [ 63.5563],\n",
      "        [  1.2372],\n",
      "        [ 13.5564],\n",
      "        [ 23.8428],\n",
      "        [  6.1883],\n",
      "        [ 14.6842],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  2.0935],\n",
      "        [ 31.3628],\n",
      "        [ 31.7628],\n",
      "        [ 32.7628],\n",
      "        [ 33.7628],\n",
      "        [ 36.7628],\n",
      "        [  1.2372],\n",
      "        [ 16.5513],\n",
      "        [ 17.1566],\n",
      "        [ 17.2967],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [ 23.0211],\n",
      "        [ 11.6216],\n",
      "        [ 40.2628],\n",
      "        [  1.2234],\n",
      "        [ 19.2151],\n",
      "        [ 20.8175],\n",
      "        [ 23.0008],\n",
      "        [ 23.8770],\n",
      "        [ 33.1702],\n",
      "        [ 32.4111],\n",
      "        [ 33.1692],\n",
      "        [ 42.7628],\n",
      "        [ 49.7628]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 22.169570446014404\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 115\n",
      "剩餘X 資料 torch.Size([88, 10])\n",
      "剩餘Y 資料 torch.Size([88, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (2890.435302734375, 0)\n",
      "The second_loss value of k: (2890.435302734375, 53)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([55.])\n",
      "目前模型的Data狀態 torch.Size([123, 1])\n",
      "<<預測值>>\n",
      "tensor([[102.9490],\n",
      "        [  1.2372],\n",
      "        [287.1056],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [ 17.5206],\n",
      "        [221.7718],\n",
      "        [ 79.6258],\n",
      "        [  1.2372],\n",
      "        [  6.2434],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [167.7221],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [221.7718],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [ 35.4437],\n",
      "        [  1.2372],\n",
      "        [ 13.5564],\n",
      "        [  1.2372],\n",
      "        [  6.1883],\n",
      "        [ 81.1842],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  2.0935],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [ 16.5513],\n",
      "        [ 17.1566],\n",
      "        [ 17.2967],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [ 23.0211],\n",
      "        [ 11.6216],\n",
      "        [  1.2372],\n",
      "        [ 68.2234],\n",
      "        [ 19.2151],\n",
      "        [127.0175],\n",
      "        [ 23.0008],\n",
      "        [ 23.8770],\n",
      "        [ 33.1702],\n",
      "        [ 32.4111],\n",
      "        [ 33.1692],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[215.0510],\n",
      "        [  1.2372],\n",
      "        [ 38.6644],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [ 15.0228],\n",
      "        [  0.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  3.7628],\n",
      "        [  1.2372],\n",
      "        [ 17.5206],\n",
      "        [  4.2282],\n",
      "        [  7.7642],\n",
      "        [  1.2372],\n",
      "        [  6.2434],\n",
      "        [ 11.7628],\n",
      "        [  1.2372],\n",
      "        [167.7221],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  8.7628],\n",
      "        [  0.7628],\n",
      "        [  4.2282],\n",
      "        [  2.2628],\n",
      "        [  3.2428],\n",
      "        [  3.2628],\n",
      "        [  5.4628],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  8.7628],\n",
      "        [  1.2372],\n",
      "        [  9.2628],\n",
      "        [ 63.5563],\n",
      "        [  1.2372],\n",
      "        [ 13.5564],\n",
      "        [ 23.8428],\n",
      "        [  6.1883],\n",
      "        [ 14.6842],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [  2.0935],\n",
      "        [ 31.3628],\n",
      "        [ 31.7628],\n",
      "        [ 32.7628],\n",
      "        [ 33.7628],\n",
      "        [ 36.7628],\n",
      "        [  1.2372],\n",
      "        [ 16.5513],\n",
      "        [ 17.1566],\n",
      "        [ 17.2967],\n",
      "        [  1.2372],\n",
      "        [  1.2372],\n",
      "        [ 23.0211],\n",
      "        [ 11.6216],\n",
      "        [ 40.2628],\n",
      "        [  1.2234],\n",
      "        [ 19.2151],\n",
      "        [ 20.8175],\n",
      "        [ 23.0008],\n",
      "        [ 23.8770],\n",
      "        [ 33.1702],\n",
      "        [ 32.4111],\n",
      "        [ 33.1692],\n",
      "        [ 42.7628],\n",
      "        [ 49.7628],\n",
      "        [ 53.7628]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(839.1396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  214.8999],\n",
      "        [    1.2839],\n",
      "        [   38.9179],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [   14.9761],\n",
      "        [    0.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    3.7161],\n",
      "        [    1.2839],\n",
      "        [   17.1427],\n",
      "        [    4.4871],\n",
      "        [    7.7601],\n",
      "        [    1.2839],\n",
      "        [    4.5591],\n",
      "        [   11.7161],\n",
      "        [    1.2839],\n",
      "        [  167.9258],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    8.7161],\n",
      "        [    0.7161],\n",
      "        [    4.4871],\n",
      "        [    2.2161],\n",
      "        [    3.1961],\n",
      "        [    3.2161],\n",
      "        [    5.4161],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    8.7161],\n",
      "        [    1.2839],\n",
      "        [    9.2161],\n",
      "        [   64.6693],\n",
      "        [    1.2839],\n",
      "        [   13.5984],\n",
      "        [   23.7961],\n",
      "        [    6.3122],\n",
      "        [   15.2989],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    2.3852],\n",
      "        [   31.3161],\n",
      "        [   31.7161],\n",
      "        [   32.7161],\n",
      "        [   33.7161],\n",
      "        [   36.7161],\n",
      "        [    1.2839],\n",
      "        [   17.1987],\n",
      "        [   16.4533],\n",
      "        [   16.9687],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [   22.5625],\n",
      "        [   10.8101],\n",
      "        [   40.2161],\n",
      "        [    0.1242],\n",
      "        [   18.4708],\n",
      "        [   20.7933],\n",
      "        [   22.0616],\n",
      "        [   22.8916],\n",
      "        [   32.3495],\n",
      "        [   31.4891],\n",
      "        [   32.1995],\n",
      "        [   42.7161],\n",
      "        [   49.7161],\n",
      "        [   53.7161]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 22.434813976287842\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 116\n",
      "剩餘X 資料 torch.Size([87, 10])\n",
      "剩餘Y 資料 torch.Size([87, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (2885.41796875, 52)\n",
      "The second_loss value of k: (2892.57373046875, 53)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引52，y= tensor([55.])\n",
      "目前模型的Data狀態 torch.Size([124, 1])\n",
      "<<預測值>>\n",
      "tensor([[103.1001],\n",
      "        [  1.2839],\n",
      "        [286.8521],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [ 17.1427],\n",
      "        [221.5129],\n",
      "        [ 79.6299],\n",
      "        [  1.2839],\n",
      "        [  4.5591],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [167.9258],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [221.5129],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [ 34.3307],\n",
      "        [  1.2839],\n",
      "        [ 13.5984],\n",
      "        [  1.2839],\n",
      "        [  6.3122],\n",
      "        [ 81.7989],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  2.3852],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [ 17.1987],\n",
      "        [ 16.4533],\n",
      "        [ 16.9687],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [ 22.5625],\n",
      "        [ 10.8101],\n",
      "        [  1.2839],\n",
      "        [ 66.8758],\n",
      "        [ 18.4708],\n",
      "        [126.9933],\n",
      "        [ 22.0616],\n",
      "        [ 22.8916],\n",
      "        [ 32.3495],\n",
      "        [ 31.4891],\n",
      "        [ 32.1995],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839],\n",
      "        [  1.2839]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  214.8999],\n",
      "        [    1.2839],\n",
      "        [   38.9179],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [   14.9761],\n",
      "        [    0.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    3.7161],\n",
      "        [    1.2839],\n",
      "        [   17.1427],\n",
      "        [    4.4871],\n",
      "        [    7.7601],\n",
      "        [    1.2839],\n",
      "        [    4.5591],\n",
      "        [   11.7161],\n",
      "        [    1.2839],\n",
      "        [  167.9258],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    8.7161],\n",
      "        [    0.7161],\n",
      "        [    4.4871],\n",
      "        [    2.2161],\n",
      "        [    3.1961],\n",
      "        [    3.2161],\n",
      "        [    5.4161],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    8.7161],\n",
      "        [    1.2839],\n",
      "        [    9.2161],\n",
      "        [   64.6693],\n",
      "        [    1.2839],\n",
      "        [   13.5984],\n",
      "        [   23.7961],\n",
      "        [    6.3122],\n",
      "        [   15.2989],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [    2.3852],\n",
      "        [   31.3161],\n",
      "        [   31.7161],\n",
      "        [   32.7161],\n",
      "        [   33.7161],\n",
      "        [   36.7161],\n",
      "        [    1.2839],\n",
      "        [   17.1987],\n",
      "        [   16.4533],\n",
      "        [   16.9687],\n",
      "        [    1.2839],\n",
      "        [    1.2839],\n",
      "        [   22.5625],\n",
      "        [   10.8101],\n",
      "        [   40.2161],\n",
      "        [    0.1242],\n",
      "        [   18.4708],\n",
      "        [   20.7933],\n",
      "        [   22.0616],\n",
      "        [   22.8916],\n",
      "        [   32.3495],\n",
      "        [   31.4891],\n",
      "        [   32.1995],\n",
      "        [   42.7161],\n",
      "        [   49.7161],\n",
      "        [   53.7161],\n",
      "        [   53.7161]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(853.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[214.4168],\n",
      "        [  1.3444],\n",
      "        [ 38.8170],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [ 14.9156],\n",
      "        [  0.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  3.6556],\n",
      "        [  1.3444],\n",
      "        [ 16.6088],\n",
      "        [  4.3162],\n",
      "        [  7.2279],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [ 11.6556],\n",
      "        [  1.3444],\n",
      "        [168.6429],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  8.6556],\n",
      "        [  0.6556],\n",
      "        [  4.3162],\n",
      "        [  2.1556],\n",
      "        [  3.1356],\n",
      "        [  3.1556],\n",
      "        [  5.3556],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  8.6556],\n",
      "        [  1.3444],\n",
      "        [  9.1556],\n",
      "        [ 65.6755],\n",
      "        [  1.3444],\n",
      "        [ 13.5350],\n",
      "        [ 23.7356],\n",
      "        [  6.3665],\n",
      "        [ 15.7293],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.5683],\n",
      "        [ 31.2556],\n",
      "        [ 31.6556],\n",
      "        [ 32.6556],\n",
      "        [ 33.6556],\n",
      "        [ 36.6556],\n",
      "        [  1.3444],\n",
      "        [ 17.9083],\n",
      "        [ 15.6045],\n",
      "        [ 16.6102],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [ 22.2059],\n",
      "        [ 10.0127],\n",
      "        [ 40.1556],\n",
      "        [  1.3642],\n",
      "        [ 17.7696],\n",
      "        [ 21.1821],\n",
      "        [ 21.1669],\n",
      "        [ 21.7817],\n",
      "        [ 31.4442],\n",
      "        [ 30.5502],\n",
      "        [ 31.2438],\n",
      "        [ 42.6556],\n",
      "        [ 49.6556],\n",
      "        [ 53.6556],\n",
      "        [ 53.6556]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 22.700683116912842\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 117\n",
      "剩餘X 資料 torch.Size([86, 10])\n",
      "剩餘Y 資料 torch.Size([86, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (2633.38134765625, 52)\n",
      "The second_loss value of k: (3848.86474609375, 31)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引52，y= tensor([149.])\n",
      "目前模型的Data狀態 torch.Size([125, 1])\n",
      "<<預測值>>\n",
      "tensor([[103.5832],\n",
      "        [  1.3444],\n",
      "        [286.9529],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [ 16.6088],\n",
      "        [221.6838],\n",
      "        [ 80.1621],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [168.6429],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [221.6838],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [ 33.3245],\n",
      "        [  1.3444],\n",
      "        [ 13.5350],\n",
      "        [  1.3444],\n",
      "        [  6.3665],\n",
      "        [ 82.2293],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.5683],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [ 17.9083],\n",
      "        [ 15.6045],\n",
      "        [ 16.6102],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [ 22.2059],\n",
      "        [ 10.0127],\n",
      "        [  1.3444],\n",
      "        [ 65.6358],\n",
      "        [ 17.7696],\n",
      "        [127.3821],\n",
      "        [ 21.1669],\n",
      "        [ 21.7817],\n",
      "        [ 31.4442],\n",
      "        [ 30.5502],\n",
      "        [ 31.2438],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [200.3165]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[214.4168],\n",
      "        [  1.3444],\n",
      "        [ 38.8170],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [ 14.9156],\n",
      "        [  0.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  3.6556],\n",
      "        [  1.3444],\n",
      "        [ 16.6088],\n",
      "        [  4.3162],\n",
      "        [  7.2279],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [ 11.6556],\n",
      "        [  1.3444],\n",
      "        [168.6429],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  8.6556],\n",
      "        [  0.6556],\n",
      "        [  4.3162],\n",
      "        [  2.1556],\n",
      "        [  3.1356],\n",
      "        [  3.1556],\n",
      "        [  5.3556],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  8.6556],\n",
      "        [  1.3444],\n",
      "        [  9.1556],\n",
      "        [ 65.6755],\n",
      "        [  1.3444],\n",
      "        [ 13.5350],\n",
      "        [ 23.7356],\n",
      "        [  6.3665],\n",
      "        [ 15.7293],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [  1.5683],\n",
      "        [ 31.2556],\n",
      "        [ 31.6556],\n",
      "        [ 32.6556],\n",
      "        [ 33.6556],\n",
      "        [ 36.6556],\n",
      "        [  1.3444],\n",
      "        [ 17.9083],\n",
      "        [ 15.6045],\n",
      "        [ 16.6102],\n",
      "        [  1.3444],\n",
      "        [  1.3444],\n",
      "        [ 22.2059],\n",
      "        [ 10.0127],\n",
      "        [ 40.1556],\n",
      "        [  1.3642],\n",
      "        [ 17.7696],\n",
      "        [ 21.1821],\n",
      "        [ 21.1669],\n",
      "        [ 21.7817],\n",
      "        [ 31.4442],\n",
      "        [ 30.5502],\n",
      "        [ 31.2438],\n",
      "        [ 42.6556],\n",
      "        [ 49.6556],\n",
      "        [ 53.6556],\n",
      "        [ 53.6556],\n",
      "        [ 51.3165]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(866.1182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[214.7101],\n",
      "        [  1.4691],\n",
      "        [ 39.7450],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [ 14.7909],\n",
      "        [  0.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  3.5309],\n",
      "        [  1.4691],\n",
      "        [ 16.1966],\n",
      "        [  5.6186],\n",
      "        [  6.4468],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [ 11.5309],\n",
      "        [  1.4691],\n",
      "        [169.0751],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  8.5309],\n",
      "        [  0.5309],\n",
      "        [  5.6186],\n",
      "        [  2.0309],\n",
      "        [  3.0109],\n",
      "        [  3.0309],\n",
      "        [  5.2309],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  8.5309],\n",
      "        [  2.3284],\n",
      "        [  9.0309],\n",
      "        [ 68.4078],\n",
      "        [  1.4691],\n",
      "        [ 13.6471],\n",
      "        [ 23.6109],\n",
      "        [  6.5822],\n",
      "        [ 13.6642],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [ 31.1309],\n",
      "        [ 31.5309],\n",
      "        [ 32.5309],\n",
      "        [ 33.5309],\n",
      "        [ 36.5309],\n",
      "        [  1.4691],\n",
      "        [ 19.4735],\n",
      "        [ 13.4350],\n",
      "        [ 14.9966],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [ 22.0677],\n",
      "        [  7.9484],\n",
      "        [ 40.0309],\n",
      "        [  4.6035],\n",
      "        [ 14.9880],\n",
      "        [ 21.4201],\n",
      "        [ 18.8208],\n",
      "        [ 18.1471],\n",
      "        [ 29.4157],\n",
      "        [ 28.2521],\n",
      "        [ 28.8372],\n",
      "        [ 42.5309],\n",
      "        [ 49.5309],\n",
      "        [ 53.5309],\n",
      "        [ 53.5309],\n",
      "        [  2.9989]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 22.964776039123535\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 118\n",
      "剩餘X 資料 torch.Size([85, 10])\n",
      "剩餘Y 資料 torch.Size([85, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (2.1583645343780518, 81)\n",
      "The second_loss value of k: (1546.091796875, 44)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引81，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([126, 1])\n",
      "<<預測值>>\n",
      "tensor([[103.2899],\n",
      "        [  1.4691],\n",
      "        [286.0250],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [ 16.1966],\n",
      "        [220.3814],\n",
      "        [ 80.9432],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [169.0751],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [220.3814],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  2.3284],\n",
      "        [  1.4691],\n",
      "        [ 30.5922],\n",
      "        [  1.4691],\n",
      "        [ 13.6471],\n",
      "        [  1.4691],\n",
      "        [  6.5822],\n",
      "        [ 80.1642],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [ 19.4735],\n",
      "        [ 13.4350],\n",
      "        [ 14.9966],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [ 22.0677],\n",
      "        [  7.9484],\n",
      "        [  1.4691],\n",
      "        [ 62.3965],\n",
      "        [ 14.9880],\n",
      "        [127.6201],\n",
      "        [ 18.8208],\n",
      "        [ 18.1471],\n",
      "        [ 29.4157],\n",
      "        [ 28.2521],\n",
      "        [ 28.8372],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [151.9989],\n",
      "        [  1.4691]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[214.7101],\n",
      "        [  1.4691],\n",
      "        [ 39.7450],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [ 14.7909],\n",
      "        [  0.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  3.5309],\n",
      "        [  1.4691],\n",
      "        [ 16.1966],\n",
      "        [  5.6186],\n",
      "        [  6.4468],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [ 11.5309],\n",
      "        [  1.4691],\n",
      "        [169.0751],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  8.5309],\n",
      "        [  0.5309],\n",
      "        [  5.6186],\n",
      "        [  2.0309],\n",
      "        [  3.0109],\n",
      "        [  3.0309],\n",
      "        [  5.2309],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  8.5309],\n",
      "        [  2.3284],\n",
      "        [  9.0309],\n",
      "        [ 68.4078],\n",
      "        [  1.4691],\n",
      "        [ 13.6471],\n",
      "        [ 23.6109],\n",
      "        [  6.5822],\n",
      "        [ 13.6642],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [ 31.1309],\n",
      "        [ 31.5309],\n",
      "        [ 32.5309],\n",
      "        [ 33.5309],\n",
      "        [ 36.5309],\n",
      "        [  1.4691],\n",
      "        [ 19.4735],\n",
      "        [ 13.4350],\n",
      "        [ 14.9966],\n",
      "        [  1.4691],\n",
      "        [  1.4691],\n",
      "        [ 22.0677],\n",
      "        [  7.9484],\n",
      "        [ 40.0309],\n",
      "        [  4.6035],\n",
      "        [ 14.9880],\n",
      "        [ 21.4201],\n",
      "        [ 18.8208],\n",
      "        [ 18.1471],\n",
      "        [ 29.4157],\n",
      "        [ 28.2521],\n",
      "        [ 28.8372],\n",
      "        [ 42.5309],\n",
      "        [ 49.5309],\n",
      "        [ 53.5309],\n",
      "        [ 53.5309],\n",
      "        [  2.9989],\n",
      "        [  1.4691]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(836.5334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[214.8057],\n",
      "        [  1.5100],\n",
      "        [ 36.6989],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [ 14.7500],\n",
      "        [  0.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  3.4900],\n",
      "        [  1.5100],\n",
      "        [ 15.9407],\n",
      "        [  5.6966],\n",
      "        [  6.4198],\n",
      "        [  1.5100],\n",
      "        [  2.5925],\n",
      "        [ 11.4900],\n",
      "        [  1.5100],\n",
      "        [168.9550],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  8.4900],\n",
      "        [  0.4900],\n",
      "        [  5.6966],\n",
      "        [  1.9900],\n",
      "        [  2.9700],\n",
      "        [  2.9900],\n",
      "        [  5.1900],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  8.4900],\n",
      "        [  1.8063],\n",
      "        [  8.9900],\n",
      "        [ 68.8678],\n",
      "        [  1.5100],\n",
      "        [ 14.0293],\n",
      "        [ 23.5700],\n",
      "        [  7.0853],\n",
      "        [ 14.5755],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [ 31.0900],\n",
      "        [ 31.4900],\n",
      "        [ 32.4900],\n",
      "        [ 33.4900],\n",
      "        [ 36.4900],\n",
      "        [  1.5100],\n",
      "        [ 20.9519],\n",
      "        [ 13.0173],\n",
      "        [ 15.2788],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [ 21.5863],\n",
      "        [  7.4939],\n",
      "        [ 39.9900],\n",
      "        [  5.0958],\n",
      "        [ 14.6338],\n",
      "        [ 23.5943],\n",
      "        [ 18.3605],\n",
      "        [ 17.8878],\n",
      "        [ 28.9326],\n",
      "        [ 27.7701],\n",
      "        [ 28.3606],\n",
      "        [ 42.4900],\n",
      "        [ 49.4900],\n",
      "        [ 53.4900],\n",
      "        [ 53.4900],\n",
      "        [  2.8018],\n",
      "        [  1.5100]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 23.229450464248657\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 119\n",
      "剩餘X 資料 torch.Size([84, 10])\n",
      "剩餘Y 資料 torch.Size([84, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (3067.861328125, 44)\n",
      "The second_loss value of k: (3640.141357421875, 31)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引44，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([127, 1])\n",
      "<<預測值>>\n",
      "tensor([[103.1943],\n",
      "        [  1.5100],\n",
      "        [289.0711],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [ 15.9407],\n",
      "        [220.3034],\n",
      "        [ 80.9702],\n",
      "        [  1.5100],\n",
      "        [  2.5925],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [168.9550],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [220.3034],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.8063],\n",
      "        [  1.5100],\n",
      "        [ 30.1322],\n",
      "        [  1.5100],\n",
      "        [ 14.0293],\n",
      "        [  1.5100],\n",
      "        [  7.0853],\n",
      "        [ 81.0755],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [ 20.9519],\n",
      "        [ 13.0173],\n",
      "        [ 15.2788],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [ 21.5863],\n",
      "        [  7.4939],\n",
      "        [  1.5100],\n",
      "        [ 61.9042],\n",
      "        [ 14.6338],\n",
      "        [129.7943],\n",
      "        [ 18.3605],\n",
      "        [ 17.8878],\n",
      "        [ 28.9326],\n",
      "        [ 27.7701],\n",
      "        [ 28.3606],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [151.8018],\n",
      "        [  1.5100],\n",
      "        [ 55.3883]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[214.8057],\n",
      "        [  1.5100],\n",
      "        [ 36.6989],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [ 14.7500],\n",
      "        [  0.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  3.4900],\n",
      "        [  1.5100],\n",
      "        [ 15.9407],\n",
      "        [  5.6966],\n",
      "        [  6.4198],\n",
      "        [  1.5100],\n",
      "        [  2.5925],\n",
      "        [ 11.4900],\n",
      "        [  1.5100],\n",
      "        [168.9550],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  8.4900],\n",
      "        [  0.4900],\n",
      "        [  5.6966],\n",
      "        [  1.9900],\n",
      "        [  2.9700],\n",
      "        [  2.9900],\n",
      "        [  5.1900],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  8.4900],\n",
      "        [  1.8063],\n",
      "        [  8.9900],\n",
      "        [ 68.8678],\n",
      "        [  1.5100],\n",
      "        [ 14.0293],\n",
      "        [ 23.5700],\n",
      "        [  7.0853],\n",
      "        [ 14.5755],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [ 31.0900],\n",
      "        [ 31.4900],\n",
      "        [ 32.4900],\n",
      "        [ 33.4900],\n",
      "        [ 36.4900],\n",
      "        [  1.5100],\n",
      "        [ 20.9519],\n",
      "        [ 13.0173],\n",
      "        [ 15.2788],\n",
      "        [  1.5100],\n",
      "        [  1.5100],\n",
      "        [ 21.5863],\n",
      "        [  7.4939],\n",
      "        [ 39.9900],\n",
      "        [  5.0958],\n",
      "        [ 14.6338],\n",
      "        [ 23.5943],\n",
      "        [ 18.3605],\n",
      "        [ 17.8878],\n",
      "        [ 28.9326],\n",
      "        [ 27.7701],\n",
      "        [ 28.3606],\n",
      "        [ 42.4900],\n",
      "        [ 49.4900],\n",
      "        [ 53.4900],\n",
      "        [ 53.4900],\n",
      "        [  2.8018],\n",
      "        [  1.5100],\n",
      "        [ 55.3883]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(852.9181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[216.9579],\n",
      "        [  1.5492],\n",
      "        [ 36.2310],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 14.7108],\n",
      "        [  0.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  3.4508],\n",
      "        [  1.5492],\n",
      "        [ 14.7170],\n",
      "        [  4.3920],\n",
      "        [  6.3325],\n",
      "        [  1.5492],\n",
      "        [  2.2878],\n",
      "        [ 11.4508],\n",
      "        [  1.5492],\n",
      "        [166.9355],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  8.4508],\n",
      "        [  0.4508],\n",
      "        [  4.3920],\n",
      "        [  1.9508],\n",
      "        [  2.9308],\n",
      "        [  2.9508],\n",
      "        [  5.1508],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  8.4508],\n",
      "        [  1.5492],\n",
      "        [  8.9508],\n",
      "        [ 69.2335],\n",
      "        [  1.5492],\n",
      "        [ 13.6370],\n",
      "        [ 23.5308],\n",
      "        [  6.8315],\n",
      "        [ 10.8098],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 31.0508],\n",
      "        [ 31.4508],\n",
      "        [ 32.4508],\n",
      "        [ 33.4508],\n",
      "        [ 36.4508],\n",
      "        [  1.5492],\n",
      "        [ 20.9415],\n",
      "        [ 12.3516],\n",
      "        [ 14.4567],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 21.6581],\n",
      "        [  7.0616],\n",
      "        [ 39.9508],\n",
      "        [  5.3982],\n",
      "        [ 14.0733],\n",
      "        [ 24.0144],\n",
      "        [ 17.9592],\n",
      "        [ 16.7266],\n",
      "        [ 28.4835],\n",
      "        [ 27.3756],\n",
      "        [ 27.9733],\n",
      "        [ 42.4508],\n",
      "        [ 49.4508],\n",
      "        [ 53.4508],\n",
      "        [ 53.4508],\n",
      "        [  1.7422],\n",
      "        [  1.5492],\n",
      "        [  1.5492]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 23.494059562683105\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 120\n",
      "剩餘X 資料 torch.Size([83, 10])\n",
      "剩餘Y 資料 torch.Size([83, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (3524.535400390625, 31)\n",
      "The second_loss value of k: (3524.535400390625, 47)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引31，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([128, 1])\n",
      "<<預測值>>\n",
      "tensor([[101.0420],\n",
      "        [  1.5492],\n",
      "        [289.5390],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 14.7170],\n",
      "        [221.6080],\n",
      "        [ 81.0575],\n",
      "        [  1.5492],\n",
      "        [  2.2878],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [166.9355],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [221.6080],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 29.7665],\n",
      "        [  1.5492],\n",
      "        [ 13.6370],\n",
      "        [  1.5492],\n",
      "        [  6.8315],\n",
      "        [ 77.3098],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 20.9415],\n",
      "        [ 12.3516],\n",
      "        [ 14.4567],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 21.6581],\n",
      "        [  7.0616],\n",
      "        [  1.5492],\n",
      "        [ 61.6018],\n",
      "        [ 14.0733],\n",
      "        [130.2144],\n",
      "        [ 17.9592],\n",
      "        [ 16.7266],\n",
      "        [ 28.4835],\n",
      "        [ 27.3756],\n",
      "        [ 27.9733],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [150.7422],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 59.3678]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[216.9579],\n",
      "        [  1.5492],\n",
      "        [ 36.2310],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 14.7108],\n",
      "        [  0.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  3.4508],\n",
      "        [  1.5492],\n",
      "        [ 14.7170],\n",
      "        [  4.3920],\n",
      "        [  6.3325],\n",
      "        [  1.5492],\n",
      "        [  2.2878],\n",
      "        [ 11.4508],\n",
      "        [  1.5492],\n",
      "        [166.9355],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  8.4508],\n",
      "        [  0.4508],\n",
      "        [  4.3920],\n",
      "        [  1.9508],\n",
      "        [  2.9308],\n",
      "        [  2.9508],\n",
      "        [  5.1508],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  8.4508],\n",
      "        [  1.5492],\n",
      "        [  8.9508],\n",
      "        [ 69.2335],\n",
      "        [  1.5492],\n",
      "        [ 13.6370],\n",
      "        [ 23.5308],\n",
      "        [  6.8315],\n",
      "        [ 10.8098],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 31.0508],\n",
      "        [ 31.4508],\n",
      "        [ 32.4508],\n",
      "        [ 33.4508],\n",
      "        [ 36.4508],\n",
      "        [  1.5492],\n",
      "        [ 20.9415],\n",
      "        [ 12.3516],\n",
      "        [ 14.4567],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 21.6581],\n",
      "        [  7.0616],\n",
      "        [ 39.9508],\n",
      "        [  5.3982],\n",
      "        [ 14.0733],\n",
      "        [ 24.0144],\n",
      "        [ 17.9592],\n",
      "        [ 16.7266],\n",
      "        [ 28.4835],\n",
      "        [ 27.3756],\n",
      "        [ 27.9733],\n",
      "        [ 42.4508],\n",
      "        [ 49.4508],\n",
      "        [ 53.4508],\n",
      "        [ 53.4508],\n",
      "        [  1.7422],\n",
      "        [  1.5492],\n",
      "        [  1.5492],\n",
      "        [ 59.3678]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(849.0089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[215.8765],\n",
      "        [  1.6005],\n",
      "        [ 48.9966],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [ 14.6595],\n",
      "        [  0.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  3.3995],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  5.0910],\n",
      "        [  5.5268],\n",
      "        [  1.6005],\n",
      "        [  3.4327],\n",
      "        [ 11.3995],\n",
      "        [  1.6005],\n",
      "        [168.2066],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  8.3995],\n",
      "        [  0.3995],\n",
      "        [  5.0910],\n",
      "        [  1.8995],\n",
      "        [  2.8795],\n",
      "        [  2.8995],\n",
      "        [  5.0995],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  8.3995],\n",
      "        [  1.6005],\n",
      "        [  8.8995],\n",
      "        [ 69.7552],\n",
      "        [  1.6005],\n",
      "        [  9.6764],\n",
      "        [ 23.4795],\n",
      "        [  8.5836],\n",
      "        [ 12.2469],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [ 30.9995],\n",
      "        [ 31.3995],\n",
      "        [ 32.3995],\n",
      "        [ 33.3995],\n",
      "        [ 36.3995],\n",
      "        [  1.6005],\n",
      "        [ 25.0509],\n",
      "        [ 11.7172],\n",
      "        [ 11.6565],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [ 21.5571],\n",
      "        [  6.5184],\n",
      "        [ 39.8995],\n",
      "        [  5.9389],\n",
      "        [ 13.5671],\n",
      "        [ 29.9762],\n",
      "        [ 17.4181],\n",
      "        [ 15.9959],\n",
      "        [ 25.8840],\n",
      "        [ 26.8022],\n",
      "        [ 27.4129],\n",
      "        [ 42.3995],\n",
      "        [ 49.3995],\n",
      "        [ 53.3995],\n",
      "        [ 53.3995],\n",
      "        [  2.5013],\n",
      "        [  1.6005],\n",
      "        [  2.6391],\n",
      "        [ 32.2430]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 23.75892949104309\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 121\n",
      "剩餘X 資料 torch.Size([82, 10])\n",
      "剩餘Y 資料 torch.Size([82, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1039.6142578125, 46)\n",
      "The second_loss value of k: (3152.197998046875, 10)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引46，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([129, 1])\n",
      "<<預測值>>\n",
      "tensor([[102.1235],\n",
      "        [  1.6005],\n",
      "        [276.7733],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [220.9090],\n",
      "        [ 81.8632],\n",
      "        [  1.6005],\n",
      "        [  3.4327],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [168.2066],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [220.9090],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [ 29.2448],\n",
      "        [  1.6005],\n",
      "        [  9.6764],\n",
      "        [  1.6005],\n",
      "        [  8.5836],\n",
      "        [ 78.7469],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [ 25.0509],\n",
      "        [ 11.7172],\n",
      "        [ 11.6565],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [ 21.5571],\n",
      "        [  6.5184],\n",
      "        [  1.6005],\n",
      "        [ 61.0611],\n",
      "        [ 13.5671],\n",
      "        [136.1762],\n",
      "        [ 17.4181],\n",
      "        [ 15.9959],\n",
      "        [ 25.8840],\n",
      "        [ 26.8022],\n",
      "        [ 27.4129],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [151.5013],\n",
      "        [  1.6005],\n",
      "        [  2.6391],\n",
      "        [ 32.2430],\n",
      "        [ 32.2430]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[215.8765],\n",
      "        [  1.6005],\n",
      "        [ 48.9966],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [ 14.6595],\n",
      "        [  0.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  3.3995],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  5.0910],\n",
      "        [  5.5268],\n",
      "        [  1.6005],\n",
      "        [  3.4327],\n",
      "        [ 11.3995],\n",
      "        [  1.6005],\n",
      "        [168.2066],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  8.3995],\n",
      "        [  0.3995],\n",
      "        [  5.0910],\n",
      "        [  1.8995],\n",
      "        [  2.8795],\n",
      "        [  2.8995],\n",
      "        [  5.0995],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  8.3995],\n",
      "        [  1.6005],\n",
      "        [  8.8995],\n",
      "        [ 69.7552],\n",
      "        [  1.6005],\n",
      "        [  9.6764],\n",
      "        [ 23.4795],\n",
      "        [  8.5836],\n",
      "        [ 12.2469],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [ 30.9995],\n",
      "        [ 31.3995],\n",
      "        [ 32.3995],\n",
      "        [ 33.3995],\n",
      "        [ 36.3995],\n",
      "        [  1.6005],\n",
      "        [ 25.0509],\n",
      "        [ 11.7172],\n",
      "        [ 11.6565],\n",
      "        [  1.6005],\n",
      "        [  1.6005],\n",
      "        [ 21.5571],\n",
      "        [  6.5184],\n",
      "        [ 39.8995],\n",
      "        [  5.9389],\n",
      "        [ 13.5671],\n",
      "        [ 29.9762],\n",
      "        [ 17.4181],\n",
      "        [ 15.9959],\n",
      "        [ 25.8840],\n",
      "        [ 26.8022],\n",
      "        [ 27.4129],\n",
      "        [ 42.3995],\n",
      "        [ 49.3995],\n",
      "        [ 53.3995],\n",
      "        [ 53.3995],\n",
      "        [  2.5013],\n",
      "        [  1.6005],\n",
      "        [  2.6391],\n",
      "        [ 32.2430],\n",
      "        [ 32.2430]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(839.0400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 73\n",
      "Number of shrink: 27\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[215.3322],\n",
      "        [  1.6292],\n",
      "        [ 53.2253],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 14.6308],\n",
      "        [  0.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  3.3708],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  5.5691],\n",
      "        [  5.2832],\n",
      "        [  1.6292],\n",
      "        [  2.4508],\n",
      "        [ 11.3708],\n",
      "        [  1.6292],\n",
      "        [169.0778],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  8.3708],\n",
      "        [  0.3708],\n",
      "        [  5.5691],\n",
      "        [  1.8708],\n",
      "        [  2.8508],\n",
      "        [  2.8708],\n",
      "        [  5.0708],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  8.3708],\n",
      "        [  1.6292],\n",
      "        [  8.8708],\n",
      "        [ 70.0053],\n",
      "        [  1.6292],\n",
      "        [  7.9740],\n",
      "        [ 23.4508],\n",
      "        [  9.9835],\n",
      "        [ 12.4910],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 30.9708],\n",
      "        [ 31.3708],\n",
      "        [ 32.3708],\n",
      "        [ 33.3708],\n",
      "        [ 36.3708],\n",
      "        [  1.6292],\n",
      "        [ 28.2285],\n",
      "        [ 11.3629],\n",
      "        [ 10.4304],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 21.3484],\n",
      "        [  6.1947],\n",
      "        [ 39.8708],\n",
      "        [  6.1024],\n",
      "        [ 13.2418],\n",
      "        [ 34.8201],\n",
      "        [ 17.1265],\n",
      "        [ 15.5529],\n",
      "        [ 24.5343],\n",
      "        [ 26.5269],\n",
      "        [ 27.1439],\n",
      "        [ 42.3708],\n",
      "        [ 49.3708],\n",
      "        [ 53.3708],\n",
      "        [ 53.3708],\n",
      "        [  2.4258],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 17.8786],\n",
      "        [ 17.8786]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 24.023913383483887\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 122\n",
      "剩餘X 資料 torch.Size([81, 10])\n",
      "剩餘Y 資料 torch.Size([81, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (2543.18798828125, 10)\n",
      "The second_loss value of k: (3952.74365234375, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引10，y= tensor([23.5000])\n",
      "目前模型的Data狀態 torch.Size([130, 1])\n",
      "<<預測值>>\n",
      "tensor([[102.6677],\n",
      "        [  1.6292],\n",
      "        [272.5447],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [220.4309],\n",
      "        [ 82.1068],\n",
      "        [  1.6292],\n",
      "        [  2.4508],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [169.0778],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [220.4309],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 28.9947],\n",
      "        [  1.6292],\n",
      "        [  7.9740],\n",
      "        [  1.6292],\n",
      "        [  9.9835],\n",
      "        [ 78.9910],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 28.2285],\n",
      "        [ 11.3629],\n",
      "        [ 10.4304],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 21.3484],\n",
      "        [  6.1947],\n",
      "        [  1.6292],\n",
      "        [ 60.8976],\n",
      "        [ 13.2418],\n",
      "        [141.0201],\n",
      "        [ 17.1265],\n",
      "        [ 15.5529],\n",
      "        [ 24.5343],\n",
      "        [ 26.5269],\n",
      "        [ 27.1439],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [151.4258],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 17.8786],\n",
      "        [ 17.8786],\n",
      "        [ 73.9300]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[215.3322],\n",
      "        [  1.6292],\n",
      "        [ 53.2253],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 14.6308],\n",
      "        [  0.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  3.3708],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  5.5691],\n",
      "        [  5.2832],\n",
      "        [  1.6292],\n",
      "        [  2.4508],\n",
      "        [ 11.3708],\n",
      "        [  1.6292],\n",
      "        [169.0778],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  8.3708],\n",
      "        [  0.3708],\n",
      "        [  5.5691],\n",
      "        [  1.8708],\n",
      "        [  2.8508],\n",
      "        [  2.8708],\n",
      "        [  5.0708],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  8.3708],\n",
      "        [  1.6292],\n",
      "        [  8.8708],\n",
      "        [ 70.0053],\n",
      "        [  1.6292],\n",
      "        [  7.9740],\n",
      "        [ 23.4508],\n",
      "        [  9.9835],\n",
      "        [ 12.4910],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 30.9708],\n",
      "        [ 31.3708],\n",
      "        [ 32.3708],\n",
      "        [ 33.3708],\n",
      "        [ 36.3708],\n",
      "        [  1.6292],\n",
      "        [ 28.2285],\n",
      "        [ 11.3629],\n",
      "        [ 10.4304],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 21.3484],\n",
      "        [  6.1947],\n",
      "        [ 39.8708],\n",
      "        [  6.1024],\n",
      "        [ 13.2418],\n",
      "        [ 34.8201],\n",
      "        [ 17.1265],\n",
      "        [ 15.5529],\n",
      "        [ 24.5343],\n",
      "        [ 26.5269],\n",
      "        [ 27.1439],\n",
      "        [ 42.3708],\n",
      "        [ 49.3708],\n",
      "        [ 53.3708],\n",
      "        [ 53.3708],\n",
      "        [  2.4258],\n",
      "        [  1.6292],\n",
      "        [  1.6292],\n",
      "        [ 17.8786],\n",
      "        [ 17.8786],\n",
      "        [ 50.4300]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(847.3102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[216.2099],\n",
      "        [  1.6940],\n",
      "        [ 60.3712],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [ 14.5660],\n",
      "        [  0.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  3.3060],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  0.9797],\n",
      "        [  7.5912],\n",
      "        [  1.6940],\n",
      "        [  2.2351],\n",
      "        [ 11.3060],\n",
      "        [  1.6940],\n",
      "        [168.0497],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  8.3060],\n",
      "        [  0.3060],\n",
      "        [  0.9797],\n",
      "        [  1.8060],\n",
      "        [  2.7860],\n",
      "        [  2.8060],\n",
      "        [  5.0060],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  8.3060],\n",
      "        [  3.0332],\n",
      "        [  8.8060],\n",
      "        [ 68.8139],\n",
      "        [  1.6940],\n",
      "        [  5.2323],\n",
      "        [ 23.3860],\n",
      "        [  8.4867],\n",
      "        [ 15.6485],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [ 30.9060],\n",
      "        [ 31.3060],\n",
      "        [ 32.3060],\n",
      "        [ 33.3060],\n",
      "        [ 36.3060],\n",
      "        [  1.6940],\n",
      "        [ 25.6498],\n",
      "        [ 11.6102],\n",
      "        [  7.8646],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [ 22.8876],\n",
      "        [  6.7401],\n",
      "        [ 39.8060],\n",
      "        [  4.4668],\n",
      "        [ 12.2059],\n",
      "        [ 33.6468],\n",
      "        [ 17.9382],\n",
      "        [ 16.4530],\n",
      "        [ 24.4921],\n",
      "        [ 27.2550],\n",
      "        [ 27.9878],\n",
      "        [ 42.3060],\n",
      "        [ 49.3060],\n",
      "        [ 53.3060],\n",
      "        [ 53.3060],\n",
      "        [ 15.1741],\n",
      "        [  1.6940],\n",
      "        [  1.8848],\n",
      "        [ 11.2014],\n",
      "        [ 11.2014],\n",
      "        [ 27.8297]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 24.291173696517944\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 123\n",
      "剩餘X 資料 torch.Size([80, 10])\n",
      "剩餘Y 資料 torch.Size([80, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (49.52988815307617, 55)\n",
      "The second_loss value of k: (3944.593994140625, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引55，y= tensor([4.])\n",
      "目前模型的Data狀態 torch.Size([131, 1])\n",
      "<<預測值>>\n",
      "tensor([[101.7901],\n",
      "        [  1.6940],\n",
      "        [265.3988],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [225.0203],\n",
      "        [ 79.7988],\n",
      "        [  1.6940],\n",
      "        [  2.2351],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [168.0497],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [225.0203],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  3.0332],\n",
      "        [  1.6940],\n",
      "        [ 30.1861],\n",
      "        [  1.6940],\n",
      "        [  5.2323],\n",
      "        [  1.6940],\n",
      "        [  8.4867],\n",
      "        [ 82.1485],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [ 25.6498],\n",
      "        [ 11.6102],\n",
      "        [  7.8646],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [ 22.8876],\n",
      "        [  6.7401],\n",
      "        [  1.6940],\n",
      "        [ 62.5332],\n",
      "        [ 12.2059],\n",
      "        [139.8468],\n",
      "        [ 17.9382],\n",
      "        [ 16.4530],\n",
      "        [ 24.4921],\n",
      "        [ 27.2550],\n",
      "        [ 27.9878],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [133.8259],\n",
      "        [  1.6940],\n",
      "        [  1.8848],\n",
      "        [ 11.2014],\n",
      "        [ 11.2014],\n",
      "        [ 51.3297],\n",
      "        [ 11.0377]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[216.2099],\n",
      "        [  1.6940],\n",
      "        [ 60.3712],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [ 14.5660],\n",
      "        [  0.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  3.3060],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  0.9797],\n",
      "        [  7.5912],\n",
      "        [  1.6940],\n",
      "        [  2.2351],\n",
      "        [ 11.3060],\n",
      "        [  1.6940],\n",
      "        [168.0497],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  8.3060],\n",
      "        [  0.3060],\n",
      "        [  0.9797],\n",
      "        [  1.8060],\n",
      "        [  2.7860],\n",
      "        [  2.8060],\n",
      "        [  5.0060],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  8.3060],\n",
      "        [  3.0332],\n",
      "        [  8.8060],\n",
      "        [ 68.8139],\n",
      "        [  1.6940],\n",
      "        [  5.2323],\n",
      "        [ 23.3860],\n",
      "        [  8.4867],\n",
      "        [ 15.6485],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [ 30.9060],\n",
      "        [ 31.3060],\n",
      "        [ 32.3060],\n",
      "        [ 33.3060],\n",
      "        [ 36.3060],\n",
      "        [  1.6940],\n",
      "        [ 25.6498],\n",
      "        [ 11.6102],\n",
      "        [  7.8646],\n",
      "        [  1.6940],\n",
      "        [  1.6940],\n",
      "        [ 22.8876],\n",
      "        [  6.7401],\n",
      "        [ 39.8060],\n",
      "        [  4.4668],\n",
      "        [ 12.2059],\n",
      "        [ 33.6468],\n",
      "        [ 17.9382],\n",
      "        [ 16.4530],\n",
      "        [ 24.4921],\n",
      "        [ 27.2550],\n",
      "        [ 27.9878],\n",
      "        [ 42.3060],\n",
      "        [ 49.3060],\n",
      "        [ 53.3060],\n",
      "        [ 53.3060],\n",
      "        [ 15.1741],\n",
      "        [  1.6940],\n",
      "        [  1.8848],\n",
      "        [ 11.2014],\n",
      "        [ 11.2014],\n",
      "        [ 27.8297],\n",
      "        [  7.0377]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(830.6202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 71\n",
      "Number of shrink: 29\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[216.3315],\n",
      "        [  1.7001],\n",
      "        [ 60.7289],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [ 14.5599],\n",
      "        [  0.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  3.2999],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  0.8822],\n",
      "        [  7.5407],\n",
      "        [  1.7001],\n",
      "        [  1.8829],\n",
      "        [ 11.2999],\n",
      "        [  1.7001],\n",
      "        [167.8675],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  8.2999],\n",
      "        [  0.2999],\n",
      "        [  0.8822],\n",
      "        [  1.7999],\n",
      "        [  2.7799],\n",
      "        [  2.7999],\n",
      "        [  4.9999],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  8.2999],\n",
      "        [  3.2629],\n",
      "        [  8.7999],\n",
      "        [ 68.6144],\n",
      "        [  1.7001],\n",
      "        [  5.0757],\n",
      "        [ 23.3799],\n",
      "        [  8.2185],\n",
      "        [ 15.6079],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [ 30.8999],\n",
      "        [ 31.2999],\n",
      "        [ 32.2999],\n",
      "        [ 33.2999],\n",
      "        [ 36.2999],\n",
      "        [  1.7001],\n",
      "        [ 25.1544],\n",
      "        [ 11.6547],\n",
      "        [  7.8219],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [ 22.9876],\n",
      "        [  6.8583],\n",
      "        [ 39.7999],\n",
      "        [  4.2427],\n",
      "        [ 12.2851],\n",
      "        [ 33.2209],\n",
      "        [ 18.0867],\n",
      "        [ 16.6025],\n",
      "        [ 24.5916],\n",
      "        [ 27.3690],\n",
      "        [ 28.1232],\n",
      "        [ 42.2999],\n",
      "        [ 49.2999],\n",
      "        [ 53.2999],\n",
      "        [ 53.2999],\n",
      "        [ 16.3186],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [ 11.6425],\n",
      "        [ 11.6425],\n",
      "        [ 26.6397],\n",
      "        [  0.3786]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 24.563774347305298\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 124\n",
      "剩餘X 資料 torch.Size([79, 10])\n",
      "剩餘Y 資料 torch.Size([79, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (3943.833740234375, 1)\n",
      "The second_loss value of k: (4018.066650390625, 67)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([64.5000])\n",
      "目前模型的Data狀態 torch.Size([132, 1])\n",
      "<<預測值>>\n",
      "tensor([[101.6685],\n",
      "        [  1.7001],\n",
      "        [265.0411],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [225.1178],\n",
      "        [ 79.8493],\n",
      "        [  1.7001],\n",
      "        [  1.8829],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [167.8675],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [225.1178],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  3.2629],\n",
      "        [  1.7001],\n",
      "        [ 30.3856],\n",
      "        [  1.7001],\n",
      "        [  5.0757],\n",
      "        [  1.7001],\n",
      "        [  8.2185],\n",
      "        [ 82.1079],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [ 25.1544],\n",
      "        [ 11.6547],\n",
      "        [  7.8219],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [ 22.9876],\n",
      "        [  6.8583],\n",
      "        [  1.7001],\n",
      "        [ 62.7573],\n",
      "        [ 12.2851],\n",
      "        [139.4209],\n",
      "        [ 18.0867],\n",
      "        [ 16.6025],\n",
      "        [ 24.5916],\n",
      "        [ 27.3690],\n",
      "        [ 28.1232],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [132.6814],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [ 11.6425],\n",
      "        [ 11.6425],\n",
      "        [ 50.1397],\n",
      "        [  4.3786],\n",
      "        [  1.7001]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[216.3315],\n",
      "        [  1.7001],\n",
      "        [ 60.7289],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [ 14.5599],\n",
      "        [  0.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  3.2999],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  0.8822],\n",
      "        [  7.5407],\n",
      "        [  1.7001],\n",
      "        [  1.8829],\n",
      "        [ 11.2999],\n",
      "        [  1.7001],\n",
      "        [167.8675],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  8.2999],\n",
      "        [  0.2999],\n",
      "        [  0.8822],\n",
      "        [  1.7999],\n",
      "        [  2.7799],\n",
      "        [  2.7999],\n",
      "        [  4.9999],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  8.2999],\n",
      "        [  3.2629],\n",
      "        [  8.7999],\n",
      "        [ 68.6144],\n",
      "        [  1.7001],\n",
      "        [  5.0757],\n",
      "        [ 23.3799],\n",
      "        [  8.2185],\n",
      "        [ 15.6079],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [ 30.8999],\n",
      "        [ 31.2999],\n",
      "        [ 32.2999],\n",
      "        [ 33.2999],\n",
      "        [ 36.2999],\n",
      "        [  1.7001],\n",
      "        [ 25.1544],\n",
      "        [ 11.6547],\n",
      "        [  7.8219],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [ 22.9876],\n",
      "        [  6.8583],\n",
      "        [ 39.7999],\n",
      "        [  4.2427],\n",
      "        [ 12.2851],\n",
      "        [ 33.2209],\n",
      "        [ 18.0867],\n",
      "        [ 16.6025],\n",
      "        [ 24.5916],\n",
      "        [ 27.3690],\n",
      "        [ 28.1232],\n",
      "        [ 42.2999],\n",
      "        [ 49.2999],\n",
      "        [ 53.2999],\n",
      "        [ 53.2999],\n",
      "        [ 16.3186],\n",
      "        [  1.7001],\n",
      "        [  1.7001],\n",
      "        [ 11.6425],\n",
      "        [ 11.6425],\n",
      "        [ 26.6397],\n",
      "        [  0.3786],\n",
      "        [ 62.7999]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(853.5815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 74\n",
      "Number of shrink: 26\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[216.2586],\n",
      "        [  1.7063],\n",
      "        [ 60.2368],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [ 14.5537],\n",
      "        [  0.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  3.2937],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  0.6739],\n",
      "        [  7.5511],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [ 11.2937],\n",
      "        [  1.7063],\n",
      "        [167.9764],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  8.2937],\n",
      "        [  0.2937],\n",
      "        [  0.6739],\n",
      "        [  1.7937],\n",
      "        [  2.7737],\n",
      "        [  2.7937],\n",
      "        [  4.9937],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  8.2937],\n",
      "        [  3.1595],\n",
      "        [  8.7937],\n",
      "        [ 68.5228],\n",
      "        [  1.7063],\n",
      "        [  5.0948],\n",
      "        [ 23.3737],\n",
      "        [  8.2632],\n",
      "        [ 15.6823],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [ 30.8937],\n",
      "        [ 31.2937],\n",
      "        [ 32.2937],\n",
      "        [ 33.2937],\n",
      "        [ 36.2937],\n",
      "        [  1.7063],\n",
      "        [ 25.3037],\n",
      "        [ 11.6487],\n",
      "        [  7.8541],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [ 23.0183],\n",
      "        [  6.8962],\n",
      "        [ 39.7937],\n",
      "        [  4.1296],\n",
      "        [ 12.2963],\n",
      "        [ 33.6187],\n",
      "        [ 18.1449],\n",
      "        [ 16.6539],\n",
      "        [ 24.5998],\n",
      "        [ 27.4080],\n",
      "        [ 28.1753],\n",
      "        [ 42.2937],\n",
      "        [ 49.2937],\n",
      "        [ 53.2937],\n",
      "        [ 53.2937],\n",
      "        [ 16.2101],\n",
      "        [  1.7063],\n",
      "        [  2.2657],\n",
      "        [ 11.5969],\n",
      "        [ 11.5969],\n",
      "        [ 26.7366],\n",
      "        [  0.4036],\n",
      "        [ 62.7937]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 24.831263303756714\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 125\n",
      "剩餘X 資料 torch.Size([78, 10])\n",
      "剩餘Y 資料 torch.Size([78, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (4037.472412109375, 66)\n",
      "The second_loss value of k: (4514.14599609375, 77)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引66，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([133, 1])\n",
      "<<預測值>>\n",
      "tensor([[101.7414],\n",
      "        [  1.7063],\n",
      "        [265.5332],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [225.3261],\n",
      "        [ 79.8389],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [167.9764],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [225.3261],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  3.1595],\n",
      "        [  1.7063],\n",
      "        [ 30.4772],\n",
      "        [  1.7063],\n",
      "        [  5.0948],\n",
      "        [  1.7063],\n",
      "        [  8.2632],\n",
      "        [ 82.1823],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [ 25.3037],\n",
      "        [ 11.6487],\n",
      "        [  7.8541],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [ 23.0183],\n",
      "        [  6.8962],\n",
      "        [  1.7063],\n",
      "        [ 62.8704],\n",
      "        [ 12.2963],\n",
      "        [139.8187],\n",
      "        [ 18.1449],\n",
      "        [ 16.6539],\n",
      "        [ 24.5998],\n",
      "        [ 27.4080],\n",
      "        [ 28.1753],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [132.7899],\n",
      "        [  1.7063],\n",
      "        [  2.2657],\n",
      "        [ 11.5969],\n",
      "        [ 11.5969],\n",
      "        [ 50.2366],\n",
      "        [  4.4036],\n",
      "        [  1.7063],\n",
      "        [ 63.5411]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[216.2586],\n",
      "        [  1.7063],\n",
      "        [ 60.2368],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [ 14.5537],\n",
      "        [  0.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  3.2937],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  0.6739],\n",
      "        [  7.5511],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [ 11.2937],\n",
      "        [  1.7063],\n",
      "        [167.9764],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  8.2937],\n",
      "        [  0.2937],\n",
      "        [  0.6739],\n",
      "        [  1.7937],\n",
      "        [  2.7737],\n",
      "        [  2.7937],\n",
      "        [  4.9937],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  8.2937],\n",
      "        [  3.1595],\n",
      "        [  8.7937],\n",
      "        [ 68.5228],\n",
      "        [  1.7063],\n",
      "        [  5.0948],\n",
      "        [ 23.3737],\n",
      "        [  8.2632],\n",
      "        [ 15.6823],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [ 30.8937],\n",
      "        [ 31.2937],\n",
      "        [ 32.2937],\n",
      "        [ 33.2937],\n",
      "        [ 36.2937],\n",
      "        [  1.7063],\n",
      "        [ 25.3037],\n",
      "        [ 11.6487],\n",
      "        [  7.8541],\n",
      "        [  1.7063],\n",
      "        [  1.7063],\n",
      "        [ 23.0183],\n",
      "        [  6.8962],\n",
      "        [ 39.7937],\n",
      "        [  4.1296],\n",
      "        [ 12.2963],\n",
      "        [ 33.6187],\n",
      "        [ 18.1449],\n",
      "        [ 16.6539],\n",
      "        [ 24.5998],\n",
      "        [ 27.4080],\n",
      "        [ 28.1753],\n",
      "        [ 42.2937],\n",
      "        [ 49.2937],\n",
      "        [ 53.2937],\n",
      "        [ 53.2937],\n",
      "        [ 16.2101],\n",
      "        [  1.7063],\n",
      "        [  2.2657],\n",
      "        [ 11.5969],\n",
      "        [ 11.5969],\n",
      "        [ 26.7366],\n",
      "        [  0.4036],\n",
      "        [ 62.7937],\n",
      "        [ 63.5411]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(877.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[216.5350],\n",
      "        [  1.7536],\n",
      "        [ 72.6223],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 14.5064],\n",
      "        [  0.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  3.2464],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  0.8611],\n",
      "        [  5.2725],\n",
      "        [  1.7536],\n",
      "        [  3.7636],\n",
      "        [ 11.2464],\n",
      "        [  1.7536],\n",
      "        [168.5582],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  8.2464],\n",
      "        [  0.2464],\n",
      "        [  0.8611],\n",
      "        [  1.7464],\n",
      "        [  2.7264],\n",
      "        [  2.7464],\n",
      "        [  4.9464],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  8.2464],\n",
      "        [  1.7536],\n",
      "        [  8.7464],\n",
      "        [ 69.1124],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 23.3264],\n",
      "        [  8.2316],\n",
      "        [ 15.5785],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 30.8464],\n",
      "        [ 31.2464],\n",
      "        [ 32.2464],\n",
      "        [ 33.2464],\n",
      "        [ 36.2464],\n",
      "        [  1.7536],\n",
      "        [ 25.4407],\n",
      "        [ 11.5879],\n",
      "        [  4.9489],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 22.2825],\n",
      "        [  6.1145],\n",
      "        [ 39.7464],\n",
      "        [  3.8769],\n",
      "        [ 12.2535],\n",
      "        [ 35.3926],\n",
      "        [ 17.5172],\n",
      "        [ 16.2465],\n",
      "        [ 23.0130],\n",
      "        [ 27.3039],\n",
      "        [ 27.9498],\n",
      "        [ 42.2464],\n",
      "        [ 49.2464],\n",
      "        [ 53.2464],\n",
      "        [ 53.2464],\n",
      "        [ 13.6599],\n",
      "        [  1.7536],\n",
      "        [  2.9442],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 13.7164],\n",
      "        [  1.6663],\n",
      "        [ 62.7464],\n",
      "        [ 28.4875]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 25.096649169921875\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 126\n",
      "剩餘X 資料 torch.Size([77, 10])\n",
      "剩餘Y 資料 torch.Size([77, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (4288.3193359375, 76)\n",
      "The second_loss value of k: (4795.06689453125, 38)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引76，y= tensor([236.])\n",
      "目前模型的Data狀態 torch.Size([134, 1])\n",
      "<<預測值>>\n",
      "tensor([[101.4650],\n",
      "        [  1.7536],\n",
      "        [253.1477],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [225.1389],\n",
      "        [ 82.1175],\n",
      "        [  1.7536],\n",
      "        [  3.7636],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [168.5582],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [225.1389],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 29.8876],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  8.2316],\n",
      "        [ 82.0785],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 25.4407],\n",
      "        [ 11.5879],\n",
      "        [  4.9489],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 22.2825],\n",
      "        [  6.1145],\n",
      "        [  1.7536],\n",
      "        [ 63.1231],\n",
      "        [ 12.2535],\n",
      "        [141.5926],\n",
      "        [ 17.5172],\n",
      "        [ 16.2465],\n",
      "        [ 23.0130],\n",
      "        [ 27.3039],\n",
      "        [ 27.9498],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [135.3401],\n",
      "        [  1.7536],\n",
      "        [  2.9442],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 37.2164],\n",
      "        [  5.6663],\n",
      "        [  1.7536],\n",
      "        [ 28.4875],\n",
      "        [170.5147]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[216.5350],\n",
      "        [  1.7536],\n",
      "        [ 72.6223],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 14.5064],\n",
      "        [  0.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  3.2464],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  0.8611],\n",
      "        [  5.2725],\n",
      "        [  1.7536],\n",
      "        [  3.7636],\n",
      "        [ 11.2464],\n",
      "        [  1.7536],\n",
      "        [168.5582],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  8.2464],\n",
      "        [  0.2464],\n",
      "        [  0.8611],\n",
      "        [  1.7464],\n",
      "        [  2.7264],\n",
      "        [  2.7464],\n",
      "        [  4.9464],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  8.2464],\n",
      "        [  1.7536],\n",
      "        [  8.7464],\n",
      "        [ 69.1124],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 23.3264],\n",
      "        [  8.2316],\n",
      "        [ 15.5785],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 30.8464],\n",
      "        [ 31.2464],\n",
      "        [ 32.2464],\n",
      "        [ 33.2464],\n",
      "        [ 36.2464],\n",
      "        [  1.7536],\n",
      "        [ 25.4407],\n",
      "        [ 11.5879],\n",
      "        [  4.9489],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 22.2825],\n",
      "        [  6.1145],\n",
      "        [ 39.7464],\n",
      "        [  3.8769],\n",
      "        [ 12.2535],\n",
      "        [ 35.3926],\n",
      "        [ 17.5172],\n",
      "        [ 16.2465],\n",
      "        [ 23.0130],\n",
      "        [ 27.3039],\n",
      "        [ 27.9498],\n",
      "        [ 42.2464],\n",
      "        [ 49.2464],\n",
      "        [ 53.2464],\n",
      "        [ 53.2464],\n",
      "        [ 13.6599],\n",
      "        [  1.7536],\n",
      "        [  2.9442],\n",
      "        [  1.7536],\n",
      "        [  1.7536],\n",
      "        [ 13.7164],\n",
      "        [  1.6663],\n",
      "        [ 62.7464],\n",
      "        [ 28.4875],\n",
      "        [ 65.4853]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(886.2299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  216.7428],\n",
      "        [    1.8380],\n",
      "        [   68.1714],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   14.4220],\n",
      "        [    0.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    3.1620],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   16.9111],\n",
      "        [    3.6590],\n",
      "        [    1.8380],\n",
      "        [    2.9556],\n",
      "        [   11.1620],\n",
      "        [    1.8380],\n",
      "        [  172.1209],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    8.1620],\n",
      "        [    0.1620],\n",
      "        [   16.9111],\n",
      "        [    1.6620],\n",
      "        [    2.6420],\n",
      "        [    2.6620],\n",
      "        [    4.8620],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    8.1620],\n",
      "        [    6.1473],\n",
      "        [    8.6620],\n",
      "        [   71.0180],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   23.2420],\n",
      "        [    7.7870],\n",
      "        [   11.6340],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   30.7620],\n",
      "        [   31.1620],\n",
      "        [   32.1620],\n",
      "        [   33.1620],\n",
      "        [   36.1620],\n",
      "        [    1.8380],\n",
      "        [   25.2730],\n",
      "        [   10.0010],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   24.4659],\n",
      "        [    4.1190],\n",
      "        [   39.6620],\n",
      "        [    4.5556],\n",
      "        [    9.2339],\n",
      "        [   37.1398],\n",
      "        [   15.6796],\n",
      "        [   11.8356],\n",
      "        [   22.2465],\n",
      "        [   26.3521],\n",
      "        [   26.7596],\n",
      "        [   42.1620],\n",
      "        [   49.1620],\n",
      "        [   53.1620],\n",
      "        [   53.1620],\n",
      "        [   10.5977],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   11.8903],\n",
      "        [    1.8921],\n",
      "        [   62.6620],\n",
      "        [   22.9599],\n",
      "        [   45.1880]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 25.36362099647522\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 127\n",
      "剩餘X 資料 torch.Size([76, 10])\n",
      "剩餘Y 資料 torch.Size([76, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (4783.384765625, 38)\n",
      "The second_loss value of k: (5984.88134765625, 64)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引38，y= tensor([71.])\n",
      "目前模型的Data狀態 torch.Size([135, 1])\n",
      "<<預測值>>\n",
      "tensor([[101.2572],\n",
      "        [  1.8380],\n",
      "        [257.5985],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [242.9111],\n",
      "        [ 83.7310],\n",
      "        [  1.8380],\n",
      "        [  2.9556],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [172.1209],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [242.9111],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  6.1473],\n",
      "        [  1.8380],\n",
      "        [ 27.9820],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  7.7870],\n",
      "        [ 78.1340],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [ 25.2730],\n",
      "        [ 10.0010],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [ 24.4659],\n",
      "        [  4.1190],\n",
      "        [  1.8380],\n",
      "        [ 62.4444],\n",
      "        [  9.2339],\n",
      "        [143.3398],\n",
      "        [ 15.6796],\n",
      "        [ 11.8356],\n",
      "        [ 22.2465],\n",
      "        [ 26.3521],\n",
      "        [ 26.7596],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [138.4023],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [  1.8380],\n",
      "        [ 35.3903],\n",
      "        [  5.8921],\n",
      "        [  1.8380],\n",
      "        [ 22.9599],\n",
      "        [190.8120],\n",
      "        [  1.8380]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  216.7428],\n",
      "        [    1.8380],\n",
      "        [   68.1714],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   14.4220],\n",
      "        [    0.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    3.1620],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   16.9111],\n",
      "        [    3.6590],\n",
      "        [    1.8380],\n",
      "        [    2.9556],\n",
      "        [   11.1620],\n",
      "        [    1.8380],\n",
      "        [  172.1209],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    8.1620],\n",
      "        [    0.1620],\n",
      "        [   16.9111],\n",
      "        [    1.6620],\n",
      "        [    2.6420],\n",
      "        [    2.6620],\n",
      "        [    4.8620],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    8.1620],\n",
      "        [    6.1473],\n",
      "        [    8.6620],\n",
      "        [   71.0180],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   23.2420],\n",
      "        [    7.7870],\n",
      "        [   11.6340],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   30.7620],\n",
      "        [   31.1620],\n",
      "        [   32.1620],\n",
      "        [   33.1620],\n",
      "        [   36.1620],\n",
      "        [    1.8380],\n",
      "        [   25.2730],\n",
      "        [   10.0010],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   24.4659],\n",
      "        [    4.1190],\n",
      "        [   39.6620],\n",
      "        [    4.5556],\n",
      "        [    9.2339],\n",
      "        [   37.1398],\n",
      "        [   15.6796],\n",
      "        [   11.8356],\n",
      "        [   22.2465],\n",
      "        [   26.3521],\n",
      "        [   26.7596],\n",
      "        [   42.1620],\n",
      "        [   49.1620],\n",
      "        [   53.1620],\n",
      "        [   53.1620],\n",
      "        [   10.5977],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [    1.8380],\n",
      "        [   11.8903],\n",
      "        [    1.8921],\n",
      "        [   62.6620],\n",
      "        [   22.9599],\n",
      "        [   45.1880],\n",
      "        [   69.1620]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(903.5374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  216.7854],\n",
      "        [    1.8591],\n",
      "        [   66.3160],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   14.4009],\n",
      "        [    0.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    3.1409],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   17.1858],\n",
      "        [    3.4966],\n",
      "        [    1.8591],\n",
      "        [    2.6953],\n",
      "        [   11.1409],\n",
      "        [    1.8591],\n",
      "        [  172.8173],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    8.1409],\n",
      "        [    0.1409],\n",
      "        [   17.1858],\n",
      "        [    1.6409],\n",
      "        [    2.6209],\n",
      "        [    2.6409],\n",
      "        [    4.8409],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    8.1409],\n",
      "        [    5.0880],\n",
      "        [    8.6409],\n",
      "        [   71.9909],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   23.2209],\n",
      "        [    7.4300],\n",
      "        [   11.9000],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   30.7409],\n",
      "        [   31.1409],\n",
      "        [   32.1409],\n",
      "        [   33.1409],\n",
      "        [   36.1409],\n",
      "        [    1.8591],\n",
      "        [   24.7399],\n",
      "        [    9.7533],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   23.5526],\n",
      "        [    3.2266],\n",
      "        [   39.6409],\n",
      "        [    5.0945],\n",
      "        [    8.6575],\n",
      "        [   36.7735],\n",
      "        [   14.8060],\n",
      "        [   11.2633],\n",
      "        [   22.0380],\n",
      "        [   25.8670],\n",
      "        [   26.1526],\n",
      "        [   42.1409],\n",
      "        [   49.1409],\n",
      "        [   53.1409],\n",
      "        [   53.1409],\n",
      "        [   10.4394],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   12.2892],\n",
      "        [    0.8114],\n",
      "        [   62.6409],\n",
      "        [   23.2031],\n",
      "        [   44.9612],\n",
      "        [   69.1409]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 25.628356218338013\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 128\n",
      "剩餘X 資料 torch.Size([75, 10])\n",
      "剩餘Y 資料 torch.Size([75, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (5981.61181640625, 63)\n",
      "The second_loss value of k: (6207.65869140625, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引63，y= tensor([79.2000])\n",
      "目前模型的Data狀態 torch.Size([136, 1])\n",
      "<<預測值>>\n",
      "tensor([[101.2146],\n",
      "        [  1.8591],\n",
      "        [259.4540],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [243.1858],\n",
      "        [ 83.8934],\n",
      "        [  1.8591],\n",
      "        [  2.6953],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [172.8173],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [243.1858],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  5.0880],\n",
      "        [  1.8591],\n",
      "        [ 27.0091],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  7.4300],\n",
      "        [ 78.4000],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [ 24.7399],\n",
      "        [  9.7533],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [ 23.5526],\n",
      "        [  3.2266],\n",
      "        [  1.8591],\n",
      "        [ 61.9055],\n",
      "        [  8.6575],\n",
      "        [142.9735],\n",
      "        [ 14.8060],\n",
      "        [ 11.2633],\n",
      "        [ 22.0380],\n",
      "        [ 25.8670],\n",
      "        [ 26.1526],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [138.5606],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [  1.8591],\n",
      "        [ 35.7892],\n",
      "        [  4.8114],\n",
      "        [  1.8591],\n",
      "        [ 23.2031],\n",
      "        [191.0388],\n",
      "        [  1.8591],\n",
      "        [  1.8591]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  216.7854],\n",
      "        [    1.8591],\n",
      "        [   66.3160],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   14.4009],\n",
      "        [    0.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    3.1409],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   17.1858],\n",
      "        [    3.4966],\n",
      "        [    1.8591],\n",
      "        [    2.6953],\n",
      "        [   11.1409],\n",
      "        [    1.8591],\n",
      "        [  172.8173],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    8.1409],\n",
      "        [    0.1409],\n",
      "        [   17.1858],\n",
      "        [    1.6409],\n",
      "        [    2.6209],\n",
      "        [    2.6409],\n",
      "        [    4.8409],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    8.1409],\n",
      "        [    5.0880],\n",
      "        [    8.6409],\n",
      "        [   71.9909],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   23.2209],\n",
      "        [    7.4300],\n",
      "        [   11.9000],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   30.7409],\n",
      "        [   31.1409],\n",
      "        [   32.1409],\n",
      "        [   33.1409],\n",
      "        [   36.1409],\n",
      "        [    1.8591],\n",
      "        [   24.7399],\n",
      "        [    9.7533],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   23.5526],\n",
      "        [    3.2266],\n",
      "        [   39.6409],\n",
      "        [    5.0945],\n",
      "        [    8.6575],\n",
      "        [   36.7735],\n",
      "        [   14.8060],\n",
      "        [   11.2633],\n",
      "        [   22.0380],\n",
      "        [   25.8670],\n",
      "        [   26.1526],\n",
      "        [   42.1409],\n",
      "        [   49.1409],\n",
      "        [   53.1409],\n",
      "        [   53.1409],\n",
      "        [   10.4394],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [    1.8591],\n",
      "        [   12.2892],\n",
      "        [    0.8114],\n",
      "        [   62.6409],\n",
      "        [   23.2031],\n",
      "        [   44.9612],\n",
      "        [   69.1409],\n",
      "        [   77.3409]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(940.1926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  216.9412],\n",
      "        [    1.8766],\n",
      "        [   65.0753],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   14.3834],\n",
      "        [    0.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    3.1234],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   17.4397],\n",
      "        [    3.3911],\n",
      "        [    1.8766],\n",
      "        [    2.5897],\n",
      "        [   11.1234],\n",
      "        [    1.8766],\n",
      "        [  173.1399],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    8.1234],\n",
      "        [    0.1234],\n",
      "        [   17.4397],\n",
      "        [    1.6234],\n",
      "        [    2.6034],\n",
      "        [    2.6234],\n",
      "        [    4.8234],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    8.1234],\n",
      "        [    4.1906],\n",
      "        [    8.6234],\n",
      "        [   72.3094],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   23.2034],\n",
      "        [    7.1980],\n",
      "        [   11.7827],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   30.7234],\n",
      "        [   31.1234],\n",
      "        [   32.1234],\n",
      "        [   33.1234],\n",
      "        [   36.1234],\n",
      "        [    1.8766],\n",
      "        [   24.3438],\n",
      "        [    9.7461],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   23.0621],\n",
      "        [    2.8510],\n",
      "        [   39.6234],\n",
      "        [    5.0512],\n",
      "        [    8.4643],\n",
      "        [   36.8308],\n",
      "        [   14.4883],\n",
      "        [   11.1337],\n",
      "        [   22.0598],\n",
      "        [   25.7915],\n",
      "        [   26.0162],\n",
      "        [   42.1234],\n",
      "        [   49.1234],\n",
      "        [   53.1234],\n",
      "        [   53.1234],\n",
      "        [    9.9748],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   12.2302],\n",
      "        [    0.6667],\n",
      "        [   62.6234],\n",
      "        [   22.6787],\n",
      "        [   44.8917],\n",
      "        [   69.1234],\n",
      "        [   77.3234]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 25.887343406677246\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 129\n",
      "剩餘X 資料 torch.Size([74, 10])\n",
      "剩餘Y 資料 torch.Size([74, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (6235.873046875, 1)\n",
      "The second_loss value of k: (7009.60205078125, 18)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([137, 1])\n",
      "<<預測值>>\n",
      "tensor([[101.0588],\n",
      "        [  1.8766],\n",
      "        [260.6947],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [243.4397],\n",
      "        [ 83.9989],\n",
      "        [  1.8766],\n",
      "        [  2.5897],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [173.1399],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [243.4397],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  4.1906],\n",
      "        [  1.8766],\n",
      "        [ 26.6906],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  7.1980],\n",
      "        [ 78.2827],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [ 24.3438],\n",
      "        [  9.7461],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [ 23.0621],\n",
      "        [  2.8510],\n",
      "        [  1.8766],\n",
      "        [ 61.9488],\n",
      "        [  8.4643],\n",
      "        [143.0308],\n",
      "        [ 14.4883],\n",
      "        [ 11.1337],\n",
      "        [ 22.0598],\n",
      "        [ 25.7915],\n",
      "        [ 26.0162],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [139.0252],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [ 35.7302],\n",
      "        [  4.6667],\n",
      "        [  1.8766],\n",
      "        [ 22.6787],\n",
      "        [191.1083],\n",
      "        [  1.8766],\n",
      "        [  1.8766],\n",
      "        [ 78.9675]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  216.9412],\n",
      "        [    1.8766],\n",
      "        [   65.0753],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   14.3834],\n",
      "        [    0.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    3.1234],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   17.4397],\n",
      "        [    3.3911],\n",
      "        [    1.8766],\n",
      "        [    2.5897],\n",
      "        [   11.1234],\n",
      "        [    1.8766],\n",
      "        [  173.1399],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    8.1234],\n",
      "        [    0.1234],\n",
      "        [   17.4397],\n",
      "        [    1.6234],\n",
      "        [    2.6034],\n",
      "        [    2.6234],\n",
      "        [    4.8234],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    8.1234],\n",
      "        [    4.1906],\n",
      "        [    8.6234],\n",
      "        [   72.3094],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   23.2034],\n",
      "        [    7.1980],\n",
      "        [   11.7827],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   30.7234],\n",
      "        [   31.1234],\n",
      "        [   32.1234],\n",
      "        [   33.1234],\n",
      "        [   36.1234],\n",
      "        [    1.8766],\n",
      "        [   24.3438],\n",
      "        [    9.7461],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   23.0621],\n",
      "        [    2.8510],\n",
      "        [   39.6234],\n",
      "        [    5.0512],\n",
      "        [    8.4643],\n",
      "        [   36.8308],\n",
      "        [   14.4883],\n",
      "        [   11.1337],\n",
      "        [   22.0598],\n",
      "        [   25.7915],\n",
      "        [   26.0162],\n",
      "        [   42.1234],\n",
      "        [   49.1234],\n",
      "        [   53.1234],\n",
      "        [   53.1234],\n",
      "        [    9.9748],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [    1.8766],\n",
      "        [   12.2302],\n",
      "        [    0.6667],\n",
      "        [   62.6234],\n",
      "        [   22.6787],\n",
      "        [   44.8917],\n",
      "        [   69.1234],\n",
      "        [   77.3234],\n",
      "        [   78.9675]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(978.3864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  218.3742],\n",
      "        [    1.9441],\n",
      "        [   74.4547],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   14.3159],\n",
      "        [    0.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    3.0559],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   20.6103],\n",
      "        [   11.6139],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   11.0559],\n",
      "        [    1.9441],\n",
      "        [  174.2123],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    8.0559],\n",
      "        [    0.0559],\n",
      "        [   20.6103],\n",
      "        [    1.5559],\n",
      "        [    2.5359],\n",
      "        [    2.5559],\n",
      "        [    4.7559],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    8.0559],\n",
      "        [    5.1827],\n",
      "        [    8.5559],\n",
      "        [   74.3891],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   23.1359],\n",
      "        [    1.9441],\n",
      "        [    1.5282],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   30.6559],\n",
      "        [   31.0559],\n",
      "        [   32.0559],\n",
      "        [   33.0559],\n",
      "        [   36.0559],\n",
      "        [    1.9441],\n",
      "        [   12.7731],\n",
      "        [    8.0444],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   22.7955],\n",
      "        [    1.9441],\n",
      "        [   39.5559],\n",
      "        [    6.3564],\n",
      "        [    4.6096],\n",
      "        [   21.5361],\n",
      "        [   12.6043],\n",
      "        [    6.7051],\n",
      "        [   22.0405],\n",
      "        [   24.6195],\n",
      "        [   24.6174],\n",
      "        [   42.0559],\n",
      "        [   49.0559],\n",
      "        [   53.0559],\n",
      "        [   53.0559],\n",
      "        [   13.0491],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    8.0610],\n",
      "        [    1.1822],\n",
      "        [   62.5559],\n",
      "        [   27.7441],\n",
      "        [   37.7168],\n",
      "        [   69.0559],\n",
      "        [   77.2559],\n",
      "        [   63.1352]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 26.145947694778442\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 130\n",
      "剩餘X 資料 torch.Size([73, 10])\n",
      "剩餘Y 資料 torch.Size([73, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (5127.240234375, 71)\n",
      "The second_loss value of k: (6998.314453125, 17)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引71，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([138, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 99.6258],\n",
      "        [  1.9441],\n",
      "        [251.3153],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [246.6103],\n",
      "        [ 75.7761],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [174.2123],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [246.6103],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  5.1827],\n",
      "        [  1.9441],\n",
      "        [ 24.6109],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [ 64.9718],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [ 12.7731],\n",
      "        [  8.0444],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [ 22.7955],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [ 60.6436],\n",
      "        [  4.6096],\n",
      "        [127.7361],\n",
      "        [ 12.6043],\n",
      "        [  6.7051],\n",
      "        [ 22.0405],\n",
      "        [ 24.6195],\n",
      "        [ 24.6174],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [135.9509],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [ 31.5610],\n",
      "        [  5.1822],\n",
      "        [  1.9441],\n",
      "        [ 27.7441],\n",
      "        [198.2832],\n",
      "        [  1.9441],\n",
      "        [  1.9441],\n",
      "        [ 63.1352],\n",
      "        [ 71.6048]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  218.3742],\n",
      "        [    1.9441],\n",
      "        [   74.4547],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   14.3159],\n",
      "        [    0.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    3.0559],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   20.6103],\n",
      "        [   11.6139],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   11.0559],\n",
      "        [    1.9441],\n",
      "        [  174.2123],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    8.0559],\n",
      "        [    0.0559],\n",
      "        [   20.6103],\n",
      "        [    1.5559],\n",
      "        [    2.5359],\n",
      "        [    2.5559],\n",
      "        [    4.7559],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    8.0559],\n",
      "        [    5.1827],\n",
      "        [    8.5559],\n",
      "        [   74.3891],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   23.1359],\n",
      "        [    1.9441],\n",
      "        [    1.5282],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   30.6559],\n",
      "        [   31.0559],\n",
      "        [   32.0559],\n",
      "        [   33.0559],\n",
      "        [   36.0559],\n",
      "        [    1.9441],\n",
      "        [   12.7731],\n",
      "        [    8.0444],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [   22.7955],\n",
      "        [    1.9441],\n",
      "        [   39.5559],\n",
      "        [    6.3564],\n",
      "        [    4.6096],\n",
      "        [   21.5361],\n",
      "        [   12.6043],\n",
      "        [    6.7051],\n",
      "        [   22.0405],\n",
      "        [   24.6195],\n",
      "        [   24.6174],\n",
      "        [   42.0559],\n",
      "        [   49.0559],\n",
      "        [   53.0559],\n",
      "        [   53.0559],\n",
      "        [   13.0491],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    1.9441],\n",
      "        [    8.0610],\n",
      "        [    1.1822],\n",
      "        [   62.5559],\n",
      "        [   27.7441],\n",
      "        [   37.7168],\n",
      "        [   69.0559],\n",
      "        [   77.2559],\n",
      "        [   63.1352],\n",
      "        [   71.6048]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(997.2803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  221.9210],\n",
      "        [    2.0423],\n",
      "        [   78.4741],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   14.2177],\n",
      "        [    1.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.9577],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   23.6908],\n",
      "        [   10.3750],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   10.9577],\n",
      "        [    2.0423],\n",
      "        [  172.7189],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    7.9577],\n",
      "        [    0.0423],\n",
      "        [   23.6908],\n",
      "        [    1.4577],\n",
      "        [    2.4377],\n",
      "        [    2.4577],\n",
      "        [    4.6577],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    7.9577],\n",
      "        [    2.0423],\n",
      "        [    8.4577],\n",
      "        [   71.4747],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   23.0377],\n",
      "        [    2.0423],\n",
      "        [   24.6968],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   30.5577],\n",
      "        [   30.9577],\n",
      "        [   31.9577],\n",
      "        [   32.9577],\n",
      "        [   35.9577],\n",
      "        [    2.0423],\n",
      "        [    4.9136],\n",
      "        [    7.6216],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   25.2836],\n",
      "        [    2.5535],\n",
      "        [   39.4577],\n",
      "        [    2.5482],\n",
      "        [    5.5310],\n",
      "        [   15.3011],\n",
      "        [   14.7529],\n",
      "        [    4.3106],\n",
      "        [   23.8506],\n",
      "        [   26.5982],\n",
      "        [   26.8300],\n",
      "        [   41.9577],\n",
      "        [   48.9577],\n",
      "        [   52.9577],\n",
      "        [   52.9577],\n",
      "        [   26.0553],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    0.0956],\n",
      "        [    1.9577],\n",
      "        [   62.4577],\n",
      "        [   31.0099],\n",
      "        [   30.5012],\n",
      "        [   68.9577],\n",
      "        [   77.1577],\n",
      "        [   52.8590],\n",
      "        [   44.2699]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 26.40401816368103\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 131\n",
      "剩餘X 資料 torch.Size([72, 10])\n",
      "剩餘Y 資料 torch.Size([72, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (6981.89453125, 17)\n",
      "The second_loss value of k: (7217.81640625, 53)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([85.6000])\n",
      "目前模型的Data狀態 torch.Size([139, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 96.0790],\n",
      "        [  2.0423],\n",
      "        [247.2959],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [249.6908],\n",
      "        [ 77.0150],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [172.7189],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [249.6908],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [ 27.5253],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [ 41.8032],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  4.9136],\n",
      "        [  7.6216],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [ 25.2836],\n",
      "        [  2.5535],\n",
      "        [  2.0423],\n",
      "        [ 64.4518],\n",
      "        [  5.5310],\n",
      "        [121.5011],\n",
      "        [ 14.7529],\n",
      "        [  4.3106],\n",
      "        [ 23.8506],\n",
      "        [ 26.5982],\n",
      "        [ 26.8300],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [122.9447],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [ 23.4044],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [ 31.0099],\n",
      "        [205.4988],\n",
      "        [  2.0423],\n",
      "        [  2.0423],\n",
      "        [ 52.8590],\n",
      "        [ 44.2699],\n",
      "        [  2.0423]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  221.9210],\n",
      "        [    2.0423],\n",
      "        [   78.4741],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   14.2177],\n",
      "        [    1.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.9577],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   23.6908],\n",
      "        [   10.3750],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   10.9577],\n",
      "        [    2.0423],\n",
      "        [  172.7189],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    7.9577],\n",
      "        [    0.0423],\n",
      "        [   23.6908],\n",
      "        [    1.4577],\n",
      "        [    2.4377],\n",
      "        [    2.4577],\n",
      "        [    4.6577],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    7.9577],\n",
      "        [    2.0423],\n",
      "        [    8.4577],\n",
      "        [   71.4747],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   23.0377],\n",
      "        [    2.0423],\n",
      "        [   24.6968],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   30.5577],\n",
      "        [   30.9577],\n",
      "        [   31.9577],\n",
      "        [   32.9577],\n",
      "        [   35.9577],\n",
      "        [    2.0423],\n",
      "        [    4.9136],\n",
      "        [    7.6216],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [   25.2836],\n",
      "        [    2.5535],\n",
      "        [   39.4577],\n",
      "        [    2.5482],\n",
      "        [    5.5310],\n",
      "        [   15.3011],\n",
      "        [   14.7529],\n",
      "        [    4.3106],\n",
      "        [   23.8506],\n",
      "        [   26.5982],\n",
      "        [   26.8300],\n",
      "        [   41.9577],\n",
      "        [   48.9577],\n",
      "        [   52.9577],\n",
      "        [   52.9577],\n",
      "        [   26.0553],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    2.0423],\n",
      "        [    0.0956],\n",
      "        [    1.9577],\n",
      "        [   62.4577],\n",
      "        [   31.0099],\n",
      "        [   30.5012],\n",
      "        [   68.9577],\n",
      "        [   77.1577],\n",
      "        [   52.8590],\n",
      "        [   44.2699],\n",
      "        [   83.5577]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1024.5060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 71\n",
      "Number of shrink: 29\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  221.3199],\n",
      "        [    2.0504],\n",
      "        [   77.9860],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [   14.2096],\n",
      "        [    1.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.9496],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [   24.1567],\n",
      "        [   10.5138],\n",
      "        [    2.0504],\n",
      "        [    2.1014],\n",
      "        [   10.9496],\n",
      "        [    2.0504],\n",
      "        [  173.5221],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    7.9496],\n",
      "        [    0.0504],\n",
      "        [   24.1567],\n",
      "        [    1.4496],\n",
      "        [    2.4296],\n",
      "        [    2.4496],\n",
      "        [    4.6496],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    7.9496],\n",
      "        [    2.0504],\n",
      "        [    8.4496],\n",
      "        [   71.0883],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [   23.0296],\n",
      "        [    2.0504],\n",
      "        [   25.4339],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [   30.5496],\n",
      "        [   30.9496],\n",
      "        [   31.9496],\n",
      "        [   32.9496],\n",
      "        [   35.9496],\n",
      "        [    2.0504],\n",
      "        [    5.3390],\n",
      "        [    7.6388],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [   25.5750],\n",
      "        [    2.8045],\n",
      "        [   39.4496],\n",
      "        [    2.1460],\n",
      "        [    5.6428],\n",
      "        [   16.2884],\n",
      "        [   15.0503],\n",
      "        [    4.3316],\n",
      "        [   23.9205],\n",
      "        [   26.8170],\n",
      "        [   27.0907],\n",
      "        [   41.9496],\n",
      "        [   48.9496],\n",
      "        [   52.9496],\n",
      "        [   52.9496],\n",
      "        [   25.5816],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    0.2190],\n",
      "        [    1.9496],\n",
      "        [   62.4496],\n",
      "        [   30.3117],\n",
      "        [   30.0209],\n",
      "        [   68.9496],\n",
      "        [   77.1496],\n",
      "        [   53.1102],\n",
      "        [   44.2316],\n",
      "        [   83.5496]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 26.668754816055298\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 132\n",
      "剩餘X 資料 torch.Size([71, 10])\n",
      "剩餘Y 資料 torch.Size([71, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (7216.43701171875, 52)\n",
      "The second_loss value of k: (8056.9443359375, 19)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引52，y= tensor([87.])\n",
      "目前模型的Data狀態 torch.Size([140, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 96.6801],\n",
      "        [  2.0504],\n",
      "        [247.7840],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [250.1567],\n",
      "        [ 76.8762],\n",
      "        [  2.0504],\n",
      "        [  2.1014],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [173.5221],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [250.1567],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [ 27.9117],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [ 41.0661],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  5.3390],\n",
      "        [  7.6388],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [ 25.5750],\n",
      "        [  2.8045],\n",
      "        [  2.0504],\n",
      "        [ 64.8540],\n",
      "        [  5.6428],\n",
      "        [122.4884],\n",
      "        [ 15.0503],\n",
      "        [  4.3316],\n",
      "        [ 23.9205],\n",
      "        [ 26.8170],\n",
      "        [ 27.0907],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [123.4184],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [ 23.7190],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [ 30.3117],\n",
      "        [205.9791],\n",
      "        [  2.0504],\n",
      "        [  2.0504],\n",
      "        [ 53.1102],\n",
      "        [ 44.2316],\n",
      "        [  2.0504],\n",
      "        [  2.0504]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  221.3199],\n",
      "        [    2.0504],\n",
      "        [   77.9860],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [   14.2096],\n",
      "        [    1.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.9496],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [   24.1567],\n",
      "        [   10.5138],\n",
      "        [    2.0504],\n",
      "        [    2.1014],\n",
      "        [   10.9496],\n",
      "        [    2.0504],\n",
      "        [  173.5221],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    7.9496],\n",
      "        [    0.0504],\n",
      "        [   24.1567],\n",
      "        [    1.4496],\n",
      "        [    2.4296],\n",
      "        [    2.4496],\n",
      "        [    4.6496],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    7.9496],\n",
      "        [    2.0504],\n",
      "        [    8.4496],\n",
      "        [   71.0883],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [   23.0296],\n",
      "        [    2.0504],\n",
      "        [   25.4339],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [   30.5496],\n",
      "        [   30.9496],\n",
      "        [   31.9496],\n",
      "        [   32.9496],\n",
      "        [   35.9496],\n",
      "        [    2.0504],\n",
      "        [    5.3390],\n",
      "        [    7.6388],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [   25.5750],\n",
      "        [    2.8045],\n",
      "        [   39.4496],\n",
      "        [    2.1460],\n",
      "        [    5.6428],\n",
      "        [   16.2884],\n",
      "        [   15.0503],\n",
      "        [    4.3316],\n",
      "        [   23.9205],\n",
      "        [   26.8170],\n",
      "        [   27.0907],\n",
      "        [   41.9496],\n",
      "        [   48.9496],\n",
      "        [   52.9496],\n",
      "        [   52.9496],\n",
      "        [   25.5816],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    2.0504],\n",
      "        [    0.2190],\n",
      "        [    1.9496],\n",
      "        [   62.4496],\n",
      "        [   30.3117],\n",
      "        [   30.0209],\n",
      "        [   68.9496],\n",
      "        [   77.1496],\n",
      "        [   53.1102],\n",
      "        [   44.2316],\n",
      "        [   83.5496],\n",
      "        [   84.9496]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1068.5300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 70\n",
      "Number of shrink: 30\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  221.1849],\n",
      "        [    2.0524],\n",
      "        [   77.9139],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [   14.2076],\n",
      "        [    1.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.9476],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [   24.1695],\n",
      "        [   10.5189],\n",
      "        [    2.0524],\n",
      "        [    2.0753],\n",
      "        [   10.9476],\n",
      "        [    2.0524],\n",
      "        [  173.6909],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.1033],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    7.9476],\n",
      "        [    0.0524],\n",
      "        [   24.1695],\n",
      "        [    1.4476],\n",
      "        [    2.4276],\n",
      "        [    2.4476],\n",
      "        [    4.6476],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    7.9476],\n",
      "        [    2.0524],\n",
      "        [    8.4476],\n",
      "        [   71.0385],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [   23.0276],\n",
      "        [    2.0524],\n",
      "        [   25.4492],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [   30.5476],\n",
      "        [   30.9476],\n",
      "        [   31.9476],\n",
      "        [   32.9476],\n",
      "        [   35.9476],\n",
      "        [    2.0524],\n",
      "        [    5.3909],\n",
      "        [    7.6380],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [   25.5923],\n",
      "        [    2.8323],\n",
      "        [   39.4476],\n",
      "        [    2.0924],\n",
      "        [    5.6611],\n",
      "        [   16.4309],\n",
      "        [   15.0857],\n",
      "        [    4.3481],\n",
      "        [   23.9216],\n",
      "        [   26.8407],\n",
      "        [   27.1209],\n",
      "        [   41.9476],\n",
      "        [   48.9476],\n",
      "        [   52.9476],\n",
      "        [   52.9476],\n",
      "        [   25.5835],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    0.2033],\n",
      "        [    1.9476],\n",
      "        [   62.4476],\n",
      "        [   30.2051],\n",
      "        [   30.0253],\n",
      "        [   68.9476],\n",
      "        [   77.1476],\n",
      "        [   53.1808],\n",
      "        [   44.2632],\n",
      "        [   83.5476],\n",
      "        [   84.9476]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 26.931625843048096\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 133\n",
      "剩餘X 資料 torch.Size([70, 10])\n",
      "剩餘Y 資料 torch.Size([70, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (8058.30322265625, 19)\n",
      "The second_loss value of k: (8058.30322265625, 61)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引19，y= tensor([22.3000])\n",
      "目前模型的Data狀態 torch.Size([141, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 96.8151],\n",
      "        [  2.0524],\n",
      "        [247.8561],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [250.1695],\n",
      "        [ 76.8711],\n",
      "        [  2.0524],\n",
      "        [  2.0753],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [173.6909],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.1033],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [250.1695],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [ 27.9615],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [ 41.0508],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  5.3909],\n",
      "        [  7.6380],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [ 25.5923],\n",
      "        [  2.8323],\n",
      "        [  2.0524],\n",
      "        [ 64.9076],\n",
      "        [  5.6611],\n",
      "        [122.6309],\n",
      "        [ 15.0857],\n",
      "        [  4.3481],\n",
      "        [ 23.9216],\n",
      "        [ 26.8407],\n",
      "        [ 27.1209],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [123.4165],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [ 23.7033],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [ 30.2051],\n",
      "        [205.9747],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [ 53.1808],\n",
      "        [ 44.2632],\n",
      "        [  2.0524],\n",
      "        [  2.0524],\n",
      "        [112.0680]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  221.1849],\n",
      "        [    2.0524],\n",
      "        [   77.9139],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [   14.2076],\n",
      "        [    1.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.9476],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [   24.1695],\n",
      "        [   10.5189],\n",
      "        [    2.0524],\n",
      "        [    2.0753],\n",
      "        [   10.9476],\n",
      "        [    2.0524],\n",
      "        [  173.6909],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.1033],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    7.9476],\n",
      "        [    0.0524],\n",
      "        [   24.1695],\n",
      "        [    1.4476],\n",
      "        [    2.4276],\n",
      "        [    2.4476],\n",
      "        [    4.6476],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    7.9476],\n",
      "        [    2.0524],\n",
      "        [    8.4476],\n",
      "        [   71.0385],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [   23.0276],\n",
      "        [    2.0524],\n",
      "        [   25.4492],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [   30.5476],\n",
      "        [   30.9476],\n",
      "        [   31.9476],\n",
      "        [   32.9476],\n",
      "        [   35.9476],\n",
      "        [    2.0524],\n",
      "        [    5.3909],\n",
      "        [    7.6380],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [   25.5923],\n",
      "        [    2.8323],\n",
      "        [   39.4476],\n",
      "        [    2.0924],\n",
      "        [    5.6611],\n",
      "        [   16.4309],\n",
      "        [   15.0857],\n",
      "        [    4.3481],\n",
      "        [   23.9216],\n",
      "        [   26.8407],\n",
      "        [   27.1209],\n",
      "        [   41.9476],\n",
      "        [   48.9476],\n",
      "        [   52.9476],\n",
      "        [   52.9476],\n",
      "        [   25.5835],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    2.0524],\n",
      "        [    0.2033],\n",
      "        [    1.9476],\n",
      "        [   62.4476],\n",
      "        [   30.2051],\n",
      "        [   30.0253],\n",
      "        [   68.9476],\n",
      "        [   77.1476],\n",
      "        [   53.1808],\n",
      "        [   44.2632],\n",
      "        [   83.5476],\n",
      "        [   84.9476],\n",
      "        [   89.7681]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1118.0651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  227.1096],\n",
      "        [    2.2080],\n",
      "        [   80.7086],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   14.0520],\n",
      "        [    1.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.7920],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   20.8600],\n",
      "        [    9.7943],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   10.7920],\n",
      "        [    2.2080],\n",
      "        [  167.4157],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    7.7920],\n",
      "        [    0.2080],\n",
      "        [   20.8600],\n",
      "        [    1.2920],\n",
      "        [    2.2720],\n",
      "        [    2.2920],\n",
      "        [    4.4920],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    7.7920],\n",
      "        [    2.2080],\n",
      "        [    8.2920],\n",
      "        [   68.8844],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   22.8720],\n",
      "        [    2.2080],\n",
      "        [   29.3716],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   30.3920],\n",
      "        [   30.7920],\n",
      "        [   31.7920],\n",
      "        [   32.7920],\n",
      "        [   35.7920],\n",
      "        [    2.2080],\n",
      "        [    6.4762],\n",
      "        [    7.1675],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   26.3685],\n",
      "        [    4.6000],\n",
      "        [   39.2920],\n",
      "        [    1.3809],\n",
      "        [    6.4455],\n",
      "        [   17.5596],\n",
      "        [   16.8340],\n",
      "        [    4.1638],\n",
      "        [   23.6037],\n",
      "        [   27.2214],\n",
      "        [   27.9450],\n",
      "        [   41.7920],\n",
      "        [   48.7920],\n",
      "        [   52.7920],\n",
      "        [   52.7920],\n",
      "        [   24.1429],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    3.6443],\n",
      "        [    0.8398],\n",
      "        [   62.2920],\n",
      "        [   35.0130],\n",
      "        [   34.4912],\n",
      "        [   68.7920],\n",
      "        [   76.9920],\n",
      "        [   53.6748],\n",
      "        [   43.0832],\n",
      "        [   83.3920],\n",
      "        [   84.7920],\n",
      "        [   64.2214]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 27.19246816635132\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 134\n",
      "剩餘X 資料 torch.Size([69, 10])\n",
      "剩餘Y 資料 torch.Size([69, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (4124.384765625, 60)\n",
      "The second_loss value of k: (8152.63818359375, 21)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引60，y= tensor([22.3000])\n",
      "目前模型的Data狀態 torch.Size([142, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 90.8904],\n",
      "        [  2.2080],\n",
      "        [245.0614],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [246.8600],\n",
      "        [ 77.5957],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [167.4157],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [246.8600],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [ 30.1156],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [ 37.1284],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  6.4762],\n",
      "        [  7.1675],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [ 26.3685],\n",
      "        [  4.6000],\n",
      "        [  2.2080],\n",
      "        [ 65.6191],\n",
      "        [  6.4455],\n",
      "        [123.7596],\n",
      "        [ 16.8340],\n",
      "        [  4.1638],\n",
      "        [ 23.6037],\n",
      "        [ 27.2214],\n",
      "        [ 27.9450],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [124.8571],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [ 27.1443],\n",
      "        [  4.8398],\n",
      "        [  2.2080],\n",
      "        [ 35.0130],\n",
      "        [201.5088],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [ 53.6748],\n",
      "        [ 43.0832],\n",
      "        [  2.2080],\n",
      "        [  2.2080],\n",
      "        [ 86.5214],\n",
      "        [ 86.5214]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  227.1096],\n",
      "        [    2.2080],\n",
      "        [   80.7086],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   14.0520],\n",
      "        [    1.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.7920],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   20.8600],\n",
      "        [    9.7943],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   10.7920],\n",
      "        [    2.2080],\n",
      "        [  167.4157],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    7.7920],\n",
      "        [    0.2080],\n",
      "        [   20.8600],\n",
      "        [    1.2920],\n",
      "        [    2.2720],\n",
      "        [    2.2920],\n",
      "        [    4.4920],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    7.7920],\n",
      "        [    2.2080],\n",
      "        [    8.2920],\n",
      "        [   68.8844],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   22.8720],\n",
      "        [    2.2080],\n",
      "        [   29.3716],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   30.3920],\n",
      "        [   30.7920],\n",
      "        [   31.7920],\n",
      "        [   32.7920],\n",
      "        [   35.7920],\n",
      "        [    2.2080],\n",
      "        [    6.4762],\n",
      "        [    7.1675],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [   26.3685],\n",
      "        [    4.6000],\n",
      "        [   39.2920],\n",
      "        [    1.3809],\n",
      "        [    6.4455],\n",
      "        [   17.5596],\n",
      "        [   16.8340],\n",
      "        [    4.1638],\n",
      "        [   23.6037],\n",
      "        [   27.2214],\n",
      "        [   27.9450],\n",
      "        [   41.7920],\n",
      "        [   48.7920],\n",
      "        [   52.7920],\n",
      "        [   52.7920],\n",
      "        [   24.1429],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    2.2080],\n",
      "        [    3.6443],\n",
      "        [    0.8398],\n",
      "        [   62.2920],\n",
      "        [   35.0130],\n",
      "        [   34.4912],\n",
      "        [   68.7920],\n",
      "        [   76.9920],\n",
      "        [   53.6748],\n",
      "        [   43.0832],\n",
      "        [   83.3920],\n",
      "        [   84.7920],\n",
      "        [   64.2214],\n",
      "        [   64.2214]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1118.9138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 80\n",
      "Number of shrink: 20\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  228.7184],\n",
      "        [    2.4357],\n",
      "        [   80.7123],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   13.8243],\n",
      "        [    1.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.5643],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   20.9435],\n",
      "        [   10.2500],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   10.5643],\n",
      "        [    2.4357],\n",
      "        [  169.5338],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    7.5643],\n",
      "        [    0.4357],\n",
      "        [   20.9435],\n",
      "        [    1.0643],\n",
      "        [    2.0443],\n",
      "        [    2.0643],\n",
      "        [    4.2643],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    7.5643],\n",
      "        [    2.4357],\n",
      "        [    8.0643],\n",
      "        [   67.8279],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   22.6443],\n",
      "        [    2.4357],\n",
      "        [   27.3542],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   30.1643],\n",
      "        [   30.5643],\n",
      "        [   31.5643],\n",
      "        [   32.5643],\n",
      "        [   35.5643],\n",
      "        [    2.4357],\n",
      "        [    6.1195],\n",
      "        [    6.1050],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   25.5994],\n",
      "        [    4.9079],\n",
      "        [   39.0643],\n",
      "        [    0.7273],\n",
      "        [    5.2320],\n",
      "        [   19.3358],\n",
      "        [   17.3461],\n",
      "        [    2.9759],\n",
      "        [   22.6310],\n",
      "        [   26.9204],\n",
      "        [   27.9833],\n",
      "        [   41.5643],\n",
      "        [   48.5643],\n",
      "        [   52.5643],\n",
      "        [   52.5643],\n",
      "        [   23.4538],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.6246],\n",
      "        [    0.0116],\n",
      "        [   62.0643],\n",
      "        [   36.0642],\n",
      "        [   36.4392],\n",
      "        [   68.5643],\n",
      "        [   76.7643],\n",
      "        [   54.6753],\n",
      "        [   44.3844],\n",
      "        [   83.1643],\n",
      "        [   84.5643],\n",
      "        [   30.6043],\n",
      "        [   30.6043]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 27.486969232559204\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 135\n",
      "剩餘X 資料 torch.Size([68, 10])\n",
      "剩餘Y 資料 torch.Size([68, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (8111.58251953125, 21)\n",
      "The second_loss value of k: (9132.5400390625, 67)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引21，y= tensor([92.5000])\n",
      "目前模型的Data狀態 torch.Size([143, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 89.2816],\n",
      "        [  2.4357],\n",
      "        [245.0577],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [246.9435],\n",
      "        [ 77.1400],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [169.5338],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [246.9435],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [ 31.1722],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [ 39.1458],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  6.1195],\n",
      "        [  6.1050],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [ 25.5994],\n",
      "        [  4.9079],\n",
      "        [  2.4357],\n",
      "        [ 66.2727],\n",
      "        [  5.2320],\n",
      "        [125.5358],\n",
      "        [ 17.3461],\n",
      "        [  2.9759],\n",
      "        [ 22.6310],\n",
      "        [ 26.9204],\n",
      "        [ 27.9833],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [125.5462],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [ 26.1246],\n",
      "        [  3.9884],\n",
      "        [  2.4357],\n",
      "        [ 36.0642],\n",
      "        [199.5608],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [ 54.6753],\n",
      "        [ 44.3844],\n",
      "        [  2.4357],\n",
      "        [  2.4357],\n",
      "        [ 52.9043],\n",
      "        [ 52.9043],\n",
      "        [  2.4357]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  228.7184],\n",
      "        [    2.4357],\n",
      "        [   80.7123],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   13.8243],\n",
      "        [    1.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.5643],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   20.9435],\n",
      "        [   10.2500],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   10.5643],\n",
      "        [    2.4357],\n",
      "        [  169.5338],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    7.5643],\n",
      "        [    0.4357],\n",
      "        [   20.9435],\n",
      "        [    1.0643],\n",
      "        [    2.0443],\n",
      "        [    2.0643],\n",
      "        [    4.2643],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    7.5643],\n",
      "        [    2.4357],\n",
      "        [    8.0643],\n",
      "        [   67.8279],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   22.6443],\n",
      "        [    2.4357],\n",
      "        [   27.3542],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   30.1643],\n",
      "        [   30.5643],\n",
      "        [   31.5643],\n",
      "        [   32.5643],\n",
      "        [   35.5643],\n",
      "        [    2.4357],\n",
      "        [    6.1195],\n",
      "        [    6.1050],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [   25.5994],\n",
      "        [    4.9079],\n",
      "        [   39.0643],\n",
      "        [    0.7273],\n",
      "        [    5.2320],\n",
      "        [   19.3358],\n",
      "        [   17.3461],\n",
      "        [    2.9759],\n",
      "        [   22.6310],\n",
      "        [   26.9204],\n",
      "        [   27.9833],\n",
      "        [   41.5643],\n",
      "        [   48.5643],\n",
      "        [   52.5643],\n",
      "        [   52.5643],\n",
      "        [   23.4538],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.4357],\n",
      "        [    2.6246],\n",
      "        [    0.0116],\n",
      "        [   62.0643],\n",
      "        [   36.0642],\n",
      "        [   36.4392],\n",
      "        [   68.5643],\n",
      "        [   76.7643],\n",
      "        [   54.6753],\n",
      "        [   44.3844],\n",
      "        [   83.1643],\n",
      "        [   84.5643],\n",
      "        [   30.6043],\n",
      "        [   30.6043],\n",
      "        [   90.0643]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1131.9403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[225.4171],\n",
      "        [  2.5348],\n",
      "        [ 84.9872],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 13.7252],\n",
      "        [  1.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.4652],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 23.1355],\n",
      "        [  9.4902],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 10.4652],\n",
      "        [  2.5348],\n",
      "        [176.2325],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  7.4652],\n",
      "        [  0.5348],\n",
      "        [ 23.1355],\n",
      "        [  0.9652],\n",
      "        [  1.9452],\n",
      "        [  1.9652],\n",
      "        [  4.1652],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  7.4652],\n",
      "        [  2.5348],\n",
      "        [  7.9652],\n",
      "        [ 67.6122],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 22.5452],\n",
      "        [  2.5348],\n",
      "        [ 26.0315],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 30.0652],\n",
      "        [ 30.4652],\n",
      "        [ 31.4652],\n",
      "        [ 32.4652],\n",
      "        [ 35.4652],\n",
      "        [  2.5348],\n",
      "        [  4.4807],\n",
      "        [  5.2295],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 25.5277],\n",
      "        [  4.7130],\n",
      "        [ 38.9652],\n",
      "        [  0.4778],\n",
      "        [  4.3623],\n",
      "        [ 18.6757],\n",
      "        [ 17.2841],\n",
      "        [  2.5348],\n",
      "        [ 21.7468],\n",
      "        [ 26.6033],\n",
      "        [ 27.7994],\n",
      "        [ 41.4652],\n",
      "        [ 48.4652],\n",
      "        [ 52.4652],\n",
      "        [ 52.4652],\n",
      "        [ 22.2936],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  0.9783],\n",
      "        [  0.8414],\n",
      "        [ 61.9652],\n",
      "        [ 29.2431],\n",
      "        [ 34.0086],\n",
      "        [ 68.4652],\n",
      "        [ 76.6652],\n",
      "        [ 53.1727],\n",
      "        [ 43.8530],\n",
      "        [ 83.0652],\n",
      "        [ 84.4652],\n",
      "        [ 16.4333],\n",
      "        [ 16.4333],\n",
      "        [ 89.9652]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 27.785398721694946\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 136\n",
      "剩餘X 資料 torch.Size([67, 10])\n",
      "剩餘Y 資料 torch.Size([67, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (8681.8125, 12)\n",
      "The second_loss value of k: (9113.6005859375, 66)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([206.])\n",
      "目前模型的Data狀態 torch.Size([144, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 92.5828],\n",
      "        [  2.5348],\n",
      "        [240.7828],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [249.1355],\n",
      "        [ 77.8998],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [176.2325],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [249.1355],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 31.3878],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 40.4685],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  4.4807],\n",
      "        [  5.2295],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 25.5277],\n",
      "        [  4.7130],\n",
      "        [  2.5348],\n",
      "        [ 66.5222],\n",
      "        [  4.3623],\n",
      "        [124.8757],\n",
      "        [ 17.2841],\n",
      "        [  2.5348],\n",
      "        [ 21.7468],\n",
      "        [ 26.6033],\n",
      "        [ 27.7994],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [126.7064],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 22.5217],\n",
      "        [  4.8414],\n",
      "        [  2.5348],\n",
      "        [ 29.2431],\n",
      "        [201.9914],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 53.1727],\n",
      "        [ 43.8530],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 38.7333],\n",
      "        [ 38.7333],\n",
      "        [  2.5348],\n",
      "        [112.8238]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[225.4171],\n",
      "        [  2.5348],\n",
      "        [ 84.9872],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 13.7252],\n",
      "        [  1.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.4652],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 23.1355],\n",
      "        [  9.4902],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 10.4652],\n",
      "        [  2.5348],\n",
      "        [176.2325],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  7.4652],\n",
      "        [  0.5348],\n",
      "        [ 23.1355],\n",
      "        [  0.9652],\n",
      "        [  1.9452],\n",
      "        [  1.9652],\n",
      "        [  4.1652],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  7.4652],\n",
      "        [  2.5348],\n",
      "        [  7.9652],\n",
      "        [ 67.6122],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 22.5452],\n",
      "        [  2.5348],\n",
      "        [ 26.0315],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 30.0652],\n",
      "        [ 30.4652],\n",
      "        [ 31.4652],\n",
      "        [ 32.4652],\n",
      "        [ 35.4652],\n",
      "        [  2.5348],\n",
      "        [  4.4807],\n",
      "        [  5.2295],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [ 25.5277],\n",
      "        [  4.7130],\n",
      "        [ 38.9652],\n",
      "        [  0.4778],\n",
      "        [  4.3623],\n",
      "        [ 18.6757],\n",
      "        [ 17.2841],\n",
      "        [  2.5348],\n",
      "        [ 21.7468],\n",
      "        [ 26.6033],\n",
      "        [ 27.7994],\n",
      "        [ 41.4652],\n",
      "        [ 48.4652],\n",
      "        [ 52.4652],\n",
      "        [ 52.4652],\n",
      "        [ 22.2936],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  2.5348],\n",
      "        [  0.9783],\n",
      "        [  0.8414],\n",
      "        [ 61.9652],\n",
      "        [ 29.2431],\n",
      "        [ 34.0086],\n",
      "        [ 68.4652],\n",
      "        [ 76.6652],\n",
      "        [ 53.1727],\n",
      "        [ 43.8530],\n",
      "        [ 83.0652],\n",
      "        [ 84.4652],\n",
      "        [ 16.4333],\n",
      "        [ 16.4333],\n",
      "        [ 89.9652],\n",
      "        [ 93.1762]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1178.1530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  199.7756],\n",
      "        [    2.6099],\n",
      "        [   83.8135],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   13.6501],\n",
      "        [    1.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.3901],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   21.4884],\n",
      "        [    9.6672],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   10.3901],\n",
      "        [    2.6099],\n",
      "        [  210.8417],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    7.3901],\n",
      "        [    0.6099],\n",
      "        [   21.4884],\n",
      "        [    0.8901],\n",
      "        [    1.8701],\n",
      "        [    1.8901],\n",
      "        [    4.0901],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    7.3901],\n",
      "        [    2.6099],\n",
      "        [    7.8901],\n",
      "        [   67.6268],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   22.4701],\n",
      "        [    2.6099],\n",
      "        [   24.2712],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   29.9901],\n",
      "        [   30.3901],\n",
      "        [   31.3901],\n",
      "        [   32.3901],\n",
      "        [   35.3901],\n",
      "        [    2.6099],\n",
      "        [    4.1979],\n",
      "        [    4.0686],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   25.3636],\n",
      "        [    4.5803],\n",
      "        [   38.8901],\n",
      "        [    0.5170],\n",
      "        [    3.7008],\n",
      "        [   18.9761],\n",
      "        [   17.1478],\n",
      "        [    2.6099],\n",
      "        [   21.4389],\n",
      "        [   26.3290],\n",
      "        [   27.5900],\n",
      "        [   41.3901],\n",
      "        [   48.3901],\n",
      "        [   52.3901],\n",
      "        [   52.3901],\n",
      "        [   30.5719],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    1.4740],\n",
      "        [    0.0733],\n",
      "        [   61.8901],\n",
      "        [   31.3062],\n",
      "        [   31.6654],\n",
      "        [   68.3901],\n",
      "        [   76.5901],\n",
      "        [   50.1227],\n",
      "        [   44.0527],\n",
      "        [   82.9901],\n",
      "        [   84.3901],\n",
      "        [   12.0543],\n",
      "        [   12.0543],\n",
      "        [   89.8901],\n",
      "        [   59.0282]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 28.080358266830444\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 137\n",
      "剩餘X 資料 torch.Size([66, 10])\n",
      "剩餘Y 資料 torch.Size([66, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (2046.34814453125, 21)\n",
      "The second_loss value of k: (8784.3857421875, 58)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引21，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([145, 1])\n",
      "<<預測值>>\n",
      "tensor([[118.2244],\n",
      "        [  2.6099],\n",
      "        [241.9565],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [247.4884],\n",
      "        [ 77.7228],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [210.8417],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [247.4884],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [ 31.3732],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [ 42.2288],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  4.1979],\n",
      "        [  4.0686],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [ 25.3636],\n",
      "        [  4.5803],\n",
      "        [  2.6099],\n",
      "        [ 66.4830],\n",
      "        [  3.7008],\n",
      "        [125.1761],\n",
      "        [ 17.1478],\n",
      "        [  2.6099],\n",
      "        [ 21.4389],\n",
      "        [ 26.3290],\n",
      "        [ 27.5900],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [118.4281],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [ 24.9740],\n",
      "        [  4.0733],\n",
      "        [  2.6099],\n",
      "        [ 31.3062],\n",
      "        [204.3346],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [ 50.1227],\n",
      "        [ 44.0527],\n",
      "        [  2.6099],\n",
      "        [  2.6099],\n",
      "        [ 34.3543],\n",
      "        [ 34.3543],\n",
      "        [  2.6099],\n",
      "        [146.9718],\n",
      "        [ 45.2366]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  199.7756],\n",
      "        [    2.6099],\n",
      "        [   83.8135],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   13.6501],\n",
      "        [    1.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.3901],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   21.4884],\n",
      "        [    9.6672],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   10.3901],\n",
      "        [    2.6099],\n",
      "        [  210.8417],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    7.3901],\n",
      "        [    0.6099],\n",
      "        [   21.4884],\n",
      "        [    0.8901],\n",
      "        [    1.8701],\n",
      "        [    1.8901],\n",
      "        [    4.0901],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    7.3901],\n",
      "        [    2.6099],\n",
      "        [    7.8901],\n",
      "        [   67.6268],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   22.4701],\n",
      "        [    2.6099],\n",
      "        [   24.2712],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   29.9901],\n",
      "        [   30.3901],\n",
      "        [   31.3901],\n",
      "        [   32.3901],\n",
      "        [   35.3901],\n",
      "        [    2.6099],\n",
      "        [    4.1979],\n",
      "        [    4.0686],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [   25.3636],\n",
      "        [    4.5803],\n",
      "        [   38.8901],\n",
      "        [    0.5170],\n",
      "        [    3.7008],\n",
      "        [   18.9761],\n",
      "        [   17.1478],\n",
      "        [    2.6099],\n",
      "        [   21.4389],\n",
      "        [   26.3290],\n",
      "        [   27.5900],\n",
      "        [   41.3901],\n",
      "        [   48.3901],\n",
      "        [   52.3901],\n",
      "        [   52.3901],\n",
      "        [   30.5719],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    2.6099],\n",
      "        [    1.4740],\n",
      "        [    0.0733],\n",
      "        [   61.8901],\n",
      "        [   31.3062],\n",
      "        [   31.6654],\n",
      "        [   68.3901],\n",
      "        [   76.5901],\n",
      "        [   50.1227],\n",
      "        [   44.0527],\n",
      "        [   82.9901],\n",
      "        [   84.3901],\n",
      "        [   12.0543],\n",
      "        [   12.0543],\n",
      "        [   89.8901],\n",
      "        [   59.0282],\n",
      "        [   45.2366]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1160.4296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[198.9781],\n",
      "        [  2.6713],\n",
      "        [ 81.7762],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 13.5887],\n",
      "        [  1.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.3287],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 20.2482],\n",
      "        [  9.6530],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 10.3287],\n",
      "        [  2.6713],\n",
      "        [213.2902],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  7.3287],\n",
      "        [  0.6713],\n",
      "        [ 20.2482],\n",
      "        [  0.8287],\n",
      "        [  1.8087],\n",
      "        [  1.8287],\n",
      "        [  4.0287],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  7.3287],\n",
      "        [  2.6713],\n",
      "        [  7.8287],\n",
      "        [ 68.7326],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 22.4087],\n",
      "        [  2.6713],\n",
      "        [ 22.1458],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 29.9287],\n",
      "        [ 30.3287],\n",
      "        [ 31.3287],\n",
      "        [ 32.3287],\n",
      "        [ 35.3287],\n",
      "        [  2.6713],\n",
      "        [  4.1657],\n",
      "        [  3.4934],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 23.8186],\n",
      "        [  3.5495],\n",
      "        [ 38.8287],\n",
      "        [  1.4318],\n",
      "        [  2.8119],\n",
      "        [ 19.2160],\n",
      "        [ 16.1088],\n",
      "        [  2.6713],\n",
      "        [ 20.7786],\n",
      "        [ 25.4840],\n",
      "        [ 26.6799],\n",
      "        [ 41.3287],\n",
      "        [ 48.3287],\n",
      "        [ 52.3287],\n",
      "        [ 52.3287],\n",
      "        [ 30.2079],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.8225],\n",
      "        [  1.6393],\n",
      "        [ 61.8287],\n",
      "        [ 32.2235],\n",
      "        [ 33.4571],\n",
      "        [ 68.3287],\n",
      "        [ 76.5287],\n",
      "        [ 50.9383],\n",
      "        [ 46.9944],\n",
      "        [ 82.9287],\n",
      "        [ 84.3287],\n",
      "        [  4.3973],\n",
      "        [  4.3973],\n",
      "        [ 89.8287],\n",
      "        [ 56.6824],\n",
      "        [  3.9932]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 28.343641757965088\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 138\n",
      "剩餘X 資料 torch.Size([65, 10])\n",
      "剩餘Y 資料 torch.Size([65, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (8614.1796875, 57)\n",
      "The second_loss value of k: (9087.55859375, 64)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引57，y= tensor([154.])\n",
      "目前模型的Data狀態 torch.Size([146, 1])\n",
      "<<預測值>>\n",
      "tensor([[119.0219],\n",
      "        [  2.6713],\n",
      "        [243.9937],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [246.2482],\n",
      "        [ 77.7370],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [213.2902],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [246.2482],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 30.2674],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 44.3542],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  4.1657],\n",
      "        [  3.4934],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 23.8186],\n",
      "        [  3.5495],\n",
      "        [  2.6713],\n",
      "        [ 65.5682],\n",
      "        [  2.8119],\n",
      "        [125.4159],\n",
      "        [ 16.1088],\n",
      "        [  2.6713],\n",
      "        [ 20.7786],\n",
      "        [ 25.4840],\n",
      "        [ 26.6799],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [118.7921],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 26.3225],\n",
      "        [  5.6393],\n",
      "        [  2.6713],\n",
      "        [ 32.2235],\n",
      "        [202.5429],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 50.9383],\n",
      "        [ 46.9944],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 26.6973],\n",
      "        [ 26.6973],\n",
      "        [  2.6713],\n",
      "        [149.3176],\n",
      "        [  3.9932],\n",
      "        [ 61.1874]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[198.9781],\n",
      "        [  2.6713],\n",
      "        [ 81.7762],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 13.5887],\n",
      "        [  1.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.3287],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 20.2482],\n",
      "        [  9.6530],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 10.3287],\n",
      "        [  2.6713],\n",
      "        [213.2902],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  7.3287],\n",
      "        [  0.6713],\n",
      "        [ 20.2482],\n",
      "        [  0.8287],\n",
      "        [  1.8087],\n",
      "        [  1.8287],\n",
      "        [  4.0287],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  7.3287],\n",
      "        [  2.6713],\n",
      "        [  7.8287],\n",
      "        [ 68.7326],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 22.4087],\n",
      "        [  2.6713],\n",
      "        [ 22.1458],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 29.9287],\n",
      "        [ 30.3287],\n",
      "        [ 31.3287],\n",
      "        [ 32.3287],\n",
      "        [ 35.3287],\n",
      "        [  2.6713],\n",
      "        [  4.1657],\n",
      "        [  3.4934],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [ 23.8186],\n",
      "        [  3.5495],\n",
      "        [ 38.8287],\n",
      "        [  1.4318],\n",
      "        [  2.8119],\n",
      "        [ 19.2160],\n",
      "        [ 16.1088],\n",
      "        [  2.6713],\n",
      "        [ 20.7786],\n",
      "        [ 25.4840],\n",
      "        [ 26.6799],\n",
      "        [ 41.3287],\n",
      "        [ 48.3287],\n",
      "        [ 52.3287],\n",
      "        [ 52.3287],\n",
      "        [ 30.2079],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.6713],\n",
      "        [  2.8225],\n",
      "        [  1.6393],\n",
      "        [ 61.8287],\n",
      "        [ 32.2235],\n",
      "        [ 33.4571],\n",
      "        [ 68.3287],\n",
      "        [ 76.5287],\n",
      "        [ 50.9383],\n",
      "        [ 46.9944],\n",
      "        [ 82.9287],\n",
      "        [ 84.3287],\n",
      "        [  4.3973],\n",
      "        [  4.3973],\n",
      "        [ 89.8287],\n",
      "        [ 56.6824],\n",
      "        [  3.9932],\n",
      "        [ 92.8126]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1197.5299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[190.7245],\n",
      "        [  2.7850],\n",
      "        [ 85.4301],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 12.0975],\n",
      "        [  1.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.2150],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 24.5341],\n",
      "        [ 13.7357],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 10.2150],\n",
      "        [  2.7850],\n",
      "        [224.4227],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  7.2150],\n",
      "        [  0.7850],\n",
      "        [ 24.5341],\n",
      "        [  0.7150],\n",
      "        [  1.6950],\n",
      "        [  1.7150],\n",
      "        [  3.9150],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  7.2150],\n",
      "        [  2.7850],\n",
      "        [  7.7150],\n",
      "        [ 73.1603],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 22.2950],\n",
      "        [  2.7850],\n",
      "        [ 19.1608],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 29.8150],\n",
      "        [ 30.2150],\n",
      "        [ 31.2150],\n",
      "        [ 32.2150],\n",
      "        [ 35.2150],\n",
      "        [  2.7850],\n",
      "        [  3.8689],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 24.3258],\n",
      "        [  2.7850],\n",
      "        [ 38.7150],\n",
      "        [  7.3804],\n",
      "        [  5.2413],\n",
      "        [ 12.4232],\n",
      "        [ 12.7004],\n",
      "        [  2.7850],\n",
      "        [ 18.6728],\n",
      "        [ 22.0811],\n",
      "        [ 23.0207],\n",
      "        [ 41.2150],\n",
      "        [ 48.2150],\n",
      "        [ 52.2150],\n",
      "        [ 52.2150],\n",
      "        [ 33.7390],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  3.4511],\n",
      "        [  3.4511],\n",
      "        [ 12.1040],\n",
      "        [  8.3462],\n",
      "        [ 61.7150],\n",
      "        [ 43.3940],\n",
      "        [ 24.4991],\n",
      "        [ 68.2150],\n",
      "        [ 76.4150],\n",
      "        [ 47.1362],\n",
      "        [ 46.1476],\n",
      "        [ 82.8150],\n",
      "        [ 84.2150],\n",
      "        [  2.9640],\n",
      "        [  2.9640],\n",
      "        [ 89.7150],\n",
      "        [ 42.4030],\n",
      "        [  2.7850],\n",
      "        [ 63.6240]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 28.606018781661987\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 139\n",
      "剩餘X 資料 torch.Size([64, 10])\n",
      "剩餘Y 資料 torch.Size([64, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (9065.8994140625, 63)\n",
      "The second_loss value of k: (10447.91015625, 28)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引63，y= tensor([98.])\n",
      "目前模型的Data狀態 torch.Size([147, 1])\n",
      "<<預測值>>\n",
      "tensor([[127.2755],\n",
      "        [  2.7850],\n",
      "        [240.3399],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  4.1625],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [250.5341],\n",
      "        [101.1257],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [224.4227],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [250.5341],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 25.8397],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 47.3392],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  3.8689],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 24.3258],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 59.6196],\n",
      "        [  5.2413],\n",
      "        [118.6232],\n",
      "        [ 12.7004],\n",
      "        [  2.7850],\n",
      "        [ 18.6728],\n",
      "        [ 22.0811],\n",
      "        [ 23.0207],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [115.2610],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  3.4511],\n",
      "        [  3.4511],\n",
      "        [ 35.6040],\n",
      "        [ 12.3462],\n",
      "        [  2.7850],\n",
      "        [ 43.3940],\n",
      "        [211.5009],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 47.1362],\n",
      "        [ 46.1476],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 25.2640],\n",
      "        [ 25.2640],\n",
      "        [  2.7850],\n",
      "        [163.5970],\n",
      "        [  2.7850],\n",
      "        [ 90.3760],\n",
      "        [  2.7850]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[190.7245],\n",
      "        [  2.7850],\n",
      "        [ 85.4301],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 12.0975],\n",
      "        [  1.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.2150],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 24.5341],\n",
      "        [ 13.7357],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 10.2150],\n",
      "        [  2.7850],\n",
      "        [224.4227],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  7.2150],\n",
      "        [  0.7850],\n",
      "        [ 24.5341],\n",
      "        [  0.7150],\n",
      "        [  1.6950],\n",
      "        [  1.7150],\n",
      "        [  3.9150],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  7.2150],\n",
      "        [  2.7850],\n",
      "        [  7.7150],\n",
      "        [ 73.1603],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 22.2950],\n",
      "        [  2.7850],\n",
      "        [ 19.1608],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 29.8150],\n",
      "        [ 30.2150],\n",
      "        [ 31.2150],\n",
      "        [ 32.2150],\n",
      "        [ 35.2150],\n",
      "        [  2.7850],\n",
      "        [  3.8689],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [ 24.3258],\n",
      "        [  2.7850],\n",
      "        [ 38.7150],\n",
      "        [  7.3804],\n",
      "        [  5.2413],\n",
      "        [ 12.4232],\n",
      "        [ 12.7004],\n",
      "        [  2.7850],\n",
      "        [ 18.6728],\n",
      "        [ 22.0811],\n",
      "        [ 23.0207],\n",
      "        [ 41.2150],\n",
      "        [ 48.2150],\n",
      "        [ 52.2150],\n",
      "        [ 52.2150],\n",
      "        [ 33.7390],\n",
      "        [  2.7850],\n",
      "        [  2.7850],\n",
      "        [  3.4511],\n",
      "        [  3.4511],\n",
      "        [ 12.1040],\n",
      "        [  8.3462],\n",
      "        [ 61.7150],\n",
      "        [ 43.3940],\n",
      "        [ 24.4991],\n",
      "        [ 68.2150],\n",
      "        [ 76.4150],\n",
      "        [ 47.1362],\n",
      "        [ 46.1476],\n",
      "        [ 82.8150],\n",
      "        [ 84.2150],\n",
      "        [  2.9640],\n",
      "        [  2.9640],\n",
      "        [ 89.7150],\n",
      "        [ 42.4030],\n",
      "        [  2.7850],\n",
      "        [ 63.6240],\n",
      "        [ 95.2150]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1228.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[191.5269],\n",
      "        [  2.8443],\n",
      "        [ 89.1671],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  8.9519],\n",
      "        [  1.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.1557],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 24.0305],\n",
      "        [ 19.4879],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 10.1557],\n",
      "        [  2.8443],\n",
      "        [222.3576],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  7.1557],\n",
      "        [  0.8443],\n",
      "        [ 24.0305],\n",
      "        [  0.6557],\n",
      "        [  1.6357],\n",
      "        [  1.6557],\n",
      "        [  3.8557],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  7.1557],\n",
      "        [  2.8443],\n",
      "        [  7.6557],\n",
      "        [ 74.8088],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 22.2357],\n",
      "        [  2.8443],\n",
      "        [ 17.6989],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 29.7557],\n",
      "        [ 30.1557],\n",
      "        [ 31.1557],\n",
      "        [ 32.1557],\n",
      "        [ 35.1557],\n",
      "        [  2.8443],\n",
      "        [  6.5067],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 24.6468],\n",
      "        [  2.8443],\n",
      "        [ 38.6557],\n",
      "        [ 10.2135],\n",
      "        [  5.5857],\n",
      "        [ 12.5678],\n",
      "        [ 11.4801],\n",
      "        [  2.8443],\n",
      "        [ 17.0611],\n",
      "        [ 20.4992],\n",
      "        [ 21.4222],\n",
      "        [ 41.1557],\n",
      "        [ 48.1557],\n",
      "        [ 52.1557],\n",
      "        [ 52.1557],\n",
      "        [ 37.8603],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 12.2513],\n",
      "        [  1.5033],\n",
      "        [ 61.6557],\n",
      "        [ 41.6315],\n",
      "        [ 23.1518],\n",
      "        [ 68.1557],\n",
      "        [ 76.3557],\n",
      "        [ 47.5976],\n",
      "        [ 46.0265],\n",
      "        [ 82.7557],\n",
      "        [ 84.1557],\n",
      "        [  2.3188],\n",
      "        [  2.3188],\n",
      "        [ 89.6557],\n",
      "        [ 42.3887],\n",
      "        [  5.4644],\n",
      "        [ 57.7452],\n",
      "        [ 95.1557]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 28.865540027618408\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 140\n",
      "剩餘X 資料 torch.Size([63, 10])\n",
      "剩餘Y 資料 torch.Size([63, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (10435.77734375, 28)\n",
      "The second_loss value of k: (10435.77734375, 36)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引28，y= tensor([105.])\n",
      "目前模型的Data狀態 torch.Size([148, 1])\n",
      "<<預測值>>\n",
      "tensor([[126.4731],\n",
      "        [  2.8443],\n",
      "        [236.6029],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  7.3081],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [250.0305],\n",
      "        [106.8779],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [222.3576],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [250.0305],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 24.1912],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 48.8011],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  6.5067],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 24.6468],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 56.7865],\n",
      "        [  5.5857],\n",
      "        [118.7678],\n",
      "        [ 11.4801],\n",
      "        [  2.8443],\n",
      "        [ 17.0611],\n",
      "        [ 20.4992],\n",
      "        [ 21.4222],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [111.1397],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 35.7513],\n",
      "        [  5.5033],\n",
      "        [  2.8443],\n",
      "        [ 41.6315],\n",
      "        [212.8482],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 47.5976],\n",
      "        [ 46.0265],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 24.6188],\n",
      "        [ 24.6188],\n",
      "        [  2.8443],\n",
      "        [163.6113],\n",
      "        [  5.4644],\n",
      "        [ 96.2548],\n",
      "        [  2.8443],\n",
      "        [  2.8443]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[191.5269],\n",
      "        [  2.8443],\n",
      "        [ 89.1671],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  8.9519],\n",
      "        [  1.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.1557],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 24.0305],\n",
      "        [ 19.4879],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 10.1557],\n",
      "        [  2.8443],\n",
      "        [222.3576],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  7.1557],\n",
      "        [  0.8443],\n",
      "        [ 24.0305],\n",
      "        [  0.6557],\n",
      "        [  1.6357],\n",
      "        [  1.6557],\n",
      "        [  3.8557],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  7.1557],\n",
      "        [  2.8443],\n",
      "        [  7.6557],\n",
      "        [ 74.8088],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 22.2357],\n",
      "        [  2.8443],\n",
      "        [ 17.6989],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 29.7557],\n",
      "        [ 30.1557],\n",
      "        [ 31.1557],\n",
      "        [ 32.1557],\n",
      "        [ 35.1557],\n",
      "        [  2.8443],\n",
      "        [  6.5067],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 24.6468],\n",
      "        [  2.8443],\n",
      "        [ 38.6557],\n",
      "        [ 10.2135],\n",
      "        [  5.5857],\n",
      "        [ 12.5678],\n",
      "        [ 11.4801],\n",
      "        [  2.8443],\n",
      "        [ 17.0611],\n",
      "        [ 20.4992],\n",
      "        [ 21.4222],\n",
      "        [ 41.1557],\n",
      "        [ 48.1557],\n",
      "        [ 52.1557],\n",
      "        [ 52.1557],\n",
      "        [ 37.8603],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [  2.8443],\n",
      "        [ 12.2513],\n",
      "        [  1.5033],\n",
      "        [ 61.6557],\n",
      "        [ 41.6315],\n",
      "        [ 23.1518],\n",
      "        [ 68.1557],\n",
      "        [ 76.3557],\n",
      "        [ 47.5976],\n",
      "        [ 46.0265],\n",
      "        [ 82.7557],\n",
      "        [ 84.1557],\n",
      "        [  2.3188],\n",
      "        [  2.3188],\n",
      "        [ 89.6557],\n",
      "        [ 42.3887],\n",
      "        [  5.4644],\n",
      "        [ 57.7452],\n",
      "        [ 95.1557],\n",
      "        [102.1557]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1286.9968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[192.9660],\n",
      "        [  2.8890],\n",
      "        [ 90.3840],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  7.2795],\n",
      "        [  1.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.1110],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 23.3395],\n",
      "        [ 18.2878],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 10.1110],\n",
      "        [  2.8890],\n",
      "        [219.7041],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  7.1110],\n",
      "        [  0.8890],\n",
      "        [ 23.3395],\n",
      "        [  0.6110],\n",
      "        [  1.5910],\n",
      "        [  1.6110],\n",
      "        [  3.8110],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  7.1110],\n",
      "        [  2.8890],\n",
      "        [  7.6110],\n",
      "        [ 75.9601],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 22.1910],\n",
      "        [  2.8890],\n",
      "        [ 16.7506],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 29.7110],\n",
      "        [ 30.1110],\n",
      "        [ 31.1110],\n",
      "        [ 32.1110],\n",
      "        [ 35.1110],\n",
      "        [  2.8890],\n",
      "        [  8.7175],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 24.7598],\n",
      "        [  2.8890],\n",
      "        [ 38.6110],\n",
      "        [ 12.2427],\n",
      "        [  4.6677],\n",
      "        [ 12.9993],\n",
      "        [ 10.6464],\n",
      "        [  2.8890],\n",
      "        [ 16.0429],\n",
      "        [ 19.3979],\n",
      "        [ 20.3084],\n",
      "        [ 41.1110],\n",
      "        [ 48.1110],\n",
      "        [ 52.1110],\n",
      "        [ 52.1110],\n",
      "        [ 39.2274],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 13.9314],\n",
      "        [  4.0477],\n",
      "        [ 61.6110],\n",
      "        [ 42.7301],\n",
      "        [ 23.0078],\n",
      "        [ 68.1110],\n",
      "        [ 76.3110],\n",
      "        [ 47.5142],\n",
      "        [ 47.2018],\n",
      "        [ 82.7110],\n",
      "        [ 84.1110],\n",
      "        [  1.4515],\n",
      "        [  1.4515],\n",
      "        [ 89.6110],\n",
      "        [ 43.5380],\n",
      "        [  5.4150],\n",
      "        [ 56.4294],\n",
      "        [ 95.1110],\n",
      "        [102.1110]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 29.125738620758057\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 141\n",
      "剩餘X 資料 torch.Size([62, 10])\n",
      "剩餘Y 資料 torch.Size([62, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (10426.6484375, 35)\n",
      "The second_loss value of k: (10754.9169921875, 13)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引35，y= tensor([105.])\n",
      "目前模型的Data狀態 torch.Size([149, 1])\n",
      "<<預測值>>\n",
      "tensor([[125.0340],\n",
      "        [  2.8890],\n",
      "        [235.3860],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  8.9805],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [249.3395],\n",
      "        [105.6778],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [219.7041],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [249.3395],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 23.0399],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 49.7494],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  8.7175],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 24.7598],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 54.7573],\n",
      "        [  4.6677],\n",
      "        [119.1992],\n",
      "        [ 10.6464],\n",
      "        [  2.8890],\n",
      "        [ 16.0429],\n",
      "        [ 19.3979],\n",
      "        [ 20.3084],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [109.7726],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 37.4314],\n",
      "        [  8.0477],\n",
      "        [  2.8890],\n",
      "        [ 42.7301],\n",
      "        [212.9922],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 47.5142],\n",
      "        [ 47.2018],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 23.7515],\n",
      "        [ 23.7515],\n",
      "        [  2.8890],\n",
      "        [162.4620],\n",
      "        [  5.4150],\n",
      "        [ 97.5706],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[192.9660],\n",
      "        [  2.8890],\n",
      "        [ 90.3840],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  7.2795],\n",
      "        [  1.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.1110],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 23.3395],\n",
      "        [ 18.2878],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 10.1110],\n",
      "        [  2.8890],\n",
      "        [219.7041],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  7.1110],\n",
      "        [  0.8890],\n",
      "        [ 23.3395],\n",
      "        [  0.6110],\n",
      "        [  1.5910],\n",
      "        [  1.6110],\n",
      "        [  3.8110],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  7.1110],\n",
      "        [  2.8890],\n",
      "        [  7.6110],\n",
      "        [ 75.9601],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 22.1910],\n",
      "        [  2.8890],\n",
      "        [ 16.7506],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 29.7110],\n",
      "        [ 30.1110],\n",
      "        [ 31.1110],\n",
      "        [ 32.1110],\n",
      "        [ 35.1110],\n",
      "        [  2.8890],\n",
      "        [  8.7175],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 24.7598],\n",
      "        [  2.8890],\n",
      "        [ 38.6110],\n",
      "        [ 12.2427],\n",
      "        [  4.6677],\n",
      "        [ 12.9993],\n",
      "        [ 10.6464],\n",
      "        [  2.8890],\n",
      "        [ 16.0429],\n",
      "        [ 19.3979],\n",
      "        [ 20.3084],\n",
      "        [ 41.1110],\n",
      "        [ 48.1110],\n",
      "        [ 52.1110],\n",
      "        [ 52.1110],\n",
      "        [ 39.2274],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [  2.8890],\n",
      "        [ 13.9314],\n",
      "        [  4.0477],\n",
      "        [ 61.6110],\n",
      "        [ 42.7301],\n",
      "        [ 23.0078],\n",
      "        [ 68.1110],\n",
      "        [ 76.3110],\n",
      "        [ 47.5142],\n",
      "        [ 47.2018],\n",
      "        [ 82.7110],\n",
      "        [ 84.1110],\n",
      "        [  1.4515],\n",
      "        [  1.4515],\n",
      "        [ 89.6110],\n",
      "        [ 43.5380],\n",
      "        [  5.4150],\n",
      "        [ 56.4294],\n",
      "        [ 95.1110],\n",
      "        [102.1110],\n",
      "        [102.1110]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1346.7357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[192.8936],\n",
      "        [  2.9249],\n",
      "        [ 92.2697],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  5.4321],\n",
      "        [  1.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.0751],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 23.0869],\n",
      "        [ 17.9435],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 10.0751],\n",
      "        [  2.9249],\n",
      "        [219.0555],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  7.0751],\n",
      "        [  0.9249],\n",
      "        [ 23.0869],\n",
      "        [  0.5751],\n",
      "        [  1.5551],\n",
      "        [  1.5751],\n",
      "        [  3.7751],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  7.0751],\n",
      "        [  2.9249],\n",
      "        [  7.5751],\n",
      "        [ 76.2106],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 22.1551],\n",
      "        [  2.9249],\n",
      "        [ 15.7640],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 29.6751],\n",
      "        [ 30.0751],\n",
      "        [ 31.0751],\n",
      "        [ 32.0751],\n",
      "        [ 35.0751],\n",
      "        [  2.9249],\n",
      "        [ 10.0002],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 25.2092],\n",
      "        [  2.9249],\n",
      "        [ 38.5751],\n",
      "        [ 13.1154],\n",
      "        [  4.4355],\n",
      "        [ 13.2882],\n",
      "        [ 10.5211],\n",
      "        [  2.9249],\n",
      "        [ 15.5214],\n",
      "        [ 18.9828],\n",
      "        [ 19.9345],\n",
      "        [ 41.0751],\n",
      "        [ 48.0751],\n",
      "        [ 52.0751],\n",
      "        [ 52.0751],\n",
      "        [ 40.2761],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 13.9951],\n",
      "        [  3.5357],\n",
      "        [ 61.5751],\n",
      "        [ 42.2838],\n",
      "        [ 22.6938],\n",
      "        [ 68.0751],\n",
      "        [ 76.2751],\n",
      "        [ 47.4586],\n",
      "        [ 47.6243],\n",
      "        [ 82.6751],\n",
      "        [ 84.0751],\n",
      "        [  1.0633],\n",
      "        [  1.0633],\n",
      "        [ 89.5751],\n",
      "        [ 43.2970],\n",
      "        [  5.3090],\n",
      "        [ 55.3875],\n",
      "        [ 95.0751],\n",
      "        [102.0751],\n",
      "        [102.0751]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 29.385624885559082\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 142\n",
      "剩餘X 資料 torch.Size([61, 10])\n",
      "剩餘Y 資料 torch.Size([61, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (10725.6669921875, 13)\n",
      "The second_loss value of k: (12226.857421875, 48)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引13，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([150, 1])\n",
      "<<預測值>>\n",
      "tensor([[125.1064],\n",
      "        [  2.9249],\n",
      "        [233.5003],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 10.8279],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [249.0869],\n",
      "        [105.3335],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [219.0555],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [249.0869],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 22.7894],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 50.7360],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 10.0002],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 25.2092],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 53.8846],\n",
      "        [  4.4355],\n",
      "        [119.4882],\n",
      "        [ 10.5211],\n",
      "        [  2.9249],\n",
      "        [ 15.5214],\n",
      "        [ 18.9828],\n",
      "        [ 19.9345],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [108.7239],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 37.4951],\n",
      "        [  7.5357],\n",
      "        [  2.9249],\n",
      "        [ 42.2838],\n",
      "        [213.3062],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 47.4586],\n",
      "        [ 47.6243],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 23.3633],\n",
      "        [ 23.3633],\n",
      "        [  2.9249],\n",
      "        [162.7030],\n",
      "        [  5.3090],\n",
      "        [ 98.6125],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [103.5648]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[192.8936],\n",
      "        [  2.9249],\n",
      "        [ 92.2697],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  5.4321],\n",
      "        [  1.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.0751],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 23.0869],\n",
      "        [ 17.9435],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 10.0751],\n",
      "        [  2.9249],\n",
      "        [219.0555],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  7.0751],\n",
      "        [  0.9249],\n",
      "        [ 23.0869],\n",
      "        [  0.5751],\n",
      "        [  1.5551],\n",
      "        [  1.5751],\n",
      "        [  3.7751],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  7.0751],\n",
      "        [  2.9249],\n",
      "        [  7.5751],\n",
      "        [ 76.2106],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 22.1551],\n",
      "        [  2.9249],\n",
      "        [ 15.7640],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 29.6751],\n",
      "        [ 30.0751],\n",
      "        [ 31.0751],\n",
      "        [ 32.0751],\n",
      "        [ 35.0751],\n",
      "        [  2.9249],\n",
      "        [ 10.0002],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 25.2092],\n",
      "        [  2.9249],\n",
      "        [ 38.5751],\n",
      "        [ 13.1154],\n",
      "        [  4.4355],\n",
      "        [ 13.2882],\n",
      "        [ 10.5211],\n",
      "        [  2.9249],\n",
      "        [ 15.5214],\n",
      "        [ 18.9828],\n",
      "        [ 19.9345],\n",
      "        [ 41.0751],\n",
      "        [ 48.0751],\n",
      "        [ 52.0751],\n",
      "        [ 52.0751],\n",
      "        [ 40.2761],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [  2.9249],\n",
      "        [ 13.9951],\n",
      "        [  3.5357],\n",
      "        [ 61.5751],\n",
      "        [ 42.2838],\n",
      "        [ 22.6938],\n",
      "        [ 68.0751],\n",
      "        [ 76.2751],\n",
      "        [ 47.4586],\n",
      "        [ 47.6243],\n",
      "        [ 82.6751],\n",
      "        [ 84.0751],\n",
      "        [  1.0633],\n",
      "        [  1.0633],\n",
      "        [ 89.5751],\n",
      "        [ 43.2970],\n",
      "        [  5.3090],\n",
      "        [ 55.3875],\n",
      "        [ 95.0751],\n",
      "        [102.0751],\n",
      "        [102.0751],\n",
      "        [103.5648]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1408.3098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[192.1241],\n",
      "        [  2.9870],\n",
      "        [115.8314],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  3.7388],\n",
      "        [  1.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.0130],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 21.0316],\n",
      "        [ 18.3279],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 10.0130],\n",
      "        [  2.9870],\n",
      "        [218.0112],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  7.0130],\n",
      "        [  0.9870],\n",
      "        [ 21.0316],\n",
      "        [  0.5130],\n",
      "        [  1.4930],\n",
      "        [  1.5130],\n",
      "        [  3.7130],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  7.0130],\n",
      "        [  2.9870],\n",
      "        [  7.5130],\n",
      "        [ 74.9842],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 22.0930],\n",
      "        [  2.9870],\n",
      "        [ 12.7233],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 29.6130],\n",
      "        [ 30.0130],\n",
      "        [ 31.0130],\n",
      "        [ 32.0130],\n",
      "        [ 35.0130],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 26.2878],\n",
      "        [  2.9870],\n",
      "        [ 38.5130],\n",
      "        [ 12.8494],\n",
      "        [  5.6581],\n",
      "        [  6.1574],\n",
      "        [ 11.6672],\n",
      "        [  2.9870],\n",
      "        [ 16.1560],\n",
      "        [ 19.4085],\n",
      "        [ 20.5603],\n",
      "        [ 41.0130],\n",
      "        [ 48.0130],\n",
      "        [ 52.0130],\n",
      "        [ 52.0130],\n",
      "        [ 34.6353],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  7.9162],\n",
      "        [  7.9162],\n",
      "        [  6.2704],\n",
      "        [  2.0916],\n",
      "        [ 61.5130],\n",
      "        [ 43.7976],\n",
      "        [ 25.0460],\n",
      "        [ 68.0130],\n",
      "        [ 76.2130],\n",
      "        [ 35.8157],\n",
      "        [ 40.5442],\n",
      "        [ 82.6130],\n",
      "        [ 84.0130],\n",
      "        [  1.7191],\n",
      "        [  1.7191],\n",
      "        [ 89.5130],\n",
      "        [ 43.7798],\n",
      "        [  4.9489],\n",
      "        [ 52.5970],\n",
      "        [ 95.0130],\n",
      "        [102.0130],\n",
      "        [102.0130],\n",
      "        [ 84.5469]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 29.64555311203003\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 143\n",
      "剩餘X 資料 torch.Size([60, 10])\n",
      "剩餘Y 資料 torch.Size([60, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (12213.123046875, 47)\n",
      "The second_loss value of k: (13792.8583984375, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引47，y= tensor([113.5000])\n",
      "目前模型的Data狀態 torch.Size([151, 1])\n",
      "<<預測值>>\n",
      "tensor([[125.8759],\n",
      "        [  2.9870],\n",
      "        [209.9386],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 12.5212],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [247.0316],\n",
      "        [105.7179],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [218.0112],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [247.0316],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 24.0158],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 53.7767],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 26.2878],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 54.1506],\n",
      "        [  5.6581],\n",
      "        [100.0426],\n",
      "        [ 11.6672],\n",
      "        [  2.9870],\n",
      "        [ 16.1560],\n",
      "        [ 19.4085],\n",
      "        [ 20.5603],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [114.3647],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  7.9162],\n",
      "        [  7.9162],\n",
      "        [ 29.7704],\n",
      "        [  6.0916],\n",
      "        [  2.9870],\n",
      "        [ 43.7976],\n",
      "        [210.9540],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 35.8157],\n",
      "        [ 40.5442],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 20.5809],\n",
      "        [ 20.5809],\n",
      "        [  2.9870],\n",
      "        [162.2202],\n",
      "        [  4.9489],\n",
      "        [101.4030],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 84.5469],\n",
      "        [  2.9870]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[192.1241],\n",
      "        [  2.9870],\n",
      "        [115.8314],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  3.7388],\n",
      "        [  1.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.0130],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 21.0316],\n",
      "        [ 18.3279],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 10.0130],\n",
      "        [  2.9870],\n",
      "        [218.0112],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  7.0130],\n",
      "        [  0.9870],\n",
      "        [ 21.0316],\n",
      "        [  0.5130],\n",
      "        [  1.4930],\n",
      "        [  1.5130],\n",
      "        [  3.7130],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  7.0130],\n",
      "        [  2.9870],\n",
      "        [  7.5130],\n",
      "        [ 74.9842],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 22.0930],\n",
      "        [  2.9870],\n",
      "        [ 12.7233],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 29.6130],\n",
      "        [ 30.0130],\n",
      "        [ 31.0130],\n",
      "        [ 32.0130],\n",
      "        [ 35.0130],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [ 26.2878],\n",
      "        [  2.9870],\n",
      "        [ 38.5130],\n",
      "        [ 12.8494],\n",
      "        [  5.6581],\n",
      "        [  6.1574],\n",
      "        [ 11.6672],\n",
      "        [  2.9870],\n",
      "        [ 16.1560],\n",
      "        [ 19.4085],\n",
      "        [ 20.5603],\n",
      "        [ 41.0130],\n",
      "        [ 48.0130],\n",
      "        [ 52.0130],\n",
      "        [ 52.0130],\n",
      "        [ 34.6353],\n",
      "        [  2.9870],\n",
      "        [  2.9870],\n",
      "        [  7.9162],\n",
      "        [  7.9162],\n",
      "        [  6.2704],\n",
      "        [  2.0916],\n",
      "        [ 61.5130],\n",
      "        [ 43.7976],\n",
      "        [ 25.0460],\n",
      "        [ 68.0130],\n",
      "        [ 76.2130],\n",
      "        [ 35.8157],\n",
      "        [ 40.5442],\n",
      "        [ 82.6130],\n",
      "        [ 84.0130],\n",
      "        [  1.7191],\n",
      "        [  1.7191],\n",
      "        [ 89.5130],\n",
      "        [ 43.7798],\n",
      "        [  4.9489],\n",
      "        [ 52.5970],\n",
      "        [ 95.0130],\n",
      "        [102.0130],\n",
      "        [102.0130],\n",
      "        [ 84.5469],\n",
      "        [110.5130]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1465.4813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[191.7841],\n",
      "        [  3.0205],\n",
      "        [117.5293],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  2.6199],\n",
      "        [  2.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  1.9795],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 21.0228],\n",
      "        [ 18.2133],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  9.9795],\n",
      "        [  3.0205],\n",
      "        [217.6047],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  6.9795],\n",
      "        [  1.0205],\n",
      "        [ 21.0228],\n",
      "        [  0.4795],\n",
      "        [  1.4595],\n",
      "        [  1.4795],\n",
      "        [  3.6795],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  6.9795],\n",
      "        [  3.0205],\n",
      "        [  7.4795],\n",
      "        [ 74.0814],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 22.0595],\n",
      "        [  3.0205],\n",
      "        [ 12.2815],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 29.5795],\n",
      "        [ 29.9795],\n",
      "        [ 30.9795],\n",
      "        [ 31.9795],\n",
      "        [ 34.9795],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 27.1322],\n",
      "        [  3.0205],\n",
      "        [ 38.4795],\n",
      "        [ 12.3928],\n",
      "        [  6.1436],\n",
      "        [  5.8769],\n",
      "        [ 12.4456],\n",
      "        [  3.0205],\n",
      "        [ 16.2385],\n",
      "        [ 19.7650],\n",
      "        [ 21.0534],\n",
      "        [ 40.9795],\n",
      "        [ 47.9795],\n",
      "        [ 51.9795],\n",
      "        [ 51.9795],\n",
      "        [ 34.7174],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  7.9623],\n",
      "        [  7.9623],\n",
      "        [  5.7624],\n",
      "        [  1.5921],\n",
      "        [ 61.4795],\n",
      "        [ 44.1150],\n",
      "        [ 25.2543],\n",
      "        [ 67.9795],\n",
      "        [ 76.1795],\n",
      "        [ 35.8831],\n",
      "        [ 40.2329],\n",
      "        [ 82.5795],\n",
      "        [ 83.9795],\n",
      "        [  2.0116],\n",
      "        [  2.0116],\n",
      "        [ 89.4795],\n",
      "        [ 43.9776],\n",
      "        [  4.7334],\n",
      "        [ 52.7609],\n",
      "        [ 94.9795],\n",
      "        [101.9795],\n",
      "        [101.9795],\n",
      "        [ 83.7442],\n",
      "        [110.4795]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 29.904545307159424\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 144\n",
      "剩餘X 資料 torch.Size([59, 10])\n",
      "剩餘Y 資料 torch.Size([59, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (13784.998046875, 12)\n",
      "The second_loss value of k: (18490.4296875, 45)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([120.4300])\n",
      "目前模型的Data狀態 torch.Size([152, 1])\n",
      "<<預測值>>\n",
      "tensor([[126.2158],\n",
      "        [  3.0205],\n",
      "        [208.2407],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 13.6401],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [247.0228],\n",
      "        [105.6033],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [217.6047],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [247.0228],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 24.9186],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 54.2185],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 27.1322],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 54.6072],\n",
      "        [  6.1436],\n",
      "        [100.3231],\n",
      "        [ 12.4456],\n",
      "        [  3.0205],\n",
      "        [ 16.2385],\n",
      "        [ 19.7650],\n",
      "        [ 21.0534],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [114.2826],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  7.9623],\n",
      "        [  7.9623],\n",
      "        [ 29.2624],\n",
      "        [  5.5921],\n",
      "        [  3.0205],\n",
      "        [ 44.1150],\n",
      "        [210.7457],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 35.8831],\n",
      "        [ 40.2329],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 20.2884],\n",
      "        [ 20.2884],\n",
      "        [  3.0205],\n",
      "        [162.0224],\n",
      "        [  4.7334],\n",
      "        [101.2391],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 83.7442],\n",
      "        [  3.0205],\n",
      "        [  3.0205]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[191.7841],\n",
      "        [  3.0205],\n",
      "        [117.5293],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  2.6199],\n",
      "        [  2.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  1.9795],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 21.0228],\n",
      "        [ 18.2133],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  9.9795],\n",
      "        [  3.0205],\n",
      "        [217.6047],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  6.9795],\n",
      "        [  1.0205],\n",
      "        [ 21.0228],\n",
      "        [  0.4795],\n",
      "        [  1.4595],\n",
      "        [  1.4795],\n",
      "        [  3.6795],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  6.9795],\n",
      "        [  3.0205],\n",
      "        [  7.4795],\n",
      "        [ 74.0814],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 22.0595],\n",
      "        [  3.0205],\n",
      "        [ 12.2815],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 29.5795],\n",
      "        [ 29.9795],\n",
      "        [ 30.9795],\n",
      "        [ 31.9795],\n",
      "        [ 34.9795],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [ 27.1322],\n",
      "        [  3.0205],\n",
      "        [ 38.4795],\n",
      "        [ 12.3928],\n",
      "        [  6.1436],\n",
      "        [  5.8769],\n",
      "        [ 12.4456],\n",
      "        [  3.0205],\n",
      "        [ 16.2385],\n",
      "        [ 19.7650],\n",
      "        [ 21.0534],\n",
      "        [ 40.9795],\n",
      "        [ 47.9795],\n",
      "        [ 51.9795],\n",
      "        [ 51.9795],\n",
      "        [ 34.7174],\n",
      "        [  3.0205],\n",
      "        [  3.0205],\n",
      "        [  7.9623],\n",
      "        [  7.9623],\n",
      "        [  5.7624],\n",
      "        [  1.5921],\n",
      "        [ 61.4795],\n",
      "        [ 44.1150],\n",
      "        [ 25.2543],\n",
      "        [ 67.9795],\n",
      "        [ 76.1795],\n",
      "        [ 35.8831],\n",
      "        [ 40.2329],\n",
      "        [ 82.5795],\n",
      "        [ 83.9795],\n",
      "        [  2.0116],\n",
      "        [  2.0116],\n",
      "        [ 89.4795],\n",
      "        [ 43.9776],\n",
      "        [  4.7334],\n",
      "        [ 52.7609],\n",
      "        [ 94.9795],\n",
      "        [101.9795],\n",
      "        [101.9795],\n",
      "        [ 83.7442],\n",
      "        [110.4795],\n",
      "        [117.4095]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1545.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[191.4260],\n",
      "        [  3.0542],\n",
      "        [118.1980],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  1.5516],\n",
      "        [  2.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  1.9458],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 21.5928],\n",
      "        [ 18.5217],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  9.9458],\n",
      "        [  3.0542],\n",
      "        [217.4272],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  6.9458],\n",
      "        [  1.0542],\n",
      "        [ 21.5928],\n",
      "        [  0.4458],\n",
      "        [  1.4258],\n",
      "        [  1.4458],\n",
      "        [  3.6458],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  6.9458],\n",
      "        [  3.0542],\n",
      "        [  7.4458],\n",
      "        [ 73.7970],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 22.0258],\n",
      "        [  3.0542],\n",
      "        [ 11.1922],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 29.5458],\n",
      "        [ 29.9458],\n",
      "        [ 30.9458],\n",
      "        [ 31.9458],\n",
      "        [ 34.9458],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 27.6695],\n",
      "        [  3.0542],\n",
      "        [ 38.4458],\n",
      "        [ 12.4869],\n",
      "        [  6.2932],\n",
      "        [  5.3831],\n",
      "        [ 12.6885],\n",
      "        [  3.0542],\n",
      "        [ 16.0380],\n",
      "        [ 19.7140],\n",
      "        [ 21.0863],\n",
      "        [ 40.9458],\n",
      "        [ 47.9458],\n",
      "        [ 51.9458],\n",
      "        [ 51.9458],\n",
      "        [ 34.6677],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  7.9694],\n",
      "        [  7.9694],\n",
      "        [  5.8616],\n",
      "        [  1.0455],\n",
      "        [ 61.4458],\n",
      "        [ 44.7840],\n",
      "        [ 24.8551],\n",
      "        [ 67.9458],\n",
      "        [ 76.1458],\n",
      "        [ 36.1324],\n",
      "        [ 40.7063],\n",
      "        [ 82.5458],\n",
      "        [ 83.9458],\n",
      "        [  1.8656],\n",
      "        [  1.8656],\n",
      "        [ 89.4458],\n",
      "        [ 43.8616],\n",
      "        [  6.5643],\n",
      "        [ 52.0855],\n",
      "        [ 94.9458],\n",
      "        [101.9458],\n",
      "        [101.9458],\n",
      "        [ 83.5064],\n",
      "        [110.4458],\n",
      "        [117.3758]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 30.162498474121094\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 145\n",
      "剩餘X 資料 torch.Size([58, 10])\n",
      "剩餘Y 資料 torch.Size([58, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (18481.2734375, 44)\n",
      "The second_loss value of k: (22384.900390625, 17)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引44，y= tensor([139.])\n",
      "目前模型的Data狀態 torch.Size([153, 1])\n",
      "<<預測值>>\n",
      "tensor([[126.5740],\n",
      "        [  3.0542],\n",
      "        [207.5720],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 14.7084],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [247.5928],\n",
      "        [105.9117],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [217.4272],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [247.5928],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 25.2030],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 55.3078],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 27.6695],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 54.5131],\n",
      "        [  6.2932],\n",
      "        [100.8169],\n",
      "        [ 12.6885],\n",
      "        [  3.0542],\n",
      "        [ 16.0380],\n",
      "        [ 19.7140],\n",
      "        [ 21.0863],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [114.3323],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  7.9694],\n",
      "        [  7.9694],\n",
      "        [ 29.3616],\n",
      "        [  5.0455],\n",
      "        [  3.0542],\n",
      "        [ 44.7840],\n",
      "        [211.1449],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 36.1324],\n",
      "        [ 40.7063],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 20.4344],\n",
      "        [ 20.4344],\n",
      "        [  3.0542],\n",
      "        [162.1384],\n",
      "        [  6.5643],\n",
      "        [101.9145],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 83.5064],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[191.4260],\n",
      "        [  3.0542],\n",
      "        [118.1980],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  1.5516],\n",
      "        [  2.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  1.9458],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 21.5928],\n",
      "        [ 18.5217],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  9.9458],\n",
      "        [  3.0542],\n",
      "        [217.4272],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  6.9458],\n",
      "        [  1.0542],\n",
      "        [ 21.5928],\n",
      "        [  0.4458],\n",
      "        [  1.4258],\n",
      "        [  1.4458],\n",
      "        [  3.6458],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  6.9458],\n",
      "        [  3.0542],\n",
      "        [  7.4458],\n",
      "        [ 73.7970],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 22.0258],\n",
      "        [  3.0542],\n",
      "        [ 11.1922],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 29.5458],\n",
      "        [ 29.9458],\n",
      "        [ 30.9458],\n",
      "        [ 31.9458],\n",
      "        [ 34.9458],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [ 27.6695],\n",
      "        [  3.0542],\n",
      "        [ 38.4458],\n",
      "        [ 12.4869],\n",
      "        [  6.2932],\n",
      "        [  5.3831],\n",
      "        [ 12.6885],\n",
      "        [  3.0542],\n",
      "        [ 16.0380],\n",
      "        [ 19.7140],\n",
      "        [ 21.0863],\n",
      "        [ 40.9458],\n",
      "        [ 47.9458],\n",
      "        [ 51.9458],\n",
      "        [ 51.9458],\n",
      "        [ 34.6677],\n",
      "        [  3.0542],\n",
      "        [  3.0542],\n",
      "        [  7.9694],\n",
      "        [  7.9694],\n",
      "        [  5.8616],\n",
      "        [  1.0455],\n",
      "        [ 61.4458],\n",
      "        [ 44.7840],\n",
      "        [ 24.8551],\n",
      "        [ 67.9458],\n",
      "        [ 76.1458],\n",
      "        [ 36.1324],\n",
      "        [ 40.7063],\n",
      "        [ 82.5458],\n",
      "        [ 83.9458],\n",
      "        [  1.8656],\n",
      "        [  1.8656],\n",
      "        [ 89.4458],\n",
      "        [ 43.8616],\n",
      "        [  6.5643],\n",
      "        [ 52.0855],\n",
      "        [ 94.9458],\n",
      "        [101.9458],\n",
      "        [101.9458],\n",
      "        [ 83.5064],\n",
      "        [110.4458],\n",
      "        [117.3758],\n",
      "        [135.9458]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1655.5094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  191.0765],\n",
      "        [    3.1142],\n",
      "        [  119.5451],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    0.1017],\n",
      "        [    2.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    1.8858],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [   21.6197],\n",
      "        [   18.4365],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    9.8858],\n",
      "        [    3.1142],\n",
      "        [  217.1726],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    6.8858],\n",
      "        [    1.1142],\n",
      "        [   21.6197],\n",
      "        [    0.3858],\n",
      "        [    1.3658],\n",
      "        [    1.3858],\n",
      "        [    3.5858],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    6.8858],\n",
      "        [    3.1142],\n",
      "        [    7.3858],\n",
      "        [   73.5023],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [   21.9658],\n",
      "        [    3.1142],\n",
      "        [   11.3090],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [   29.4858],\n",
      "        [   29.8858],\n",
      "        [   30.8858],\n",
      "        [   31.8858],\n",
      "        [   34.8858],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [   28.2342],\n",
      "        [    3.1142],\n",
      "        [   38.3858],\n",
      "        [   12.7351],\n",
      "        [    6.2874],\n",
      "        [    4.6330],\n",
      "        [   12.9054],\n",
      "        [    3.1142],\n",
      "        [   15.5373],\n",
      "        [   19.4911],\n",
      "        [   20.9928],\n",
      "        [   40.8858],\n",
      "        [   47.8858],\n",
      "        [   51.8858],\n",
      "        [   51.8858],\n",
      "        [   35.6441],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    7.2171],\n",
      "        [    7.2171],\n",
      "        [    5.6670],\n",
      "        [    1.2071],\n",
      "        [   61.3858],\n",
      "        [   44.7682],\n",
      "        [   24.6881],\n",
      "        [   67.8858],\n",
      "        [   76.0858],\n",
      "        [   36.0919],\n",
      "        [   40.2063],\n",
      "        [   82.4858],\n",
      "        [   83.8858],\n",
      "        [    2.3116],\n",
      "        [    2.3116],\n",
      "        [   89.3858],\n",
      "        [   43.7134],\n",
      "        [    7.2147],\n",
      "        [   51.6941],\n",
      "        [   94.8858],\n",
      "        [  101.8858],\n",
      "        [  101.8858],\n",
      "        [   83.1155],\n",
      "        [  110.3858],\n",
      "        [  117.3158],\n",
      "        [  135.8858]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 30.422199010849\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 146\n",
      "剩餘X 資料 torch.Size([57, 10])\n",
      "剩餘Y 資料 torch.Size([57, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (22366.951171875, 17)\n",
      "The second_loss value of k: (22366.951171875, 33)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([152.6700])\n",
      "目前模型的Data狀態 torch.Size([154, 1])\n",
      "<<預測值>>\n",
      "tensor([[126.9235],\n",
      "        [  3.1142],\n",
      "        [206.2249],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [ 16.1583],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [247.6197],\n",
      "        [105.8265],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [217.1726],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [247.6197],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [ 25.4977],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [ 55.1910],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [ 28.2342],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [ 54.2649],\n",
      "        [  6.2874],\n",
      "        [101.5669],\n",
      "        [ 12.9054],\n",
      "        [  3.1142],\n",
      "        [ 15.5373],\n",
      "        [ 19.4911],\n",
      "        [ 20.9928],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [113.3559],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  7.2171],\n",
      "        [  7.2171],\n",
      "        [ 29.1670],\n",
      "        [  5.2071],\n",
      "        [  3.1142],\n",
      "        [ 44.7682],\n",
      "        [211.3119],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [ 36.0919],\n",
      "        [ 40.2063],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [ 19.9884],\n",
      "        [ 19.9884],\n",
      "        [  3.1142],\n",
      "        [162.2866],\n",
      "        [  7.2147],\n",
      "        [102.3059],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [ 83.1155],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142],\n",
      "        [  3.1142]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  191.0765],\n",
      "        [    3.1142],\n",
      "        [  119.5451],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    0.1017],\n",
      "        [    2.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    1.8858],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [   21.6197],\n",
      "        [   18.4365],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    9.8858],\n",
      "        [    3.1142],\n",
      "        [  217.1726],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    6.8858],\n",
      "        [    1.1142],\n",
      "        [   21.6197],\n",
      "        [    0.3858],\n",
      "        [    1.3658],\n",
      "        [    1.3858],\n",
      "        [    3.5858],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    6.8858],\n",
      "        [    3.1142],\n",
      "        [    7.3858],\n",
      "        [   73.5023],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [   21.9658],\n",
      "        [    3.1142],\n",
      "        [   11.3090],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [   29.4858],\n",
      "        [   29.8858],\n",
      "        [   30.8858],\n",
      "        [   31.8858],\n",
      "        [   34.8858],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [   28.2342],\n",
      "        [    3.1142],\n",
      "        [   38.3858],\n",
      "        [   12.7351],\n",
      "        [    6.2874],\n",
      "        [    4.6330],\n",
      "        [   12.9054],\n",
      "        [    3.1142],\n",
      "        [   15.5373],\n",
      "        [   19.4911],\n",
      "        [   20.9928],\n",
      "        [   40.8858],\n",
      "        [   47.8858],\n",
      "        [   51.8858],\n",
      "        [   51.8858],\n",
      "        [   35.6441],\n",
      "        [    3.1142],\n",
      "        [    3.1142],\n",
      "        [    7.2171],\n",
      "        [    7.2171],\n",
      "        [    5.6670],\n",
      "        [    1.2071],\n",
      "        [   61.3858],\n",
      "        [   44.7682],\n",
      "        [   24.6881],\n",
      "        [   67.8858],\n",
      "        [   76.0858],\n",
      "        [   36.0919],\n",
      "        [   40.2063],\n",
      "        [   82.4858],\n",
      "        [   83.8858],\n",
      "        [    2.3116],\n",
      "        [    2.3116],\n",
      "        [   89.3858],\n",
      "        [   43.7134],\n",
      "        [    7.2147],\n",
      "        [   51.6941],\n",
      "        [   94.8858],\n",
      "        [  101.8858],\n",
      "        [  101.8858],\n",
      "        [   83.1155],\n",
      "        [  110.3858],\n",
      "        [  117.3158],\n",
      "        [  135.8858],\n",
      "        [  149.5558]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1788.4915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  191.2766],\n",
      "        [    3.1419],\n",
      "        [  118.0896],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    0.0658],\n",
      "        [    2.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    1.8581],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [   21.9383],\n",
      "        [   18.2513],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    9.8581],\n",
      "        [    3.1419],\n",
      "        [  216.5291],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    6.8581],\n",
      "        [    1.1419],\n",
      "        [   21.9383],\n",
      "        [    0.3581],\n",
      "        [    1.3381],\n",
      "        [    1.3581],\n",
      "        [    3.5581],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    6.8581],\n",
      "        [    3.1419],\n",
      "        [    7.3581],\n",
      "        [   73.0478],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [   21.9381],\n",
      "        [    3.1419],\n",
      "        [   11.0162],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [   29.4581],\n",
      "        [   29.8581],\n",
      "        [   30.8581],\n",
      "        [   31.8581],\n",
      "        [   34.8581],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [   28.5714],\n",
      "        [    3.1419],\n",
      "        [   38.3581],\n",
      "        [   12.4908],\n",
      "        [    6.4451],\n",
      "        [    3.2974],\n",
      "        [   13.2580],\n",
      "        [    3.1419],\n",
      "        [   15.5425],\n",
      "        [   19.6018],\n",
      "        [   21.1894],\n",
      "        [   40.8581],\n",
      "        [   47.8581],\n",
      "        [   51.8581],\n",
      "        [   51.8581],\n",
      "        [   35.2425],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    8.0174],\n",
      "        [    8.0174],\n",
      "        [    6.8743],\n",
      "        [    3.2684],\n",
      "        [   61.3581],\n",
      "        [   46.9898],\n",
      "        [   24.9437],\n",
      "        [   67.8581],\n",
      "        [   76.0581],\n",
      "        [   36.9191],\n",
      "        [   40.9860],\n",
      "        [   82.4581],\n",
      "        [   83.8581],\n",
      "        [    2.5930],\n",
      "        [    2.5930],\n",
      "        [   89.3581],\n",
      "        [   44.3708],\n",
      "        [    6.3291],\n",
      "        [   51.9637],\n",
      "        [   94.8581],\n",
      "        [  101.8581],\n",
      "        [  101.8581],\n",
      "        [   83.6428],\n",
      "        [  110.3581],\n",
      "        [  117.2881],\n",
      "        [  135.8581],\n",
      "        [  149.5281]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 30.682230949401855\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 147\n",
      "剩餘X 資料 torch.Size([56, 10])\n",
      "剩餘Y 資料 torch.Size([56, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (22358.654296875, 32)\n",
      "The second_loss value of k: (29707.318359375, 37)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引32，y= tensor([152.6700])\n",
      "目前模型的Data狀態 torch.Size([155, 1])\n",
      "<<預測值>>\n",
      "tensor([[126.7234],\n",
      "        [  3.1419],\n",
      "        [207.6804],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [ 16.3258],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [247.9383],\n",
      "        [105.6413],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [216.5291],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [247.9383],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [ 25.9522],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [ 55.4838],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [ 28.5714],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [ 54.5092],\n",
      "        [  6.4451],\n",
      "        [102.9026],\n",
      "        [ 13.2580],\n",
      "        [  3.1419],\n",
      "        [ 15.5425],\n",
      "        [ 19.6018],\n",
      "        [ 21.1894],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [113.7575],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  8.0174],\n",
      "        [  8.0174],\n",
      "        [ 30.3743],\n",
      "        [  7.2684],\n",
      "        [  3.1419],\n",
      "        [ 46.9898],\n",
      "        [211.0563],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [ 36.9191],\n",
      "        [ 40.9860],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [ 19.7070],\n",
      "        [ 19.7070],\n",
      "        [  3.1419],\n",
      "        [161.6292],\n",
      "        [  6.3291],\n",
      "        [102.0363],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [ 83.6428],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419],\n",
      "        [  3.1419]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  191.2766],\n",
      "        [    3.1419],\n",
      "        [  118.0896],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    0.0658],\n",
      "        [    2.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    1.8581],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [   21.9383],\n",
      "        [   18.2513],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    9.8581],\n",
      "        [    3.1419],\n",
      "        [  216.5291],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    6.8581],\n",
      "        [    1.1419],\n",
      "        [   21.9383],\n",
      "        [    0.3581],\n",
      "        [    1.3381],\n",
      "        [    1.3581],\n",
      "        [    3.5581],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    6.8581],\n",
      "        [    3.1419],\n",
      "        [    7.3581],\n",
      "        [   73.0478],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [   21.9381],\n",
      "        [    3.1419],\n",
      "        [   11.0162],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [   29.4581],\n",
      "        [   29.8581],\n",
      "        [   30.8581],\n",
      "        [   31.8581],\n",
      "        [   34.8581],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [   28.5714],\n",
      "        [    3.1419],\n",
      "        [   38.3581],\n",
      "        [   12.4908],\n",
      "        [    6.4451],\n",
      "        [    3.2974],\n",
      "        [   13.2580],\n",
      "        [    3.1419],\n",
      "        [   15.5425],\n",
      "        [   19.6018],\n",
      "        [   21.1894],\n",
      "        [   40.8581],\n",
      "        [   47.8581],\n",
      "        [   51.8581],\n",
      "        [   51.8581],\n",
      "        [   35.2425],\n",
      "        [    3.1419],\n",
      "        [    3.1419],\n",
      "        [    8.0174],\n",
      "        [    8.0174],\n",
      "        [    6.8743],\n",
      "        [    3.2684],\n",
      "        [   61.3581],\n",
      "        [   46.9898],\n",
      "        [   24.9437],\n",
      "        [   67.8581],\n",
      "        [   76.0581],\n",
      "        [   36.9191],\n",
      "        [   40.9860],\n",
      "        [   82.4581],\n",
      "        [   83.8581],\n",
      "        [    2.5930],\n",
      "        [    2.5930],\n",
      "        [   89.3581],\n",
      "        [   44.3708],\n",
      "        [    6.3291],\n",
      "        [   51.9637],\n",
      "        [   94.8581],\n",
      "        [  101.8581],\n",
      "        [  101.8581],\n",
      "        [   83.6428],\n",
      "        [  110.3581],\n",
      "        [  117.2881],\n",
      "        [  135.8581],\n",
      "        [  149.5281],\n",
      "        [  149.5281]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(1920.3673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[191.3242],\n",
      "        [  3.1752],\n",
      "        [119.1109],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  0.5148],\n",
      "        [  2.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  1.8248],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 21.3501],\n",
      "        [ 17.8662],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  9.8248],\n",
      "        [  3.1752],\n",
      "        [216.0830],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  6.8248],\n",
      "        [  1.1752],\n",
      "        [ 21.3501],\n",
      "        [  0.3248],\n",
      "        [  1.3048],\n",
      "        [  1.3248],\n",
      "        [  3.5248],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  6.8248],\n",
      "        [  3.1752],\n",
      "        [  7.3248],\n",
      "        [ 72.7714],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 21.9048],\n",
      "        [  3.1752],\n",
      "        [ 11.4480],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 29.4248],\n",
      "        [ 29.8248],\n",
      "        [ 30.8248],\n",
      "        [ 31.8248],\n",
      "        [ 34.8248],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 28.7709],\n",
      "        [  3.1752],\n",
      "        [ 38.3248],\n",
      "        [ 12.4758],\n",
      "        [  6.4680],\n",
      "        [  2.9460],\n",
      "        [ 13.4595],\n",
      "        [  3.1752],\n",
      "        [ 15.2986],\n",
      "        [ 19.5540],\n",
      "        [ 21.2226],\n",
      "        [ 40.8248],\n",
      "        [ 47.8248],\n",
      "        [ 51.8248],\n",
      "        [ 51.8248],\n",
      "        [ 36.3010],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  7.3414],\n",
      "        [  7.3414],\n",
      "        [  6.1455],\n",
      "        [  1.5458],\n",
      "        [ 61.3248],\n",
      "        [ 46.4805],\n",
      "        [ 25.4911],\n",
      "        [ 67.8248],\n",
      "        [ 76.0248],\n",
      "        [ 36.9169],\n",
      "        [ 40.2713],\n",
      "        [ 82.4248],\n",
      "        [ 83.8248],\n",
      "        [  3.1161],\n",
      "        [  3.1161],\n",
      "        [ 89.3248],\n",
      "        [ 44.6846],\n",
      "        [  5.2265],\n",
      "        [ 52.5291],\n",
      "        [ 94.8248],\n",
      "        [101.8248],\n",
      "        [101.8248],\n",
      "        [ 83.3059],\n",
      "        [110.3248],\n",
      "        [117.2548],\n",
      "        [135.8248],\n",
      "        [149.4948],\n",
      "        [149.4948]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 30.93773603439331\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 148\n",
      "剩餘X 資料 torch.Size([55, 10])\n",
      "剩餘Y 資料 torch.Size([55, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (29695.84765625, 36)\n",
      "The second_loss value of k: (31267.01953125, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引36，y= tensor([175.5000])\n",
      "目前模型的Data狀態 torch.Size([156, 1])\n",
      "<<預測值>>\n",
      "tensor([[126.6758],\n",
      "        [  3.1752],\n",
      "        [206.6590],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 16.7748],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [247.3501],\n",
      "        [105.2562],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [216.0830],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [247.3501],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 26.2286],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 55.0520],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 28.7709],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 54.5242],\n",
      "        [  6.4680],\n",
      "        [103.2540],\n",
      "        [ 13.4595],\n",
      "        [  3.1752],\n",
      "        [ 15.2986],\n",
      "        [ 19.5540],\n",
      "        [ 21.2226],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [112.6990],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  7.3414],\n",
      "        [  7.3414],\n",
      "        [ 29.6455],\n",
      "        [  5.5458],\n",
      "        [  3.1752],\n",
      "        [ 46.4805],\n",
      "        [210.5089],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 36.9169],\n",
      "        [ 40.2713],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 19.1839],\n",
      "        [ 19.1839],\n",
      "        [  3.1752],\n",
      "        [161.3154],\n",
      "        [  5.2265],\n",
      "        [101.4709],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 83.3059],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[191.3242],\n",
      "        [  3.1752],\n",
      "        [119.1109],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  0.5148],\n",
      "        [  2.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  1.8248],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 21.3501],\n",
      "        [ 17.8662],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  9.8248],\n",
      "        [  3.1752],\n",
      "        [216.0830],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  6.8248],\n",
      "        [  1.1752],\n",
      "        [ 21.3501],\n",
      "        [  0.3248],\n",
      "        [  1.3048],\n",
      "        [  1.3248],\n",
      "        [  3.5248],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  6.8248],\n",
      "        [  3.1752],\n",
      "        [  7.3248],\n",
      "        [ 72.7714],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 21.9048],\n",
      "        [  3.1752],\n",
      "        [ 11.4480],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 29.4248],\n",
      "        [ 29.8248],\n",
      "        [ 30.8248],\n",
      "        [ 31.8248],\n",
      "        [ 34.8248],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [ 28.7709],\n",
      "        [  3.1752],\n",
      "        [ 38.3248],\n",
      "        [ 12.4758],\n",
      "        [  6.4680],\n",
      "        [  2.9460],\n",
      "        [ 13.4595],\n",
      "        [  3.1752],\n",
      "        [ 15.2986],\n",
      "        [ 19.5540],\n",
      "        [ 21.2226],\n",
      "        [ 40.8248],\n",
      "        [ 47.8248],\n",
      "        [ 51.8248],\n",
      "        [ 51.8248],\n",
      "        [ 36.3010],\n",
      "        [  3.1752],\n",
      "        [  3.1752],\n",
      "        [  7.3414],\n",
      "        [  7.3414],\n",
      "        [  6.1455],\n",
      "        [  1.5458],\n",
      "        [ 61.3248],\n",
      "        [ 46.4805],\n",
      "        [ 25.4911],\n",
      "        [ 67.8248],\n",
      "        [ 76.0248],\n",
      "        [ 36.9169],\n",
      "        [ 40.2713],\n",
      "        [ 82.4248],\n",
      "        [ 83.8248],\n",
      "        [  3.1161],\n",
      "        [  3.1161],\n",
      "        [ 89.3248],\n",
      "        [ 44.6846],\n",
      "        [  5.2265],\n",
      "        [ 52.5291],\n",
      "        [ 94.8248],\n",
      "        [101.8248],\n",
      "        [101.8248],\n",
      "        [ 83.3059],\n",
      "        [110.3248],\n",
      "        [117.2548],\n",
      "        [135.8248],\n",
      "        [149.4948],\n",
      "        [149.4948],\n",
      "        [172.3248]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2097.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[191.0731],\n",
      "        [  3.2174],\n",
      "        [118.6084],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  1.3969],\n",
      "        [  2.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  1.7826],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 22.4205],\n",
      "        [ 18.0201],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  9.7826],\n",
      "        [  3.2174],\n",
      "        [216.1348],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  6.7826],\n",
      "        [  1.2174],\n",
      "        [ 22.4205],\n",
      "        [  0.2826],\n",
      "        [  1.2626],\n",
      "        [  1.2826],\n",
      "        [  3.4826],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  6.7826],\n",
      "        [  3.2174],\n",
      "        [  7.2826],\n",
      "        [ 73.0184],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 21.8626],\n",
      "        [  3.2174],\n",
      "        [ 10.5275],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 29.3826],\n",
      "        [ 29.7826],\n",
      "        [ 30.7826],\n",
      "        [ 31.7826],\n",
      "        [ 34.7826],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 28.9808],\n",
      "        [  3.2174],\n",
      "        [ 38.2826],\n",
      "        [ 13.0213],\n",
      "        [  6.1406],\n",
      "        [  2.2024],\n",
      "        [ 13.2110],\n",
      "        [  3.2174],\n",
      "        [ 14.7963],\n",
      "        [ 19.1050],\n",
      "        [ 20.8242],\n",
      "        [ 40.7826],\n",
      "        [ 47.7826],\n",
      "        [ 51.7826],\n",
      "        [ 51.7826],\n",
      "        [ 36.0529],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  7.4236],\n",
      "        [  7.4236],\n",
      "        [  7.0444],\n",
      "        [  3.0288],\n",
      "        [ 61.2826],\n",
      "        [ 47.7489],\n",
      "        [ 24.5700],\n",
      "        [ 67.7826],\n",
      "        [ 75.9826],\n",
      "        [ 37.0824],\n",
      "        [ 41.0891],\n",
      "        [ 82.3826],\n",
      "        [ 83.7826],\n",
      "        [  3.2308],\n",
      "        [  3.2308],\n",
      "        [ 89.2826],\n",
      "        [ 44.3571],\n",
      "        [  6.5427],\n",
      "        [ 51.4512],\n",
      "        [ 94.7826],\n",
      "        [101.7826],\n",
      "        [101.7826],\n",
      "        [ 83.5156],\n",
      "        [110.2826],\n",
      "        [117.2126],\n",
      "        [135.7826],\n",
      "        [149.4526],\n",
      "        [149.4526],\n",
      "        [172.2826]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 31.19602870941162\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 149\n",
      "剩餘X 資料 torch.Size([54, 10])\n",
      "剩餘Y 資料 torch.Size([54, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (31252.0859375, 12)\n",
      "The second_loss value of k: (33064.875, 18)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([180.])\n",
      "目前模型的Data狀態 torch.Size([157, 1])\n",
      "<<預測值>>\n",
      "tensor([[126.9269],\n",
      "        [  3.2174],\n",
      "        [207.1616],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 17.6569],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [248.4205],\n",
      "        [105.4101],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [216.1348],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [248.4205],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 25.9816],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 55.9725],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 28.9808],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 53.9787],\n",
      "        [  6.1406],\n",
      "        [103.9976],\n",
      "        [ 13.2110],\n",
      "        [  3.2174],\n",
      "        [ 14.7963],\n",
      "        [ 19.1050],\n",
      "        [ 20.8242],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [112.9471],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  7.4236],\n",
      "        [  7.4236],\n",
      "        [ 30.5444],\n",
      "        [  7.0288],\n",
      "        [  3.2174],\n",
      "        [ 47.7489],\n",
      "        [211.4300],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 37.0824],\n",
      "        [ 41.0891],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 19.0692],\n",
      "        [ 19.0692],\n",
      "        [  3.2174],\n",
      "        [161.6429],\n",
      "        [  6.5427],\n",
      "        [102.5488],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 83.5156],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[191.0731],\n",
      "        [  3.2174],\n",
      "        [118.6084],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  1.3969],\n",
      "        [  2.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  1.7826],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 22.4205],\n",
      "        [ 18.0201],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  9.7826],\n",
      "        [  3.2174],\n",
      "        [216.1348],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  6.7826],\n",
      "        [  1.2174],\n",
      "        [ 22.4205],\n",
      "        [  0.2826],\n",
      "        [  1.2626],\n",
      "        [  1.2826],\n",
      "        [  3.4826],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  6.7826],\n",
      "        [  3.2174],\n",
      "        [  7.2826],\n",
      "        [ 73.0184],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 21.8626],\n",
      "        [  3.2174],\n",
      "        [ 10.5275],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 29.3826],\n",
      "        [ 29.7826],\n",
      "        [ 30.7826],\n",
      "        [ 31.7826],\n",
      "        [ 34.7826],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [ 28.9808],\n",
      "        [  3.2174],\n",
      "        [ 38.2826],\n",
      "        [ 13.0213],\n",
      "        [  6.1406],\n",
      "        [  2.2024],\n",
      "        [ 13.2110],\n",
      "        [  3.2174],\n",
      "        [ 14.7963],\n",
      "        [ 19.1050],\n",
      "        [ 20.8242],\n",
      "        [ 40.7826],\n",
      "        [ 47.7826],\n",
      "        [ 51.7826],\n",
      "        [ 51.7826],\n",
      "        [ 36.0529],\n",
      "        [  3.2174],\n",
      "        [  3.2174],\n",
      "        [  7.4236],\n",
      "        [  7.4236],\n",
      "        [  7.0444],\n",
      "        [  3.0288],\n",
      "        [ 61.2826],\n",
      "        [ 47.7489],\n",
      "        [ 24.5700],\n",
      "        [ 67.7826],\n",
      "        [ 75.9826],\n",
      "        [ 37.0824],\n",
      "        [ 41.0891],\n",
      "        [ 82.3826],\n",
      "        [ 83.7826],\n",
      "        [  3.2308],\n",
      "        [  3.2308],\n",
      "        [ 89.2826],\n",
      "        [ 44.3571],\n",
      "        [  6.5427],\n",
      "        [ 51.4512],\n",
      "        [ 94.7826],\n",
      "        [101.7826],\n",
      "        [101.7826],\n",
      "        [ 83.5156],\n",
      "        [110.2826],\n",
      "        [117.2126],\n",
      "        [135.7826],\n",
      "        [149.4526],\n",
      "        [149.4526],\n",
      "        [172.2826],\n",
      "        [176.7826]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2281.9351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[191.3674],\n",
      "        [  3.2554],\n",
      "        [117.7410],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  1.3308],\n",
      "        [  2.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  1.7446],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 22.1977],\n",
      "        [ 17.7209],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  9.7446],\n",
      "        [  3.2554],\n",
      "        [215.5864],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  6.7446],\n",
      "        [  1.2554],\n",
      "        [ 22.1977],\n",
      "        [  0.2446],\n",
      "        [  1.2246],\n",
      "        [  1.2446],\n",
      "        [  3.4446],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  6.7446],\n",
      "        [  3.2554],\n",
      "        [  7.2446],\n",
      "        [ 72.7451],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 21.8246],\n",
      "        [  3.2554],\n",
      "        [ 11.2155],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 29.3445],\n",
      "        [ 29.7446],\n",
      "        [ 30.7446],\n",
      "        [ 31.7446],\n",
      "        [ 34.7445],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 29.0689],\n",
      "        [  3.2554],\n",
      "        [ 38.2445],\n",
      "        [ 12.8864],\n",
      "        [  6.1705],\n",
      "        [  1.4831],\n",
      "        [ 13.3891],\n",
      "        [  3.2554],\n",
      "        [ 14.7031],\n",
      "        [ 19.0957],\n",
      "        [ 20.8855],\n",
      "        [ 40.7445],\n",
      "        [ 47.7445],\n",
      "        [ 51.7445],\n",
      "        [ 51.7445],\n",
      "        [ 36.2103],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  8.0196],\n",
      "        [  8.0196],\n",
      "        [  7.8215],\n",
      "        [  5.0067],\n",
      "        [ 61.2445],\n",
      "        [ 49.3654],\n",
      "        [ 25.1091],\n",
      "        [ 67.7446],\n",
      "        [ 75.9445],\n",
      "        [ 37.3507],\n",
      "        [ 40.9436],\n",
      "        [ 82.3446],\n",
      "        [ 83.7446],\n",
      "        [  3.7875],\n",
      "        [  3.7875],\n",
      "        [ 89.2446],\n",
      "        [ 44.9759],\n",
      "        [  5.0502],\n",
      "        [ 51.9006],\n",
      "        [ 94.7446],\n",
      "        [101.7446],\n",
      "        [101.7446],\n",
      "        [ 83.6012],\n",
      "        [110.2446],\n",
      "        [117.1746],\n",
      "        [135.7446],\n",
      "        [149.4146],\n",
      "        [149.4146],\n",
      "        [172.2446],\n",
      "        [176.7446]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 31.45557475090027\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 150\n",
      "剩餘X 資料 torch.Size([53, 10])\n",
      "剩餘Y 資料 torch.Size([53, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (32907.7578125, 17)\n",
      "The second_loss value of k: (34873.52734375, 41)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([158, 1])\n",
      "<<預測值>>\n",
      "tensor([[126.6326],\n",
      "        [  3.2554],\n",
      "        [208.0290],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 17.5908],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [248.1977],\n",
      "        [105.1109],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [215.5864],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [248.1977],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 26.2549],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 55.2845],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 29.0689],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 54.1136],\n",
      "        [  6.1705],\n",
      "        [104.7169],\n",
      "        [ 13.3891],\n",
      "        [  3.2554],\n",
      "        [ 14.7031],\n",
      "        [ 19.0957],\n",
      "        [ 20.8855],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [112.7897],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  8.0196],\n",
      "        [  8.0196],\n",
      "        [ 31.3215],\n",
      "        [  9.0067],\n",
      "        [  3.2554],\n",
      "        [ 49.3654],\n",
      "        [210.8909],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 37.3507],\n",
      "        [ 40.9436],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 18.5125],\n",
      "        [ 18.5125],\n",
      "        [  3.2554],\n",
      "        [161.0241],\n",
      "        [  5.0502],\n",
      "        [102.0994],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 83.6012],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [181.4050]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[191.3674],\n",
      "        [  3.2554],\n",
      "        [117.7410],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  1.3308],\n",
      "        [  2.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  1.7446],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 22.1977],\n",
      "        [ 17.7209],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  9.7446],\n",
      "        [  3.2554],\n",
      "        [215.5864],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  6.7446],\n",
      "        [  1.2554],\n",
      "        [ 22.1977],\n",
      "        [  0.2446],\n",
      "        [  1.2246],\n",
      "        [  1.2446],\n",
      "        [  3.4446],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  6.7446],\n",
      "        [  3.2554],\n",
      "        [  7.2446],\n",
      "        [ 72.7451],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 21.8246],\n",
      "        [  3.2554],\n",
      "        [ 11.2155],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 29.3445],\n",
      "        [ 29.7446],\n",
      "        [ 30.7446],\n",
      "        [ 31.7446],\n",
      "        [ 34.7445],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [ 29.0689],\n",
      "        [  3.2554],\n",
      "        [ 38.2445],\n",
      "        [ 12.8864],\n",
      "        [  6.1705],\n",
      "        [  1.4831],\n",
      "        [ 13.3891],\n",
      "        [  3.2554],\n",
      "        [ 14.7031],\n",
      "        [ 19.0957],\n",
      "        [ 20.8855],\n",
      "        [ 40.7445],\n",
      "        [ 47.7445],\n",
      "        [ 51.7445],\n",
      "        [ 51.7445],\n",
      "        [ 36.2103],\n",
      "        [  3.2554],\n",
      "        [  3.2554],\n",
      "        [  8.0196],\n",
      "        [  8.0196],\n",
      "        [  7.8215],\n",
      "        [  5.0067],\n",
      "        [ 61.2445],\n",
      "        [ 49.3654],\n",
      "        [ 25.1091],\n",
      "        [ 67.7446],\n",
      "        [ 75.9445],\n",
      "        [ 37.3507],\n",
      "        [ 40.9436],\n",
      "        [ 82.3446],\n",
      "        [ 83.7446],\n",
      "        [  3.7875],\n",
      "        [  3.7875],\n",
      "        [ 89.2446],\n",
      "        [ 44.9759],\n",
      "        [  5.0502],\n",
      "        [ 51.9006],\n",
      "        [ 94.7446],\n",
      "        [101.7446],\n",
      "        [101.7446],\n",
      "        [ 83.6012],\n",
      "        [110.2446],\n",
      "        [117.1746],\n",
      "        [135.7446],\n",
      "        [149.4146],\n",
      "        [149.4146],\n",
      "        [172.2446],\n",
      "        [176.7446],\n",
      "        [181.4050]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2474.6763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  187.2767],\n",
      "        [    3.4386],\n",
      "        [  120.3390],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.1744],\n",
      "        [    2.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    1.5614],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [   14.5005],\n",
      "        [   13.2823],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    9.5614],\n",
      "        [    3.4386],\n",
      "        [  214.6285],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    6.5614],\n",
      "        [    1.4386],\n",
      "        [   14.5005],\n",
      "        [    0.0614],\n",
      "        [    1.0414],\n",
      "        [    1.0614],\n",
      "        [    3.2614],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    6.5614],\n",
      "        [    3.4386],\n",
      "        [    7.0614],\n",
      "        [   71.2267],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [   21.6414],\n",
      "        [    3.4386],\n",
      "        [    6.9629],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [   29.1614],\n",
      "        [   29.5614],\n",
      "        [   30.5614],\n",
      "        [   31.5614],\n",
      "        [   34.5614],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [   20.2243],\n",
      "        [    3.5621],\n",
      "        [   38.0614],\n",
      "        [   10.3149],\n",
      "        [   11.2720],\n",
      "        [    6.8506],\n",
      "        [   14.5823],\n",
      "        [    3.4386],\n",
      "        [   16.4588],\n",
      "        [   20.6658],\n",
      "        [   22.4427],\n",
      "        [   40.5614],\n",
      "        [   47.5614],\n",
      "        [   51.5614],\n",
      "        [   51.5614],\n",
      "        [   39.7556],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [   11.7187],\n",
      "        [   11.7187],\n",
      "        [    7.0457],\n",
      "        [    2.2641],\n",
      "        [   61.0614],\n",
      "        [   50.0854],\n",
      "        [   67.9083],\n",
      "        [   67.5614],\n",
      "        [   75.7614],\n",
      "        [   45.7503],\n",
      "        [   52.4604],\n",
      "        [   82.1614],\n",
      "        [   83.5614],\n",
      "        [    6.3315],\n",
      "        [    6.3315],\n",
      "        [   89.0614],\n",
      "        [   47.6991],\n",
      "        [    3.4386],\n",
      "        [   68.6456],\n",
      "        [   94.5614],\n",
      "        [  101.5614],\n",
      "        [  101.5614],\n",
      "        [   79.1105],\n",
      "        [  110.0614],\n",
      "        [  116.9914],\n",
      "        [  135.5614],\n",
      "        [  149.2314],\n",
      "        [  149.2314],\n",
      "        [  172.0614],\n",
      "        [  176.5614],\n",
      "        [  136.6252]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 31.71235990524292\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 151\n",
      "剩餘X 資料 torch.Size([52, 10])\n",
      "剩餘Y 資料 torch.Size([52, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (33874.42578125, 30)\n",
      "The second_loss value of k: (34805.15625, 40)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引30，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([159, 1])\n",
      "<<預測值>>\n",
      "tensor([[130.7233],\n",
      "        [  3.4386],\n",
      "        [205.4310],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [ 13.0856],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [211.4995],\n",
      "        [100.6723],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [214.6285],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [211.4995],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [ 27.7733],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [ 59.5371],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [ 20.2243],\n",
      "        [  3.5621],\n",
      "        [  3.4386],\n",
      "        [ 56.6851],\n",
      "        [ 11.2720],\n",
      "        [ 99.3494],\n",
      "        [ 14.5823],\n",
      "        [  3.4386],\n",
      "        [ 16.4588],\n",
      "        [ 20.6658],\n",
      "        [ 22.4427],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [109.2444],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [ 11.7187],\n",
      "        [ 11.7187],\n",
      "        [ 30.5457],\n",
      "        [  6.2641],\n",
      "        [  3.4386],\n",
      "        [ 50.0854],\n",
      "        [168.0917],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [ 45.7503],\n",
      "        [ 52.4604],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [ 28.6315],\n",
      "        [ 28.6315],\n",
      "        [  3.4386],\n",
      "        [158.3009],\n",
      "        [  3.4386],\n",
      "        [ 85.3544],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [ 79.1105],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [  3.4386],\n",
      "        [136.6252],\n",
      "        [184.0501]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  187.2767],\n",
      "        [    3.4386],\n",
      "        [  120.3390],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.1744],\n",
      "        [    2.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    1.5614],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [   14.5005],\n",
      "        [   13.2823],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    9.5614],\n",
      "        [    3.4386],\n",
      "        [  214.6285],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    6.5614],\n",
      "        [    1.4386],\n",
      "        [   14.5005],\n",
      "        [    0.0614],\n",
      "        [    1.0414],\n",
      "        [    1.0614],\n",
      "        [    3.2614],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    6.5614],\n",
      "        [    3.4386],\n",
      "        [    7.0614],\n",
      "        [   71.2267],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [   21.6414],\n",
      "        [    3.4386],\n",
      "        [    6.9629],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [   29.1614],\n",
      "        [   29.5614],\n",
      "        [   30.5614],\n",
      "        [   31.5614],\n",
      "        [   34.5614],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [   20.2243],\n",
      "        [    3.5621],\n",
      "        [   38.0614],\n",
      "        [   10.3149],\n",
      "        [   11.2720],\n",
      "        [    6.8506],\n",
      "        [   14.5823],\n",
      "        [    3.4386],\n",
      "        [   16.4588],\n",
      "        [   20.6658],\n",
      "        [   22.4427],\n",
      "        [   40.5614],\n",
      "        [   47.5614],\n",
      "        [   51.5614],\n",
      "        [   51.5614],\n",
      "        [   39.7556],\n",
      "        [    3.4386],\n",
      "        [    3.4386],\n",
      "        [   11.7187],\n",
      "        [   11.7187],\n",
      "        [    7.0457],\n",
      "        [    2.2641],\n",
      "        [   61.0614],\n",
      "        [   50.0854],\n",
      "        [   67.9083],\n",
      "        [   67.5614],\n",
      "        [   75.7614],\n",
      "        [   45.7503],\n",
      "        [   52.4604],\n",
      "        [   82.1614],\n",
      "        [   83.5614],\n",
      "        [    6.3315],\n",
      "        [    6.3315],\n",
      "        [   89.0614],\n",
      "        [   47.6991],\n",
      "        [    3.4386],\n",
      "        [   68.6456],\n",
      "        [   94.5614],\n",
      "        [  101.5614],\n",
      "        [  101.5614],\n",
      "        [   79.1105],\n",
      "        [  110.0614],\n",
      "        [  116.9914],\n",
      "        [  135.5614],\n",
      "        [  149.2314],\n",
      "        [  149.2314],\n",
      "        [  172.0614],\n",
      "        [  176.5614],\n",
      "        [  136.6252],\n",
      "        [  184.0501]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2611.5847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  186.2681],\n",
      "        [    3.5743],\n",
      "        [  132.3735],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    2.0094],\n",
      "        [    2.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    1.4257],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [   33.7819],\n",
      "        [    2.2868],\n",
      "        [    3.8474],\n",
      "        [    3.5743],\n",
      "        [    9.4257],\n",
      "        [    3.5743],\n",
      "        [  210.5076],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    6.4257],\n",
      "        [    1.5743],\n",
      "        [   33.7819],\n",
      "        [    0.0743],\n",
      "        [    0.9057],\n",
      "        [    0.9257],\n",
      "        [    3.1257],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    6.4257],\n",
      "        [    3.5743],\n",
      "        [    6.9257],\n",
      "        [   75.8162],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [   21.5057],\n",
      "        [    3.5743],\n",
      "        [    2.8378],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [   29.0257],\n",
      "        [   29.4257],\n",
      "        [   30.4257],\n",
      "        [   31.4257],\n",
      "        [   34.4257],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [   15.3123],\n",
      "        [    3.5743],\n",
      "        [   37.9257],\n",
      "        [   16.9853],\n",
      "        [    8.6291],\n",
      "        [   15.7357],\n",
      "        [   11.0999],\n",
      "        [    3.5743],\n",
      "        [   13.5361],\n",
      "        [   16.9032],\n",
      "        [   18.4734],\n",
      "        [   40.4257],\n",
      "        [   47.4257],\n",
      "        [   51.4257],\n",
      "        [   51.4257],\n",
      "        [   42.3199],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [   13.9971],\n",
      "        [   13.9971],\n",
      "        [    9.2371],\n",
      "        [    9.2933],\n",
      "        [   60.9257],\n",
      "        [   52.4518],\n",
      "        [   87.2815],\n",
      "        [   67.4257],\n",
      "        [   75.6256],\n",
      "        [   44.2460],\n",
      "        [   62.7726],\n",
      "        [   82.0257],\n",
      "        [   83.4257],\n",
      "        [    9.7559],\n",
      "        [    9.7559],\n",
      "        [   88.9257],\n",
      "        [   47.6929],\n",
      "        [    4.4028],\n",
      "        [   71.2809],\n",
      "        [   94.4257],\n",
      "        [  101.4257],\n",
      "        [  101.4257],\n",
      "        [   72.2408],\n",
      "        [  109.9257],\n",
      "        [  116.8557],\n",
      "        [  135.4257],\n",
      "        [  149.0957],\n",
      "        [  149.0957],\n",
      "        [  171.9257],\n",
      "        [  176.4257],\n",
      "        [  119.1433],\n",
      "        [  166.1487]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 31.97174620628357\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 152\n",
      "剩餘X 資料 torch.Size([51, 10])\n",
      "剩餘Y 資料 torch.Size([51, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (34754.52734375, 39)\n",
      "The second_loss value of k: (36643.78125, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引39，y= tensor([190.])\n",
      "目前模型的Data狀態 torch.Size([160, 1])\n",
      "<<預測值>>\n",
      "tensor([[131.7319],\n",
      "        [  3.5743],\n",
      "        [193.3965],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [ 18.2694],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [192.2181],\n",
      "        [ 89.6768],\n",
      "        [  3.8474],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [210.5076],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [192.2181],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [ 23.1838],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [ 69.3378],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [ 15.3123],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [ 50.0147],\n",
      "        [  8.6291],\n",
      "        [ 90.4642],\n",
      "        [ 11.0999],\n",
      "        [  3.5743],\n",
      "        [ 13.5361],\n",
      "        [ 16.9032],\n",
      "        [ 18.4734],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [106.6801],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [ 13.9971],\n",
      "        [ 13.9971],\n",
      "        [ 32.7371],\n",
      "        [ 13.2933],\n",
      "        [  3.5743],\n",
      "        [ 52.4518],\n",
      "        [148.7185],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [ 44.2460],\n",
      "        [ 62.7726],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [ 32.0559],\n",
      "        [ 32.0559],\n",
      "        [  3.5743],\n",
      "        [158.3071],\n",
      "        [  4.4028],\n",
      "        [ 82.7191],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [ 72.2408],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [  3.5743],\n",
      "        [119.1433],\n",
      "        [166.1487],\n",
      "        [  3.5743]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  186.2681],\n",
      "        [    3.5743],\n",
      "        [  132.3735],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    2.0094],\n",
      "        [    2.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    1.4257],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [   33.7819],\n",
      "        [    2.2868],\n",
      "        [    3.8474],\n",
      "        [    3.5743],\n",
      "        [    9.4257],\n",
      "        [    3.5743],\n",
      "        [  210.5076],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    6.4257],\n",
      "        [    1.5743],\n",
      "        [   33.7819],\n",
      "        [    0.0743],\n",
      "        [    0.9057],\n",
      "        [    0.9257],\n",
      "        [    3.1257],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    6.4257],\n",
      "        [    3.5743],\n",
      "        [    6.9257],\n",
      "        [   75.8162],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [   21.5057],\n",
      "        [    3.5743],\n",
      "        [    2.8378],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [   29.0257],\n",
      "        [   29.4257],\n",
      "        [   30.4257],\n",
      "        [   31.4257],\n",
      "        [   34.4257],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [   15.3123],\n",
      "        [    3.5743],\n",
      "        [   37.9257],\n",
      "        [   16.9853],\n",
      "        [    8.6291],\n",
      "        [   15.7357],\n",
      "        [   11.0999],\n",
      "        [    3.5743],\n",
      "        [   13.5361],\n",
      "        [   16.9032],\n",
      "        [   18.4734],\n",
      "        [   40.4257],\n",
      "        [   47.4257],\n",
      "        [   51.4257],\n",
      "        [   51.4257],\n",
      "        [   42.3199],\n",
      "        [    3.5743],\n",
      "        [    3.5743],\n",
      "        [   13.9971],\n",
      "        [   13.9971],\n",
      "        [    9.2371],\n",
      "        [    9.2933],\n",
      "        [   60.9257],\n",
      "        [   52.4518],\n",
      "        [   87.2815],\n",
      "        [   67.4257],\n",
      "        [   75.6256],\n",
      "        [   44.2460],\n",
      "        [   62.7726],\n",
      "        [   82.0257],\n",
      "        [   83.4257],\n",
      "        [    9.7559],\n",
      "        [    9.7559],\n",
      "        [   88.9257],\n",
      "        [   47.6929],\n",
      "        [    4.4028],\n",
      "        [   71.2809],\n",
      "        [   94.4257],\n",
      "        [  101.4257],\n",
      "        [  101.4257],\n",
      "        [   72.2408],\n",
      "        [  109.9257],\n",
      "        [  116.8557],\n",
      "        [  135.4257],\n",
      "        [  149.0957],\n",
      "        [  149.0957],\n",
      "        [  171.9257],\n",
      "        [  176.4257],\n",
      "        [  119.1433],\n",
      "        [  166.1487],\n",
      "        [  186.4257]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2786.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 80\n",
      "Number of shrink: 20\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[189.5863],\n",
      "        [  3.7190],\n",
      "        [138.5202],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  5.0573],\n",
      "        [  2.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  1.2810],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 34.1847],\n",
      "        [  0.3003],\n",
      "        [  3.9786],\n",
      "        [  3.7190],\n",
      "        [  9.2810],\n",
      "        [  3.7190],\n",
      "        [204.7951],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  6.2810],\n",
      "        [  1.7190],\n",
      "        [ 34.1847],\n",
      "        [  0.2190],\n",
      "        [  0.7610],\n",
      "        [  0.7810],\n",
      "        [  2.9810],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  6.2810],\n",
      "        [  3.7190],\n",
      "        [  6.7810],\n",
      "        [ 79.0948],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 21.3610],\n",
      "        [  3.7190],\n",
      "        [  5.6497],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 28.8810],\n",
      "        [ 29.2810],\n",
      "        [ 30.2810],\n",
      "        [ 31.2810],\n",
      "        [ 34.2810],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 15.1588],\n",
      "        [  3.7190],\n",
      "        [ 37.7810],\n",
      "        [ 22.0984],\n",
      "        [  5.9494],\n",
      "        [ 17.0133],\n",
      "        [  8.4954],\n",
      "        [  3.7190],\n",
      "        [ 10.4759],\n",
      "        [ 13.7498],\n",
      "        [ 15.2887],\n",
      "        [ 40.2810],\n",
      "        [ 47.2810],\n",
      "        [ 51.2810],\n",
      "        [ 51.2810],\n",
      "        [ 46.0531],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 11.2417],\n",
      "        [ 11.2417],\n",
      "        [  9.1602],\n",
      "        [  5.3521],\n",
      "        [ 60.7810],\n",
      "        [ 51.2275],\n",
      "        [ 85.6828],\n",
      "        [ 67.2810],\n",
      "        [ 75.4810],\n",
      "        [ 42.3803],\n",
      "        [ 63.5131],\n",
      "        [ 81.8810],\n",
      "        [ 83.2810],\n",
      "        [  7.6613],\n",
      "        [  7.6613],\n",
      "        [ 88.7810],\n",
      "        [ 50.2074],\n",
      "        [  7.7455],\n",
      "        [ 68.1963],\n",
      "        [ 94.2810],\n",
      "        [101.2810],\n",
      "        [101.2810],\n",
      "        [ 70.9061],\n",
      "        [109.7810],\n",
      "        [116.7110],\n",
      "        [135.2810],\n",
      "        [148.9510],\n",
      "        [148.9510],\n",
      "        [171.7810],\n",
      "        [176.2810],\n",
      "        [122.7043],\n",
      "        [159.5837],\n",
      "        [186.2810]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 32.23071217536926\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 153\n",
      "剩餘X 資料 torch.Size([50, 10])\n",
      "剩餘Y 資料 torch.Size([50, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (36588.41015625, 6)\n",
      "The second_loss value of k: (38526.22265625, 24)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([195.])\n",
      "目前模型的Data狀態 torch.Size([161, 1])\n",
      "<<預測值>>\n",
      "tensor([[128.4137],\n",
      "        [  3.7190],\n",
      "        [187.2498],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 21.3173],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [191.8153],\n",
      "        [ 87.6903],\n",
      "        [  3.9786],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [204.7951],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [191.8153],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 19.9052],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 72.1497],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 15.1588],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 44.9016],\n",
      "        [  5.9494],\n",
      "        [ 89.1867],\n",
      "        [  8.4954],\n",
      "        [  3.7190],\n",
      "        [ 10.4759],\n",
      "        [ 13.7498],\n",
      "        [ 15.2887],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [102.9469],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 11.2417],\n",
      "        [ 11.2417],\n",
      "        [ 32.6602],\n",
      "        [  9.3521],\n",
      "        [  3.7190],\n",
      "        [ 51.2275],\n",
      "        [150.3172],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 42.3803],\n",
      "        [ 63.5131],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 29.9613],\n",
      "        [ 29.9613],\n",
      "        [  3.7190],\n",
      "        [155.7926],\n",
      "        [  7.7455],\n",
      "        [ 85.8037],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 70.9061],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [122.7043],\n",
      "        [159.5837],\n",
      "        [  3.7190],\n",
      "        [  3.7190]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[189.5863],\n",
      "        [  3.7190],\n",
      "        [138.5202],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  5.0573],\n",
      "        [  2.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  1.2810],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 34.1847],\n",
      "        [  0.3003],\n",
      "        [  3.9786],\n",
      "        [  3.7190],\n",
      "        [  9.2810],\n",
      "        [  3.7190],\n",
      "        [204.7951],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  6.2810],\n",
      "        [  1.7190],\n",
      "        [ 34.1847],\n",
      "        [  0.2190],\n",
      "        [  0.7610],\n",
      "        [  0.7810],\n",
      "        [  2.9810],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  6.2810],\n",
      "        [  3.7190],\n",
      "        [  6.7810],\n",
      "        [ 79.0948],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 21.3610],\n",
      "        [  3.7190],\n",
      "        [  5.6497],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 28.8810],\n",
      "        [ 29.2810],\n",
      "        [ 30.2810],\n",
      "        [ 31.2810],\n",
      "        [ 34.2810],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 15.1588],\n",
      "        [  3.7190],\n",
      "        [ 37.7810],\n",
      "        [ 22.0984],\n",
      "        [  5.9494],\n",
      "        [ 17.0133],\n",
      "        [  8.4954],\n",
      "        [  3.7190],\n",
      "        [ 10.4759],\n",
      "        [ 13.7498],\n",
      "        [ 15.2887],\n",
      "        [ 40.2810],\n",
      "        [ 47.2810],\n",
      "        [ 51.2810],\n",
      "        [ 51.2810],\n",
      "        [ 46.0531],\n",
      "        [  3.7190],\n",
      "        [  3.7190],\n",
      "        [ 11.2417],\n",
      "        [ 11.2417],\n",
      "        [  9.1602],\n",
      "        [  5.3521],\n",
      "        [ 60.7810],\n",
      "        [ 51.2275],\n",
      "        [ 85.6828],\n",
      "        [ 67.2810],\n",
      "        [ 75.4810],\n",
      "        [ 42.3803],\n",
      "        [ 63.5131],\n",
      "        [ 81.8810],\n",
      "        [ 83.2810],\n",
      "        [  7.6613],\n",
      "        [  7.6613],\n",
      "        [ 88.7810],\n",
      "        [ 50.2074],\n",
      "        [  7.7455],\n",
      "        [ 68.1963],\n",
      "        [ 94.2810],\n",
      "        [101.2810],\n",
      "        [101.2810],\n",
      "        [ 70.9061],\n",
      "        [109.7810],\n",
      "        [116.7110],\n",
      "        [135.2810],\n",
      "        [148.9510],\n",
      "        [148.9510],\n",
      "        [171.7810],\n",
      "        [176.2810],\n",
      "        [122.7043],\n",
      "        [159.5837],\n",
      "        [186.2810],\n",
      "        [191.2810]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(2986.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[190.0180],\n",
      "        [  3.7987],\n",
      "        [134.3206],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  6.8323],\n",
      "        [  2.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  1.2013],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 32.7501],\n",
      "        [  0.3683],\n",
      "        [  5.2269],\n",
      "        [  3.7987],\n",
      "        [  9.2013],\n",
      "        [  3.7987],\n",
      "        [203.9333],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  6.2013],\n",
      "        [  1.7987],\n",
      "        [ 32.7501],\n",
      "        [  0.2987],\n",
      "        [  0.6813],\n",
      "        [  0.7013],\n",
      "        [  2.9013],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  6.2013],\n",
      "        [  3.7987],\n",
      "        [  6.7013],\n",
      "        [ 80.0958],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 21.2813],\n",
      "        [  3.7987],\n",
      "        [  6.4811],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 28.8013],\n",
      "        [ 29.2013],\n",
      "        [ 30.2013],\n",
      "        [ 31.2013],\n",
      "        [ 34.2013],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 15.3206],\n",
      "        [  3.7987],\n",
      "        [ 37.7013],\n",
      "        [ 23.8042],\n",
      "        [  5.0113],\n",
      "        [ 14.0455],\n",
      "        [  7.6307],\n",
      "        [  3.7987],\n",
      "        [  9.3973],\n",
      "        [ 12.5515],\n",
      "        [ 14.1397],\n",
      "        [ 40.2013],\n",
      "        [ 47.2013],\n",
      "        [ 51.2013],\n",
      "        [ 51.2013],\n",
      "        [ 47.4549],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 12.8316],\n",
      "        [ 12.8316],\n",
      "        [ 13.3326],\n",
      "        [  8.2165],\n",
      "        [ 60.7013],\n",
      "        [ 57.0937],\n",
      "        [ 84.1948],\n",
      "        [ 67.2013],\n",
      "        [ 75.4013],\n",
      "        [ 43.5522],\n",
      "        [ 65.4093],\n",
      "        [ 81.8013],\n",
      "        [ 83.2013],\n",
      "        [  6.5394],\n",
      "        [  6.5394],\n",
      "        [ 88.7013],\n",
      "        [ 50.1801],\n",
      "        [  6.0136],\n",
      "        [ 65.4756],\n",
      "        [ 94.2013],\n",
      "        [101.2013],\n",
      "        [101.2013],\n",
      "        [ 73.0192],\n",
      "        [109.7013],\n",
      "        [116.6313],\n",
      "        [135.2013],\n",
      "        [148.8713],\n",
      "        [148.8713],\n",
      "        [171.7013],\n",
      "        [176.2013],\n",
      "        [124.9703],\n",
      "        [158.2555],\n",
      "        [186.2013],\n",
      "        [191.2013]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 32.48970437049866\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 154\n",
      "剩餘X 資料 torch.Size([49, 10])\n",
      "剩餘Y 資料 torch.Size([49, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (38494.9375, 23)\n",
      "The second_loss value of k: (50266.20703125, 32)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引23，y= tensor([200.])\n",
      "目前模型的Data狀態 torch.Size([162, 1])\n",
      "<<預測值>>\n",
      "tensor([[127.9820],\n",
      "        [  3.7987],\n",
      "        [191.4493],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 23.0923],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [193.2499],\n",
      "        [ 87.7583],\n",
      "        [  5.2269],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [203.9333],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [193.2499],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 18.9042],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 72.9811],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 15.3206],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 43.1958],\n",
      "        [  5.0113],\n",
      "        [ 92.1545],\n",
      "        [  7.6307],\n",
      "        [  3.7987],\n",
      "        [  9.3973],\n",
      "        [ 12.5515],\n",
      "        [ 14.1397],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [101.5451],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 12.8316],\n",
      "        [ 12.8316],\n",
      "        [ 36.8326],\n",
      "        [ 12.2165],\n",
      "        [  3.7987],\n",
      "        [ 57.0937],\n",
      "        [151.8052],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 43.5522],\n",
      "        [ 65.4093],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 28.8394],\n",
      "        [ 28.8394],\n",
      "        [  3.7987],\n",
      "        [155.8199],\n",
      "        [  6.0136],\n",
      "        [ 88.5244],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 73.0192],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [124.9703],\n",
      "        [158.2555],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[190.0180],\n",
      "        [  3.7987],\n",
      "        [134.3206],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  6.8323],\n",
      "        [  2.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  1.2013],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 32.7501],\n",
      "        [  0.3683],\n",
      "        [  5.2269],\n",
      "        [  3.7987],\n",
      "        [  9.2013],\n",
      "        [  3.7987],\n",
      "        [203.9333],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  6.2013],\n",
      "        [  1.7987],\n",
      "        [ 32.7501],\n",
      "        [  0.2987],\n",
      "        [  0.6813],\n",
      "        [  0.7013],\n",
      "        [  2.9013],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  6.2013],\n",
      "        [  3.7987],\n",
      "        [  6.7013],\n",
      "        [ 80.0958],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 21.2813],\n",
      "        [  3.7987],\n",
      "        [  6.4811],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 28.8013],\n",
      "        [ 29.2013],\n",
      "        [ 30.2013],\n",
      "        [ 31.2013],\n",
      "        [ 34.2013],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 15.3206],\n",
      "        [  3.7987],\n",
      "        [ 37.7013],\n",
      "        [ 23.8042],\n",
      "        [  5.0113],\n",
      "        [ 14.0455],\n",
      "        [  7.6307],\n",
      "        [  3.7987],\n",
      "        [  9.3973],\n",
      "        [ 12.5515],\n",
      "        [ 14.1397],\n",
      "        [ 40.2013],\n",
      "        [ 47.2013],\n",
      "        [ 51.2013],\n",
      "        [ 51.2013],\n",
      "        [ 47.4549],\n",
      "        [  3.7987],\n",
      "        [  3.7987],\n",
      "        [ 12.8316],\n",
      "        [ 12.8316],\n",
      "        [ 13.3326],\n",
      "        [  8.2165],\n",
      "        [ 60.7013],\n",
      "        [ 57.0937],\n",
      "        [ 84.1948],\n",
      "        [ 67.2013],\n",
      "        [ 75.4013],\n",
      "        [ 43.5522],\n",
      "        [ 65.4093],\n",
      "        [ 81.8013],\n",
      "        [ 83.2013],\n",
      "        [  6.5394],\n",
      "        [  6.5394],\n",
      "        [ 88.7013],\n",
      "        [ 50.1801],\n",
      "        [  6.0136],\n",
      "        [ 65.4756],\n",
      "        [ 94.2013],\n",
      "        [101.2013],\n",
      "        [101.2013],\n",
      "        [ 73.0192],\n",
      "        [109.7013],\n",
      "        [116.6313],\n",
      "        [135.2013],\n",
      "        [148.8713],\n",
      "        [148.8713],\n",
      "        [171.7013],\n",
      "        [176.2013],\n",
      "        [124.9703],\n",
      "        [158.2555],\n",
      "        [186.2013],\n",
      "        [191.2013],\n",
      "        [196.2013]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(3201.2390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  189.6875],\n",
      "        [    3.8647],\n",
      "        [  136.1285],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    8.6134],\n",
      "        [    2.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    1.1353],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [   32.8091],\n",
      "        [    0.0060],\n",
      "        [    4.4130],\n",
      "        [    3.8647],\n",
      "        [    9.1353],\n",
      "        [    3.8647],\n",
      "        [  203.7611],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    6.1353],\n",
      "        [    1.8647],\n",
      "        [   32.8091],\n",
      "        [    0.3647],\n",
      "        [    0.6153],\n",
      "        [    0.6353],\n",
      "        [    2.8353],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    6.1353],\n",
      "        [    3.8647],\n",
      "        [    6.6353],\n",
      "        [   80.2695],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [   21.2153],\n",
      "        [    3.8647],\n",
      "        [    6.7181],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [   28.7353],\n",
      "        [   29.1353],\n",
      "        [   30.1353],\n",
      "        [   31.1353],\n",
      "        [   34.1353],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [   15.7017],\n",
      "        [    3.8647],\n",
      "        [   37.6353],\n",
      "        [   24.5804],\n",
      "        [    4.6225],\n",
      "        [   13.3876],\n",
      "        [    7.4676],\n",
      "        [    3.8647],\n",
      "        [    8.5986],\n",
      "        [   11.9974],\n",
      "        [   13.6807],\n",
      "        [   40.1353],\n",
      "        [   47.1353],\n",
      "        [   51.1353],\n",
      "        [   51.1353],\n",
      "        [   49.2258],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [   11.3554],\n",
      "        [   11.3554],\n",
      "        [   12.6840],\n",
      "        [    6.0017],\n",
      "        [   60.6353],\n",
      "        [   56.1636],\n",
      "        [   83.7626],\n",
      "        [   67.1353],\n",
      "        [   75.3353],\n",
      "        [   43.3588],\n",
      "        [   64.9356],\n",
      "        [   81.7353],\n",
      "        [   83.1353],\n",
      "        [    5.6674],\n",
      "        [    5.6674],\n",
      "        [   88.6353],\n",
      "        [   49.7009],\n",
      "        [    4.8792],\n",
      "        [   64.7882],\n",
      "        [   94.1353],\n",
      "        [  101.1353],\n",
      "        [  101.1353],\n",
      "        [   72.7754],\n",
      "        [  109.6353],\n",
      "        [  116.5653],\n",
      "        [  135.1353],\n",
      "        [  148.8053],\n",
      "        [  148.8053],\n",
      "        [  171.6353],\n",
      "        [  176.1353],\n",
      "        [  125.8805],\n",
      "        [  156.9318],\n",
      "        [  186.1353],\n",
      "        [  191.1353],\n",
      "        [  196.1353]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 32.74912643432617\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 155\n",
      "剩餘X 資料 torch.Size([48, 10])\n",
      "剩餘Y 資料 torch.Size([48, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (50236.6328125, 31)\n",
      "The second_loss value of k: (53435.21484375, 46)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引31，y= tensor([228.])\n",
      "目前模型的Data狀態 torch.Size([163, 1])\n",
      "<<預測值>>\n",
      "tensor([[128.3125],\n",
      "        [  3.8647],\n",
      "        [189.6415],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [ 24.8734],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [193.1909],\n",
      "        [ 87.3960],\n",
      "        [  4.4130],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [203.7611],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [193.1909],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [ 18.7305],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [ 73.2181],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [ 15.7017],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [ 42.4196],\n",
      "        [  4.6225],\n",
      "        [ 92.8124],\n",
      "        [  7.4676],\n",
      "        [  3.8647],\n",
      "        [  8.5986],\n",
      "        [ 11.9974],\n",
      "        [ 13.6807],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [ 99.7742],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [ 11.3554],\n",
      "        [ 11.3554],\n",
      "        [ 36.1840],\n",
      "        [ 10.0017],\n",
      "        [  3.8647],\n",
      "        [ 56.1636],\n",
      "        [152.2374],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [ 43.3588],\n",
      "        [ 64.9356],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [ 27.9674],\n",
      "        [ 27.9674],\n",
      "        [  3.8647],\n",
      "        [156.2991],\n",
      "        [  4.8792],\n",
      "        [ 89.2118],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [ 72.7754],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [125.8805],\n",
      "        [156.9318],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647],\n",
      "        [  3.8647]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  189.6875],\n",
      "        [    3.8647],\n",
      "        [  136.1285],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    8.6134],\n",
      "        [    2.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    1.1353],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [   32.8091],\n",
      "        [    0.0060],\n",
      "        [    4.4130],\n",
      "        [    3.8647],\n",
      "        [    9.1353],\n",
      "        [    3.8647],\n",
      "        [  203.7611],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    6.1353],\n",
      "        [    1.8647],\n",
      "        [   32.8091],\n",
      "        [    0.3647],\n",
      "        [    0.6153],\n",
      "        [    0.6353],\n",
      "        [    2.8353],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    6.1353],\n",
      "        [    3.8647],\n",
      "        [    6.6353],\n",
      "        [   80.2695],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [   21.2153],\n",
      "        [    3.8647],\n",
      "        [    6.7181],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [   28.7353],\n",
      "        [   29.1353],\n",
      "        [   30.1353],\n",
      "        [   31.1353],\n",
      "        [   34.1353],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [   15.7017],\n",
      "        [    3.8647],\n",
      "        [   37.6353],\n",
      "        [   24.5804],\n",
      "        [    4.6225],\n",
      "        [   13.3876],\n",
      "        [    7.4676],\n",
      "        [    3.8647],\n",
      "        [    8.5986],\n",
      "        [   11.9974],\n",
      "        [   13.6807],\n",
      "        [   40.1353],\n",
      "        [   47.1353],\n",
      "        [   51.1353],\n",
      "        [   51.1353],\n",
      "        [   49.2258],\n",
      "        [    3.8647],\n",
      "        [    3.8647],\n",
      "        [   11.3554],\n",
      "        [   11.3554],\n",
      "        [   12.6840],\n",
      "        [    6.0017],\n",
      "        [   60.6353],\n",
      "        [   56.1636],\n",
      "        [   83.7626],\n",
      "        [   67.1353],\n",
      "        [   75.3353],\n",
      "        [   43.3588],\n",
      "        [   64.9356],\n",
      "        [   81.7353],\n",
      "        [   83.1353],\n",
      "        [    5.6674],\n",
      "        [    5.6674],\n",
      "        [   88.6353],\n",
      "        [   49.7009],\n",
      "        [    4.8792],\n",
      "        [   64.7882],\n",
      "        [   94.1353],\n",
      "        [  101.1353],\n",
      "        [  101.1353],\n",
      "        [   72.7754],\n",
      "        [  109.6353],\n",
      "        [  116.5653],\n",
      "        [  135.1353],\n",
      "        [  148.8053],\n",
      "        [  148.8053],\n",
      "        [  171.6353],\n",
      "        [  176.1353],\n",
      "        [  125.8805],\n",
      "        [  156.9318],\n",
      "        [  186.1353],\n",
      "        [  191.1353],\n",
      "        [  196.1353],\n",
      "        [  224.1353]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(3486.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 80\n",
      "Number of shrink: 20\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[188.7464],\n",
      "        [  3.9678],\n",
      "        [137.4161],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 11.7677],\n",
      "        [  2.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  1.0322],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 32.6920],\n",
      "        [  1.2915],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  9.0322],\n",
      "        [  3.9678],\n",
      "        [203.9199],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  6.0322],\n",
      "        [  1.9678],\n",
      "        [ 32.6920],\n",
      "        [  0.4678],\n",
      "        [  0.5122],\n",
      "        [  0.5322],\n",
      "        [  2.7322],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  6.0322],\n",
      "        [  3.9678],\n",
      "        [  6.5322],\n",
      "        [ 80.5267],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 21.1122],\n",
      "        [  3.9678],\n",
      "        [  8.5064],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 28.6322],\n",
      "        [ 29.0322],\n",
      "        [ 30.0322],\n",
      "        [ 31.0322],\n",
      "        [ 34.0322],\n",
      "        [  3.9678],\n",
      "        [  4.0968],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 16.2274],\n",
      "        [  3.9678],\n",
      "        [ 37.5322],\n",
      "        [ 25.7846],\n",
      "        [  3.9678],\n",
      "        [ 10.5184],\n",
      "        [  7.2272],\n",
      "        [  3.9678],\n",
      "        [  7.2689],\n",
      "        [ 11.1425],\n",
      "        [ 12.9752],\n",
      "        [ 40.0322],\n",
      "        [ 47.0322],\n",
      "        [ 51.0322],\n",
      "        [ 51.0322],\n",
      "        [ 49.7763],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  7.8527],\n",
      "        [  7.8527],\n",
      "        [ 13.2159],\n",
      "        [ 10.7140],\n",
      "        [ 60.5322],\n",
      "        [ 53.8933],\n",
      "        [ 83.3870],\n",
      "        [ 67.0322],\n",
      "        [ 75.2322],\n",
      "        [ 44.4750],\n",
      "        [ 67.2064],\n",
      "        [ 81.6322],\n",
      "        [ 83.0322],\n",
      "        [  4.2150],\n",
      "        [  4.2150],\n",
      "        [ 88.5322],\n",
      "        [ 48.4815],\n",
      "        [  3.9678],\n",
      "        [ 64.2518],\n",
      "        [ 94.0322],\n",
      "        [101.0322],\n",
      "        [101.0322],\n",
      "        [ 74.0411],\n",
      "        [109.5322],\n",
      "        [116.4622],\n",
      "        [135.0322],\n",
      "        [148.7022],\n",
      "        [148.7022],\n",
      "        [171.5322],\n",
      "        [176.0322],\n",
      "        [126.9431],\n",
      "        [154.9102],\n",
      "        [186.0322],\n",
      "        [191.0322],\n",
      "        [196.0322],\n",
      "        [224.0322]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 33.00619721412659\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 156\n",
      "剩餘X 資料 torch.Size([47, 10])\n",
      "剩餘Y 資料 torch.Size([47, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (53442.51171875, 45)\n",
      "The second_loss value of k: (54771.08984375, 21)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引45，y= tensor([349.])\n",
      "目前模型的Data狀態 torch.Size([164, 1])\n",
      "<<預測值>>\n",
      "tensor([[129.2536],\n",
      "        [  3.9678],\n",
      "        [188.3539],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 28.0277],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [193.3080],\n",
      "        [ 86.0985],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [203.9199],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [193.3080],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 18.4733],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 75.0064],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  4.0968],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 16.2274],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 41.2154],\n",
      "        [  3.9678],\n",
      "        [ 95.6816],\n",
      "        [  7.2272],\n",
      "        [  3.9678],\n",
      "        [  7.2689],\n",
      "        [ 11.1425],\n",
      "        [ 12.9752],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 99.2237],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  7.8527],\n",
      "        [  7.8527],\n",
      "        [ 36.7159],\n",
      "        [ 14.7140],\n",
      "        [  3.9678],\n",
      "        [ 53.8933],\n",
      "        [152.6130],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 44.4750],\n",
      "        [ 67.2064],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 26.5150],\n",
      "        [ 26.5150],\n",
      "        [  3.9678],\n",
      "        [157.5185],\n",
      "        [  3.9678],\n",
      "        [ 89.7482],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 74.0411],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [126.9431],\n",
      "        [154.9102],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [117.8236]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[188.7464],\n",
      "        [  3.9678],\n",
      "        [137.4161],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 11.7677],\n",
      "        [  2.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  1.0322],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 32.6920],\n",
      "        [  1.2915],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  9.0322],\n",
      "        [  3.9678],\n",
      "        [203.9199],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  6.0322],\n",
      "        [  1.9678],\n",
      "        [ 32.6920],\n",
      "        [  0.4678],\n",
      "        [  0.5122],\n",
      "        [  0.5322],\n",
      "        [  2.7322],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  6.0322],\n",
      "        [  3.9678],\n",
      "        [  6.5322],\n",
      "        [ 80.5267],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 21.1122],\n",
      "        [  3.9678],\n",
      "        [  8.5064],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 28.6322],\n",
      "        [ 29.0322],\n",
      "        [ 30.0322],\n",
      "        [ 31.0322],\n",
      "        [ 34.0322],\n",
      "        [  3.9678],\n",
      "        [  4.0968],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [ 16.2274],\n",
      "        [  3.9678],\n",
      "        [ 37.5322],\n",
      "        [ 25.7846],\n",
      "        [  3.9678],\n",
      "        [ 10.5184],\n",
      "        [  7.2272],\n",
      "        [  3.9678],\n",
      "        [  7.2689],\n",
      "        [ 11.1425],\n",
      "        [ 12.9752],\n",
      "        [ 40.0322],\n",
      "        [ 47.0322],\n",
      "        [ 51.0322],\n",
      "        [ 51.0322],\n",
      "        [ 49.7763],\n",
      "        [  3.9678],\n",
      "        [  3.9678],\n",
      "        [  7.8527],\n",
      "        [  7.8527],\n",
      "        [ 13.2159],\n",
      "        [ 10.7140],\n",
      "        [ 60.5322],\n",
      "        [ 53.8933],\n",
      "        [ 83.3870],\n",
      "        [ 67.0322],\n",
      "        [ 75.2322],\n",
      "        [ 44.4750],\n",
      "        [ 67.2064],\n",
      "        [ 81.6322],\n",
      "        [ 83.0322],\n",
      "        [  4.2150],\n",
      "        [  4.2150],\n",
      "        [ 88.5322],\n",
      "        [ 48.4815],\n",
      "        [  3.9678],\n",
      "        [ 64.2518],\n",
      "        [ 94.0322],\n",
      "        [101.0322],\n",
      "        [101.0322],\n",
      "        [ 74.0411],\n",
      "        [109.5322],\n",
      "        [116.4622],\n",
      "        [135.0322],\n",
      "        [148.7022],\n",
      "        [148.7022],\n",
      "        [171.5322],\n",
      "        [176.0322],\n",
      "        [126.9431],\n",
      "        [154.9102],\n",
      "        [186.0322],\n",
      "        [191.0322],\n",
      "        [196.0322],\n",
      "        [224.0322],\n",
      "        [231.1764]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(3786.3521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[190.5762],\n",
      "        [  4.0669],\n",
      "        [ 93.4535],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  9.1732],\n",
      "        [  3.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  0.9331],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 29.6600],\n",
      "        [  0.3286],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  8.9331],\n",
      "        [  4.0669],\n",
      "        [202.9608],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  5.9331],\n",
      "        [  2.0669],\n",
      "        [ 29.6600],\n",
      "        [  0.5669],\n",
      "        [  0.4131],\n",
      "        [  0.4331],\n",
      "        [  2.6331],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  5.9331],\n",
      "        [  4.0669],\n",
      "        [  6.4331],\n",
      "        [ 78.2014],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 21.0131],\n",
      "        [  4.0669],\n",
      "        [  1.1262],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 28.5331],\n",
      "        [ 28.9331],\n",
      "        [ 29.9331],\n",
      "        [ 30.9331],\n",
      "        [ 33.9331],\n",
      "        [  4.0669],\n",
      "        [ 25.7490],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 17.0756],\n",
      "        [  4.0669],\n",
      "        [ 37.4331],\n",
      "        [ 22.7738],\n",
      "        [  4.8638],\n",
      "        [ 23.5371],\n",
      "        [  8.8543],\n",
      "        [  4.0669],\n",
      "        [  7.9679],\n",
      "        [ 12.5285],\n",
      "        [ 14.5960],\n",
      "        [ 39.9331],\n",
      "        [ 46.9331],\n",
      "        [ 50.9331],\n",
      "        [ 50.9331],\n",
      "        [ 62.9955],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  5.8495],\n",
      "        [  5.8495],\n",
      "        [ 29.6217],\n",
      "        [  4.8342],\n",
      "        [ 60.4331],\n",
      "        [ 69.8348],\n",
      "        [ 82.0563],\n",
      "        [ 66.9331],\n",
      "        [ 75.1331],\n",
      "        [ 64.5036],\n",
      "        [ 73.2795],\n",
      "        [ 81.5331],\n",
      "        [ 82.9331],\n",
      "        [  7.8668],\n",
      "        [  7.8668],\n",
      "        [ 88.4331],\n",
      "        [ 51.4161],\n",
      "        [  4.0669],\n",
      "        [ 68.8941],\n",
      "        [ 93.9331],\n",
      "        [100.9331],\n",
      "        [100.9331],\n",
      "        [102.9456],\n",
      "        [109.4331],\n",
      "        [116.3631],\n",
      "        [134.9331],\n",
      "        [148.6031],\n",
      "        [148.6031],\n",
      "        [171.4331],\n",
      "        [175.9331],\n",
      "        [127.4388],\n",
      "        [163.7681],\n",
      "        [185.9331],\n",
      "        [190.9331],\n",
      "        [195.9331],\n",
      "        [223.9331],\n",
      "        [199.9102]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 33.26447629928589\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 157\n",
      "剩餘X 資料 torch.Size([46, 10])\n",
      "剩餘Y 資料 torch.Size([46, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (54724.68359375, 21)\n",
      "The second_loss value of k: (64114.44140625, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引21，y= tensor([238.])\n",
      "目前模型的Data狀態 torch.Size([165, 1])\n",
      "<<預測值>>\n",
      "tensor([[127.4238],\n",
      "        [  4.0669],\n",
      "        [232.3165],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 25.4332],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [196.3400],\n",
      "        [ 87.7186],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [202.9608],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [196.3400],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 20.7986],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 65.3738],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 25.7490],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 17.0756],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 44.2262],\n",
      "        [  4.8638],\n",
      "        [129.7371],\n",
      "        [  8.8543],\n",
      "        [  4.0669],\n",
      "        [  7.9679],\n",
      "        [ 12.5285],\n",
      "        [ 14.5960],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 86.0045],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  5.8495],\n",
      "        [  5.8495],\n",
      "        [ 53.1217],\n",
      "        [  8.8342],\n",
      "        [  4.0669],\n",
      "        [ 69.8348],\n",
      "        [153.9437],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 64.5036],\n",
      "        [ 73.2795],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 30.1668],\n",
      "        [ 30.1668],\n",
      "        [  4.0669],\n",
      "        [154.5839],\n",
      "        [  4.0669],\n",
      "        [ 85.1059],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [102.9456],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [127.4388],\n",
      "        [163.7681],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [149.0898],\n",
      "        [  4.0669]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[190.5762],\n",
      "        [  4.0669],\n",
      "        [ 93.4535],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  9.1732],\n",
      "        [  3.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  0.9331],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 29.6600],\n",
      "        [  0.3286],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  8.9331],\n",
      "        [  4.0669],\n",
      "        [202.9608],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  5.9331],\n",
      "        [  2.0669],\n",
      "        [ 29.6600],\n",
      "        [  0.5669],\n",
      "        [  0.4131],\n",
      "        [  0.4331],\n",
      "        [  2.6331],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  5.9331],\n",
      "        [  4.0669],\n",
      "        [  6.4331],\n",
      "        [ 78.2014],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 21.0131],\n",
      "        [  4.0669],\n",
      "        [  1.1262],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 28.5331],\n",
      "        [ 28.9331],\n",
      "        [ 29.9331],\n",
      "        [ 30.9331],\n",
      "        [ 33.9331],\n",
      "        [  4.0669],\n",
      "        [ 25.7490],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [ 17.0756],\n",
      "        [  4.0669],\n",
      "        [ 37.4331],\n",
      "        [ 22.7738],\n",
      "        [  4.8638],\n",
      "        [ 23.5371],\n",
      "        [  8.8543],\n",
      "        [  4.0669],\n",
      "        [  7.9679],\n",
      "        [ 12.5285],\n",
      "        [ 14.5960],\n",
      "        [ 39.9331],\n",
      "        [ 46.9331],\n",
      "        [ 50.9331],\n",
      "        [ 50.9331],\n",
      "        [ 62.9955],\n",
      "        [  4.0669],\n",
      "        [  4.0669],\n",
      "        [  5.8495],\n",
      "        [  5.8495],\n",
      "        [ 29.6217],\n",
      "        [  4.8342],\n",
      "        [ 60.4331],\n",
      "        [ 69.8348],\n",
      "        [ 82.0563],\n",
      "        [ 66.9331],\n",
      "        [ 75.1331],\n",
      "        [ 64.5036],\n",
      "        [ 73.2795],\n",
      "        [ 81.5331],\n",
      "        [ 82.9331],\n",
      "        [  7.8668],\n",
      "        [  7.8668],\n",
      "        [ 88.4331],\n",
      "        [ 51.4161],\n",
      "        [  4.0669],\n",
      "        [ 68.8941],\n",
      "        [ 93.9331],\n",
      "        [100.9331],\n",
      "        [100.9331],\n",
      "        [102.9456],\n",
      "        [109.4331],\n",
      "        [116.3631],\n",
      "        [134.9331],\n",
      "        [148.6031],\n",
      "        [148.6031],\n",
      "        [171.4331],\n",
      "        [175.9331],\n",
      "        [127.4388],\n",
      "        [163.7681],\n",
      "        [185.9331],\n",
      "        [190.9331],\n",
      "        [195.9331],\n",
      "        [223.9331],\n",
      "        [199.9102],\n",
      "        [233.9331]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4048.2393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[189.3082],\n",
      "        [  4.1504],\n",
      "        [ 89.8438],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  6.8659],\n",
      "        [  3.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  0.8496],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 29.2365],\n",
      "        [  0.6098],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  8.8496],\n",
      "        [  4.1504],\n",
      "        [206.0499],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  5.8496],\n",
      "        [  2.1504],\n",
      "        [ 29.2365],\n",
      "        [  0.6504],\n",
      "        [  0.3296],\n",
      "        [  0.3496],\n",
      "        [  2.5496],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  5.8496],\n",
      "        [  4.1504],\n",
      "        [  6.3496],\n",
      "        [ 78.7146],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 20.9296],\n",
      "        [  4.1504],\n",
      "        [  2.0204],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 28.4496],\n",
      "        [ 28.8496],\n",
      "        [ 29.8496],\n",
      "        [ 30.8496],\n",
      "        [ 33.8496],\n",
      "        [  4.1504],\n",
      "        [ 23.3319],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 15.5815],\n",
      "        [  4.1504],\n",
      "        [ 37.3496],\n",
      "        [ 22.2078],\n",
      "        [  4.4081],\n",
      "        [ 22.9843],\n",
      "        [  8.1491],\n",
      "        [  4.1504],\n",
      "        [  8.0078],\n",
      "        [ 12.3507],\n",
      "        [ 14.3344],\n",
      "        [ 39.8496],\n",
      "        [ 46.8496],\n",
      "        [ 50.8496],\n",
      "        [ 50.8496],\n",
      "        [ 62.5919],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  6.5761],\n",
      "        [  6.5761],\n",
      "        [ 29.0053],\n",
      "        [  1.4321],\n",
      "        [ 60.3496],\n",
      "        [ 70.3861],\n",
      "        [ 82.5011],\n",
      "        [ 66.8496],\n",
      "        [ 75.0496],\n",
      "        [ 64.2702],\n",
      "        [ 72.7934],\n",
      "        [ 81.4496],\n",
      "        [ 82.8496],\n",
      "        [  8.6679],\n",
      "        [  8.6679],\n",
      "        [ 88.3496],\n",
      "        [ 49.8410],\n",
      "        [  4.1504],\n",
      "        [ 69.7529],\n",
      "        [ 93.8496],\n",
      "        [100.8496],\n",
      "        [100.8496],\n",
      "        [103.1486],\n",
      "        [109.3496],\n",
      "        [116.2796],\n",
      "        [134.8496],\n",
      "        [148.5196],\n",
      "        [148.5196],\n",
      "        [171.3496],\n",
      "        [175.8496],\n",
      "        [125.9530],\n",
      "        [166.1979],\n",
      "        [185.8496],\n",
      "        [190.8496],\n",
      "        [195.8496],\n",
      "        [223.8496],\n",
      "        [198.3617],\n",
      "        [233.8496]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 33.52267909049988\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 158\n",
      "剩餘X 資料 torch.Size([45, 10])\n",
      "剩餘Y 資料 torch.Size([45, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (63622.296875, 6)\n",
      "The second_loss value of k: (74446.890625, 26)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([166, 1])\n",
      "<<預測值>>\n",
      "tensor([[128.6918],\n",
      "        [  4.1504],\n",
      "        [235.9261],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 23.1259],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [196.7635],\n",
      "        [ 87.9998],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [206.0499],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [196.7635],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 20.2854],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 64.4796],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 23.3319],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 15.5815],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 44.7922],\n",
      "        [  4.4081],\n",
      "        [129.1842],\n",
      "        [  8.1491],\n",
      "        [  4.1504],\n",
      "        [  8.0078],\n",
      "        [ 12.3507],\n",
      "        [ 14.3344],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 86.4081],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  6.5761],\n",
      "        [  6.5761],\n",
      "        [ 52.5053],\n",
      "        [  5.4321],\n",
      "        [  4.1504],\n",
      "        [ 70.3861],\n",
      "        [153.4989],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 64.2702],\n",
      "        [ 72.7934],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 30.9679],\n",
      "        [ 30.9679],\n",
      "        [  4.1504],\n",
      "        [156.1590],\n",
      "        [  4.1504],\n",
      "        [ 84.2471],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [103.1486],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [125.9530],\n",
      "        [166.1979],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [150.6383],\n",
      "        [  4.1504],\n",
      "        [252.2346]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[189.3082],\n",
      "        [  4.1504],\n",
      "        [ 89.8438],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  6.8659],\n",
      "        [  3.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  0.8496],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 29.2365],\n",
      "        [  0.6098],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  8.8496],\n",
      "        [  4.1504],\n",
      "        [206.0499],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  5.8496],\n",
      "        [  2.1504],\n",
      "        [ 29.2365],\n",
      "        [  0.6504],\n",
      "        [  0.3296],\n",
      "        [  0.3496],\n",
      "        [  2.5496],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  5.8496],\n",
      "        [  4.1504],\n",
      "        [  6.3496],\n",
      "        [ 78.7146],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 20.9296],\n",
      "        [  4.1504],\n",
      "        [  2.0204],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 28.4496],\n",
      "        [ 28.8496],\n",
      "        [ 29.8496],\n",
      "        [ 30.8496],\n",
      "        [ 33.8496],\n",
      "        [  4.1504],\n",
      "        [ 23.3319],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [ 15.5815],\n",
      "        [  4.1504],\n",
      "        [ 37.3496],\n",
      "        [ 22.2078],\n",
      "        [  4.4081],\n",
      "        [ 22.9843],\n",
      "        [  8.1491],\n",
      "        [  4.1504],\n",
      "        [  8.0078],\n",
      "        [ 12.3507],\n",
      "        [ 14.3344],\n",
      "        [ 39.8496],\n",
      "        [ 46.8496],\n",
      "        [ 50.8496],\n",
      "        [ 50.8496],\n",
      "        [ 62.5919],\n",
      "        [  4.1504],\n",
      "        [  4.1504],\n",
      "        [  6.5761],\n",
      "        [  6.5761],\n",
      "        [ 29.0053],\n",
      "        [  1.4321],\n",
      "        [ 60.3496],\n",
      "        [ 70.3861],\n",
      "        [ 82.5011],\n",
      "        [ 66.8496],\n",
      "        [ 75.0496],\n",
      "        [ 64.2702],\n",
      "        [ 72.7934],\n",
      "        [ 81.4496],\n",
      "        [ 82.8496],\n",
      "        [  8.6679],\n",
      "        [  8.6679],\n",
      "        [ 88.3496],\n",
      "        [ 49.8410],\n",
      "        [  4.1504],\n",
      "        [ 69.7529],\n",
      "        [ 93.8496],\n",
      "        [100.8496],\n",
      "        [100.8496],\n",
      "        [103.1486],\n",
      "        [109.3496],\n",
      "        [116.2796],\n",
      "        [134.8496],\n",
      "        [148.5196],\n",
      "        [148.5196],\n",
      "        [171.3496],\n",
      "        [175.8496],\n",
      "        [125.9530],\n",
      "        [166.1979],\n",
      "        [185.8496],\n",
      "        [190.8496],\n",
      "        [195.8496],\n",
      "        [223.8496],\n",
      "        [198.3617],\n",
      "        [233.8496],\n",
      "        [252.2346]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4402.2402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 25\n",
      "Number of shrink: 0\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  189.5828],\n",
      "        [    4.1522],\n",
      "        [   88.8539],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    6.6266],\n",
      "        [    3.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    0.8478],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [   30.0697],\n",
      "        [    0.3293],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    8.8478],\n",
      "        [    4.1522],\n",
      "        [  205.6682],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    5.8478],\n",
      "        [    2.1522],\n",
      "        [   30.0697],\n",
      "        [    0.6522],\n",
      "        [    0.3278],\n",
      "        [    0.3478],\n",
      "        [    2.5478],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    5.8478],\n",
      "        [    4.1522],\n",
      "        [    6.3478],\n",
      "        [   78.8301],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [   20.9278],\n",
      "        [    4.1522],\n",
      "        [    2.2457],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [   28.4478],\n",
      "        [   28.8478],\n",
      "        [   29.8478],\n",
      "        [   30.8478],\n",
      "        [   33.8478],\n",
      "        [    4.1522],\n",
      "        [   23.3265],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [   15.3264],\n",
      "        [    4.1522],\n",
      "        [   37.3478],\n",
      "        [   22.3200],\n",
      "        [    4.3709],\n",
      "        [   22.8838],\n",
      "        [    8.0576],\n",
      "        [    4.1522],\n",
      "        [    8.0700],\n",
      "        [   12.2852],\n",
      "        [   14.2564],\n",
      "        [   39.8478],\n",
      "        [   46.8478],\n",
      "        [   50.8478],\n",
      "        [   50.8478],\n",
      "        [   63.7721],\n",
      "        [    4.1522],\n",
      "        [    4.1522],\n",
      "        [    7.8942],\n",
      "        [    7.8942],\n",
      "        [   29.4359],\n",
      "        [    0.1522],\n",
      "        [   60.3478],\n",
      "        [   72.4428],\n",
      "        [   83.3982],\n",
      "        [   66.8478],\n",
      "        [   75.0478],\n",
      "        [   64.3733],\n",
      "        [   72.5317],\n",
      "        [   81.4478],\n",
      "        [   82.8478],\n",
      "        [    8.5979],\n",
      "        [    8.5979],\n",
      "        [   88.3478],\n",
      "        [   50.2202],\n",
      "        [    4.1522],\n",
      "        [   69.8545],\n",
      "        [   93.8478],\n",
      "        [  100.8478],\n",
      "        [  100.8478],\n",
      "        [  103.1494],\n",
      "        [  109.3478],\n",
      "        [  116.2778],\n",
      "        [  134.8478],\n",
      "        [  148.5178],\n",
      "        [  148.5178],\n",
      "        [  171.3478],\n",
      "        [  175.8478],\n",
      "        [  125.0982],\n",
      "        [  165.7612],\n",
      "        [  185.8478],\n",
      "        [  190.8478],\n",
      "        [  195.8478],\n",
      "        [  223.8478],\n",
      "        [  197.9532],\n",
      "        [  233.8478],\n",
      "        [  249.9121]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  182.7967],\n",
      "        [    4.3271],\n",
      "        [   83.0929],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    6.6034],\n",
      "        [    3.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    0.6729],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [   69.2581],\n",
      "        [    1.5462],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    8.6729],\n",
      "        [    4.3271],\n",
      "        [  208.9451],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    5.6729],\n",
      "        [    2.3271],\n",
      "        [   69.2581],\n",
      "        [    0.8271],\n",
      "        [    0.1529],\n",
      "        [    0.1729],\n",
      "        [    2.3729],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    5.6729],\n",
      "        [    4.3271],\n",
      "        [    6.1729],\n",
      "        [   73.9033],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [   20.7529],\n",
      "        [    4.3271],\n",
      "        [    2.9069],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [   28.2729],\n",
      "        [   28.6729],\n",
      "        [   29.6729],\n",
      "        [   30.6729],\n",
      "        [   33.6729],\n",
      "        [    4.3271],\n",
      "        [   24.4249],\n",
      "        [    4.3271],\n",
      "        [    9.8692],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    9.4085],\n",
      "        [    4.3271],\n",
      "        [   37.1729],\n",
      "        [   16.9838],\n",
      "        [   11.2312],\n",
      "        [   28.4210],\n",
      "        [   12.0791],\n",
      "        [    4.3271],\n",
      "        [   10.8066],\n",
      "        [   15.6745],\n",
      "        [   18.0300],\n",
      "        [   39.6729],\n",
      "        [   46.6729],\n",
      "        [   50.6729],\n",
      "        [   50.6729],\n",
      "        [  125.6524],\n",
      "        [    4.3271],\n",
      "        [    6.8661],\n",
      "        [   12.0394],\n",
      "        [   12.0394],\n",
      "        [    1.1297],\n",
      "        [    0.3271],\n",
      "        [   60.1729],\n",
      "        [   79.4073],\n",
      "        [  122.8845],\n",
      "        [   66.6729],\n",
      "        [   74.8729],\n",
      "        [   78.1164],\n",
      "        [   54.8517],\n",
      "        [   81.2729],\n",
      "        [   82.6729],\n",
      "        [   10.4382],\n",
      "        [   10.4382],\n",
      "        [   88.1729],\n",
      "        [   49.2061],\n",
      "        [    4.3271],\n",
      "        [   85.8071],\n",
      "        [   93.6729],\n",
      "        [  100.6729],\n",
      "        [  100.6729],\n",
      "        [  105.4940],\n",
      "        [  109.1729],\n",
      "        [  116.1029],\n",
      "        [  134.6729],\n",
      "        [  148.3429],\n",
      "        [  148.3429],\n",
      "        [  171.1729],\n",
      "        [  175.6729],\n",
      "        [   83.8668],\n",
      "        [  156.4162],\n",
      "        [  185.6729],\n",
      "        [  190.6729],\n",
      "        [  195.6729],\n",
      "        [  223.6729],\n",
      "        [  192.5223],\n",
      "        [  233.6729],\n",
      "        [  127.1435]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 33.84480547904968\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 159\n",
      "剩餘X 資料 torch.Size([44, 10])\n",
      "剩餘Y 資料 torch.Size([44, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (42255.421875, 7)\n",
      "The second_loss value of k: (63872.9296875, 37)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引7，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([167, 1])\n",
      "<<預測值>>\n",
      "tensor([[135.2033],\n",
      "        [  4.3271],\n",
      "        [242.6771],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [ 22.8634],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [156.7419],\n",
      "        [ 88.9362],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [208.9451],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [156.7419],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [ 25.0967],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [ 63.5931],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [ 24.4249],\n",
      "        [  4.3271],\n",
      "        [  9.8692],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  9.4085],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [ 50.0162],\n",
      "        [ 11.2312],\n",
      "        [134.6210],\n",
      "        [ 12.0791],\n",
      "        [  4.3271],\n",
      "        [ 10.8066],\n",
      "        [ 15.6745],\n",
      "        [ 18.0300],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [ 23.3476],\n",
      "        [  4.3271],\n",
      "        [  6.8661],\n",
      "        [ 12.0394],\n",
      "        [ 12.0394],\n",
      "        [ 24.6297],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [ 79.4073],\n",
      "        [113.1155],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [ 78.1164],\n",
      "        [ 54.8517],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [ 32.7382],\n",
      "        [ 32.7382],\n",
      "        [  4.3271],\n",
      "        [156.7939],\n",
      "        [  4.3271],\n",
      "        [ 68.1929],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [105.4940],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [ 83.8668],\n",
      "        [156.4162],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [  4.3271],\n",
      "        [156.4777],\n",
      "        [  4.3271],\n",
      "        [127.1435],\n",
      "        [205.5612]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  182.7967],\n",
      "        [    4.3271],\n",
      "        [   83.0929],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    6.6034],\n",
      "        [    3.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    0.6729],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [   69.2581],\n",
      "        [    1.5462],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    8.6729],\n",
      "        [    4.3271],\n",
      "        [  208.9451],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    5.6729],\n",
      "        [    2.3271],\n",
      "        [   69.2581],\n",
      "        [    0.8271],\n",
      "        [    0.1529],\n",
      "        [    0.1729],\n",
      "        [    2.3729],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    5.6729],\n",
      "        [    4.3271],\n",
      "        [    6.1729],\n",
      "        [   73.9033],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [   20.7529],\n",
      "        [    4.3271],\n",
      "        [    2.9069],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [   28.2729],\n",
      "        [   28.6729],\n",
      "        [   29.6729],\n",
      "        [   30.6729],\n",
      "        [   33.6729],\n",
      "        [    4.3271],\n",
      "        [   24.4249],\n",
      "        [    4.3271],\n",
      "        [    9.8692],\n",
      "        [    4.3271],\n",
      "        [    4.3271],\n",
      "        [    9.4085],\n",
      "        [    4.3271],\n",
      "        [   37.1729],\n",
      "        [   16.9838],\n",
      "        [   11.2312],\n",
      "        [   28.4210],\n",
      "        [   12.0791],\n",
      "        [    4.3271],\n",
      "        [   10.8066],\n",
      "        [   15.6745],\n",
      "        [   18.0300],\n",
      "        [   39.6729],\n",
      "        [   46.6729],\n",
      "        [   50.6729],\n",
      "        [   50.6729],\n",
      "        [  125.6524],\n",
      "        [    4.3271],\n",
      "        [    6.8661],\n",
      "        [   12.0394],\n",
      "        [   12.0394],\n",
      "        [    1.1297],\n",
      "        [    0.3271],\n",
      "        [   60.1729],\n",
      "        [   79.4073],\n",
      "        [  122.8845],\n",
      "        [   66.6729],\n",
      "        [   74.8729],\n",
      "        [   78.1164],\n",
      "        [   54.8517],\n",
      "        [   81.2729],\n",
      "        [   82.6729],\n",
      "        [   10.4382],\n",
      "        [   10.4382],\n",
      "        [   88.1729],\n",
      "        [   49.2061],\n",
      "        [    4.3271],\n",
      "        [   85.8071],\n",
      "        [   93.6729],\n",
      "        [  100.6729],\n",
      "        [  100.6729],\n",
      "        [  105.4940],\n",
      "        [  109.1729],\n",
      "        [  116.1029],\n",
      "        [  134.6729],\n",
      "        [  148.3429],\n",
      "        [  148.3429],\n",
      "        [  171.1729],\n",
      "        [  175.6729],\n",
      "        [   83.8668],\n",
      "        [  156.4162],\n",
      "        [  185.6729],\n",
      "        [  190.6729],\n",
      "        [  195.6729],\n",
      "        [  223.6729],\n",
      "        [  192.5223],\n",
      "        [  233.6729],\n",
      "        [  127.1435],\n",
      "        [  205.5612]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4426.0181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  179.6519],\n",
      "        [    4.4933],\n",
      "        [   82.3431],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    5.8781],\n",
      "        [    3.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    0.5067],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [  104.9715],\n",
      "        [    2.9291],\n",
      "        [   19.2799],\n",
      "        [    4.4933],\n",
      "        [    8.5067],\n",
      "        [    4.4933],\n",
      "        [  207.6715],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    5.5067],\n",
      "        [    2.4933],\n",
      "        [  104.9715],\n",
      "        [    0.9933],\n",
      "        [    0.0133],\n",
      "        [    0.0067],\n",
      "        [    2.2067],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    5.5067],\n",
      "        [    4.4933],\n",
      "        [    6.0067],\n",
      "        [   67.3457],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [   20.5867],\n",
      "        [    4.4933],\n",
      "        [   27.8350],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [   28.1067],\n",
      "        [   28.5067],\n",
      "        [   29.5067],\n",
      "        [   30.5067],\n",
      "        [   33.5067],\n",
      "        [    4.4933],\n",
      "        [   21.4355],\n",
      "        [    4.4933],\n",
      "        [   15.7881],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    5.5276],\n",
      "        [    6.7903],\n",
      "        [   37.0067],\n",
      "        [   10.7348],\n",
      "        [   19.0941],\n",
      "        [   27.6785],\n",
      "        [   17.5699],\n",
      "        [    9.4916],\n",
      "        [   14.3723],\n",
      "        [   19.8928],\n",
      "        [   22.8332],\n",
      "        [   39.5067],\n",
      "        [   46.5067],\n",
      "        [   50.5067],\n",
      "        [   50.5067],\n",
      "        [  117.0884],\n",
      "        [    4.4933],\n",
      "        [    4.7709],\n",
      "        [   21.8315],\n",
      "        [   21.8315],\n",
      "        [   22.5100],\n",
      "        [    0.4933],\n",
      "        [   60.0067],\n",
      "        [   91.4236],\n",
      "        [  161.5900],\n",
      "        [   66.5067],\n",
      "        [   57.1059],\n",
      "        [   81.2665],\n",
      "        [   57.0676],\n",
      "        [   81.1067],\n",
      "        [   82.5067],\n",
      "        [   15.5898],\n",
      "        [   15.5898],\n",
      "        [   88.0067],\n",
      "        [   52.4767],\n",
      "        [    4.4933],\n",
      "        [   99.8741],\n",
      "        [   93.5067],\n",
      "        [  100.5067],\n",
      "        [  100.5067],\n",
      "        [  100.6853],\n",
      "        [  109.0067],\n",
      "        [  115.9367],\n",
      "        [  134.5067],\n",
      "        [  148.1767],\n",
      "        [  148.1767],\n",
      "        [  171.0067],\n",
      "        [  175.5067],\n",
      "        [   44.3029],\n",
      "        [  146.0509],\n",
      "        [  185.5067],\n",
      "        [  190.5067],\n",
      "        [  195.5067],\n",
      "        [  223.5067],\n",
      "        [  192.7285],\n",
      "        [  233.5067],\n",
      "        [   82.2458],\n",
      "        [  137.2221]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 34.10211801528931\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 160\n",
      "剩餘X 資料 torch.Size([43, 10])\n",
      "剩餘Y 資料 torch.Size([43, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (45915.67578125, 36)\n",
      "The second_loss value of k: (47152.3515625, 27)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引36，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([168, 1])\n",
      "<<預測值>>\n",
      "tensor([[138.3481],\n",
      "        [  4.4933],\n",
      "        [243.4269],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [ 22.1381],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [121.0285],\n",
      "        [ 84.4609],\n",
      "        [ 19.2799],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [207.6715],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [121.0285],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [ 31.6543],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [ 38.6650],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [ 21.4355],\n",
      "        [  4.4933],\n",
      "        [ 15.7881],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  5.5276],\n",
      "        [  6.7903],\n",
      "        [  4.4933],\n",
      "        [ 56.2652],\n",
      "        [ 19.0941],\n",
      "        [133.8785],\n",
      "        [ 17.5699],\n",
      "        [  9.4916],\n",
      "        [ 14.3723],\n",
      "        [ 19.8928],\n",
      "        [ 22.8332],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [ 31.9116],\n",
      "        [  4.4933],\n",
      "        [  4.7709],\n",
      "        [ 21.8315],\n",
      "        [ 21.8315],\n",
      "        [ 46.0100],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [ 91.4236],\n",
      "        [ 74.4100],\n",
      "        [  4.4933],\n",
      "        [ 22.0941],\n",
      "        [ 81.2665],\n",
      "        [ 57.0676],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [ 37.8898],\n",
      "        [ 37.8898],\n",
      "        [  4.4933],\n",
      "        [153.5233],\n",
      "        [  4.4933],\n",
      "        [ 54.1259],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [100.6853],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [ 44.3029],\n",
      "        [146.0509],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [  4.4933],\n",
      "        [156.2715],\n",
      "        [  4.4933],\n",
      "        [ 82.2458],\n",
      "        [137.2221],\n",
      "        [214.2794]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  179.6519],\n",
      "        [    4.4933],\n",
      "        [   82.3431],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    5.8781],\n",
      "        [    3.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    0.5067],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [  104.9715],\n",
      "        [    2.9291],\n",
      "        [   19.2799],\n",
      "        [    4.4933],\n",
      "        [    8.5067],\n",
      "        [    4.4933],\n",
      "        [  207.6715],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    5.5067],\n",
      "        [    2.4933],\n",
      "        [  104.9715],\n",
      "        [    0.9933],\n",
      "        [    0.0133],\n",
      "        [    0.0067],\n",
      "        [    2.2067],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    5.5067],\n",
      "        [    4.4933],\n",
      "        [    6.0067],\n",
      "        [   67.3457],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [   20.5867],\n",
      "        [    4.4933],\n",
      "        [   27.8350],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [   28.1067],\n",
      "        [   28.5067],\n",
      "        [   29.5067],\n",
      "        [   30.5067],\n",
      "        [   33.5067],\n",
      "        [    4.4933],\n",
      "        [   21.4355],\n",
      "        [    4.4933],\n",
      "        [   15.7881],\n",
      "        [    4.4933],\n",
      "        [    4.4933],\n",
      "        [    5.5276],\n",
      "        [    6.7903],\n",
      "        [   37.0067],\n",
      "        [   10.7348],\n",
      "        [   19.0941],\n",
      "        [   27.6785],\n",
      "        [   17.5699],\n",
      "        [    9.4916],\n",
      "        [   14.3723],\n",
      "        [   19.8928],\n",
      "        [   22.8332],\n",
      "        [   39.5067],\n",
      "        [   46.5067],\n",
      "        [   50.5067],\n",
      "        [   50.5067],\n",
      "        [  117.0884],\n",
      "        [    4.4933],\n",
      "        [    4.7709],\n",
      "        [   21.8315],\n",
      "        [   21.8315],\n",
      "        [   22.5100],\n",
      "        [    0.4933],\n",
      "        [   60.0067],\n",
      "        [   91.4236],\n",
      "        [  161.5900],\n",
      "        [   66.5067],\n",
      "        [   57.1059],\n",
      "        [   81.2665],\n",
      "        [   57.0676],\n",
      "        [   81.1067],\n",
      "        [   82.5067],\n",
      "        [   15.5898],\n",
      "        [   15.5898],\n",
      "        [   88.0067],\n",
      "        [   52.4767],\n",
      "        [    4.4933],\n",
      "        [   99.8741],\n",
      "        [   93.5067],\n",
      "        [  100.5067],\n",
      "        [  100.5067],\n",
      "        [  100.6853],\n",
      "        [  109.0067],\n",
      "        [  115.9367],\n",
      "        [  134.5067],\n",
      "        [  148.1767],\n",
      "        [  148.1767],\n",
      "        [  171.0067],\n",
      "        [  175.5067],\n",
      "        [   44.3029],\n",
      "        [  146.0509],\n",
      "        [  185.5067],\n",
      "        [  190.5067],\n",
      "        [  195.5067],\n",
      "        [  223.5067],\n",
      "        [  192.7285],\n",
      "        [  233.5067],\n",
      "        [   82.2458],\n",
      "        [  137.2221],\n",
      "        [  214.2794]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4568.2354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  180.0497],\n",
      "        [    4.6497],\n",
      "        [   88.5330],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [   11.6233],\n",
      "        [    3.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    0.3503],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [  124.3761],\n",
      "        [   16.6827],\n",
      "        [   28.0513],\n",
      "        [    4.6497],\n",
      "        [    8.3503],\n",
      "        [    4.6497],\n",
      "        [  201.8100],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    9.5103],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    5.3503],\n",
      "        [    2.6497],\n",
      "        [  124.3761],\n",
      "        [    1.1497],\n",
      "        [    0.1697],\n",
      "        [    0.1497],\n",
      "        [    2.0503],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    5.3503],\n",
      "        [    4.6497],\n",
      "        [    5.8503],\n",
      "        [   67.2300],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [   20.4303],\n",
      "        [    4.6497],\n",
      "        [   35.8672],\n",
      "        [    8.4381],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [   27.9503],\n",
      "        [   28.3503],\n",
      "        [   29.3503],\n",
      "        [   30.3503],\n",
      "        [   33.3503],\n",
      "        [    4.6497],\n",
      "        [   26.1152],\n",
      "        [    4.6497],\n",
      "        [   16.9572],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    7.9861],\n",
      "        [   36.8503],\n",
      "        [   13.1517],\n",
      "        [   18.8317],\n",
      "        [   28.0262],\n",
      "        [   18.1352],\n",
      "        [   10.3248],\n",
      "        [   13.4288],\n",
      "        [   19.2194],\n",
      "        [   22.3570],\n",
      "        [   39.3503],\n",
      "        [   46.3503],\n",
      "        [   50.3503],\n",
      "        [   50.3503],\n",
      "        [  108.8563],\n",
      "        [    4.6497],\n",
      "        [   15.1839],\n",
      "        [   22.2797],\n",
      "        [   22.2797],\n",
      "        [   38.9270],\n",
      "        [    5.9954],\n",
      "        [   59.8503],\n",
      "        [   94.1642],\n",
      "        [  180.2311],\n",
      "        [   66.3503],\n",
      "        [   49.9284],\n",
      "        [   81.2460],\n",
      "        [   66.1408],\n",
      "        [   80.9503],\n",
      "        [   82.3503],\n",
      "        [   18.3727],\n",
      "        [   18.3727],\n",
      "        [   87.8503],\n",
      "        [   54.9049],\n",
      "        [    4.6497],\n",
      "        [  106.9670],\n",
      "        [   93.3503],\n",
      "        [  100.3503],\n",
      "        [  100.3503],\n",
      "        [   99.2409],\n",
      "        [  108.8503],\n",
      "        [  115.7803],\n",
      "        [  134.3503],\n",
      "        [  148.0203],\n",
      "        [  148.0203],\n",
      "        [  170.8503],\n",
      "        [  175.3503],\n",
      "        [   27.6378],\n",
      "        [  131.4668],\n",
      "        [  185.3503],\n",
      "        [  190.3503],\n",
      "        [  195.3503],\n",
      "        [  223.3503],\n",
      "        [  196.2250],\n",
      "        [  233.3503],\n",
      "        [   68.8653],\n",
      "        [  104.1317],\n",
      "        [  183.7997]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 34.36617588996887\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 161\n",
      "剩餘X 資料 torch.Size([42, 10])\n",
      "剩餘Y 資料 torch.Size([42, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (31149.79296875, 41)\n",
      "The second_loss value of k: (31610.208984375, 32)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引41，y= tensor([177.])\n",
      "目前模型的Data狀態 torch.Size([169, 1])\n",
      "<<預測值>>\n",
      "tensor([[137.9503],\n",
      "        [  4.6497],\n",
      "        [237.2370],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [ 27.8833],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [101.6239],\n",
      "        [ 70.7073],\n",
      "        [ 28.0513],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [201.8100],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  9.5103],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [101.6239],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [ 31.7700],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [ 30.6328],\n",
      "        [  8.4381],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [ 26.1152],\n",
      "        [  4.6497],\n",
      "        [ 16.9572],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  7.9861],\n",
      "        [  4.6497],\n",
      "        [ 53.8483],\n",
      "        [ 18.8317],\n",
      "        [134.2262],\n",
      "        [ 18.1352],\n",
      "        [ 10.3248],\n",
      "        [ 13.4288],\n",
      "        [ 19.2194],\n",
      "        [ 22.3570],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [ 40.1437],\n",
      "        [  4.6497],\n",
      "        [ 15.1839],\n",
      "        [ 22.2797],\n",
      "        [ 22.2797],\n",
      "        [ 62.4270],\n",
      "        [  9.9954],\n",
      "        [  4.6497],\n",
      "        [ 94.1642],\n",
      "        [ 55.7689],\n",
      "        [  4.6497],\n",
      "        [ 29.2716],\n",
      "        [ 81.2460],\n",
      "        [ 66.1408],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [ 40.6727],\n",
      "        [ 40.6727],\n",
      "        [  4.6497],\n",
      "        [151.0951],\n",
      "        [  4.6497],\n",
      "        [ 47.0330],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [ 99.2409],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [ 27.6378],\n",
      "        [131.4668],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [  4.6497],\n",
      "        [152.7750],\n",
      "        [  4.6497],\n",
      "        [ 68.8653],\n",
      "        [104.1317],\n",
      "        [183.7997],\n",
      "        [353.4930]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  180.0497],\n",
      "        [    4.6497],\n",
      "        [   88.5330],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [   11.6233],\n",
      "        [    3.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    0.3503],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [  124.3761],\n",
      "        [   16.6827],\n",
      "        [   28.0513],\n",
      "        [    4.6497],\n",
      "        [    8.3503],\n",
      "        [    4.6497],\n",
      "        [  201.8100],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    9.5103],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    5.3503],\n",
      "        [    2.6497],\n",
      "        [  124.3761],\n",
      "        [    1.1497],\n",
      "        [    0.1697],\n",
      "        [    0.1497],\n",
      "        [    2.0503],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    5.3503],\n",
      "        [    4.6497],\n",
      "        [    5.8503],\n",
      "        [   67.2300],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [   20.4303],\n",
      "        [    4.6497],\n",
      "        [   35.8672],\n",
      "        [    8.4381],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [   27.9503],\n",
      "        [   28.3503],\n",
      "        [   29.3503],\n",
      "        [   30.3503],\n",
      "        [   33.3503],\n",
      "        [    4.6497],\n",
      "        [   26.1152],\n",
      "        [    4.6497],\n",
      "        [   16.9572],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    4.6497],\n",
      "        [    7.9861],\n",
      "        [   36.8503],\n",
      "        [   13.1517],\n",
      "        [   18.8317],\n",
      "        [   28.0262],\n",
      "        [   18.1352],\n",
      "        [   10.3248],\n",
      "        [   13.4288],\n",
      "        [   19.2194],\n",
      "        [   22.3570],\n",
      "        [   39.3503],\n",
      "        [   46.3503],\n",
      "        [   50.3503],\n",
      "        [   50.3503],\n",
      "        [  108.8563],\n",
      "        [    4.6497],\n",
      "        [   15.1839],\n",
      "        [   22.2797],\n",
      "        [   22.2797],\n",
      "        [   38.9270],\n",
      "        [    5.9954],\n",
      "        [   59.8503],\n",
      "        [   94.1642],\n",
      "        [  180.2311],\n",
      "        [   66.3503],\n",
      "        [   49.9284],\n",
      "        [   81.2460],\n",
      "        [   66.1408],\n",
      "        [   80.9503],\n",
      "        [   82.3503],\n",
      "        [   18.3727],\n",
      "        [   18.3727],\n",
      "        [   87.8503],\n",
      "        [   54.9049],\n",
      "        [    4.6497],\n",
      "        [  106.9670],\n",
      "        [   93.3503],\n",
      "        [  100.3503],\n",
      "        [  100.3503],\n",
      "        [   99.2409],\n",
      "        [  108.8503],\n",
      "        [  115.7803],\n",
      "        [  134.3503],\n",
      "        [  148.0203],\n",
      "        [  148.0203],\n",
      "        [  170.8503],\n",
      "        [  175.3503],\n",
      "        [   27.6378],\n",
      "        [  131.4668],\n",
      "        [  185.3503],\n",
      "        [  190.3503],\n",
      "        [  195.3503],\n",
      "        [  223.3503],\n",
      "        [  196.2250],\n",
      "        [  233.3503],\n",
      "        [   68.8653],\n",
      "        [  104.1317],\n",
      "        [  183.7997],\n",
      "        [  176.4930]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4671.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 80\n",
      "Number of shrink: 20\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  204.9020],\n",
      "        [    5.0268],\n",
      "        [  114.0727],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    7.0891],\n",
      "        [    4.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    0.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [  136.3291],\n",
      "        [   24.0862],\n",
      "        [   17.7007],\n",
      "        [    5.0268],\n",
      "        [    7.9732],\n",
      "        [   15.5856],\n",
      "        [  160.1617],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    6.1261],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    4.9732],\n",
      "        [    3.0268],\n",
      "        [  136.3291],\n",
      "        [    1.5268],\n",
      "        [    0.5468],\n",
      "        [    0.5268],\n",
      "        [    1.6732],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    4.9732],\n",
      "        [    5.0268],\n",
      "        [    5.4732],\n",
      "        [   59.5316],\n",
      "        [    8.5295],\n",
      "        [    6.3850],\n",
      "        [   20.0532],\n",
      "        [    8.1179],\n",
      "        [   45.0089],\n",
      "        [   16.2832],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [   27.5732],\n",
      "        [   27.9732],\n",
      "        [   28.9732],\n",
      "        [   29.9732],\n",
      "        [   32.9732],\n",
      "        [    5.2609],\n",
      "        [   33.5913],\n",
      "        [    5.0268],\n",
      "        [   21.3246],\n",
      "        [   13.4602],\n",
      "        [   17.5599],\n",
      "        [   12.1875],\n",
      "        [   16.4639],\n",
      "        [   36.4732],\n",
      "        [   11.1002],\n",
      "        [   23.7676],\n",
      "        [   28.0493],\n",
      "        [   25.7919],\n",
      "        [   17.1829],\n",
      "        [   15.1105],\n",
      "        [   23.0697],\n",
      "        [   27.1694],\n",
      "        [   38.9732],\n",
      "        [   45.9732],\n",
      "        [   49.9732],\n",
      "        [   49.9732],\n",
      "        [  114.2154],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [   20.1313],\n",
      "        [   20.1313],\n",
      "        [   33.2506],\n",
      "        [    9.8677],\n",
      "        [   59.4732],\n",
      "        [   91.0565],\n",
      "        [  191.0893],\n",
      "        [   65.9732],\n",
      "        [   43.1499],\n",
      "        [   81.7906],\n",
      "        [   55.4724],\n",
      "        [   80.5732],\n",
      "        [   81.9732],\n",
      "        [   11.8760],\n",
      "        [   11.8760],\n",
      "        [   87.4732],\n",
      "        [   90.5547],\n",
      "        [    5.0268],\n",
      "        [  124.4854],\n",
      "        [   92.9732],\n",
      "        [   99.9732],\n",
      "        [   99.9732],\n",
      "        [   91.8265],\n",
      "        [  108.4732],\n",
      "        [  115.4032],\n",
      "        [  133.9732],\n",
      "        [  147.6432],\n",
      "        [  147.6432],\n",
      "        [  170.4732],\n",
      "        [  174.9732],\n",
      "        [   22.4040],\n",
      "        [  117.0488],\n",
      "        [  184.9732],\n",
      "        [  189.9732],\n",
      "        [  194.9732],\n",
      "        [  222.9732],\n",
      "        [  208.2400],\n",
      "        [  232.9732],\n",
      "        [   48.7484],\n",
      "        [   84.2865],\n",
      "        [  153.9083],\n",
      "        [   81.9756]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 34.64293193817139\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 162\n",
      "剩餘X 資料 torch.Size([41, 10])\n",
      "剩餘Y 資料 torch.Size([41, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (17269.861328125, 32)\n",
      "The second_loss value of k: (18680.015625, 27)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引32，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([170, 1])\n",
      "<<預測值>>\n",
      "tensor([[113.0980],\n",
      "        [  5.0268],\n",
      "        [211.6973],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [ 23.3491],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [ 89.6709],\n",
      "        [ 63.3038],\n",
      "        [ 17.7007],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [ 15.5856],\n",
      "        [160.1617],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  6.1261],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [ 89.6709],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [ 39.4684],\n",
      "        [  8.5295],\n",
      "        [  6.3850],\n",
      "        [  5.0268],\n",
      "        [  8.1179],\n",
      "        [ 21.4911],\n",
      "        [ 16.2832],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.2609],\n",
      "        [ 33.5913],\n",
      "        [  5.0268],\n",
      "        [ 21.3246],\n",
      "        [ 13.4602],\n",
      "        [ 17.5599],\n",
      "        [ 12.1875],\n",
      "        [ 16.4639],\n",
      "        [  5.0268],\n",
      "        [ 55.8998],\n",
      "        [ 23.7676],\n",
      "        [134.2493],\n",
      "        [ 25.7919],\n",
      "        [ 17.1829],\n",
      "        [ 15.1105],\n",
      "        [ 23.0697],\n",
      "        [ 27.1694],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [ 34.7846],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [ 20.1313],\n",
      "        [ 20.1313],\n",
      "        [ 56.7506],\n",
      "        [ 13.8677],\n",
      "        [  5.0268],\n",
      "        [ 91.0565],\n",
      "        [ 44.9107],\n",
      "        [  5.0268],\n",
      "        [ 36.0501],\n",
      "        [ 81.7906],\n",
      "        [ 55.4724],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [ 34.1760],\n",
      "        [ 34.1760],\n",
      "        [  5.0268],\n",
      "        [115.4453],\n",
      "        [  5.0268],\n",
      "        [ 29.5146],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [ 91.8265],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [ 22.4040],\n",
      "        [117.0488],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [  5.0268],\n",
      "        [140.7600],\n",
      "        [  5.0268],\n",
      "        [ 48.7484],\n",
      "        [ 84.2865],\n",
      "        [153.9083],\n",
      "        [258.9756],\n",
      "        [131.4148]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  204.9020],\n",
      "        [    5.0268],\n",
      "        [  114.0727],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    7.0891],\n",
      "        [    4.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    0.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [  136.3291],\n",
      "        [   24.0862],\n",
      "        [   17.7007],\n",
      "        [    5.0268],\n",
      "        [    7.9732],\n",
      "        [   15.5856],\n",
      "        [  160.1617],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    6.1261],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    4.9732],\n",
      "        [    3.0268],\n",
      "        [  136.3291],\n",
      "        [    1.5268],\n",
      "        [    0.5468],\n",
      "        [    0.5268],\n",
      "        [    1.6732],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [    4.9732],\n",
      "        [    5.0268],\n",
      "        [    5.4732],\n",
      "        [   59.5316],\n",
      "        [    8.5295],\n",
      "        [    6.3850],\n",
      "        [   20.0532],\n",
      "        [    8.1179],\n",
      "        [   45.0089],\n",
      "        [   16.2832],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [   27.5732],\n",
      "        [   27.9732],\n",
      "        [   28.9732],\n",
      "        [   29.9732],\n",
      "        [   32.9732],\n",
      "        [    5.2609],\n",
      "        [   33.5913],\n",
      "        [    5.0268],\n",
      "        [   21.3246],\n",
      "        [   13.4602],\n",
      "        [   17.5599],\n",
      "        [   12.1875],\n",
      "        [   16.4639],\n",
      "        [   36.4732],\n",
      "        [   11.1002],\n",
      "        [   23.7676],\n",
      "        [   28.0493],\n",
      "        [   25.7919],\n",
      "        [   17.1829],\n",
      "        [   15.1105],\n",
      "        [   23.0697],\n",
      "        [   27.1694],\n",
      "        [   38.9732],\n",
      "        [   45.9732],\n",
      "        [   49.9732],\n",
      "        [   49.9732],\n",
      "        [  114.2154],\n",
      "        [    5.0268],\n",
      "        [    5.0268],\n",
      "        [   20.1313],\n",
      "        [   20.1313],\n",
      "        [   33.2506],\n",
      "        [    9.8677],\n",
      "        [   59.4732],\n",
      "        [   91.0565],\n",
      "        [  191.0893],\n",
      "        [   65.9732],\n",
      "        [   43.1499],\n",
      "        [   81.7906],\n",
      "        [   55.4724],\n",
      "        [   80.5732],\n",
      "        [   81.9732],\n",
      "        [   11.8760],\n",
      "        [   11.8760],\n",
      "        [   87.4732],\n",
      "        [   90.5547],\n",
      "        [    5.0268],\n",
      "        [  124.4854],\n",
      "        [   92.9732],\n",
      "        [   99.9732],\n",
      "        [   99.9732],\n",
      "        [   91.8265],\n",
      "        [  108.4732],\n",
      "        [  115.4032],\n",
      "        [  133.9732],\n",
      "        [  147.6432],\n",
      "        [  147.6432],\n",
      "        [  170.4732],\n",
      "        [  174.9732],\n",
      "        [   22.4040],\n",
      "        [  117.0488],\n",
      "        [  184.9732],\n",
      "        [  189.9732],\n",
      "        [  194.9732],\n",
      "        [  222.9732],\n",
      "        [  208.2400],\n",
      "        [  232.9732],\n",
      "        [   48.7484],\n",
      "        [   84.2865],\n",
      "        [  153.9083],\n",
      "        [   81.9756],\n",
      "        [  131.4148]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4605.4097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 82\n",
      "Number of shrink: 18\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[212.8276],\n",
      "        [  5.4389],\n",
      "        [ 87.0833],\n",
      "        [  5.4389],\n",
      "        [ 98.5112],\n",
      "        [ 11.7717],\n",
      "        [  4.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  0.4389],\n",
      "        [  5.4389],\n",
      "        [ 34.7606],\n",
      "        [158.4293],\n",
      "        [  6.8168],\n",
      "        [ 17.4126],\n",
      "        [  5.4389],\n",
      "        [  7.5611],\n",
      "        [ 28.4278],\n",
      "        [156.5593],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  4.5611],\n",
      "        [  7.2197],\n",
      "        [158.4293],\n",
      "        [  1.9389],\n",
      "        [  0.9589],\n",
      "        [  0.9389],\n",
      "        [  1.2611],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  4.5611],\n",
      "        [  5.4389],\n",
      "        [  5.0611],\n",
      "        [ 65.2339],\n",
      "        [ 20.3902],\n",
      "        [ 15.7943],\n",
      "        [ 32.4541],\n",
      "        [ 12.4670],\n",
      "        [ 61.0611],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 27.1611],\n",
      "        [ 27.5611],\n",
      "        [ 28.5611],\n",
      "        [ 29.5611],\n",
      "        [ 32.5611],\n",
      "        [  5.4389],\n",
      "        [ 43.5218],\n",
      "        [  5.4389],\n",
      "        [ 25.3786],\n",
      "        [ 10.5253],\n",
      "        [ 14.3691],\n",
      "        [ 10.3626],\n",
      "        [ 12.7825],\n",
      "        [ 36.0611],\n",
      "        [ 18.6862],\n",
      "        [ 23.6961],\n",
      "        [ 34.6632],\n",
      "        [ 21.2292],\n",
      "        [  5.4389],\n",
      "        [ 13.2010],\n",
      "        [ 18.3908],\n",
      "        [ 22.2346],\n",
      "        [ 38.5611],\n",
      "        [ 45.5611],\n",
      "        [ 49.5611],\n",
      "        [ 49.5611],\n",
      "        [143.5611],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 45.9279],\n",
      "        [ 45.9279],\n",
      "        [ 25.1164],\n",
      "        [  1.4389],\n",
      "        [ 59.0611],\n",
      "        [140.3409],\n",
      "        [190.6345],\n",
      "        [ 65.5611],\n",
      "        [  3.7245],\n",
      "        [ 74.6231],\n",
      "        [  5.4389],\n",
      "        [ 80.1611],\n",
      "        [ 81.5611],\n",
      "        [  0.8004],\n",
      "        [  0.8004],\n",
      "        [ 87.0611],\n",
      "        [ 90.9525],\n",
      "        [  5.4389],\n",
      "        [103.6778],\n",
      "        [ 42.7851],\n",
      "        [ 99.5611],\n",
      "        [ 99.5611],\n",
      "        [ 99.1617],\n",
      "        [108.0611],\n",
      "        [114.9911],\n",
      "        [133.5611],\n",
      "        [147.2311],\n",
      "        [147.2311],\n",
      "        [170.0611],\n",
      "        [174.5611],\n",
      "        [ 25.9331],\n",
      "        [111.0936],\n",
      "        [184.5611],\n",
      "        [189.5611],\n",
      "        [194.5611],\n",
      "        [222.5611],\n",
      "        [194.1940],\n",
      "        [136.5983],\n",
      "        [  5.4389],\n",
      "        [ 85.9235],\n",
      "        [135.4645],\n",
      "        [ 18.0542],\n",
      "        [  5.4389]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 34.91831612586975\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 163\n",
      "剩餘X 資料 torch.Size([40, 10])\n",
      "剩餘Y 資料 torch.Size([40, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (20939.123046875, 27)\n",
      "The second_loss value of k: (21135.85546875, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引27，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([171, 1])\n",
      "<<預測值>>\n",
      "tensor([[105.1724],\n",
      "        [  5.4389],\n",
      "        [238.6867],\n",
      "        [  5.4389],\n",
      "        [ 98.5112],\n",
      "        [ 28.0317],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 34.7606],\n",
      "        [ 67.5707],\n",
      "        [ 80.5732],\n",
      "        [ 17.4126],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 28.4278],\n",
      "        [156.5593],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  9.2197],\n",
      "        [ 67.5707],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 33.7661],\n",
      "        [ 20.3902],\n",
      "        [ 15.7943],\n",
      "        [ 57.5341],\n",
      "        [ 12.4670],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 43.5218],\n",
      "        [  5.4389],\n",
      "        [ 25.3786],\n",
      "        [ 10.5253],\n",
      "        [ 14.3691],\n",
      "        [ 10.3626],\n",
      "        [ 12.7825],\n",
      "        [  5.4389],\n",
      "        [ 48.3138],\n",
      "        [ 23.6961],\n",
      "        [140.8632],\n",
      "        [ 21.2292],\n",
      "        [  5.4389],\n",
      "        [ 13.2010],\n",
      "        [ 18.3908],\n",
      "        [ 22.2346],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 45.9279],\n",
      "        [ 45.9279],\n",
      "        [ 48.6164],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [140.3409],\n",
      "        [ 45.3655],\n",
      "        [  5.4389],\n",
      "        [ 75.4755],\n",
      "        [ 74.6231],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 23.1004],\n",
      "        [ 23.1004],\n",
      "        [  5.4389],\n",
      "        [115.0475],\n",
      "        [  5.4389],\n",
      "        [ 50.3222],\n",
      "        [ 55.2149],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 99.1617],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 25.9331],\n",
      "        [111.0936],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [154.8060],\n",
      "        [101.4017],\n",
      "        [  5.4389],\n",
      "        [ 85.9235],\n",
      "        [135.4645],\n",
      "        [195.0542],\n",
      "        [  5.4389],\n",
      "        [144.7036]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[212.8276],\n",
      "        [  5.4389],\n",
      "        [ 87.0833],\n",
      "        [  5.4389],\n",
      "        [ 98.5112],\n",
      "        [ 11.7717],\n",
      "        [  4.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  0.4389],\n",
      "        [  5.4389],\n",
      "        [ 34.7606],\n",
      "        [158.4293],\n",
      "        [  6.8168],\n",
      "        [ 17.4126],\n",
      "        [  5.4389],\n",
      "        [  7.5611],\n",
      "        [ 28.4278],\n",
      "        [156.5593],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  4.5611],\n",
      "        [  7.2197],\n",
      "        [158.4293],\n",
      "        [  1.9389],\n",
      "        [  0.9589],\n",
      "        [  0.9389],\n",
      "        [  1.2611],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  4.5611],\n",
      "        [  5.4389],\n",
      "        [  5.0611],\n",
      "        [ 65.2339],\n",
      "        [ 20.3902],\n",
      "        [ 15.7943],\n",
      "        [ 32.4541],\n",
      "        [ 12.4670],\n",
      "        [ 61.0611],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 27.1611],\n",
      "        [ 27.5611],\n",
      "        [ 28.5611],\n",
      "        [ 29.5611],\n",
      "        [ 32.5611],\n",
      "        [  5.4389],\n",
      "        [ 43.5218],\n",
      "        [  5.4389],\n",
      "        [ 25.3786],\n",
      "        [ 10.5253],\n",
      "        [ 14.3691],\n",
      "        [ 10.3626],\n",
      "        [ 12.7825],\n",
      "        [ 36.0611],\n",
      "        [ 18.6862],\n",
      "        [ 23.6961],\n",
      "        [ 34.6632],\n",
      "        [ 21.2292],\n",
      "        [  5.4389],\n",
      "        [ 13.2010],\n",
      "        [ 18.3908],\n",
      "        [ 22.2346],\n",
      "        [ 38.5611],\n",
      "        [ 45.5611],\n",
      "        [ 49.5611],\n",
      "        [ 49.5611],\n",
      "        [143.5611],\n",
      "        [  5.4389],\n",
      "        [  5.4389],\n",
      "        [ 45.9279],\n",
      "        [ 45.9279],\n",
      "        [ 25.1164],\n",
      "        [  1.4389],\n",
      "        [ 59.0611],\n",
      "        [140.3409],\n",
      "        [190.6345],\n",
      "        [ 65.5611],\n",
      "        [  3.7245],\n",
      "        [ 74.6231],\n",
      "        [  5.4389],\n",
      "        [ 80.1611],\n",
      "        [ 81.5611],\n",
      "        [  0.8004],\n",
      "        [  0.8004],\n",
      "        [ 87.0611],\n",
      "        [ 90.9525],\n",
      "        [  5.4389],\n",
      "        [103.6778],\n",
      "        [ 42.7851],\n",
      "        [ 99.5611],\n",
      "        [ 99.5611],\n",
      "        [ 99.1617],\n",
      "        [108.0611],\n",
      "        [114.9911],\n",
      "        [133.5611],\n",
      "        [147.2311],\n",
      "        [147.2311],\n",
      "        [170.0611],\n",
      "        [174.5611],\n",
      "        [ 25.9331],\n",
      "        [111.0936],\n",
      "        [184.5611],\n",
      "        [189.5611],\n",
      "        [194.5611],\n",
      "        [222.5611],\n",
      "        [194.1940],\n",
      "        [136.5983],\n",
      "        [  5.4389],\n",
      "        [ 85.9235],\n",
      "        [135.4645],\n",
      "        [ 18.0542],\n",
      "        [  5.4389],\n",
      "        [144.7036]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4433.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[209.6332],\n",
      "        [  5.5396],\n",
      "        [ 98.8828],\n",
      "        [  5.5396],\n",
      "        [101.6094],\n",
      "        [ 17.1205],\n",
      "        [  4.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  0.5396],\n",
      "        [  5.5396],\n",
      "        [ 10.1548],\n",
      "        [161.8719],\n",
      "        [ 13.6137],\n",
      "        [ 24.3553],\n",
      "        [  5.5396],\n",
      "        [  7.4604],\n",
      "        [ 34.0200],\n",
      "        [157.8433],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 23.2746],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  4.4604],\n",
      "        [  5.3969],\n",
      "        [161.8719],\n",
      "        [  2.0396],\n",
      "        [  1.0596],\n",
      "        [  1.0396],\n",
      "        [  1.1604],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  4.4604],\n",
      "        [  5.5396],\n",
      "        [  4.9604],\n",
      "        [ 68.7848],\n",
      "        [ 26.7395],\n",
      "        [ 14.4376],\n",
      "        [ 32.5432],\n",
      "        [ 15.1769],\n",
      "        [ 60.9604],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 27.0604],\n",
      "        [ 27.4604],\n",
      "        [ 28.4604],\n",
      "        [ 29.4604],\n",
      "        [ 32.4604],\n",
      "        [  5.5396],\n",
      "        [ 48.7514],\n",
      "        [  5.5396],\n",
      "        [ 23.6551],\n",
      "        [  8.4860],\n",
      "        [ 12.0491],\n",
      "        [  8.2897],\n",
      "        [ 10.6964],\n",
      "        [ 35.9604],\n",
      "        [ 23.1602],\n",
      "        [ 21.0169],\n",
      "        [ 36.8602],\n",
      "        [ 18.5474],\n",
      "        [  5.5396],\n",
      "        [  9.9860],\n",
      "        [ 15.9626],\n",
      "        [ 19.5257],\n",
      "        [ 38.4604],\n",
      "        [ 45.4604],\n",
      "        [ 49.4604],\n",
      "        [ 49.4604],\n",
      "        [143.4604],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 26.2178],\n",
      "        [ 26.2178],\n",
      "        [ 26.4786],\n",
      "        [  1.5396],\n",
      "        [ 58.9604],\n",
      "        [112.6505],\n",
      "        [194.7859],\n",
      "        [ 65.4604],\n",
      "        [ 15.3410],\n",
      "        [ 78.9004],\n",
      "        [  5.5396],\n",
      "        [ 80.0604],\n",
      "        [ 81.4604],\n",
      "        [  3.8925],\n",
      "        [  3.8925],\n",
      "        [ 86.9604],\n",
      "        [ 86.4545],\n",
      "        [  5.5396],\n",
      "        [106.8745],\n",
      "        [ 35.1235],\n",
      "        [ 99.4604],\n",
      "        [ 99.4604],\n",
      "        [103.0159],\n",
      "        [107.9604],\n",
      "        [114.8904],\n",
      "        [133.4604],\n",
      "        [147.1304],\n",
      "        [147.1304],\n",
      "        [169.9604],\n",
      "        [174.4604],\n",
      "        [ 22.0662],\n",
      "        [103.9945],\n",
      "        [184.4604],\n",
      "        [189.4604],\n",
      "        [194.4604],\n",
      "        [222.4604],\n",
      "        [198.9938],\n",
      "        [146.3635],\n",
      "        [  5.5396],\n",
      "        [ 78.2623],\n",
      "        [126.2033],\n",
      "        [ 26.6835],\n",
      "        [  5.5396],\n",
      "        [135.0601]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 35.19070243835449\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 164\n",
      "剩餘X 資料 torch.Size([39, 10])\n",
      "剩餘Y 資料 torch.Size([39, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (19305.05859375, 2)\n",
      "The second_loss value of k: (27241.619140625, 22)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([172, 1])\n",
      "<<預測值>>\n",
      "tensor([[108.3668],\n",
      "        [  5.5396],\n",
      "        [226.8872],\n",
      "        [  5.5396],\n",
      "        [101.6094],\n",
      "        [ 33.3805],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 10.1548],\n",
      "        [ 64.1281],\n",
      "        [ 73.7763],\n",
      "        [ 24.3553],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 34.0200],\n",
      "        [157.8433],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 23.2746],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  7.3969],\n",
      "        [ 64.1281],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 30.2152],\n",
      "        [ 26.7395],\n",
      "        [ 14.4376],\n",
      "        [ 57.6232],\n",
      "        [ 15.1769],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 48.7514],\n",
      "        [  5.5396],\n",
      "        [ 23.6551],\n",
      "        [  8.4860],\n",
      "        [ 12.0491],\n",
      "        [  8.2897],\n",
      "        [ 10.6964],\n",
      "        [  5.5396],\n",
      "        [ 43.8398],\n",
      "        [ 21.0169],\n",
      "        [143.0602],\n",
      "        [ 18.5474],\n",
      "        [  5.5396],\n",
      "        [  9.9860],\n",
      "        [ 15.9626],\n",
      "        [ 19.5257],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 26.2178],\n",
      "        [ 26.2178],\n",
      "        [ 49.9786],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [112.6505],\n",
      "        [ 41.2141],\n",
      "        [  5.5396],\n",
      "        [ 63.8590],\n",
      "        [ 78.9004],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 26.1925],\n",
      "        [ 26.1925],\n",
      "        [  5.5396],\n",
      "        [119.5455],\n",
      "        [  5.5396],\n",
      "        [ 47.1255],\n",
      "        [ 62.8765],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [103.0159],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 22.0662],\n",
      "        [103.9945],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [150.0062],\n",
      "        [ 91.6365],\n",
      "        [  5.5396],\n",
      "        [ 78.2623],\n",
      "        [126.2033],\n",
      "        [203.6835],\n",
      "        [  5.5396],\n",
      "        [135.0601],\n",
      "        [138.9426]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[209.6332],\n",
      "        [  5.5396],\n",
      "        [ 98.8828],\n",
      "        [  5.5396],\n",
      "        [101.6094],\n",
      "        [ 17.1205],\n",
      "        [  4.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  0.5396],\n",
      "        [  5.5396],\n",
      "        [ 10.1548],\n",
      "        [161.8719],\n",
      "        [ 13.6137],\n",
      "        [ 24.3553],\n",
      "        [  5.5396],\n",
      "        [  7.4604],\n",
      "        [ 34.0200],\n",
      "        [157.8433],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 23.2746],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  4.4604],\n",
      "        [  5.3969],\n",
      "        [161.8719],\n",
      "        [  2.0396],\n",
      "        [  1.0596],\n",
      "        [  1.0396],\n",
      "        [  1.1604],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  4.4604],\n",
      "        [  5.5396],\n",
      "        [  4.9604],\n",
      "        [ 68.7848],\n",
      "        [ 26.7395],\n",
      "        [ 14.4376],\n",
      "        [ 32.5432],\n",
      "        [ 15.1769],\n",
      "        [ 60.9604],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 27.0604],\n",
      "        [ 27.4604],\n",
      "        [ 28.4604],\n",
      "        [ 29.4604],\n",
      "        [ 32.4604],\n",
      "        [  5.5396],\n",
      "        [ 48.7514],\n",
      "        [  5.5396],\n",
      "        [ 23.6551],\n",
      "        [  8.4860],\n",
      "        [ 12.0491],\n",
      "        [  8.2897],\n",
      "        [ 10.6964],\n",
      "        [ 35.9604],\n",
      "        [ 23.1602],\n",
      "        [ 21.0169],\n",
      "        [ 36.8602],\n",
      "        [ 18.5474],\n",
      "        [  5.5396],\n",
      "        [  9.9860],\n",
      "        [ 15.9626],\n",
      "        [ 19.5257],\n",
      "        [ 38.4604],\n",
      "        [ 45.4604],\n",
      "        [ 49.4604],\n",
      "        [ 49.4604],\n",
      "        [143.4604],\n",
      "        [  5.5396],\n",
      "        [  5.5396],\n",
      "        [ 26.2178],\n",
      "        [ 26.2178],\n",
      "        [ 26.4786],\n",
      "        [  1.5396],\n",
      "        [ 58.9604],\n",
      "        [112.6505],\n",
      "        [194.7859],\n",
      "        [ 65.4604],\n",
      "        [ 15.3410],\n",
      "        [ 78.9004],\n",
      "        [  5.5396],\n",
      "        [ 80.0604],\n",
      "        [ 81.4604],\n",
      "        [  3.8925],\n",
      "        [  3.8925],\n",
      "        [ 86.9604],\n",
      "        [ 86.4545],\n",
      "        [  5.5396],\n",
      "        [106.8745],\n",
      "        [ 35.1235],\n",
      "        [ 99.4604],\n",
      "        [ 99.4604],\n",
      "        [103.0159],\n",
      "        [107.9604],\n",
      "        [114.8904],\n",
      "        [133.4604],\n",
      "        [147.1304],\n",
      "        [147.1304],\n",
      "        [169.9604],\n",
      "        [174.4604],\n",
      "        [ 22.0662],\n",
      "        [103.9945],\n",
      "        [184.4604],\n",
      "        [189.4604],\n",
      "        [194.4604],\n",
      "        [222.4604],\n",
      "        [198.9938],\n",
      "        [146.3635],\n",
      "        [  5.5396],\n",
      "        [ 78.2623],\n",
      "        [126.2033],\n",
      "        [ 26.6835],\n",
      "        [  5.5396],\n",
      "        [135.0601],\n",
      "        [138.9426]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4488.3501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[215.1571],\n",
      "        [  5.6799],\n",
      "        [105.9959],\n",
      "        [  5.6799],\n",
      "        [100.0712],\n",
      "        [ 17.3532],\n",
      "        [  4.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  0.6799],\n",
      "        [  5.6799],\n",
      "        [ 14.7620],\n",
      "        [170.5965],\n",
      "        [ 24.0978],\n",
      "        [ 20.6494],\n",
      "        [  5.6799],\n",
      "        [  7.3201],\n",
      "        [ 35.3857],\n",
      "        [148.6654],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  8.2076],\n",
      "        [  6.6726],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 34.7561],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  4.3201],\n",
      "        [  7.2682],\n",
      "        [170.5965],\n",
      "        [  2.1799],\n",
      "        [  1.1999],\n",
      "        [  1.1799],\n",
      "        [  1.0201],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  4.3201],\n",
      "        [  5.6799],\n",
      "        [  4.8201],\n",
      "        [ 73.1071],\n",
      "        [ 29.1686],\n",
      "        [ 15.4703],\n",
      "        [ 31.8751],\n",
      "        [ 15.5930],\n",
      "        [ 60.8201],\n",
      "        [  7.7978],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 26.9201],\n",
      "        [ 27.3201],\n",
      "        [ 28.3201],\n",
      "        [ 29.3201],\n",
      "        [ 32.3201],\n",
      "        [  5.6799],\n",
      "        [ 49.2885],\n",
      "        [  5.6799],\n",
      "        [ 22.9318],\n",
      "        [  6.3287],\n",
      "        [  9.5655],\n",
      "        [  5.6799],\n",
      "        [  8.2605],\n",
      "        [ 35.8201],\n",
      "        [ 28.8615],\n",
      "        [ 17.4580],\n",
      "        [ 30.8213],\n",
      "        [ 15.3374],\n",
      "        [  5.6799],\n",
      "        [  7.9025],\n",
      "        [ 12.9456],\n",
      "        [ 16.1825],\n",
      "        [ 38.3201],\n",
      "        [ 45.3201],\n",
      "        [ 49.3201],\n",
      "        [ 49.3201],\n",
      "        [143.3201],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 27.4844],\n",
      "        [ 27.4844],\n",
      "        [ 32.5515],\n",
      "        [  1.6799],\n",
      "        [ 58.8201],\n",
      "        [113.9110],\n",
      "        [203.8347],\n",
      "        [ 65.3201],\n",
      "        [ 16.6157],\n",
      "        [ 77.1323],\n",
      "        [ 15.6772],\n",
      "        [ 79.9201],\n",
      "        [ 81.3201],\n",
      "        [  0.7058],\n",
      "        [  0.7058],\n",
      "        [ 86.8201],\n",
      "        [ 92.1095],\n",
      "        [  5.6799],\n",
      "        [110.0421],\n",
      "        [ 33.3795],\n",
      "        [ 99.3201],\n",
      "        [ 99.3201],\n",
      "        [ 99.7500],\n",
      "        [107.8201],\n",
      "        [114.7501],\n",
      "        [133.3201],\n",
      "        [146.9901],\n",
      "        [146.9901],\n",
      "        [169.8201],\n",
      "        [174.3201],\n",
      "        [ 14.7329],\n",
      "        [ 92.0950],\n",
      "        [184.3201],\n",
      "        [189.3201],\n",
      "        [194.3201],\n",
      "        [222.3201],\n",
      "        [204.6787],\n",
      "        [143.8680],\n",
      "        [  5.6799],\n",
      "        [ 62.5252],\n",
      "        [109.0385],\n",
      "        [ 16.7287],\n",
      "        [  5.6799],\n",
      "        [119.6480],\n",
      "        [122.0591]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 35.45935940742493\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 165\n",
      "剩餘X 資料 torch.Size([38, 10])\n",
      "剩餘Y 資料 torch.Size([38, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (18631.94921875, 21)\n",
      "The second_loss value of k: (20764.890625, 18)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引21，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([173, 1])\n",
      "<<預測值>>\n",
      "tensor([[102.8429],\n",
      "        [  5.6799],\n",
      "        [219.7741],\n",
      "        [  5.6799],\n",
      "        [100.0712],\n",
      "        [ 33.6132],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 14.7620],\n",
      "        [ 55.4035],\n",
      "        [ 63.2922],\n",
      "        [ 20.6494],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 35.3857],\n",
      "        [148.6654],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  8.2076],\n",
      "        [  6.6726],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 34.7561],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  9.2682],\n",
      "        [ 55.4035],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 25.8929],\n",
      "        [ 29.1686],\n",
      "        [ 15.4703],\n",
      "        [ 56.9551],\n",
      "        [ 15.5930],\n",
      "        [  5.6799],\n",
      "        [  7.7978],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 49.2885],\n",
      "        [  5.6799],\n",
      "        [ 22.9318],\n",
      "        [  6.3287],\n",
      "        [  9.5655],\n",
      "        [  5.6799],\n",
      "        [  8.2605],\n",
      "        [  5.6799],\n",
      "        [ 38.1385],\n",
      "        [ 17.4580],\n",
      "        [137.0213],\n",
      "        [ 15.3374],\n",
      "        [  5.6799],\n",
      "        [  7.9025],\n",
      "        [ 12.9456],\n",
      "        [ 16.1825],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 27.4844],\n",
      "        [ 27.4844],\n",
      "        [ 56.0515],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [113.9110],\n",
      "        [ 32.1653],\n",
      "        [  5.6799],\n",
      "        [ 62.5843],\n",
      "        [ 77.1323],\n",
      "        [ 15.6772],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 23.0058],\n",
      "        [ 23.0058],\n",
      "        [  5.6799],\n",
      "        [113.8905],\n",
      "        [  5.6799],\n",
      "        [ 43.9579],\n",
      "        [ 64.6205],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 99.7500],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 14.7329],\n",
      "        [ 92.0950],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [144.3213],\n",
      "        [ 94.1321],\n",
      "        [  5.6799],\n",
      "        [ 62.5252],\n",
      "        [109.0385],\n",
      "        [193.7287],\n",
      "        [  5.6799],\n",
      "        [119.6480],\n",
      "        [122.0591],\n",
      "        [136.4989]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[215.1571],\n",
      "        [  5.6799],\n",
      "        [105.9959],\n",
      "        [  5.6799],\n",
      "        [100.0712],\n",
      "        [ 17.3532],\n",
      "        [  4.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  0.6799],\n",
      "        [  5.6799],\n",
      "        [ 14.7620],\n",
      "        [170.5965],\n",
      "        [ 24.0978],\n",
      "        [ 20.6494],\n",
      "        [  5.6799],\n",
      "        [  7.3201],\n",
      "        [ 35.3857],\n",
      "        [148.6654],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  8.2076],\n",
      "        [  6.6726],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 34.7561],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  4.3201],\n",
      "        [  7.2682],\n",
      "        [170.5965],\n",
      "        [  2.1799],\n",
      "        [  1.1999],\n",
      "        [  1.1799],\n",
      "        [  1.0201],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [  4.3201],\n",
      "        [  5.6799],\n",
      "        [  4.8201],\n",
      "        [ 73.1071],\n",
      "        [ 29.1686],\n",
      "        [ 15.4703],\n",
      "        [ 31.8751],\n",
      "        [ 15.5930],\n",
      "        [ 60.8201],\n",
      "        [  7.7978],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 26.9201],\n",
      "        [ 27.3201],\n",
      "        [ 28.3201],\n",
      "        [ 29.3201],\n",
      "        [ 32.3201],\n",
      "        [  5.6799],\n",
      "        [ 49.2885],\n",
      "        [  5.6799],\n",
      "        [ 22.9318],\n",
      "        [  6.3287],\n",
      "        [  9.5655],\n",
      "        [  5.6799],\n",
      "        [  8.2605],\n",
      "        [ 35.8201],\n",
      "        [ 28.8615],\n",
      "        [ 17.4580],\n",
      "        [ 30.8213],\n",
      "        [ 15.3374],\n",
      "        [  5.6799],\n",
      "        [  7.9025],\n",
      "        [ 12.9456],\n",
      "        [ 16.1825],\n",
      "        [ 38.3201],\n",
      "        [ 45.3201],\n",
      "        [ 49.3201],\n",
      "        [ 49.3201],\n",
      "        [143.3201],\n",
      "        [  5.6799],\n",
      "        [  5.6799],\n",
      "        [ 27.4844],\n",
      "        [ 27.4844],\n",
      "        [ 32.5515],\n",
      "        [  1.6799],\n",
      "        [ 58.8201],\n",
      "        [113.9110],\n",
      "        [203.8347],\n",
      "        [ 65.3201],\n",
      "        [ 16.6157],\n",
      "        [ 77.1323],\n",
      "        [ 15.6772],\n",
      "        [ 79.9201],\n",
      "        [ 81.3201],\n",
      "        [  0.7058],\n",
      "        [  0.7058],\n",
      "        [ 86.8201],\n",
      "        [ 92.1095],\n",
      "        [  5.6799],\n",
      "        [110.0421],\n",
      "        [ 33.3795],\n",
      "        [ 99.3201],\n",
      "        [ 99.3201],\n",
      "        [ 99.7500],\n",
      "        [107.8201],\n",
      "        [114.7501],\n",
      "        [133.3201],\n",
      "        [146.9901],\n",
      "        [146.9901],\n",
      "        [169.8201],\n",
      "        [174.3201],\n",
      "        [ 14.7329],\n",
      "        [ 92.0950],\n",
      "        [184.3201],\n",
      "        [189.3201],\n",
      "        [194.3201],\n",
      "        [222.3201],\n",
      "        [204.6787],\n",
      "        [143.8680],\n",
      "        [  5.6799],\n",
      "        [ 62.5252],\n",
      "        [109.0385],\n",
      "        [ 16.7287],\n",
      "        [  5.6799],\n",
      "        [119.6480],\n",
      "        [122.0591],\n",
      "        [136.4989]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4548.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[206.3521],\n",
      "        [  5.8071],\n",
      "        [105.4714],\n",
      "        [  5.8071],\n",
      "        [100.2337],\n",
      "        [ 24.2563],\n",
      "        [  4.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  0.8071],\n",
      "        [  5.8071],\n",
      "        [ 22.6322],\n",
      "        [183.9667],\n",
      "        [ 34.6967],\n",
      "        [ 14.4620],\n",
      "        [  5.8071],\n",
      "        [  7.1929],\n",
      "        [ 35.3670],\n",
      "        [157.2824],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  8.6124],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 49.6116],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  4.1929],\n",
      "        [  5.6821],\n",
      "        [183.9667],\n",
      "        [  2.3071],\n",
      "        [  1.3271],\n",
      "        [  1.3071],\n",
      "        [  0.8929],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  4.1929],\n",
      "        [  5.8071],\n",
      "        [  4.6929],\n",
      "        [ 70.1555],\n",
      "        [ 29.7237],\n",
      "        [ 16.6874],\n",
      "        [ 33.4148],\n",
      "        [ 16.0133],\n",
      "        [ 60.6929],\n",
      "        [ 15.2514],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 26.7929],\n",
      "        [ 27.1929],\n",
      "        [ 28.1929],\n",
      "        [ 29.1929],\n",
      "        [ 32.1929],\n",
      "        [  5.8071],\n",
      "        [ 49.4307],\n",
      "        [  5.8071],\n",
      "        [ 25.2044],\n",
      "        [  9.7813],\n",
      "        [ 13.3008],\n",
      "        [  5.8071],\n",
      "        [ 10.7643],\n",
      "        [ 35.6929],\n",
      "        [ 26.4978],\n",
      "        [ 18.5299],\n",
      "        [ 31.2818],\n",
      "        [ 17.9196],\n",
      "        [  5.8071],\n",
      "        [  9.4588],\n",
      "        [ 14.7666],\n",
      "        [ 18.2860],\n",
      "        [ 38.1929],\n",
      "        [ 45.1929],\n",
      "        [ 49.1929],\n",
      "        [ 49.1929],\n",
      "        [143.1929],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 32.8025],\n",
      "        [ 32.8025],\n",
      "        [ 41.3520],\n",
      "        [  1.8071],\n",
      "        [ 58.6929],\n",
      "        [121.2136],\n",
      "        [220.7213],\n",
      "        [ 65.1929],\n",
      "        [ 14.9093],\n",
      "        [ 80.1218],\n",
      "        [ 28.1933],\n",
      "        [ 79.7929],\n",
      "        [ 81.1929],\n",
      "        [  5.2026],\n",
      "        [  5.2026],\n",
      "        [ 86.6929],\n",
      "        [ 83.7997],\n",
      "        [  5.8071],\n",
      "        [115.5544],\n",
      "        [ 30.8995],\n",
      "        [ 99.1929],\n",
      "        [ 99.1929],\n",
      "        [ 98.1128],\n",
      "        [107.6929],\n",
      "        [114.6229],\n",
      "        [133.1929],\n",
      "        [146.8629],\n",
      "        [146.8629],\n",
      "        [169.6929],\n",
      "        [174.1929],\n",
      "        [  5.8071],\n",
      "        [ 85.3633],\n",
      "        [184.1929],\n",
      "        [189.1929],\n",
      "        [194.1929],\n",
      "        [222.1929],\n",
      "        [204.4506],\n",
      "        [144.0543],\n",
      "        [  5.8071],\n",
      "        [ 31.9173],\n",
      "        [ 91.4925],\n",
      "        [  7.9866],\n",
      "        [  5.8071],\n",
      "        [ 96.9582],\n",
      "        [103.2826],\n",
      "        [ 82.8649]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 35.73126673698425\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 166\n",
      "剩餘X 資料 torch.Size([37, 10])\n",
      "剩餘Y 資料 torch.Size([37, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (10204.2060546875, 32)\n",
      "The second_loss value of k: (10941.04296875, 18)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引32，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([174, 1])\n",
      "<<預測值>>\n",
      "tensor([[111.6479],\n",
      "        [  5.8071],\n",
      "        [220.2986],\n",
      "        [  5.8071],\n",
      "        [100.2337],\n",
      "        [ 40.5163],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 22.6322],\n",
      "        [ 42.0333],\n",
      "        [ 52.6933],\n",
      "        [ 14.4620],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 35.3670],\n",
      "        [157.2824],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  8.6124],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 49.6116],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  7.6821],\n",
      "        [ 42.0333],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 28.8445],\n",
      "        [ 29.7237],\n",
      "        [ 16.6874],\n",
      "        [ 58.4948],\n",
      "        [ 16.0133],\n",
      "        [  5.8071],\n",
      "        [ 15.2514],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 49.4307],\n",
      "        [  5.8071],\n",
      "        [ 25.2044],\n",
      "        [  9.7813],\n",
      "        [ 13.3008],\n",
      "        [  5.8071],\n",
      "        [ 10.7643],\n",
      "        [  5.8071],\n",
      "        [ 40.5022],\n",
      "        [ 18.5299],\n",
      "        [137.4818],\n",
      "        [ 17.9196],\n",
      "        [  5.8071],\n",
      "        [  9.4588],\n",
      "        [ 14.7666],\n",
      "        [ 18.2860],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 32.8025],\n",
      "        [ 32.8025],\n",
      "        [ 64.8520],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [121.2136],\n",
      "        [ 15.2787],\n",
      "        [  5.8071],\n",
      "        [ 64.2907],\n",
      "        [ 80.1218],\n",
      "        [ 28.1933],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 17.0974],\n",
      "        [ 17.0974],\n",
      "        [  5.8071],\n",
      "        [122.2003],\n",
      "        [  5.8071],\n",
      "        [ 38.4456],\n",
      "        [ 67.1005],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 98.1128],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 85.3633],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [144.5494],\n",
      "        [ 93.9457],\n",
      "        [  5.8071],\n",
      "        [ 31.9173],\n",
      "        [ 91.4925],\n",
      "        [184.9866],\n",
      "        [  5.8071],\n",
      "        [ 96.9582],\n",
      "        [103.2826],\n",
      "        [ 82.8649],\n",
      "        [101.0159]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[206.3521],\n",
      "        [  5.8071],\n",
      "        [105.4714],\n",
      "        [  5.8071],\n",
      "        [100.2337],\n",
      "        [ 24.2563],\n",
      "        [  4.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  0.8071],\n",
      "        [  5.8071],\n",
      "        [ 22.6322],\n",
      "        [183.9667],\n",
      "        [ 34.6967],\n",
      "        [ 14.4620],\n",
      "        [  5.8071],\n",
      "        [  7.1929],\n",
      "        [ 35.3670],\n",
      "        [157.2824],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  8.6124],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 49.6116],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  4.1929],\n",
      "        [  5.6821],\n",
      "        [183.9667],\n",
      "        [  2.3071],\n",
      "        [  1.3271],\n",
      "        [  1.3071],\n",
      "        [  0.8929],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [  4.1929],\n",
      "        [  5.8071],\n",
      "        [  4.6929],\n",
      "        [ 70.1555],\n",
      "        [ 29.7237],\n",
      "        [ 16.6874],\n",
      "        [ 33.4148],\n",
      "        [ 16.0133],\n",
      "        [ 60.6929],\n",
      "        [ 15.2514],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 26.7929],\n",
      "        [ 27.1929],\n",
      "        [ 28.1929],\n",
      "        [ 29.1929],\n",
      "        [ 32.1929],\n",
      "        [  5.8071],\n",
      "        [ 49.4307],\n",
      "        [  5.8071],\n",
      "        [ 25.2044],\n",
      "        [  9.7813],\n",
      "        [ 13.3008],\n",
      "        [  5.8071],\n",
      "        [ 10.7643],\n",
      "        [ 35.6929],\n",
      "        [ 26.4978],\n",
      "        [ 18.5299],\n",
      "        [ 31.2818],\n",
      "        [ 17.9196],\n",
      "        [  5.8071],\n",
      "        [  9.4588],\n",
      "        [ 14.7666],\n",
      "        [ 18.2860],\n",
      "        [ 38.1929],\n",
      "        [ 45.1929],\n",
      "        [ 49.1929],\n",
      "        [ 49.1929],\n",
      "        [143.1929],\n",
      "        [  5.8071],\n",
      "        [  5.8071],\n",
      "        [ 32.8025],\n",
      "        [ 32.8025],\n",
      "        [ 41.3520],\n",
      "        [  1.8071],\n",
      "        [ 58.6929],\n",
      "        [121.2136],\n",
      "        [220.7213],\n",
      "        [ 65.1929],\n",
      "        [ 14.9093],\n",
      "        [ 80.1218],\n",
      "        [ 28.1933],\n",
      "        [ 79.7929],\n",
      "        [ 81.1929],\n",
      "        [  5.2026],\n",
      "        [  5.2026],\n",
      "        [ 86.6929],\n",
      "        [ 83.7997],\n",
      "        [  5.8071],\n",
      "        [115.5544],\n",
      "        [ 30.8995],\n",
      "        [ 99.1929],\n",
      "        [ 99.1929],\n",
      "        [ 98.1128],\n",
      "        [107.6929],\n",
      "        [114.6229],\n",
      "        [133.1929],\n",
      "        [146.8629],\n",
      "        [146.8629],\n",
      "        [169.6929],\n",
      "        [174.1929],\n",
      "        [  5.8071],\n",
      "        [ 85.3633],\n",
      "        [184.1929],\n",
      "        [189.1929],\n",
      "        [194.1929],\n",
      "        [222.1929],\n",
      "        [204.4506],\n",
      "        [144.0543],\n",
      "        [  5.8071],\n",
      "        [ 31.9173],\n",
      "        [ 91.4925],\n",
      "        [  7.9866],\n",
      "        [  5.8071],\n",
      "        [ 96.9582],\n",
      "        [103.2826],\n",
      "        [ 82.8649],\n",
      "        [101.0159]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4533.8608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[199.5604],\n",
      "        [  5.9448],\n",
      "        [108.4330],\n",
      "        [  5.9448],\n",
      "        [100.1501],\n",
      "        [ 27.8331],\n",
      "        [  4.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  0.9448],\n",
      "        [  5.9448],\n",
      "        [ 25.5400],\n",
      "        [201.1737],\n",
      "        [ 46.0166],\n",
      "        [  9.8314],\n",
      "        [  5.9448],\n",
      "        [  7.0552],\n",
      "        [ 29.1974],\n",
      "        [165.2152],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  7.9226],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 60.2318],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  4.0552],\n",
      "        [  6.9720],\n",
      "        [201.1737],\n",
      "        [  2.4448],\n",
      "        [  1.4648],\n",
      "        [  1.4448],\n",
      "        [  0.7552],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  4.0552],\n",
      "        [  5.9448],\n",
      "        [  4.5552],\n",
      "        [ 69.9977],\n",
      "        [ 25.7564],\n",
      "        [ 15.1623],\n",
      "        [ 38.0633],\n",
      "        [ 13.7366],\n",
      "        [ 60.5552],\n",
      "        [ 18.3904],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 26.6552],\n",
      "        [ 27.0552],\n",
      "        [ 28.0552],\n",
      "        [ 29.0552],\n",
      "        [ 32.0552],\n",
      "        [  5.9448],\n",
      "        [ 45.5665],\n",
      "        [  5.9448],\n",
      "        [ 25.0155],\n",
      "        [  9.6715],\n",
      "        [ 13.2592],\n",
      "        [  5.9448],\n",
      "        [ 10.6315],\n",
      "        [ 35.5552],\n",
      "        [ 26.1903],\n",
      "        [ 17.7006],\n",
      "        [ 27.1879],\n",
      "        [ 17.8911],\n",
      "        [  6.8565],\n",
      "        [  9.3951],\n",
      "        [ 14.6515],\n",
      "        [ 18.2392],\n",
      "        [ 38.0552],\n",
      "        [ 45.0552],\n",
      "        [ 49.0552],\n",
      "        [ 49.0552],\n",
      "        [143.0552],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 35.1581],\n",
      "        [ 35.1581],\n",
      "        [ 45.7946],\n",
      "        [  1.9448],\n",
      "        [ 58.5552],\n",
      "        [122.6480],\n",
      "        [230.0552],\n",
      "        [ 65.0552],\n",
      "        [ 15.9292],\n",
      "        [ 79.7101],\n",
      "        [ 35.6626],\n",
      "        [ 79.6552],\n",
      "        [ 81.0552],\n",
      "        [ 13.0907],\n",
      "        [ 13.0907],\n",
      "        [ 86.5552],\n",
      "        [ 76.5153],\n",
      "        [  5.9448],\n",
      "        [122.8895],\n",
      "        [ 27.3425],\n",
      "        [ 99.0552],\n",
      "        [ 99.0552],\n",
      "        [ 93.9054],\n",
      "        [107.5552],\n",
      "        [114.4852],\n",
      "        [133.0552],\n",
      "        [146.7252],\n",
      "        [146.7252],\n",
      "        [169.5552],\n",
      "        [174.0552],\n",
      "        [  5.9448],\n",
      "        [ 77.3517],\n",
      "        [184.0552],\n",
      "        [189.0552],\n",
      "        [194.0552],\n",
      "        [222.0552],\n",
      "        [207.4031],\n",
      "        [143.7606],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 73.0181],\n",
      "        [  1.8308],\n",
      "        [  5.9448],\n",
      "        [ 73.2034],\n",
      "        [ 83.5447],\n",
      "        [ 28.7586],\n",
      "        [ 55.9045]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 36.05475163459778\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 167\n",
      "剩餘X 資料 torch.Size([36, 10])\n",
      "剩餘Y 資料 torch.Size([36, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (4214.25244140625, 17)\n",
      "The second_loss value of k: (4345.25830078125, 18)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([175, 1])\n",
      "<<預測值>>\n",
      "tensor([[118.4396],\n",
      "        [  5.9448],\n",
      "        [217.3370],\n",
      "        [  5.9448],\n",
      "        [100.1501],\n",
      "        [ 44.0931],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 25.5400],\n",
      "        [ 24.8263],\n",
      "        [ 41.3734],\n",
      "        [  9.8314],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 29.1974],\n",
      "        [165.2152],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  7.9226],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 60.2318],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  8.9720],\n",
      "        [ 24.8263],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 29.0023],\n",
      "        [ 25.7564],\n",
      "        [ 15.1623],\n",
      "        [ 63.1433],\n",
      "        [ 13.7366],\n",
      "        [  5.9448],\n",
      "        [ 18.3904],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 45.5665],\n",
      "        [  5.9448],\n",
      "        [ 25.0155],\n",
      "        [  9.6715],\n",
      "        [ 13.2592],\n",
      "        [  5.9448],\n",
      "        [ 10.6315],\n",
      "        [  5.9448],\n",
      "        [ 40.8097],\n",
      "        [ 17.7006],\n",
      "        [133.3879],\n",
      "        [ 17.8911],\n",
      "        [  6.8565],\n",
      "        [  9.3951],\n",
      "        [ 14.6515],\n",
      "        [ 18.2392],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 35.1581],\n",
      "        [ 35.1581],\n",
      "        [ 69.2946],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [122.6480],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 63.2708],\n",
      "        [ 79.7101],\n",
      "        [ 35.6626],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  9.2093],\n",
      "        [  9.2093],\n",
      "        [  5.9448],\n",
      "        [129.4847],\n",
      "        [  5.9448],\n",
      "        [ 31.1105],\n",
      "        [ 70.6575],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 93.9054],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 77.3517],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [141.5969],\n",
      "        [ 94.2394],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 73.0181],\n",
      "        [175.1692],\n",
      "        [  5.9448],\n",
      "        [ 73.2034],\n",
      "        [ 83.5447],\n",
      "        [ 28.7586],\n",
      "        [ 55.9045],\n",
      "        [ 64.9173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[199.5604],\n",
      "        [  5.9448],\n",
      "        [108.4330],\n",
      "        [  5.9448],\n",
      "        [100.1501],\n",
      "        [ 27.8331],\n",
      "        [  4.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  0.9448],\n",
      "        [  5.9448],\n",
      "        [ 25.5400],\n",
      "        [201.1737],\n",
      "        [ 46.0166],\n",
      "        [  9.8314],\n",
      "        [  5.9448],\n",
      "        [  7.0552],\n",
      "        [ 29.1974],\n",
      "        [165.2152],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  7.9226],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 60.2318],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  4.0552],\n",
      "        [  6.9720],\n",
      "        [201.1737],\n",
      "        [  2.4448],\n",
      "        [  1.4648],\n",
      "        [  1.4448],\n",
      "        [  0.7552],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [  4.0552],\n",
      "        [  5.9448],\n",
      "        [  4.5552],\n",
      "        [ 69.9977],\n",
      "        [ 25.7564],\n",
      "        [ 15.1623],\n",
      "        [ 38.0633],\n",
      "        [ 13.7366],\n",
      "        [ 60.5552],\n",
      "        [ 18.3904],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 26.6552],\n",
      "        [ 27.0552],\n",
      "        [ 28.0552],\n",
      "        [ 29.0552],\n",
      "        [ 32.0552],\n",
      "        [  5.9448],\n",
      "        [ 45.5665],\n",
      "        [  5.9448],\n",
      "        [ 25.0155],\n",
      "        [  9.6715],\n",
      "        [ 13.2592],\n",
      "        [  5.9448],\n",
      "        [ 10.6315],\n",
      "        [ 35.5552],\n",
      "        [ 26.1903],\n",
      "        [ 17.7006],\n",
      "        [ 27.1879],\n",
      "        [ 17.8911],\n",
      "        [  6.8565],\n",
      "        [  9.3951],\n",
      "        [ 14.6515],\n",
      "        [ 18.2392],\n",
      "        [ 38.0552],\n",
      "        [ 45.0552],\n",
      "        [ 49.0552],\n",
      "        [ 49.0552],\n",
      "        [143.0552],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 35.1581],\n",
      "        [ 35.1581],\n",
      "        [ 45.7946],\n",
      "        [  1.9448],\n",
      "        [ 58.5552],\n",
      "        [122.6480],\n",
      "        [230.0552],\n",
      "        [ 65.0552],\n",
      "        [ 15.9292],\n",
      "        [ 79.7101],\n",
      "        [ 35.6626],\n",
      "        [ 79.6552],\n",
      "        [ 81.0552],\n",
      "        [ 13.0907],\n",
      "        [ 13.0907],\n",
      "        [ 86.5552],\n",
      "        [ 76.5153],\n",
      "        [  5.9448],\n",
      "        [122.8895],\n",
      "        [ 27.3425],\n",
      "        [ 99.0552],\n",
      "        [ 99.0552],\n",
      "        [ 93.9054],\n",
      "        [107.5552],\n",
      "        [114.4852],\n",
      "        [133.0552],\n",
      "        [146.7252],\n",
      "        [146.7252],\n",
      "        [169.5552],\n",
      "        [174.0552],\n",
      "        [  5.9448],\n",
      "        [ 77.3517],\n",
      "        [184.0552],\n",
      "        [189.0552],\n",
      "        [194.0552],\n",
      "        [222.0552],\n",
      "        [207.4031],\n",
      "        [143.7606],\n",
      "        [  5.9448],\n",
      "        [  5.9448],\n",
      "        [ 73.0181],\n",
      "        [  1.8308],\n",
      "        [  5.9448],\n",
      "        [ 73.2034],\n",
      "        [ 83.5447],\n",
      "        [ 28.7586],\n",
      "        [ 55.9045],\n",
      "        [ 64.9173]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4502.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[195.9414],\n",
      "        [  6.0178],\n",
      "        [109.1687],\n",
      "        [  6.0178],\n",
      "        [ 99.0929],\n",
      "        [ 29.9891],\n",
      "        [  5.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  1.0178],\n",
      "        [  6.0178],\n",
      "        [ 23.4963],\n",
      "        [205.1538],\n",
      "        [ 49.1958],\n",
      "        [  7.9764],\n",
      "        [  6.0178],\n",
      "        [  6.9822],\n",
      "        [ 29.1967],\n",
      "        [169.3437],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 61.9900],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  3.9822],\n",
      "        [  4.0178],\n",
      "        [205.1538],\n",
      "        [  2.5178],\n",
      "        [  1.5378],\n",
      "        [  1.5178],\n",
      "        [  0.6822],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  3.9822],\n",
      "        [  6.0178],\n",
      "        [  4.4822],\n",
      "        [ 68.9677],\n",
      "        [ 25.2874],\n",
      "        [ 14.0360],\n",
      "        [ 36.1015],\n",
      "        [ 13.0034],\n",
      "        [ 60.4822],\n",
      "        [ 19.7904],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 26.5822],\n",
      "        [ 26.9822],\n",
      "        [ 27.9822],\n",
      "        [ 28.9822],\n",
      "        [ 31.9822],\n",
      "        [  6.0178],\n",
      "        [ 45.1946],\n",
      "        [  6.0178],\n",
      "        [ 24.6272],\n",
      "        [ 10.6621],\n",
      "        [ 14.4764],\n",
      "        [  6.0178],\n",
      "        [ 11.0804],\n",
      "        [ 35.4822],\n",
      "        [ 25.3008],\n",
      "        [ 17.6588],\n",
      "        [ 28.4924],\n",
      "        [ 18.5146],\n",
      "        [  7.3449],\n",
      "        [  8.9431],\n",
      "        [ 14.7750],\n",
      "        [ 18.5893],\n",
      "        [ 37.9822],\n",
      "        [ 44.9822],\n",
      "        [ 48.9822],\n",
      "        [ 48.9822],\n",
      "        [142.9822],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 33.2490],\n",
      "        [ 33.2490],\n",
      "        [ 46.7354],\n",
      "        [  2.0178],\n",
      "        [ 58.4822],\n",
      "        [120.8915],\n",
      "        [229.9822],\n",
      "        [ 64.9822],\n",
      "        [ 17.7445],\n",
      "        [ 80.3963],\n",
      "        [ 37.9601],\n",
      "        [ 79.5822],\n",
      "        [ 80.9822],\n",
      "        [ 15.9240],\n",
      "        [ 15.9240],\n",
      "        [ 86.4822],\n",
      "        [ 73.0242],\n",
      "        [  6.0178],\n",
      "        [125.7838],\n",
      "        [ 28.2839],\n",
      "        [ 98.9822],\n",
      "        [ 98.9822],\n",
      "        [ 93.3137],\n",
      "        [107.4822],\n",
      "        [114.4122],\n",
      "        [132.9822],\n",
      "        [146.6522],\n",
      "        [146.6522],\n",
      "        [169.4822],\n",
      "        [173.9822],\n",
      "        [  6.0178],\n",
      "        [ 76.0598],\n",
      "        [183.9822],\n",
      "        [188.9822],\n",
      "        [193.9822],\n",
      "        [221.9822],\n",
      "        [207.5905],\n",
      "        [148.0072],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 68.6912],\n",
      "        [  5.2901],\n",
      "        [  6.0178],\n",
      "        [ 66.4423],\n",
      "        [ 79.1355],\n",
      "        [ 13.8647],\n",
      "        [ 43.8195],\n",
      "        [ 52.0101]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 36.330284118652344\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 168\n",
      "剩餘X 資料 torch.Size([35, 10])\n",
      "剩餘Y 資料 torch.Size([35, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (2851.281494140625, 17)\n",
      "The second_loss value of k: (7331.001953125, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([176, 1])\n",
      "<<預測值>>\n",
      "tensor([[122.0586],\n",
      "        [  6.0178],\n",
      "        [216.6013],\n",
      "        [  6.0178],\n",
      "        [ 99.0929],\n",
      "        [ 46.2491],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 23.4963],\n",
      "        [ 20.8462],\n",
      "        [ 38.1942],\n",
      "        [  7.9764],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 29.1967],\n",
      "        [169.3437],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 61.9900],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 20.8462],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 30.0323],\n",
      "        [ 25.2874],\n",
      "        [ 14.0360],\n",
      "        [ 61.1815],\n",
      "        [ 13.0034],\n",
      "        [  6.0178],\n",
      "        [ 19.7904],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 45.1946],\n",
      "        [  6.0178],\n",
      "        [ 24.6272],\n",
      "        [ 10.6621],\n",
      "        [ 14.4764],\n",
      "        [  6.0178],\n",
      "        [ 11.0804],\n",
      "        [  6.0178],\n",
      "        [ 41.6992],\n",
      "        [ 17.6588],\n",
      "        [134.6924],\n",
      "        [ 18.5146],\n",
      "        [  7.3449],\n",
      "        [  8.9431],\n",
      "        [ 14.7750],\n",
      "        [ 18.5893],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 33.2490],\n",
      "        [ 33.2490],\n",
      "        [ 70.2354],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [120.8915],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 61.4555],\n",
      "        [ 80.3963],\n",
      "        [ 37.9601],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.3760],\n",
      "        [  6.3760],\n",
      "        [  6.0178],\n",
      "        [132.9758],\n",
      "        [  6.0178],\n",
      "        [ 28.2162],\n",
      "        [ 69.7161],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 93.3137],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 76.0598],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [141.4095],\n",
      "        [ 89.9928],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 68.6912],\n",
      "        [171.7099],\n",
      "        [  6.0178],\n",
      "        [ 66.4423],\n",
      "        [ 79.1355],\n",
      "        [ 13.8647],\n",
      "        [ 43.8195],\n",
      "        [ 52.0101],\n",
      "        [ 53.3974]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[195.9414],\n",
      "        [  6.0178],\n",
      "        [109.1687],\n",
      "        [  6.0178],\n",
      "        [ 99.0929],\n",
      "        [ 29.9891],\n",
      "        [  5.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  1.0178],\n",
      "        [  6.0178],\n",
      "        [ 23.4963],\n",
      "        [205.1538],\n",
      "        [ 49.1958],\n",
      "        [  7.9764],\n",
      "        [  6.0178],\n",
      "        [  6.9822],\n",
      "        [ 29.1967],\n",
      "        [169.3437],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 61.9900],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  3.9822],\n",
      "        [  4.0178],\n",
      "        [205.1538],\n",
      "        [  2.5178],\n",
      "        [  1.5378],\n",
      "        [  1.5178],\n",
      "        [  0.6822],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [  3.9822],\n",
      "        [  6.0178],\n",
      "        [  4.4822],\n",
      "        [ 68.9677],\n",
      "        [ 25.2874],\n",
      "        [ 14.0360],\n",
      "        [ 36.1015],\n",
      "        [ 13.0034],\n",
      "        [ 60.4822],\n",
      "        [ 19.7904],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 26.5822],\n",
      "        [ 26.9822],\n",
      "        [ 27.9822],\n",
      "        [ 28.9822],\n",
      "        [ 31.9822],\n",
      "        [  6.0178],\n",
      "        [ 45.1946],\n",
      "        [  6.0178],\n",
      "        [ 24.6272],\n",
      "        [ 10.6621],\n",
      "        [ 14.4764],\n",
      "        [  6.0178],\n",
      "        [ 11.0804],\n",
      "        [ 35.4822],\n",
      "        [ 25.3008],\n",
      "        [ 17.6588],\n",
      "        [ 28.4924],\n",
      "        [ 18.5146],\n",
      "        [  7.3449],\n",
      "        [  8.9431],\n",
      "        [ 14.7750],\n",
      "        [ 18.5893],\n",
      "        [ 37.9822],\n",
      "        [ 44.9822],\n",
      "        [ 48.9822],\n",
      "        [ 48.9822],\n",
      "        [142.9822],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 33.2490],\n",
      "        [ 33.2490],\n",
      "        [ 46.7354],\n",
      "        [  2.0178],\n",
      "        [ 58.4822],\n",
      "        [120.8915],\n",
      "        [229.9822],\n",
      "        [ 64.9822],\n",
      "        [ 17.7445],\n",
      "        [ 80.3963],\n",
      "        [ 37.9601],\n",
      "        [ 79.5822],\n",
      "        [ 80.9822],\n",
      "        [ 15.9240],\n",
      "        [ 15.9240],\n",
      "        [ 86.4822],\n",
      "        [ 73.0242],\n",
      "        [  6.0178],\n",
      "        [125.7838],\n",
      "        [ 28.2839],\n",
      "        [ 98.9822],\n",
      "        [ 98.9822],\n",
      "        [ 93.3137],\n",
      "        [107.4822],\n",
      "        [114.4122],\n",
      "        [132.9822],\n",
      "        [146.6522],\n",
      "        [146.6522],\n",
      "        [169.4822],\n",
      "        [173.9822],\n",
      "        [  6.0178],\n",
      "        [ 76.0598],\n",
      "        [183.9822],\n",
      "        [188.9822],\n",
      "        [193.9822],\n",
      "        [221.9822],\n",
      "        [207.5905],\n",
      "        [148.0072],\n",
      "        [  6.0178],\n",
      "        [  6.0178],\n",
      "        [ 68.6912],\n",
      "        [  5.2901],\n",
      "        [  6.0178],\n",
      "        [ 66.4423],\n",
      "        [ 79.1355],\n",
      "        [ 13.8647],\n",
      "        [ 43.8195],\n",
      "        [ 52.0101],\n",
      "        [ 53.3974]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4484.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[192.7278],\n",
      "        [  6.1423],\n",
      "        [108.9930],\n",
      "        [  6.1423],\n",
      "        [100.8762],\n",
      "        [ 33.6163],\n",
      "        [  5.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  1.1423],\n",
      "        [  6.1423],\n",
      "        [ 24.4451],\n",
      "        [209.2928],\n",
      "        [ 50.8481],\n",
      "        [  8.8996],\n",
      "        [  6.1423],\n",
      "        [  6.8577],\n",
      "        [ 31.0674],\n",
      "        [174.1241],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  7.9160],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 51.2000],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  3.8577],\n",
      "        [  4.1423],\n",
      "        [209.2928],\n",
      "        [  2.6423],\n",
      "        [  1.6623],\n",
      "        [  2.2855],\n",
      "        [  0.5577],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  3.8577],\n",
      "        [  6.1423],\n",
      "        [  4.3577],\n",
      "        [ 68.5423],\n",
      "        [ 25.6837],\n",
      "        [ 13.1851],\n",
      "        [ 36.3060],\n",
      "        [ 12.1899],\n",
      "        [ 60.3577],\n",
      "        [ 17.8159],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 26.4577],\n",
      "        [ 26.8577],\n",
      "        [ 27.8577],\n",
      "        [ 28.8577],\n",
      "        [ 31.8577],\n",
      "        [  6.1423],\n",
      "        [ 45.3353],\n",
      "        [  6.1423],\n",
      "        [ 23.3310],\n",
      "        [ 11.5267],\n",
      "        [ 15.6138],\n",
      "        [  6.1423],\n",
      "        [ 11.0498],\n",
      "        [ 35.3577],\n",
      "        [ 25.4093],\n",
      "        [ 17.1327],\n",
      "        [ 29.9747],\n",
      "        [ 18.5725],\n",
      "        [  6.1423],\n",
      "        [  7.7878],\n",
      "        [ 14.1093],\n",
      "        [ 18.1964],\n",
      "        [ 37.8577],\n",
      "        [ 44.8577],\n",
      "        [ 48.8577],\n",
      "        [ 48.8577],\n",
      "        [142.8577],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 32.8345],\n",
      "        [ 32.8345],\n",
      "        [ 49.0411],\n",
      "        [  2.1423],\n",
      "        [ 58.3577],\n",
      "        [122.6623],\n",
      "        [229.8577],\n",
      "        [ 64.8577],\n",
      "        [ 18.3451],\n",
      "        [ 77.8008],\n",
      "        [ 30.5822],\n",
      "        [ 79.4577],\n",
      "        [ 80.8577],\n",
      "        [ 16.1577],\n",
      "        [ 16.1577],\n",
      "        [ 86.3577],\n",
      "        [ 68.4901],\n",
      "        [  6.1423],\n",
      "        [125.2041],\n",
      "        [ 26.2560],\n",
      "        [ 98.8577],\n",
      "        [ 98.8577],\n",
      "        [ 92.4174],\n",
      "        [107.3577],\n",
      "        [114.2877],\n",
      "        [132.8577],\n",
      "        [146.5277],\n",
      "        [146.5277],\n",
      "        [169.3577],\n",
      "        [173.8577],\n",
      "        [  6.1423],\n",
      "        [ 74.8677],\n",
      "        [183.8577],\n",
      "        [188.8577],\n",
      "        [193.8577],\n",
      "        [221.8577],\n",
      "        [207.5738],\n",
      "        [148.3351],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 64.5134],\n",
      "        [ 17.4369],\n",
      "        [  6.1423],\n",
      "        [ 65.0680],\n",
      "        [ 78.2153],\n",
      "        [  7.2968],\n",
      "        [ 38.1159],\n",
      "        [ 44.6113],\n",
      "        [ 32.5414]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 36.58379793167114\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 169\n",
      "剩餘X 資料 torch.Size([34, 10])\n",
      "剩餘Y 資料 torch.Size([34, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (5777.78271484375, 0)\n",
      "The second_loss value of k: (10283.1796875, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([177, 1])\n",
      "<<預測值>>\n",
      "tensor([[125.2721],\n",
      "        [  6.1423],\n",
      "        [216.7769],\n",
      "        [  6.1423],\n",
      "        [100.8762],\n",
      "        [ 49.8763],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 24.4451],\n",
      "        [ 16.7072],\n",
      "        [ 36.5419],\n",
      "        [  8.8996],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 31.0674],\n",
      "        [174.1241],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  7.9160],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 51.2000],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 16.7072],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.7855],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 30.4577],\n",
      "        [ 25.6837],\n",
      "        [ 13.1851],\n",
      "        [ 61.3860],\n",
      "        [ 12.1899],\n",
      "        [  6.1423],\n",
      "        [ 17.8159],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 45.3353],\n",
      "        [  6.1423],\n",
      "        [ 23.3310],\n",
      "        [ 11.5267],\n",
      "        [ 15.6138],\n",
      "        [  6.1423],\n",
      "        [ 11.0498],\n",
      "        [  6.1423],\n",
      "        [ 41.5907],\n",
      "        [ 17.1327],\n",
      "        [136.1747],\n",
      "        [ 18.5725],\n",
      "        [  6.1423],\n",
      "        [  7.7878],\n",
      "        [ 14.1093],\n",
      "        [ 18.1964],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 32.8345],\n",
      "        [ 32.8345],\n",
      "        [ 72.5411],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [122.6623],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 60.8549],\n",
      "        [ 77.8008],\n",
      "        [ 30.5822],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [137.5099],\n",
      "        [  6.1423],\n",
      "        [ 28.7959],\n",
      "        [ 71.7440],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 92.4174],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 74.8677],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [141.4262],\n",
      "        [ 89.6648],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 64.5134],\n",
      "        [159.5631],\n",
      "        [  6.1423],\n",
      "        [ 65.0680],\n",
      "        [ 78.2153],\n",
      "        [  7.2968],\n",
      "        [ 38.1159],\n",
      "        [ 44.6113],\n",
      "        [ 32.5414],\n",
      "        [ 76.0117]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[192.7278],\n",
      "        [  6.1423],\n",
      "        [108.9930],\n",
      "        [  6.1423],\n",
      "        [100.8762],\n",
      "        [ 33.6163],\n",
      "        [  5.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  1.1423],\n",
      "        [  6.1423],\n",
      "        [ 24.4451],\n",
      "        [209.2928],\n",
      "        [ 50.8481],\n",
      "        [  8.8996],\n",
      "        [  6.1423],\n",
      "        [  6.8577],\n",
      "        [ 31.0674],\n",
      "        [174.1241],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  7.9160],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 51.2000],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  3.8577],\n",
      "        [  4.1423],\n",
      "        [209.2928],\n",
      "        [  2.6423],\n",
      "        [  1.6623],\n",
      "        [  2.2855],\n",
      "        [  0.5577],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [  3.8577],\n",
      "        [  6.1423],\n",
      "        [  4.3577],\n",
      "        [ 68.5423],\n",
      "        [ 25.6837],\n",
      "        [ 13.1851],\n",
      "        [ 36.3060],\n",
      "        [ 12.1899],\n",
      "        [ 60.3577],\n",
      "        [ 17.8159],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 26.4577],\n",
      "        [ 26.8577],\n",
      "        [ 27.8577],\n",
      "        [ 28.8577],\n",
      "        [ 31.8577],\n",
      "        [  6.1423],\n",
      "        [ 45.3353],\n",
      "        [  6.1423],\n",
      "        [ 23.3310],\n",
      "        [ 11.5267],\n",
      "        [ 15.6138],\n",
      "        [  6.1423],\n",
      "        [ 11.0498],\n",
      "        [ 35.3577],\n",
      "        [ 25.4093],\n",
      "        [ 17.1327],\n",
      "        [ 29.9747],\n",
      "        [ 18.5725],\n",
      "        [  6.1423],\n",
      "        [  7.7878],\n",
      "        [ 14.1093],\n",
      "        [ 18.1964],\n",
      "        [ 37.8577],\n",
      "        [ 44.8577],\n",
      "        [ 48.8577],\n",
      "        [ 48.8577],\n",
      "        [142.8577],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 32.8345],\n",
      "        [ 32.8345],\n",
      "        [ 49.0411],\n",
      "        [  2.1423],\n",
      "        [ 58.3577],\n",
      "        [122.6623],\n",
      "        [229.8577],\n",
      "        [ 64.8577],\n",
      "        [ 18.3451],\n",
      "        [ 77.8008],\n",
      "        [ 30.5822],\n",
      "        [ 79.4577],\n",
      "        [ 80.8577],\n",
      "        [ 16.1577],\n",
      "        [ 16.1577],\n",
      "        [ 86.3577],\n",
      "        [ 68.4901],\n",
      "        [  6.1423],\n",
      "        [125.2041],\n",
      "        [ 26.2560],\n",
      "        [ 98.8577],\n",
      "        [ 98.8577],\n",
      "        [ 92.4174],\n",
      "        [107.3577],\n",
      "        [114.2877],\n",
      "        [132.8577],\n",
      "        [146.5277],\n",
      "        [146.5277],\n",
      "        [169.3577],\n",
      "        [173.8577],\n",
      "        [  6.1423],\n",
      "        [ 74.8677],\n",
      "        [183.8577],\n",
      "        [188.8577],\n",
      "        [193.8577],\n",
      "        [221.8577],\n",
      "        [207.5738],\n",
      "        [148.3351],\n",
      "        [  6.1423],\n",
      "        [  6.1423],\n",
      "        [ 64.5134],\n",
      "        [ 17.4369],\n",
      "        [  6.1423],\n",
      "        [ 65.0680],\n",
      "        [ 78.2153],\n",
      "        [  7.2968],\n",
      "        [ 38.1159],\n",
      "        [ 44.6113],\n",
      "        [ 32.5414],\n",
      "        [ 76.0117]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4477.8726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[189.6377],\n",
      "        [  6.2301],\n",
      "        [109.9518],\n",
      "        [  6.2301],\n",
      "        [102.3555],\n",
      "        [ 36.1292],\n",
      "        [  5.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  1.2301],\n",
      "        [  6.2301],\n",
      "        [ 26.6875],\n",
      "        [212.6276],\n",
      "        [ 54.7474],\n",
      "        [  6.9147],\n",
      "        [  6.2301],\n",
      "        [  6.7699],\n",
      "        [ 31.9953],\n",
      "        [176.3540],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 10.8433],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.6276],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 61.1489],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  3.7699],\n",
      "        [  4.9352],\n",
      "        [212.6276],\n",
      "        [  2.7301],\n",
      "        [  1.7501],\n",
      "        [  4.5835],\n",
      "        [  0.4699],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  3.7699],\n",
      "        [  6.2301],\n",
      "        [  4.2699],\n",
      "        [ 67.7543],\n",
      "        [ 25.9337],\n",
      "        [ 12.8545],\n",
      "        [ 38.1792],\n",
      "        [ 11.7115],\n",
      "        [ 60.2699],\n",
      "        [ 22.0847],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 26.3699],\n",
      "        [ 26.7699],\n",
      "        [ 27.7699],\n",
      "        [ 28.7699],\n",
      "        [ 31.7699],\n",
      "        [  6.2301],\n",
      "        [ 45.2244],\n",
      "        [  6.2301],\n",
      "        [ 23.7139],\n",
      "        [ 12.8083],\n",
      "        [ 17.1115],\n",
      "        [  6.2301],\n",
      "        [ 11.5457],\n",
      "        [ 35.2699],\n",
      "        [ 25.1537],\n",
      "        [ 17.0028],\n",
      "        [ 30.3071],\n",
      "        [ 19.1058],\n",
      "        [  6.2301],\n",
      "        [  7.3722],\n",
      "        [ 14.0331],\n",
      "        [ 18.3362],\n",
      "        [ 37.7699],\n",
      "        [ 44.7699],\n",
      "        [ 48.7699],\n",
      "        [ 48.7699],\n",
      "        [142.7699],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 33.5655],\n",
      "        [ 33.5655],\n",
      "        [ 51.4127],\n",
      "        [  2.2301],\n",
      "        [ 58.2699],\n",
      "        [124.7718],\n",
      "        [229.7699],\n",
      "        [ 64.7699],\n",
      "        [ 17.9266],\n",
      "        [ 79.2839],\n",
      "        [ 37.5372],\n",
      "        [ 79.3699],\n",
      "        [ 80.7699],\n",
      "        [ 16.0699],\n",
      "        [ 16.0699],\n",
      "        [ 86.2699],\n",
      "        [ 66.2808],\n",
      "        [  6.2301],\n",
      "        [127.4445],\n",
      "        [ 25.0562],\n",
      "        [ 98.7699],\n",
      "        [ 98.7699],\n",
      "        [ 90.9925],\n",
      "        [107.2699],\n",
      "        [114.1999],\n",
      "        [132.7699],\n",
      "        [146.4399],\n",
      "        [146.4399],\n",
      "        [169.2699],\n",
      "        [173.7699],\n",
      "        [  6.2301],\n",
      "        [ 71.8574],\n",
      "        [183.7699],\n",
      "        [188.7699],\n",
      "        [193.7699],\n",
      "        [221.7699],\n",
      "        [208.2616],\n",
      "        [148.0694],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 58.2457],\n",
      "        [ 17.3510],\n",
      "        [  6.2301],\n",
      "        [ 56.6752],\n",
      "        [ 71.3109],\n",
      "        [  6.2301],\n",
      "        [ 22.1217],\n",
      "        [ 27.6101],\n",
      "        [ 20.9149],\n",
      "        [ 53.4402]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 36.836403369903564\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 170\n",
      "剩餘X 資料 torch.Size([33, 10])\n",
      "剩餘Y 資料 torch.Size([33, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (5533.859375, 2)\n",
      "The second_loss value of k: (6360.140625, 5)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([178, 1])\n",
      "<<預測值>>\n",
      "tensor([[128.3623],\n",
      "        [  6.2301],\n",
      "        [215.8182],\n",
      "        [  6.2301],\n",
      "        [102.3555],\n",
      "        [ 52.3892],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 26.6875],\n",
      "        [ 13.3724],\n",
      "        [ 32.6426],\n",
      "        [  6.9147],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 31.9953],\n",
      "        [176.3540],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 10.8433],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.6276],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 61.1489],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.9352],\n",
      "        [ 13.3724],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  9.0835],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 31.2457],\n",
      "        [ 25.9337],\n",
      "        [ 12.8545],\n",
      "        [ 63.2592],\n",
      "        [ 11.7115],\n",
      "        [  6.2301],\n",
      "        [ 22.0847],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 45.2244],\n",
      "        [  6.2301],\n",
      "        [ 23.7139],\n",
      "        [ 12.8083],\n",
      "        [ 17.1115],\n",
      "        [  6.2301],\n",
      "        [ 11.5457],\n",
      "        [  6.2301],\n",
      "        [ 41.8463],\n",
      "        [ 17.0028],\n",
      "        [136.5071],\n",
      "        [ 19.1058],\n",
      "        [  6.2301],\n",
      "        [  7.3722],\n",
      "        [ 14.0331],\n",
      "        [ 18.3362],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 33.5655],\n",
      "        [ 33.5655],\n",
      "        [ 74.9127],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [124.7718],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 61.2734],\n",
      "        [ 79.2839],\n",
      "        [ 37.5372],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [139.7192],\n",
      "        [  6.2301],\n",
      "        [ 26.5555],\n",
      "        [ 72.9438],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 90.9925],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 71.8574],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [140.7384],\n",
      "        [ 89.9306],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 58.2457],\n",
      "        [159.6490],\n",
      "        [  6.2301],\n",
      "        [ 56.6752],\n",
      "        [ 71.3109],\n",
      "        [  6.2301],\n",
      "        [ 22.1217],\n",
      "        [ 27.6101],\n",
      "        [ 20.9149],\n",
      "        [ 53.4402],\n",
      "        [ 74.3899]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[189.6377],\n",
      "        [  6.2301],\n",
      "        [109.9518],\n",
      "        [  6.2301],\n",
      "        [102.3555],\n",
      "        [ 36.1292],\n",
      "        [  5.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  1.2301],\n",
      "        [  6.2301],\n",
      "        [ 26.6875],\n",
      "        [212.6276],\n",
      "        [ 54.7474],\n",
      "        [  6.9147],\n",
      "        [  6.2301],\n",
      "        [  6.7699],\n",
      "        [ 31.9953],\n",
      "        [176.3540],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 10.8433],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.6276],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 61.1489],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  3.7699],\n",
      "        [  4.9352],\n",
      "        [212.6276],\n",
      "        [  2.7301],\n",
      "        [  1.7501],\n",
      "        [  4.5835],\n",
      "        [  0.4699],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [  3.7699],\n",
      "        [  6.2301],\n",
      "        [  4.2699],\n",
      "        [ 67.7543],\n",
      "        [ 25.9337],\n",
      "        [ 12.8545],\n",
      "        [ 38.1792],\n",
      "        [ 11.7115],\n",
      "        [ 60.2699],\n",
      "        [ 22.0847],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 26.3699],\n",
      "        [ 26.7699],\n",
      "        [ 27.7699],\n",
      "        [ 28.7699],\n",
      "        [ 31.7699],\n",
      "        [  6.2301],\n",
      "        [ 45.2244],\n",
      "        [  6.2301],\n",
      "        [ 23.7139],\n",
      "        [ 12.8083],\n",
      "        [ 17.1115],\n",
      "        [  6.2301],\n",
      "        [ 11.5457],\n",
      "        [ 35.2699],\n",
      "        [ 25.1537],\n",
      "        [ 17.0028],\n",
      "        [ 30.3071],\n",
      "        [ 19.1058],\n",
      "        [  6.2301],\n",
      "        [  7.3722],\n",
      "        [ 14.0331],\n",
      "        [ 18.3362],\n",
      "        [ 37.7699],\n",
      "        [ 44.7699],\n",
      "        [ 48.7699],\n",
      "        [ 48.7699],\n",
      "        [142.7699],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 33.5655],\n",
      "        [ 33.5655],\n",
      "        [ 51.4127],\n",
      "        [  2.2301],\n",
      "        [ 58.2699],\n",
      "        [124.7718],\n",
      "        [229.7699],\n",
      "        [ 64.7699],\n",
      "        [ 17.9266],\n",
      "        [ 79.2839],\n",
      "        [ 37.5372],\n",
      "        [ 79.3699],\n",
      "        [ 80.7699],\n",
      "        [ 16.0699],\n",
      "        [ 16.0699],\n",
      "        [ 86.2699],\n",
      "        [ 66.2808],\n",
      "        [  6.2301],\n",
      "        [127.4445],\n",
      "        [ 25.0562],\n",
      "        [ 98.7699],\n",
      "        [ 98.7699],\n",
      "        [ 90.9925],\n",
      "        [107.2699],\n",
      "        [114.1999],\n",
      "        [132.7699],\n",
      "        [146.4399],\n",
      "        [146.4399],\n",
      "        [169.2699],\n",
      "        [173.7699],\n",
      "        [  6.2301],\n",
      "        [ 71.8574],\n",
      "        [183.7699],\n",
      "        [188.7699],\n",
      "        [193.7699],\n",
      "        [221.7699],\n",
      "        [208.2616],\n",
      "        [148.0694],\n",
      "        [  6.2301],\n",
      "        [  6.2301],\n",
      "        [ 58.2457],\n",
      "        [ 17.3510],\n",
      "        [  6.2301],\n",
      "        [ 56.6752],\n",
      "        [ 71.3109],\n",
      "        [  6.2301],\n",
      "        [ 22.1217],\n",
      "        [ 27.6101],\n",
      "        [ 20.9149],\n",
      "        [ 53.4402],\n",
      "        [ 74.3899]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4469.0830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[187.6286],\n",
      "        [  6.3144],\n",
      "        [115.3196],\n",
      "        [  6.3144],\n",
      "        [100.9372],\n",
      "        [ 38.1440],\n",
      "        [  5.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  1.3144],\n",
      "        [  6.3144],\n",
      "        [ 29.5611],\n",
      "        [214.6358],\n",
      "        [ 57.3136],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.6856],\n",
      "        [ 32.3357],\n",
      "        [176.7495],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 15.7292],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 66.9806],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  3.6856],\n",
      "        [  5.5196],\n",
      "        [214.6358],\n",
      "        [  2.8144],\n",
      "        [  1.8344],\n",
      "        [  7.6103],\n",
      "        [  0.3856],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  3.6856],\n",
      "        [  6.3144],\n",
      "        [  4.1856],\n",
      "        [ 65.1800],\n",
      "        [ 24.9394],\n",
      "        [ 12.2728],\n",
      "        [ 37.9956],\n",
      "        [ 10.9588],\n",
      "        [ 60.1856],\n",
      "        [ 26.4216],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 26.2856],\n",
      "        [ 26.6856],\n",
      "        [ 27.6856],\n",
      "        [ 28.6856],\n",
      "        [ 31.6856],\n",
      "        [  6.7252],\n",
      "        [ 43.7017],\n",
      "        [  6.3144],\n",
      "        [ 24.3338],\n",
      "        [ 15.9758],\n",
      "        [ 20.6011],\n",
      "        [  6.3144],\n",
      "        [ 13.6058],\n",
      "        [ 35.1856],\n",
      "        [ 23.2658],\n",
      "        [ 18.2608],\n",
      "        [ 28.7518],\n",
      "        [ 21.2647],\n",
      "        [  8.9518],\n",
      "        [  8.0566],\n",
      "        [ 15.3188],\n",
      "        [ 19.9441],\n",
      "        [ 37.6856],\n",
      "        [ 44.6856],\n",
      "        [ 48.6856],\n",
      "        [ 48.6856],\n",
      "        [142.6856],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 34.7331],\n",
      "        [ 34.7331],\n",
      "        [ 50.9518],\n",
      "        [  2.3144],\n",
      "        [ 54.4638],\n",
      "        [125.2974],\n",
      "        [229.6856],\n",
      "        [ 64.6856],\n",
      "        [ 17.9505],\n",
      "        [ 79.3628],\n",
      "        [ 40.8714],\n",
      "        [ 79.2856],\n",
      "        [ 80.6856],\n",
      "        [ 15.9856],\n",
      "        [ 15.9856],\n",
      "        [ 86.1856],\n",
      "        [ 66.0301],\n",
      "        [  6.3144],\n",
      "        [130.1967],\n",
      "        [ 27.3690],\n",
      "        [ 98.6856],\n",
      "        [ 98.6856],\n",
      "        [ 87.1780],\n",
      "        [107.1856],\n",
      "        [114.1156],\n",
      "        [132.6856],\n",
      "        [146.3556],\n",
      "        [146.3556],\n",
      "        [169.1856],\n",
      "        [173.6856],\n",
      "        [  6.3144],\n",
      "        [ 69.9723],\n",
      "        [183.6856],\n",
      "        [188.6856],\n",
      "        [193.6856],\n",
      "        [221.6856],\n",
      "        [211.3820],\n",
      "        [151.6727],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 53.6112],\n",
      "        [ 22.2783],\n",
      "        [  6.3144],\n",
      "        [ 48.2058],\n",
      "        [ 65.0332],\n",
      "        [  6.3144],\n",
      "        [  8.1540],\n",
      "        [ 11.9735],\n",
      "        [  8.9858],\n",
      "        [ 32.1909],\n",
      "        [ 48.9998]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 37.09061813354492\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 171\n",
      "剩餘X 資料 torch.Size([32, 10])\n",
      "剩餘Y 資料 torch.Size([32, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (2554.37353515625, 2)\n",
      "The second_loss value of k: (3669.1513671875, 4)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([15.])\n",
      "目前模型的Data狀態 torch.Size([179, 1])\n",
      "<<預測值>>\n",
      "tensor([[130.3714],\n",
      "        [  6.3144],\n",
      "        [210.4504],\n",
      "        [  6.3144],\n",
      "        [100.9372],\n",
      "        [ 54.4040],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 29.5611],\n",
      "        [ 11.3642],\n",
      "        [ 30.0764],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 32.3357],\n",
      "        [176.7495],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 15.7292],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 66.9806],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  7.5196],\n",
      "        [ 11.3642],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 12.1103],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 33.8200],\n",
      "        [ 24.9394],\n",
      "        [ 12.2728],\n",
      "        [ 63.0756],\n",
      "        [ 10.9588],\n",
      "        [  6.3144],\n",
      "        [ 26.4216],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.7252],\n",
      "        [ 43.7017],\n",
      "        [  6.3144],\n",
      "        [ 24.3338],\n",
      "        [ 15.9758],\n",
      "        [ 20.6011],\n",
      "        [  6.3144],\n",
      "        [ 13.6058],\n",
      "        [  6.3144],\n",
      "        [ 43.7342],\n",
      "        [ 18.2608],\n",
      "        [134.9518],\n",
      "        [ 21.2647],\n",
      "        [  8.9518],\n",
      "        [  8.0566],\n",
      "        [ 15.3188],\n",
      "        [ 19.9441],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 34.7331],\n",
      "        [ 34.7331],\n",
      "        [ 74.4518],\n",
      "        [  6.3144],\n",
      "        [ 10.0362],\n",
      "        [125.2974],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 61.2495],\n",
      "        [ 79.3628],\n",
      "        [ 40.8714],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [139.9699],\n",
      "        [  6.3144],\n",
      "        [ 23.8033],\n",
      "        [ 70.6310],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 87.1780],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 69.9723],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [137.6180],\n",
      "        [ 86.3273],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 53.6112],\n",
      "        [154.7217],\n",
      "        [  6.3144],\n",
      "        [ 48.2058],\n",
      "        [ 65.0332],\n",
      "        [  6.3144],\n",
      "        [  8.1540],\n",
      "        [ 11.9735],\n",
      "        [  8.9858],\n",
      "        [ 32.1909],\n",
      "        [ 48.9998],\n",
      "        [ 65.5408]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[187.6286],\n",
      "        [  6.3144],\n",
      "        [115.3196],\n",
      "        [  6.3144],\n",
      "        [100.9372],\n",
      "        [ 38.1440],\n",
      "        [  5.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  1.3144],\n",
      "        [  6.3144],\n",
      "        [ 29.5611],\n",
      "        [214.6358],\n",
      "        [ 57.3136],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.6856],\n",
      "        [ 32.3357],\n",
      "        [176.7495],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 15.7292],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 66.9806],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  3.6856],\n",
      "        [  5.5196],\n",
      "        [214.6358],\n",
      "        [  2.8144],\n",
      "        [  1.8344],\n",
      "        [  7.6103],\n",
      "        [  0.3856],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [  3.6856],\n",
      "        [  6.3144],\n",
      "        [  4.1856],\n",
      "        [ 65.1800],\n",
      "        [ 24.9394],\n",
      "        [ 12.2728],\n",
      "        [ 37.9956],\n",
      "        [ 10.9588],\n",
      "        [ 60.1856],\n",
      "        [ 26.4216],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 26.2856],\n",
      "        [ 26.6856],\n",
      "        [ 27.6856],\n",
      "        [ 28.6856],\n",
      "        [ 31.6856],\n",
      "        [  6.7252],\n",
      "        [ 43.7017],\n",
      "        [  6.3144],\n",
      "        [ 24.3338],\n",
      "        [ 15.9758],\n",
      "        [ 20.6011],\n",
      "        [  6.3144],\n",
      "        [ 13.6058],\n",
      "        [ 35.1856],\n",
      "        [ 23.2658],\n",
      "        [ 18.2608],\n",
      "        [ 28.7518],\n",
      "        [ 21.2647],\n",
      "        [  8.9518],\n",
      "        [  8.0566],\n",
      "        [ 15.3188],\n",
      "        [ 19.9441],\n",
      "        [ 37.6856],\n",
      "        [ 44.6856],\n",
      "        [ 48.6856],\n",
      "        [ 48.6856],\n",
      "        [142.6856],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 34.7331],\n",
      "        [ 34.7331],\n",
      "        [ 50.9518],\n",
      "        [  2.3144],\n",
      "        [ 54.4638],\n",
      "        [125.2974],\n",
      "        [229.6856],\n",
      "        [ 64.6856],\n",
      "        [ 17.9505],\n",
      "        [ 79.3628],\n",
      "        [ 40.8714],\n",
      "        [ 79.2856],\n",
      "        [ 80.6856],\n",
      "        [ 15.9856],\n",
      "        [ 15.9856],\n",
      "        [ 86.1856],\n",
      "        [ 66.0301],\n",
      "        [  6.3144],\n",
      "        [130.1967],\n",
      "        [ 27.3690],\n",
      "        [ 98.6856],\n",
      "        [ 98.6856],\n",
      "        [ 87.1780],\n",
      "        [107.1856],\n",
      "        [114.1156],\n",
      "        [132.6856],\n",
      "        [146.3556],\n",
      "        [146.3556],\n",
      "        [169.1856],\n",
      "        [173.6856],\n",
      "        [  6.3144],\n",
      "        [ 69.9723],\n",
      "        [183.6856],\n",
      "        [188.6856],\n",
      "        [193.6856],\n",
      "        [221.6856],\n",
      "        [211.3820],\n",
      "        [151.6727],\n",
      "        [  6.3144],\n",
      "        [  6.3144],\n",
      "        [ 53.6112],\n",
      "        [ 22.2783],\n",
      "        [  6.3144],\n",
      "        [ 48.2058],\n",
      "        [ 65.0332],\n",
      "        [  6.3144],\n",
      "        [  8.1540],\n",
      "        [ 11.9735],\n",
      "        [  8.9858],\n",
      "        [ 32.1909],\n",
      "        [ 48.9998],\n",
      "        [ 50.5408]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4441.9644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[186.5770],\n",
      "        [  6.3644],\n",
      "        [114.7082],\n",
      "        [  6.3644],\n",
      "        [101.1381],\n",
      "        [ 39.1240],\n",
      "        [  5.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  1.3644],\n",
      "        [  6.3644],\n",
      "        [ 30.5319],\n",
      "        [213.8679],\n",
      "        [ 57.5673],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.6356],\n",
      "        [ 33.7250],\n",
      "        [177.8083],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 17.8035],\n",
      "        [  6.3644],\n",
      "        [  7.0801],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 70.1777],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  3.6356],\n",
      "        [  4.7191],\n",
      "        [213.8679],\n",
      "        [  2.8644],\n",
      "        [  1.8844],\n",
      "        [  8.0331],\n",
      "        [  0.3356],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  3.6356],\n",
      "        [  6.3644],\n",
      "        [  4.1356],\n",
      "        [ 63.9935],\n",
      "        [ 25.3498],\n",
      "        [ 12.1326],\n",
      "        [ 37.3023],\n",
      "        [ 10.8548],\n",
      "        [ 60.1356],\n",
      "        [ 24.9733],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 26.2356],\n",
      "        [ 26.6356],\n",
      "        [ 27.6356],\n",
      "        [ 28.6356],\n",
      "        [ 31.6356],\n",
      "        [  7.6505],\n",
      "        [ 44.0598],\n",
      "        [  6.3644],\n",
      "        [ 24.7000],\n",
      "        [ 17.3030],\n",
      "        [ 22.1292],\n",
      "        [  6.3644],\n",
      "        [ 14.3595],\n",
      "        [ 35.1356],\n",
      "        [ 22.3355],\n",
      "        [ 18.5754],\n",
      "        [ 30.3173],\n",
      "        [ 22.1347],\n",
      "        [  9.7443],\n",
      "        [  8.0578],\n",
      "        [ 15.7016],\n",
      "        [ 20.5278],\n",
      "        [ 37.6356],\n",
      "        [ 44.6356],\n",
      "        [ 48.6356],\n",
      "        [ 48.6356],\n",
      "        [142.6356],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 34.9771],\n",
      "        [ 34.9771],\n",
      "        [ 51.0318],\n",
      "        [  3.0714],\n",
      "        [ 52.8470],\n",
      "        [126.7897],\n",
      "        [229.6356],\n",
      "        [ 64.6356],\n",
      "        [ 18.9469],\n",
      "        [ 80.5754],\n",
      "        [ 42.6856],\n",
      "        [ 79.2356],\n",
      "        [ 80.6356],\n",
      "        [ 15.9356],\n",
      "        [ 15.9356],\n",
      "        [ 86.1356],\n",
      "        [ 65.3540],\n",
      "        [  6.3644],\n",
      "        [130.8901],\n",
      "        [ 28.4418],\n",
      "        [ 98.6356],\n",
      "        [ 98.6356],\n",
      "        [ 87.0406],\n",
      "        [107.1356],\n",
      "        [114.0656],\n",
      "        [132.6356],\n",
      "        [146.3056],\n",
      "        [146.3056],\n",
      "        [169.1356],\n",
      "        [173.6356],\n",
      "        [  6.3644],\n",
      "        [ 70.3056],\n",
      "        [183.6356],\n",
      "        [188.6356],\n",
      "        [193.6356],\n",
      "        [221.6356],\n",
      "        [210.7604],\n",
      "        [152.8062],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 53.5183],\n",
      "        [ 21.3100],\n",
      "        [  6.3644],\n",
      "        [ 46.7721],\n",
      "        [ 64.4058],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  8.3591],\n",
      "        [  7.5874],\n",
      "        [ 27.6010],\n",
      "        [ 44.3910],\n",
      "        [  5.9969]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 37.34682583808899\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 172\n",
      "剩餘X 資料 torch.Size([31, 10])\n",
      "剩餘Y 資料 torch.Size([31, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (3329.978515625, 3)\n",
      "The second_loss value of k: (41441.72265625, 18)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([180, 1])\n",
      "<<預測值>>\n",
      "tensor([[131.4230],\n",
      "        [  6.3644],\n",
      "        [211.0618],\n",
      "        [  6.3644],\n",
      "        [101.1381],\n",
      "        [ 55.3840],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 30.5319],\n",
      "        [ 12.1321],\n",
      "        [ 29.8227],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 33.7250],\n",
      "        [177.8083],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 17.8035],\n",
      "        [  6.3644],\n",
      "        [  7.0801],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 70.1777],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.7191],\n",
      "        [ 12.1321],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 12.5331],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 35.0065],\n",
      "        [ 25.3498],\n",
      "        [ 12.1326],\n",
      "        [ 62.3823],\n",
      "        [ 10.8548],\n",
      "        [  6.3644],\n",
      "        [ 24.9733],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  7.6505],\n",
      "        [ 44.0598],\n",
      "        [  6.3644],\n",
      "        [ 24.7000],\n",
      "        [ 17.3030],\n",
      "        [ 22.1292],\n",
      "        [  6.3644],\n",
      "        [ 14.3595],\n",
      "        [  6.3644],\n",
      "        [ 44.6645],\n",
      "        [ 18.5754],\n",
      "        [136.5173],\n",
      "        [ 22.1347],\n",
      "        [  9.7443],\n",
      "        [  8.0578],\n",
      "        [ 15.7016],\n",
      "        [ 20.5278],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 34.9771],\n",
      "        [ 34.9771],\n",
      "        [ 74.5318],\n",
      "        [  7.0714],\n",
      "        [ 11.6530],\n",
      "        [126.7897],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 60.2531],\n",
      "        [ 80.5754],\n",
      "        [ 42.6856],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [140.6460],\n",
      "        [  6.3644],\n",
      "        [ 23.1099],\n",
      "        [ 69.5582],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 87.0406],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 70.3056],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [138.2396],\n",
      "        [ 85.1938],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 53.5183],\n",
      "        [155.6900],\n",
      "        [  6.3644],\n",
      "        [ 46.7721],\n",
      "        [ 64.4058],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  8.3591],\n",
      "        [  7.5874],\n",
      "        [ 27.6010],\n",
      "        [ 44.3910],\n",
      "        [ 20.9969],\n",
      "        [ 57.7060]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[186.5770],\n",
      "        [  6.3644],\n",
      "        [114.7082],\n",
      "        [  6.3644],\n",
      "        [101.1381],\n",
      "        [ 39.1240],\n",
      "        [  5.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  1.3644],\n",
      "        [  6.3644],\n",
      "        [ 30.5319],\n",
      "        [213.8679],\n",
      "        [ 57.5673],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.6356],\n",
      "        [ 33.7250],\n",
      "        [177.8083],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 17.8035],\n",
      "        [  6.3644],\n",
      "        [  7.0801],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 70.1777],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  3.6356],\n",
      "        [  4.7191],\n",
      "        [213.8679],\n",
      "        [  2.8644],\n",
      "        [  1.8844],\n",
      "        [  8.0331],\n",
      "        [  0.3356],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  3.6356],\n",
      "        [  6.3644],\n",
      "        [  4.1356],\n",
      "        [ 63.9935],\n",
      "        [ 25.3498],\n",
      "        [ 12.1326],\n",
      "        [ 37.3023],\n",
      "        [ 10.8548],\n",
      "        [ 60.1356],\n",
      "        [ 24.9733],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 26.2356],\n",
      "        [ 26.6356],\n",
      "        [ 27.6356],\n",
      "        [ 28.6356],\n",
      "        [ 31.6356],\n",
      "        [  7.6505],\n",
      "        [ 44.0598],\n",
      "        [  6.3644],\n",
      "        [ 24.7000],\n",
      "        [ 17.3030],\n",
      "        [ 22.1292],\n",
      "        [  6.3644],\n",
      "        [ 14.3595],\n",
      "        [ 35.1356],\n",
      "        [ 22.3355],\n",
      "        [ 18.5754],\n",
      "        [ 30.3173],\n",
      "        [ 22.1347],\n",
      "        [  9.7443],\n",
      "        [  8.0578],\n",
      "        [ 15.7016],\n",
      "        [ 20.5278],\n",
      "        [ 37.6356],\n",
      "        [ 44.6356],\n",
      "        [ 48.6356],\n",
      "        [ 48.6356],\n",
      "        [142.6356],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 34.9771],\n",
      "        [ 34.9771],\n",
      "        [ 51.0318],\n",
      "        [  3.0714],\n",
      "        [ 52.8470],\n",
      "        [126.7897],\n",
      "        [229.6356],\n",
      "        [ 64.6356],\n",
      "        [ 18.9469],\n",
      "        [ 80.5754],\n",
      "        [ 42.6856],\n",
      "        [ 79.2356],\n",
      "        [ 80.6356],\n",
      "        [ 15.9356],\n",
      "        [ 15.9356],\n",
      "        [ 86.1356],\n",
      "        [ 65.3540],\n",
      "        [  6.3644],\n",
      "        [130.8901],\n",
      "        [ 28.4418],\n",
      "        [ 98.6356],\n",
      "        [ 98.6356],\n",
      "        [ 87.0406],\n",
      "        [107.1356],\n",
      "        [114.0656],\n",
      "        [132.6356],\n",
      "        [146.3056],\n",
      "        [146.3056],\n",
      "        [169.1356],\n",
      "        [173.6356],\n",
      "        [  6.3644],\n",
      "        [ 70.3056],\n",
      "        [183.6356],\n",
      "        [188.6356],\n",
      "        [193.6356],\n",
      "        [221.6356],\n",
      "        [210.7604],\n",
      "        [152.8062],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [ 53.5183],\n",
      "        [ 21.3100],\n",
      "        [  6.3644],\n",
      "        [ 46.7721],\n",
      "        [ 64.4058],\n",
      "        [  6.3644],\n",
      "        [  6.3644],\n",
      "        [  8.3591],\n",
      "        [  7.5874],\n",
      "        [ 27.6010],\n",
      "        [ 44.3910],\n",
      "        [  5.9969],\n",
      "        [ 57.7060]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4419.5913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[186.6637],\n",
      "        [  6.4079],\n",
      "        [116.5486],\n",
      "        [  6.4079],\n",
      "        [100.8651],\n",
      "        [ 40.0839],\n",
      "        [  5.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  1.4079],\n",
      "        [  6.4079],\n",
      "        [ 34.0571],\n",
      "        [213.3314],\n",
      "        [ 58.3262],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.5921],\n",
      "        [ 34.3911],\n",
      "        [176.7351],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 19.7212],\n",
      "        [  6.4079],\n",
      "        [  8.0796],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 71.5769],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  3.5921],\n",
      "        [  5.7344],\n",
      "        [213.3314],\n",
      "        [  2.9079],\n",
      "        [  1.9279],\n",
      "        [  8.1702],\n",
      "        [  0.2921],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  3.5921],\n",
      "        [  6.4079],\n",
      "        [  4.0921],\n",
      "        [ 64.4850],\n",
      "        [ 25.5711],\n",
      "        [ 12.4652],\n",
      "        [ 37.6723],\n",
      "        [ 10.7144],\n",
      "        [ 60.0921],\n",
      "        [ 27.9921],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 26.1921],\n",
      "        [ 26.5921],\n",
      "        [ 27.5921],\n",
      "        [ 28.5921],\n",
      "        [ 31.5921],\n",
      "        [  7.7845],\n",
      "        [ 43.7439],\n",
      "        [  6.4079],\n",
      "        [ 24.6570],\n",
      "        [ 17.4193],\n",
      "        [ 22.2367],\n",
      "        [  6.4079],\n",
      "        [ 14.1917],\n",
      "        [ 35.0921],\n",
      "        [ 23.2764],\n",
      "        [ 18.2104],\n",
      "        [ 28.4742],\n",
      "        [ 21.8106],\n",
      "        [  9.7692],\n",
      "        [  7.8003],\n",
      "        [ 15.2453],\n",
      "        [ 20.0627],\n",
      "        [ 37.5921],\n",
      "        [ 44.5921],\n",
      "        [ 48.5921],\n",
      "        [ 48.5921],\n",
      "        [142.5921],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 36.9254],\n",
      "        [ 36.9254],\n",
      "        [ 51.5597],\n",
      "        [  2.4079],\n",
      "        [ 52.0807],\n",
      "        [129.3427],\n",
      "        [229.5921],\n",
      "        [ 64.5921],\n",
      "        [ 17.5233],\n",
      "        [ 79.5352],\n",
      "        [ 43.6708],\n",
      "        [ 79.1921],\n",
      "        [ 79.8048],\n",
      "        [ 15.8921],\n",
      "        [ 15.8921],\n",
      "        [ 86.0921],\n",
      "        [ 65.7133],\n",
      "        [  6.4079],\n",
      "        [129.4909],\n",
      "        [ 27.9071],\n",
      "        [ 98.5921],\n",
      "        [ 98.5921],\n",
      "        [ 85.3823],\n",
      "        [107.0921],\n",
      "        [114.0221],\n",
      "        [132.5921],\n",
      "        [146.2621],\n",
      "        [146.2621],\n",
      "        [169.0921],\n",
      "        [173.5921],\n",
      "        [  6.4079],\n",
      "        [ 68.6337],\n",
      "        [183.5921],\n",
      "        [188.5921],\n",
      "        [193.5921],\n",
      "        [221.5921],\n",
      "        [212.3347],\n",
      "        [151.7684],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 52.0261],\n",
      "        [ 19.9580],\n",
      "        [  6.4079],\n",
      "        [ 47.2535],\n",
      "        [ 63.6404],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.9506],\n",
      "        [  6.5431],\n",
      "        [ 24.7974],\n",
      "        [ 41.6230],\n",
      "        [  0.8954],\n",
      "        [ 55.1881]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 37.601412296295166\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 173\n",
      "剩餘X 資料 torch.Size([30, 10])\n",
      "剩餘Y 資料 torch.Size([30, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (41232.7109375, 17)\n",
      "The second_loss value of k: (52790.82421875, 19)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([181, 1])\n",
      "<<預測值>>\n",
      "tensor([[131.3363],\n",
      "        [  6.4079],\n",
      "        [209.2214],\n",
      "        [  6.4079],\n",
      "        [100.8651],\n",
      "        [ 56.3439],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 34.0571],\n",
      "        [ 12.6686],\n",
      "        [ 29.0638],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 34.3911],\n",
      "        [176.7351],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 19.7212],\n",
      "        [  6.4079],\n",
      "        [  8.0796],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 71.5769],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  7.7344],\n",
      "        [ 12.6686],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 12.6702],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 34.5150],\n",
      "        [ 25.5711],\n",
      "        [ 12.4652],\n",
      "        [ 62.7523],\n",
      "        [ 10.7144],\n",
      "        [  6.4079],\n",
      "        [ 27.9921],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  7.7845],\n",
      "        [ 43.7439],\n",
      "        [  6.4079],\n",
      "        [ 24.6570],\n",
      "        [ 17.4193],\n",
      "        [ 22.2367],\n",
      "        [  6.4079],\n",
      "        [ 14.1917],\n",
      "        [  6.4079],\n",
      "        [ 43.7236],\n",
      "        [ 18.2104],\n",
      "        [134.6741],\n",
      "        [ 21.8106],\n",
      "        [  9.7692],\n",
      "        [  7.8003],\n",
      "        [ 15.2453],\n",
      "        [ 20.0627],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 36.9254],\n",
      "        [ 36.9254],\n",
      "        [ 75.0597],\n",
      "        [  6.4079],\n",
      "        [ 12.4193],\n",
      "        [129.3427],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 61.6767],\n",
      "        [ 79.5352],\n",
      "        [ 43.6708],\n",
      "        [  6.4079],\n",
      "        [  7.1952],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [140.2867],\n",
      "        [  6.4079],\n",
      "        [ 24.5091],\n",
      "        [ 70.0929],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 85.3823],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 68.6337],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [136.6653],\n",
      "        [ 86.2316],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 52.0261],\n",
      "        [157.0420],\n",
      "        [  6.4079],\n",
      "        [ 47.2535],\n",
      "        [ 63.6404],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.9506],\n",
      "        [  6.5431],\n",
      "        [ 24.7974],\n",
      "        [ 41.6230],\n",
      "        [ 15.8954],\n",
      "        [ 55.1881],\n",
      "        [203.0584]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[186.6637],\n",
      "        [  6.4079],\n",
      "        [116.5486],\n",
      "        [  6.4079],\n",
      "        [100.8651],\n",
      "        [ 40.0839],\n",
      "        [  5.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  1.4079],\n",
      "        [  6.4079],\n",
      "        [ 34.0571],\n",
      "        [213.3314],\n",
      "        [ 58.3262],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.5921],\n",
      "        [ 34.3911],\n",
      "        [176.7351],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 19.7212],\n",
      "        [  6.4079],\n",
      "        [  8.0796],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 71.5769],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  3.5921],\n",
      "        [  5.7344],\n",
      "        [213.3314],\n",
      "        [  2.9079],\n",
      "        [  1.9279],\n",
      "        [  8.1702],\n",
      "        [  0.2921],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  3.5921],\n",
      "        [  6.4079],\n",
      "        [  4.0921],\n",
      "        [ 64.4850],\n",
      "        [ 25.5711],\n",
      "        [ 12.4652],\n",
      "        [ 37.6723],\n",
      "        [ 10.7144],\n",
      "        [ 60.0921],\n",
      "        [ 27.9921],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 26.1921],\n",
      "        [ 26.5921],\n",
      "        [ 27.5921],\n",
      "        [ 28.5921],\n",
      "        [ 31.5921],\n",
      "        [  7.7845],\n",
      "        [ 43.7439],\n",
      "        [  6.4079],\n",
      "        [ 24.6570],\n",
      "        [ 17.4193],\n",
      "        [ 22.2367],\n",
      "        [  6.4079],\n",
      "        [ 14.1917],\n",
      "        [ 35.0921],\n",
      "        [ 23.2764],\n",
      "        [ 18.2104],\n",
      "        [ 28.4742],\n",
      "        [ 21.8106],\n",
      "        [  9.7692],\n",
      "        [  7.8003],\n",
      "        [ 15.2453],\n",
      "        [ 20.0627],\n",
      "        [ 37.5921],\n",
      "        [ 44.5921],\n",
      "        [ 48.5921],\n",
      "        [ 48.5921],\n",
      "        [142.5921],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 36.9254],\n",
      "        [ 36.9254],\n",
      "        [ 51.5597],\n",
      "        [  2.4079],\n",
      "        [ 52.0807],\n",
      "        [129.3427],\n",
      "        [229.5921],\n",
      "        [ 64.5921],\n",
      "        [ 17.5233],\n",
      "        [ 79.5352],\n",
      "        [ 43.6708],\n",
      "        [ 79.1921],\n",
      "        [ 79.8048],\n",
      "        [ 15.8921],\n",
      "        [ 15.8921],\n",
      "        [ 86.0921],\n",
      "        [ 65.7133],\n",
      "        [  6.4079],\n",
      "        [129.4909],\n",
      "        [ 27.9071],\n",
      "        [ 98.5921],\n",
      "        [ 98.5921],\n",
      "        [ 85.3823],\n",
      "        [107.0921],\n",
      "        [114.0221],\n",
      "        [132.5921],\n",
      "        [146.2621],\n",
      "        [146.2621],\n",
      "        [169.0921],\n",
      "        [173.5921],\n",
      "        [  6.4079],\n",
      "        [ 68.6337],\n",
      "        [183.5921],\n",
      "        [188.5921],\n",
      "        [193.5921],\n",
      "        [221.5921],\n",
      "        [212.3347],\n",
      "        [151.7684],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [ 52.0261],\n",
      "        [ 19.9580],\n",
      "        [  6.4079],\n",
      "        [ 47.2535],\n",
      "        [ 63.6404],\n",
      "        [  6.4079],\n",
      "        [  6.4079],\n",
      "        [  6.9506],\n",
      "        [  6.5431],\n",
      "        [ 24.7974],\n",
      "        [ 41.6230],\n",
      "        [  0.8954],\n",
      "        [ 55.1881],\n",
      "        [203.0584]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4619.1528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  165.9211],\n",
      "        [    6.7130],\n",
      "        [  107.6993],\n",
      "        [    6.7130],\n",
      "        [  105.5033],\n",
      "        [   53.6717],\n",
      "        [    5.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    1.7130],\n",
      "        [    6.7130],\n",
      "        [   16.9494],\n",
      "        [  219.2870],\n",
      "        [   80.6770],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.2870],\n",
      "        [   16.3960],\n",
      "        [  217.2352],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    9.6356],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [   14.9536],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    3.2870],\n",
      "        [    4.7130],\n",
      "        [  219.2870],\n",
      "        [    3.2130],\n",
      "        [    2.2330],\n",
      "        [    2.2130],\n",
      "        [    0.0130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    3.2870],\n",
      "        [    6.7130],\n",
      "        [    3.7870],\n",
      "        [   76.8158],\n",
      "        [   19.9436],\n",
      "        [    8.5901],\n",
      "        [   45.2990],\n",
      "        [    7.4058],\n",
      "        [   59.7870],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [   25.8870],\n",
      "        [   26.2870],\n",
      "        [   27.2870],\n",
      "        [   28.2870],\n",
      "        [   31.2870],\n",
      "        [    6.7130],\n",
      "        [   40.5998],\n",
      "        [    6.7130],\n",
      "        [   15.5676],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [   34.7870],\n",
      "        [   32.3960],\n",
      "        [    7.4125],\n",
      "        [   25.3013],\n",
      "        [   10.8105],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    7.7168],\n",
      "        [   11.3336],\n",
      "        [   37.2870],\n",
      "        [   44.2870],\n",
      "        [   48.2870],\n",
      "        [   48.2870],\n",
      "        [  142.2870],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [   28.5811],\n",
      "        [   28.5811],\n",
      "        [   32.8518],\n",
      "        [    2.7130],\n",
      "        [   57.7870],\n",
      "        [  117.9037],\n",
      "        [  229.2870],\n",
      "        [   64.2870],\n",
      "        [   30.4405],\n",
      "        [   64.9203],\n",
      "        [    6.7130],\n",
      "        [   78.8870],\n",
      "        [   80.2870],\n",
      "        [   15.5870],\n",
      "        [   15.5870],\n",
      "        [   85.7870],\n",
      "        [   25.9654],\n",
      "        [    6.7130],\n",
      "        [  138.6526],\n",
      "        [    1.7529],\n",
      "        [   98.2870],\n",
      "        [   98.2870],\n",
      "        [   91.3083],\n",
      "        [  106.7870],\n",
      "        [  113.7170],\n",
      "        [  132.2870],\n",
      "        [  145.9570],\n",
      "        [  145.9570],\n",
      "        [  168.7870],\n",
      "        [  173.2870],\n",
      "        [    6.7130],\n",
      "        [   49.8781],\n",
      "        [  183.2870],\n",
      "        [  188.2870],\n",
      "        [  193.2870],\n",
      "        [  221.2870],\n",
      "        [  208.9471],\n",
      "        [  148.1763],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [   78.7915],\n",
      "        [    6.7130],\n",
      "        [   16.1657],\n",
      "        [   35.8546],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    8.2870],\n",
      "        [    6.7130],\n",
      "        [   70.7449]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 37.85453486442566\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 174\n",
      "剩餘X 資料 torch.Size([29, 10])\n",
      "剩餘Y 資料 torch.Size([29, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (50338.85546875, 18)\n",
      "The second_loss value of k: (73055.0703125, 16)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引18，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([182, 1])\n",
      "<<預測值>>\n",
      "tensor([[152.0789],\n",
      "        [  6.7130],\n",
      "        [218.0707],\n",
      "        [  6.7130],\n",
      "        [105.5033],\n",
      "        [ 69.9317],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 16.9494],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 16.3960],\n",
      "        [217.2352],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  9.6356],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 14.9536],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 22.1842],\n",
      "        [ 19.9436],\n",
      "        [  8.5901],\n",
      "        [ 70.3790],\n",
      "        [  7.4058],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 40.5998],\n",
      "        [  6.7130],\n",
      "        [ 15.5676],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 34.6040],\n",
      "        [  7.4125],\n",
      "        [131.5013],\n",
      "        [ 10.8105],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  7.7168],\n",
      "        [ 11.3336],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 28.5811],\n",
      "        [ 28.5811],\n",
      "        [ 56.3518],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [117.9037],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 48.7595],\n",
      "        [ 64.9203],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [180.0346],\n",
      "        [  6.7130],\n",
      "        [ 15.3474],\n",
      "        [ 96.2471],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 91.3083],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 49.8781],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [140.0529],\n",
      "        [ 89.8237],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 98.2085],\n",
      "        [  6.7130],\n",
      "        [ 16.1657],\n",
      "        [ 35.8546],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [  6.7130],\n",
      "        [ 70.7449],\n",
      "        [224.3632]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  165.9211],\n",
      "        [    6.7130],\n",
      "        [  107.6993],\n",
      "        [    6.7130],\n",
      "        [  105.5033],\n",
      "        [   53.6717],\n",
      "        [    5.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    1.7130],\n",
      "        [    6.7130],\n",
      "        [   16.9494],\n",
      "        [  219.2870],\n",
      "        [   80.6770],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.2870],\n",
      "        [   16.3960],\n",
      "        [  217.2352],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    9.6356],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [   14.9536],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    3.2870],\n",
      "        [    4.7130],\n",
      "        [  219.2870],\n",
      "        [    3.2130],\n",
      "        [    2.2330],\n",
      "        [    2.2130],\n",
      "        [    0.0130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    3.2870],\n",
      "        [    6.7130],\n",
      "        [    3.7870],\n",
      "        [   76.8158],\n",
      "        [   19.9436],\n",
      "        [    8.5901],\n",
      "        [   45.2990],\n",
      "        [    7.4058],\n",
      "        [   59.7870],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [   25.8870],\n",
      "        [   26.2870],\n",
      "        [   27.2870],\n",
      "        [   28.2870],\n",
      "        [   31.2870],\n",
      "        [    6.7130],\n",
      "        [   40.5998],\n",
      "        [    6.7130],\n",
      "        [   15.5676],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [   34.7870],\n",
      "        [   32.3960],\n",
      "        [    7.4125],\n",
      "        [   25.3013],\n",
      "        [   10.8105],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    7.7168],\n",
      "        [   11.3336],\n",
      "        [   37.2870],\n",
      "        [   44.2870],\n",
      "        [   48.2870],\n",
      "        [   48.2870],\n",
      "        [  142.2870],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [   28.5811],\n",
      "        [   28.5811],\n",
      "        [   32.8518],\n",
      "        [    2.7130],\n",
      "        [   57.7870],\n",
      "        [  117.9037],\n",
      "        [  229.2870],\n",
      "        [   64.2870],\n",
      "        [   30.4405],\n",
      "        [   64.9203],\n",
      "        [    6.7130],\n",
      "        [   78.8870],\n",
      "        [   80.2870],\n",
      "        [   15.5870],\n",
      "        [   15.5870],\n",
      "        [   85.7870],\n",
      "        [   25.9654],\n",
      "        [    6.7130],\n",
      "        [  138.6526],\n",
      "        [    1.7529],\n",
      "        [   98.2870],\n",
      "        [   98.2870],\n",
      "        [   91.3083],\n",
      "        [  106.7870],\n",
      "        [  113.7170],\n",
      "        [  132.2870],\n",
      "        [  145.9570],\n",
      "        [  145.9570],\n",
      "        [  168.7870],\n",
      "        [  173.2870],\n",
      "        [    6.7130],\n",
      "        [   49.8781],\n",
      "        [  183.2870],\n",
      "        [  188.2870],\n",
      "        [  193.2870],\n",
      "        [  221.2870],\n",
      "        [  208.9471],\n",
      "        [  148.1763],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [   78.7915],\n",
      "        [    6.7130],\n",
      "        [   16.1657],\n",
      "        [   35.8546],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    6.7130],\n",
      "        [    8.2870],\n",
      "        [    6.7130],\n",
      "        [   70.7449],\n",
      "        [  224.3632]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4599.2603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 80\n",
      "Number of shrink: 20\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[207.9669],\n",
      "        [  7.1395],\n",
      "        [ 78.7548],\n",
      "        [  7.1395],\n",
      "        [106.3677],\n",
      "        [ 16.2710],\n",
      "        [  6.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  2.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [218.8605],\n",
      "        [ 80.2505],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  5.8605],\n",
      "        [  7.1395],\n",
      "        [179.0949],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  2.8605],\n",
      "        [  5.1395],\n",
      "        [218.8605],\n",
      "        [  3.6395],\n",
      "        [  2.6595],\n",
      "        [  2.6395],\n",
      "        [  0.4395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  2.8605],\n",
      "        [  7.1395],\n",
      "        [  3.3605],\n",
      "        [ 78.2002],\n",
      "        [ 19.5418],\n",
      "        [  8.2397],\n",
      "        [ 30.7024],\n",
      "        [  8.6195],\n",
      "        [ 59.3605],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 25.4605],\n",
      "        [ 25.8605],\n",
      "        [ 26.8605],\n",
      "        [ 27.8605],\n",
      "        [ 30.8605],\n",
      "        [  7.1395],\n",
      "        [ 44.8255],\n",
      "        [  7.1395],\n",
      "        [ 10.8466],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 34.3605],\n",
      "        [ 29.6411],\n",
      "        [  7.1395],\n",
      "        [ 41.1254],\n",
      "        [  8.7688],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.7772],\n",
      "        [ 11.0329],\n",
      "        [ 36.8605],\n",
      "        [ 43.8605],\n",
      "        [ 47.8605],\n",
      "        [ 47.8605],\n",
      "        [141.8605],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 21.6219],\n",
      "        [ 21.6219],\n",
      "        [ 12.9037],\n",
      "        [  3.1395],\n",
      "        [ 57.3605],\n",
      "        [115.4271],\n",
      "        [228.8605],\n",
      "        [ 63.8605],\n",
      "        [ 18.6256],\n",
      "        [ 54.3456],\n",
      "        [  7.1395],\n",
      "        [ 78.4605],\n",
      "        [ 79.8605],\n",
      "        [ 15.1605],\n",
      "        [ 15.1605],\n",
      "        [ 85.3605],\n",
      "        [ 69.1444],\n",
      "        [  7.1395],\n",
      "        [146.8605],\n",
      "        [ 25.3170],\n",
      "        [ 97.8605],\n",
      "        [ 97.8605],\n",
      "        [108.5700],\n",
      "        [106.3605],\n",
      "        [113.2905],\n",
      "        [131.8605],\n",
      "        [145.5305],\n",
      "        [145.5305],\n",
      "        [168.3605],\n",
      "        [172.8605],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [182.8605],\n",
      "        [187.8605],\n",
      "        [192.8605],\n",
      "        [220.8605],\n",
      "        [189.4454],\n",
      "        [138.4272],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [169.8605],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.8605],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 38.106635332107544\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 175\n",
      "剩餘X 資料 torch.Size([28, 10])\n",
      "剩餘Y 資料 torch.Size([28, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (15343.4453125, 26)\n",
      "The second_loss value of k: (42331.9140625, 4)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引26，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([183, 1])\n",
      "<<預測值>>\n",
      "tensor([[110.0331],\n",
      "        [  7.1395],\n",
      "        [247.0152],\n",
      "        [  7.1395],\n",
      "        [106.3677],\n",
      "        [ 32.5310],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [179.0949],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 20.7998],\n",
      "        [ 19.5418],\n",
      "        [  8.2397],\n",
      "        [ 55.7824],\n",
      "        [  8.6195],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 44.8255],\n",
      "        [  7.1395],\n",
      "        [ 10.8466],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 37.3589],\n",
      "        [  7.1395],\n",
      "        [147.3254],\n",
      "        [  8.7688],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.7772],\n",
      "        [ 11.0329],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 21.6219],\n",
      "        [ 21.6219],\n",
      "        [ 36.4037],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [115.4271],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 60.5744],\n",
      "        [ 54.3456],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [136.8556],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 72.6830],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [108.5700],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [159.5546],\n",
      "        [ 99.5727],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [123.8687]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[207.9669],\n",
      "        [  7.1395],\n",
      "        [ 78.7548],\n",
      "        [  7.1395],\n",
      "        [106.3677],\n",
      "        [ 16.2710],\n",
      "        [  6.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  2.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [218.8605],\n",
      "        [ 80.2505],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  5.8605],\n",
      "        [  7.1395],\n",
      "        [179.0949],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  2.8605],\n",
      "        [  5.1395],\n",
      "        [218.8605],\n",
      "        [  3.6395],\n",
      "        [  2.6595],\n",
      "        [  2.6395],\n",
      "        [  0.4395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  2.8605],\n",
      "        [  7.1395],\n",
      "        [  3.3605],\n",
      "        [ 78.2002],\n",
      "        [ 19.5418],\n",
      "        [  8.2397],\n",
      "        [ 30.7024],\n",
      "        [  8.6195],\n",
      "        [ 59.3605],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 25.4605],\n",
      "        [ 25.8605],\n",
      "        [ 26.8605],\n",
      "        [ 27.8605],\n",
      "        [ 30.8605],\n",
      "        [  7.1395],\n",
      "        [ 44.8255],\n",
      "        [  7.1395],\n",
      "        [ 10.8466],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 34.3605],\n",
      "        [ 29.6411],\n",
      "        [  7.1395],\n",
      "        [ 41.1254],\n",
      "        [  8.7688],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.7772],\n",
      "        [ 11.0329],\n",
      "        [ 36.8605],\n",
      "        [ 43.8605],\n",
      "        [ 47.8605],\n",
      "        [ 47.8605],\n",
      "        [141.8605],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [ 21.6219],\n",
      "        [ 21.6219],\n",
      "        [ 12.9037],\n",
      "        [  3.1395],\n",
      "        [ 57.3605],\n",
      "        [115.4271],\n",
      "        [228.8605],\n",
      "        [ 63.8605],\n",
      "        [ 18.6256],\n",
      "        [ 54.3456],\n",
      "        [  7.1395],\n",
      "        [ 78.4605],\n",
      "        [ 79.8605],\n",
      "        [ 15.1605],\n",
      "        [ 15.1605],\n",
      "        [ 85.3605],\n",
      "        [ 69.1444],\n",
      "        [  7.1395],\n",
      "        [146.8605],\n",
      "        [ 25.3170],\n",
      "        [ 97.8605],\n",
      "        [ 97.8605],\n",
      "        [108.5700],\n",
      "        [106.3605],\n",
      "        [113.2905],\n",
      "        [131.8605],\n",
      "        [145.5305],\n",
      "        [145.5305],\n",
      "        [168.3605],\n",
      "        [172.8605],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [182.8605],\n",
      "        [187.8605],\n",
      "        [192.8605],\n",
      "        [220.8605],\n",
      "        [189.4454],\n",
      "        [138.4272],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [169.8605],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.8605],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [  7.1395],\n",
      "        [123.8687]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4380.1943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[205.9137],\n",
      "        [  7.3566],\n",
      "        [ 62.9803],\n",
      "        [  7.3566],\n",
      "        [110.2432],\n",
      "        [  8.5668],\n",
      "        [  6.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  2.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [218.6434],\n",
      "        [ 80.0334],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  5.6434],\n",
      "        [  7.3566],\n",
      "        [185.5300],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 10.6095],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  2.6434],\n",
      "        [  5.3566],\n",
      "        [218.6434],\n",
      "        [  3.8566],\n",
      "        [  2.8766],\n",
      "        [  2.8566],\n",
      "        [  0.6566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  2.6434],\n",
      "        [  7.3566],\n",
      "        [  3.1434],\n",
      "        [ 78.6796],\n",
      "        [ 13.7108],\n",
      "        [  7.3566],\n",
      "        [ 37.0390],\n",
      "        [  7.3566],\n",
      "        [ 59.1434],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 25.2434],\n",
      "        [ 25.6434],\n",
      "        [ 26.6434],\n",
      "        [ 27.6434],\n",
      "        [ 30.6434],\n",
      "        [  7.3566],\n",
      "        [ 42.3123],\n",
      "        [  7.3566],\n",
      "        [ 11.1025],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 34.1434],\n",
      "        [ 26.9711],\n",
      "        [  7.3566],\n",
      "        [ 45.5790],\n",
      "        [  7.6975],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  8.2136],\n",
      "        [ 11.2403],\n",
      "        [ 36.6434],\n",
      "        [ 43.6434],\n",
      "        [ 47.6434],\n",
      "        [ 47.6434],\n",
      "        [141.6434],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 21.3186],\n",
      "        [ 21.3186],\n",
      "        [ 15.7419],\n",
      "        [  3.3566],\n",
      "        [ 57.1434],\n",
      "        [115.8148],\n",
      "        [228.6434],\n",
      "        [ 63.6434],\n",
      "        [ 14.7110],\n",
      "        [ 58.8061],\n",
      "        [  7.3566],\n",
      "        [ 78.2434],\n",
      "        [ 79.6434],\n",
      "        [ 14.9434],\n",
      "        [ 14.9434],\n",
      "        [ 85.1434],\n",
      "        [ 67.0635],\n",
      "        [  7.3566],\n",
      "        [146.6434],\n",
      "        [ 23.8330],\n",
      "        [ 97.6434],\n",
      "        [ 97.6434],\n",
      "        [114.5806],\n",
      "        [106.1434],\n",
      "        [113.0734],\n",
      "        [131.6434],\n",
      "        [145.3134],\n",
      "        [145.3134],\n",
      "        [168.1434],\n",
      "        [172.6434],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [182.6434],\n",
      "        [187.6434],\n",
      "        [192.6434],\n",
      "        [220.6434],\n",
      "        [180.3685],\n",
      "        [131.0521],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [169.6434],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.6434],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.4845]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 38.35831618309021\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 176\n",
      "剩餘X 資料 torch.Size([27, 10])\n",
      "剩餘Y 資料 torch.Size([27, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (31743.427734375, 4)\n",
      "The second_loss value of k: (72707.546875, 16)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引4，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([184, 1])\n",
      "<<預測值>>\n",
      "tensor([[112.0863],\n",
      "        [  7.3566],\n",
      "        [262.7897],\n",
      "        [  7.3566],\n",
      "        [110.2432],\n",
      "        [ 24.8268],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [185.5300],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 10.6095],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 20.3204],\n",
      "        [ 13.7108],\n",
      "        [  7.3566],\n",
      "        [ 62.1190],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 42.3123],\n",
      "        [  7.3566],\n",
      "        [ 11.1025],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 40.0289],\n",
      "        [  7.3566],\n",
      "        [151.7790],\n",
      "        [  7.6975],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  8.2136],\n",
      "        [ 11.2403],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 21.3186],\n",
      "        [ 21.3186],\n",
      "        [ 39.2419],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [115.8148],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 64.4890],\n",
      "        [ 58.8061],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [138.9365],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 74.1670],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [114.5806],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [168.6315],\n",
      "        [106.9479],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.4845],\n",
      "        [178.1669]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[205.9137],\n",
      "        [  7.3566],\n",
      "        [ 62.9803],\n",
      "        [  7.3566],\n",
      "        [110.2432],\n",
      "        [  8.5668],\n",
      "        [  6.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  2.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [218.6434],\n",
      "        [ 80.0334],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  5.6434],\n",
      "        [  7.3566],\n",
      "        [185.5300],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 10.6095],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  2.6434],\n",
      "        [  5.3566],\n",
      "        [218.6434],\n",
      "        [  3.8566],\n",
      "        [  2.8766],\n",
      "        [  2.8566],\n",
      "        [  0.6566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  2.6434],\n",
      "        [  7.3566],\n",
      "        [  3.1434],\n",
      "        [ 78.6796],\n",
      "        [ 13.7108],\n",
      "        [  7.3566],\n",
      "        [ 37.0390],\n",
      "        [  7.3566],\n",
      "        [ 59.1434],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 25.2434],\n",
      "        [ 25.6434],\n",
      "        [ 26.6434],\n",
      "        [ 27.6434],\n",
      "        [ 30.6434],\n",
      "        [  7.3566],\n",
      "        [ 42.3123],\n",
      "        [  7.3566],\n",
      "        [ 11.1025],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 34.1434],\n",
      "        [ 26.9711],\n",
      "        [  7.3566],\n",
      "        [ 45.5790],\n",
      "        [  7.6975],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  8.2136],\n",
      "        [ 11.2403],\n",
      "        [ 36.6434],\n",
      "        [ 43.6434],\n",
      "        [ 47.6434],\n",
      "        [ 47.6434],\n",
      "        [141.6434],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [ 21.3186],\n",
      "        [ 21.3186],\n",
      "        [ 15.7419],\n",
      "        [  3.3566],\n",
      "        [ 57.1434],\n",
      "        [115.8148],\n",
      "        [228.6434],\n",
      "        [ 63.6434],\n",
      "        [ 14.7110],\n",
      "        [ 58.8061],\n",
      "        [  7.3566],\n",
      "        [ 78.2434],\n",
      "        [ 79.6434],\n",
      "        [ 14.9434],\n",
      "        [ 14.9434],\n",
      "        [ 85.1434],\n",
      "        [ 67.0635],\n",
      "        [  7.3566],\n",
      "        [146.6434],\n",
      "        [ 23.8330],\n",
      "        [ 97.6434],\n",
      "        [ 97.6434],\n",
      "        [114.5806],\n",
      "        [106.1434],\n",
      "        [113.0734],\n",
      "        [131.6434],\n",
      "        [145.3134],\n",
      "        [145.3134],\n",
      "        [168.1434],\n",
      "        [172.6434],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [182.6434],\n",
      "        [187.6434],\n",
      "        [192.6434],\n",
      "        [220.6434],\n",
      "        [180.3685],\n",
      "        [131.0521],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [169.6434],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.6434],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.3566],\n",
      "        [  7.4845],\n",
      "        [178.1669]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4418.7729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[231.5702],\n",
      "        [  7.6404],\n",
      "        [ 59.4383],\n",
      "        [  7.6404],\n",
      "        [110.0878],\n",
      "        [  8.6196],\n",
      "        [  6.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  2.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [218.3596],\n",
      "        [ 79.7496],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  5.3596],\n",
      "        [  7.6404],\n",
      "        [167.0441],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  2.3596],\n",
      "        [ 12.5142],\n",
      "        [218.3596],\n",
      "        [  4.1404],\n",
      "        [  3.1604],\n",
      "        [  3.1404],\n",
      "        [  0.9404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  2.3596],\n",
      "        [  7.6404],\n",
      "        [  2.8596],\n",
      "        [ 77.9868],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 34.8619],\n",
      "        [  7.6404],\n",
      "        [ 58.8596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 24.9596],\n",
      "        [ 25.3596],\n",
      "        [ 26.3596],\n",
      "        [ 27.3596],\n",
      "        [ 30.3596],\n",
      "        [  7.6404],\n",
      "        [ 36.0757],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 33.8596],\n",
      "        [ 23.1627],\n",
      "        [  7.6404],\n",
      "        [ 45.6087],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  9.3902],\n",
      "        [ 12.2959],\n",
      "        [ 36.3596],\n",
      "        [ 43.3596],\n",
      "        [ 47.3596],\n",
      "        [ 47.3596],\n",
      "        [141.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 14.1315],\n",
      "        [ 14.1315],\n",
      "        [  7.7475],\n",
      "        [  3.6404],\n",
      "        [ 56.8596],\n",
      "        [102.8491],\n",
      "        [228.3596],\n",
      "        [ 63.3596],\n",
      "        [ 13.8567],\n",
      "        [ 39.1904],\n",
      "        [  7.6404],\n",
      "        [ 77.9596],\n",
      "        [ 79.3596],\n",
      "        [ 14.6596],\n",
      "        [ 14.6596],\n",
      "        [ 84.8596],\n",
      "        [ 89.9020],\n",
      "        [  7.6404],\n",
      "        [146.3596],\n",
      "        [ 35.3894],\n",
      "        [ 97.3596],\n",
      "        [ 97.3596],\n",
      "        [115.8547],\n",
      "        [105.8596],\n",
      "        [112.7896],\n",
      "        [131.3596],\n",
      "        [145.0296],\n",
      "        [145.0296],\n",
      "        [167.8596],\n",
      "        [172.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [182.3596],\n",
      "        [187.3596],\n",
      "        [192.3596],\n",
      "        [220.3596],\n",
      "        [178.1394],\n",
      "        [128.1880],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [169.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 70.0485]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 38.610483169555664\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 177\n",
      "剩餘X 資料 torch.Size([26, 10])\n",
      "剩餘Y 資料 torch.Size([26, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (72554.6171875, 15)\n",
      "The second_loss value of k: (78416.609375, 13)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引15，y= tensor([277.])\n",
      "目前模型的Data狀態 torch.Size([185, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 86.4298],\n",
      "        [  7.6404],\n",
      "        [266.3317],\n",
      "        [  7.6404],\n",
      "        [110.0878],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [167.0441],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 14.5142],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 21.0132],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 59.9419],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 36.0757],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 43.8373],\n",
      "        [  7.6404],\n",
      "        [151.8087],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  9.3902],\n",
      "        [ 12.2959],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 14.1315],\n",
      "        [ 14.1315],\n",
      "        [ 31.2475],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [102.8491],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 65.3433],\n",
      "        [ 39.1904],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [116.0980],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 62.6106],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [115.8547],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [170.8606],\n",
      "        [109.8120],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 70.0485],\n",
      "        [  7.6404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[231.5702],\n",
      "        [  7.6404],\n",
      "        [ 59.4383],\n",
      "        [  7.6404],\n",
      "        [110.0878],\n",
      "        [  8.6196],\n",
      "        [  6.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  2.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [218.3596],\n",
      "        [ 79.7496],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  5.3596],\n",
      "        [  7.6404],\n",
      "        [167.0441],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  2.3596],\n",
      "        [ 12.5142],\n",
      "        [218.3596],\n",
      "        [  4.1404],\n",
      "        [  3.1604],\n",
      "        [  3.1404],\n",
      "        [  0.9404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  2.3596],\n",
      "        [  7.6404],\n",
      "        [  2.8596],\n",
      "        [ 77.9868],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 34.8619],\n",
      "        [  7.6404],\n",
      "        [ 58.8596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 24.9596],\n",
      "        [ 25.3596],\n",
      "        [ 26.3596],\n",
      "        [ 27.3596],\n",
      "        [ 30.3596],\n",
      "        [  7.6404],\n",
      "        [ 36.0757],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 33.8596],\n",
      "        [ 23.1627],\n",
      "        [  7.6404],\n",
      "        [ 45.6087],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  9.3902],\n",
      "        [ 12.2959],\n",
      "        [ 36.3596],\n",
      "        [ 43.3596],\n",
      "        [ 47.3596],\n",
      "        [ 47.3596],\n",
      "        [141.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 14.1315],\n",
      "        [ 14.1315],\n",
      "        [  7.7475],\n",
      "        [  3.6404],\n",
      "        [ 56.8596],\n",
      "        [102.8491],\n",
      "        [228.3596],\n",
      "        [ 63.3596],\n",
      "        [ 13.8567],\n",
      "        [ 39.1904],\n",
      "        [  7.6404],\n",
      "        [ 77.9596],\n",
      "        [ 79.3596],\n",
      "        [ 14.6596],\n",
      "        [ 14.6596],\n",
      "        [ 84.8596],\n",
      "        [ 89.9020],\n",
      "        [  7.6404],\n",
      "        [146.3596],\n",
      "        [ 35.3894],\n",
      "        [ 97.3596],\n",
      "        [ 97.3596],\n",
      "        [115.8547],\n",
      "        [105.8596],\n",
      "        [112.7896],\n",
      "        [131.3596],\n",
      "        [145.0296],\n",
      "        [145.0296],\n",
      "        [167.8596],\n",
      "        [172.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [182.3596],\n",
      "        [187.3596],\n",
      "        [192.3596],\n",
      "        [220.3596],\n",
      "        [178.1394],\n",
      "        [128.1880],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [169.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 70.0485],\n",
      "        [269.3596]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4636.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching的第10000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 6625\n",
      "Number of shrink: 3375\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[231.5702],\n",
      "        [  7.6404],\n",
      "        [ 59.4383],\n",
      "        [  7.6404],\n",
      "        [110.0878],\n",
      "        [  8.6196],\n",
      "        [  6.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  2.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [218.3596],\n",
      "        [ 79.7496],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  5.3596],\n",
      "        [  7.6404],\n",
      "        [167.0441],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  2.3596],\n",
      "        [ 12.5142],\n",
      "        [218.3596],\n",
      "        [  4.1404],\n",
      "        [  3.1604],\n",
      "        [  3.1404],\n",
      "        [  0.9404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  2.3596],\n",
      "        [  7.6404],\n",
      "        [  2.8596],\n",
      "        [ 77.9868],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 34.8619],\n",
      "        [  7.6404],\n",
      "        [ 58.8596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 24.9596],\n",
      "        [ 25.3596],\n",
      "        [ 26.3596],\n",
      "        [ 27.3596],\n",
      "        [ 30.3596],\n",
      "        [  7.6404],\n",
      "        [ 36.0757],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 33.8596],\n",
      "        [ 23.1627],\n",
      "        [  7.6404],\n",
      "        [ 45.6087],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  9.3902],\n",
      "        [ 12.2959],\n",
      "        [ 36.3596],\n",
      "        [ 43.3596],\n",
      "        [ 47.3596],\n",
      "        [ 47.3596],\n",
      "        [141.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 14.1315],\n",
      "        [ 14.1315],\n",
      "        [  7.7475],\n",
      "        [  3.6404],\n",
      "        [ 56.8596],\n",
      "        [102.8491],\n",
      "        [228.3596],\n",
      "        [ 63.3596],\n",
      "        [ 13.8567],\n",
      "        [ 39.1904],\n",
      "        [  7.6404],\n",
      "        [ 77.9596],\n",
      "        [ 79.3596],\n",
      "        [ 14.6596],\n",
      "        [ 14.6596],\n",
      "        [ 84.8596],\n",
      "        [ 89.9020],\n",
      "        [  7.6404],\n",
      "        [146.3596],\n",
      "        [ 35.3894],\n",
      "        [ 97.3596],\n",
      "        [ 97.3596],\n",
      "        [115.8547],\n",
      "        [105.8596],\n",
      "        [112.7896],\n",
      "        [131.3596],\n",
      "        [145.0296],\n",
      "        [145.0296],\n",
      "        [167.8596],\n",
      "        [172.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [182.3596],\n",
      "        [187.3596],\n",
      "        [192.3596],\n",
      "        [220.3596],\n",
      "        [178.1394],\n",
      "        [128.1880],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [169.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.3596],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 70.0485],\n",
      "        [269.3596]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[184,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  231.4846],\n",
      "        [    7.7029],\n",
      "        [   59.3796],\n",
      "        [    7.6404],\n",
      "        [  110.1404],\n",
      "        [    8.6196],\n",
      "        [    6.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6716],\n",
      "        [    2.6716],\n",
      "        [    7.7029],\n",
      "        [    7.6404],\n",
      "        [  218.2971],\n",
      "        [   79.7496],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    5.3596],\n",
      "        [    7.7029],\n",
      "        [  167.1404],\n",
      "        [    7.6404],\n",
      "        [    7.5779],\n",
      "        [    7.6404],\n",
      "        [    7.6247],\n",
      "        [    7.6443],\n",
      "        [    7.6404],\n",
      "        [    7.6247],\n",
      "        [    7.6716],\n",
      "        [    7.7029],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.7029],\n",
      "        [    7.6247],\n",
      "        [    7.6404],\n",
      "        [    7.6716],\n",
      "        [    7.7029],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.2654],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6716],\n",
      "        [    7.7029],\n",
      "        [    7.3904],\n",
      "        [    7.6413],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.1404],\n",
      "        [    7.7654],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.7654],\n",
      "        [    7.6365],\n",
      "        [    7.6404],\n",
      "        [    7.6482],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6247],\n",
      "        [    7.6365],\n",
      "        [    7.6413],\n",
      "        [    7.6413],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6560],\n",
      "        [    7.5154],\n",
      "        [    7.7029],\n",
      "        [    7.6247],\n",
      "        [    7.7654],\n",
      "        [    7.6716],\n",
      "        [    7.6404],\n",
      "        [    7.7341],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6443],\n",
      "        [    7.6404],\n",
      "        [    2.8596],\n",
      "        [   12.5154],\n",
      "        [  218.2971],\n",
      "        [    4.1560],\n",
      "        [    3.1604],\n",
      "        [    3.2029],\n",
      "        [    0.4404],\n",
      "        [    7.6404],\n",
      "        [    7.7654],\n",
      "        [    2.3596],\n",
      "        [    7.7029],\n",
      "        [    2.8596],\n",
      "        [   77.9868],\n",
      "        [    7.6716],\n",
      "        [    7.6404],\n",
      "        [   34.8104],\n",
      "        [    7.6560],\n",
      "        [   58.8596],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   25.4596],\n",
      "        [   25.3606],\n",
      "        [   26.3596],\n",
      "        [   27.3596],\n",
      "        [   30.3596],\n",
      "        [    7.6404],\n",
      "        [   36.1091],\n",
      "        [    7.6404],\n",
      "        [    7.6716],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   33.8284],\n",
      "        [   23.1627],\n",
      "        [    7.6365],\n",
      "        [   45.7529],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    9.3902],\n",
      "        [   12.2959],\n",
      "        [   36.3596],\n",
      "        [   43.3753],\n",
      "        [   47.6096],\n",
      "        [   47.3440],\n",
      "        [  141.3596],\n",
      "        [    7.6404],\n",
      "        [    7.1404],\n",
      "        [   14.2029],\n",
      "        [   14.2029],\n",
      "        [    7.7654],\n",
      "        [    4.1404],\n",
      "        [   56.8596],\n",
      "        [  102.8904],\n",
      "        [  228.3596],\n",
      "        [   63.3596],\n",
      "        [   13.8096],\n",
      "        [   39.2654],\n",
      "        [    7.6404],\n",
      "        [   77.9596],\n",
      "        [   79.3753],\n",
      "        [   14.6284],\n",
      "        [   14.6284],\n",
      "        [   84.8128],\n",
      "        [   89.9221],\n",
      "        [    7.6404],\n",
      "        [  146.2971],\n",
      "        [   35.3596],\n",
      "        [   97.2971],\n",
      "        [   97.3596],\n",
      "        [  115.8279],\n",
      "        [  106.1096],\n",
      "        [  113.2896],\n",
      "        [  131.3128],\n",
      "        [  144.9671],\n",
      "        [  144.9671],\n",
      "        [  167.8596],\n",
      "        [  172.3596],\n",
      "        [    7.6716],\n",
      "        [    7.6560],\n",
      "        [  182.3284],\n",
      "        [  187.3596],\n",
      "        [  192.2971],\n",
      "        [  220.3596],\n",
      "        [  177.9846],\n",
      "        [  128.2346],\n",
      "        [    7.6404],\n",
      "        [    7.7029],\n",
      "        [    7.7029],\n",
      "        [  169.3596],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.7029],\n",
      "        [    7.7029],\n",
      "        [    7.7029],\n",
      "        [    7.7029],\n",
      "        [    7.6404],\n",
      "        [    7.5779],\n",
      "        [    7.6404],\n",
      "        [    7.3596],\n",
      "        [    7.6404],\n",
      "        [    7.1404],\n",
      "        [    7.6404],\n",
      "        [    7.3904],\n",
      "        [   70.0154],\n",
      "        [    0.0022]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 20\n",
      "Number of shrink: 17\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[223.4221],\n",
      "        [ 16.6404],\n",
      "        [ 56.5046],\n",
      "        [  7.6404],\n",
      "        [107.7654],\n",
      "        [  1.9634],\n",
      "        [ 13.8357],\n",
      "        [ 19.6404],\n",
      "        [ 14.2810],\n",
      "        [ 12.9841],\n",
      "        [ 15.2029],\n",
      "        [ 31.8904],\n",
      "        [205.3596],\n",
      "        [ 73.9684],\n",
      "        [ 18.1404],\n",
      "        [  0.3596],\n",
      "        [  5.1404],\n",
      "        [ 11.4529],\n",
      "        [173.5779],\n",
      "        [ 15.6970],\n",
      "        [ 18.3591],\n",
      "        [ 26.6404],\n",
      "        [ 13.3123],\n",
      "        [ 15.0818],\n",
      "        [  4.8904],\n",
      "        [ 16.0310],\n",
      "        [ 24.3904],\n",
      "        [ 22.2029],\n",
      "        [  7.6404],\n",
      "        [ 24.2654],\n",
      "        [ 15.5779],\n",
      "        [ 16.3435],\n",
      "        [ 20.9529],\n",
      "        [ 25.2654],\n",
      "        [ 26.9529],\n",
      "        [ 19.6638],\n",
      "        [ 14.4529],\n",
      "        [  4.1404],\n",
      "        [ 15.5154],\n",
      "        [ 20.2341],\n",
      "        [ 12.3591],\n",
      "        [ 25.8279],\n",
      "        [ 40.6404],\n",
      "        [ 15.8777],\n",
      "        [ 16.6560],\n",
      "        [  7.6404],\n",
      "        [ 16.3904],\n",
      "        [ 12.8904],\n",
      "        [ 25.0154],\n",
      "        [ 38.6404],\n",
      "        [  7.6404],\n",
      "        [ 17.6404],\n",
      "        [ 13.8083],\n",
      "        [  8.8904],\n",
      "        [ 10.8669],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 19.9841],\n",
      "        [ 17.2263],\n",
      "        [ 17.8933],\n",
      "        [ 17.8914],\n",
      "        [ 20.4373],\n",
      "        [ 19.1130],\n",
      "        [ 36.8904],\n",
      "        [ 13.8435],\n",
      "        [ 11.5154],\n",
      "        [ 16.3279],\n",
      "        [ 15.3435],\n",
      "        [ 16.4529],\n",
      "        [ 22.3904],\n",
      "        [  9.3904],\n",
      "        [ 13.7966],\n",
      "        [ 15.8123],\n",
      "        [ 38.1404],\n",
      "        [ 20.0857],\n",
      "        [ 14.6716],\n",
      "        [ 31.8904],\n",
      "        [ 11.6404],\n",
      "        [205.3596],\n",
      "        [ 10.8123],\n",
      "        [ 15.7151],\n",
      "        [ 10.3904],\n",
      "        [ 19.1904],\n",
      "        [  7.6404],\n",
      "        [ 34.1404],\n",
      "        [  3.7029],\n",
      "        [ 19.3904],\n",
      "        [  8.2263],\n",
      "        [ 77.9874],\n",
      "        [  6.4216],\n",
      "        [  9.9529],\n",
      "        [ 33.8104],\n",
      "        [  7.0310],\n",
      "        [ 50.4846],\n",
      "        [ 17.3279],\n",
      "        [ 11.6404],\n",
      "        [ 22.8904],\n",
      "        [ 10.2904],\n",
      "        [ 21.5110],\n",
      "        [ 25.0002],\n",
      "        [ 18.2346],\n",
      "        [ 21.0471],\n",
      "        [  7.6404],\n",
      "        [ 34.2341],\n",
      "        [  7.6404],\n",
      "        [ 11.4373],\n",
      "        [  7.6404],\n",
      "        [ 17.0588],\n",
      "        [ 14.8396],\n",
      "        [  7.6404],\n",
      "        [ 30.0159],\n",
      "        [ 23.1631],\n",
      "        [ 12.8240],\n",
      "        [ 45.8779],\n",
      "        [  7.6404],\n",
      "        [ 13.1140],\n",
      "        [ 11.4890],\n",
      "        [  9.3899],\n",
      "        [ 12.2956],\n",
      "        [ 26.6565],\n",
      "        [ 37.9065],\n",
      "        [ 27.3596],\n",
      "        [ 38.7034],\n",
      "        [123.8596],\n",
      "        [ 26.5154],\n",
      "        [  9.3904],\n",
      "        [ 30.7029],\n",
      "        [ 30.7029],\n",
      "        [ 17.1404],\n",
      "        [ 36.1404],\n",
      "        [ 45.8284],\n",
      "        [126.3904],\n",
      "        [221.1409],\n",
      "        [ 54.8596],\n",
      "        [  3.8096],\n",
      "        [ 39.2654],\n",
      "        [ 13.1404],\n",
      "        [ 47.4596],\n",
      "        [ 66.3127],\n",
      "        [ 11.1284],\n",
      "        [ 11.1284],\n",
      "        [ 76.6252],\n",
      "        [ 84.9846],\n",
      "        [ 24.8904],\n",
      "        [137.9221],\n",
      "        [ 39.8596],\n",
      "        [ 95.4221],\n",
      "        [ 83.1721],\n",
      "        [109.7029],\n",
      "        [ 59.1096],\n",
      "        [ 63.0396],\n",
      "        [122.3752],\n",
      "        [134.6546],\n",
      "        [134.6546],\n",
      "        [167.8596],\n",
      "        [148.8596],\n",
      "        [ 15.9529],\n",
      "        [ 13.2810],\n",
      "        [171.6409],\n",
      "        [187.3596],\n",
      "        [183.3596],\n",
      "        [220.3596],\n",
      "        [177.2346],\n",
      "        [126.7346],\n",
      "        [ 25.6404],\n",
      "        [ 19.2654],\n",
      "        [ 15.9216],\n",
      "        [157.3596],\n",
      "        [ 19.3904],\n",
      "        [ 18.0154],\n",
      "        [ 15.7029],\n",
      "        [ 17.0154],\n",
      "        [ 16.6404],\n",
      "        [ 13.2029],\n",
      "        [ 13.6404],\n",
      "        [ 11.2654],\n",
      "        [ 16.6404],\n",
      "        [ 23.1404],\n",
      "        [ 19.8904],\n",
      "        [ 18.8904],\n",
      "        [ 11.3904],\n",
      "        [ 11.1404],\n",
      "        [ 75.0154],\n",
      "        [  2.1554]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 60.4608039855957\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 178\n",
      "剩餘X 資料 torch.Size([25, 10])\n",
      "剩餘Y 資料 torch.Size([25, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (62015.7578125, 13)\n",
      "The second_loss value of k: (82863.1640625, 14)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引13，y= tensor([287.6700])\n",
      "目前模型的Data狀態 torch.Size([186, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 94.5779],\n",
      "        [ 16.6404],\n",
      "        [269.2654],\n",
      "        [  7.6404],\n",
      "        [107.7654],\n",
      "        [ 14.2966],\n",
      "        [ 14.8357],\n",
      "        [ 19.6404],\n",
      "        [ 14.2810],\n",
      "        [ 17.9841],\n",
      "        [ 15.2029],\n",
      "        [ 31.8904],\n",
      "        [ 20.6404],\n",
      "        [ 13.4216],\n",
      "        [ 18.1404],\n",
      "        [ -0.3596],\n",
      "        [ 18.1404],\n",
      "        [ 11.4529],\n",
      "        [173.5779],\n",
      "        [ 15.6970],\n",
      "        [ 18.3591],\n",
      "        [ 26.6404],\n",
      "        [ 13.3123],\n",
      "        [ 15.0818],\n",
      "        [  4.8904],\n",
      "        [ 16.0310],\n",
      "        [ 24.3904],\n",
      "        [ 22.2029],\n",
      "        [  7.6404],\n",
      "        [ 24.2654],\n",
      "        [ 15.5779],\n",
      "        [ 16.3435],\n",
      "        [ 20.9529],\n",
      "        [ 25.2654],\n",
      "        [ 26.9529],\n",
      "        [ 19.6638],\n",
      "        [ 14.4529],\n",
      "        [  4.1404],\n",
      "        [ 15.5154],\n",
      "        [ 20.2341],\n",
      "        [ 12.3591],\n",
      "        [ 25.8279],\n",
      "        [ 40.6404],\n",
      "        [ 15.8777],\n",
      "        [ 16.6560],\n",
      "        [  7.6404],\n",
      "        [ 16.3904],\n",
      "        [ 12.8904],\n",
      "        [ 25.0154],\n",
      "        [ 38.6404],\n",
      "        [  7.6404],\n",
      "        [ 17.6404],\n",
      "        [ 13.8083],\n",
      "        [  8.8904],\n",
      "        [ 10.8669],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 19.9841],\n",
      "        [ 17.2263],\n",
      "        [ 17.8933],\n",
      "        [ 17.8914],\n",
      "        [ 20.4373],\n",
      "        [ 19.1130],\n",
      "        [ 36.8904],\n",
      "        [ 13.8435],\n",
      "        [ 11.5154],\n",
      "        [ 16.3279],\n",
      "        [ 15.3435],\n",
      "        [ 16.4529],\n",
      "        [ 22.3904],\n",
      "        [  9.3904],\n",
      "        [ 13.7966],\n",
      "        [ 15.8123],\n",
      "        [ 38.1404],\n",
      "        [ 20.0857],\n",
      "        [ 14.6716],\n",
      "        [ 41.8904],\n",
      "        [ 13.6404],\n",
      "        [ 20.6404],\n",
      "        [ 14.3123],\n",
      "        [ 20.1951],\n",
      "        [ 14.8904],\n",
      "        [ 25.8904],\n",
      "        [  7.6404],\n",
      "        [ 34.1404],\n",
      "        [ 13.7029],\n",
      "        [ 19.3904],\n",
      "        [ 18.7263],\n",
      "        [ 21.0126],\n",
      "        [  6.4216],\n",
      "        [  9.9529],\n",
      "        [ 58.8904],\n",
      "        [  7.0310],\n",
      "        [ 16.0154],\n",
      "        [ 17.3279],\n",
      "        [ 11.6404],\n",
      "        [ 22.8904],\n",
      "        [ 42.8904],\n",
      "        [ 11.4890],\n",
      "        [  8.9998],\n",
      "        [ 16.7654],\n",
      "        [ 16.9529],\n",
      "        [  7.6404],\n",
      "        [ 34.2341],\n",
      "        [  7.6404],\n",
      "        [ 11.4373],\n",
      "        [  7.6404],\n",
      "        [ 17.0588],\n",
      "        [ 14.8396],\n",
      "        [  7.6404],\n",
      "        [ 11.4841],\n",
      "        [ 43.8369],\n",
      "        [ 12.8240],\n",
      "        [152.0779],\n",
      "        [  7.6404],\n",
      "        [ 13.1140],\n",
      "        [ 11.4890],\n",
      "        [  9.3899],\n",
      "        [ 12.2956],\n",
      "        [ 17.3435],\n",
      "        [ 13.0935],\n",
      "        [ 27.6404],\n",
      "        [ 16.2966],\n",
      "        [ 25.1404],\n",
      "        [ 26.5154],\n",
      "        [  9.3904],\n",
      "        [ 30.7029],\n",
      "        [ 30.7029],\n",
      "        [ 40.6404],\n",
      "        [ 40.1404],\n",
      "        [ 18.6716],\n",
      "        [126.3904],\n",
      "        [ 14.8591],\n",
      "        [ 16.1404],\n",
      "        [ 75.3904],\n",
      "        [ 39.2654],\n",
      "        [ 13.1404],\n",
      "        [ 38.1404],\n",
      "        [ 20.6873],\n",
      "        [ 11.1716],\n",
      "        [ 11.1716],\n",
      "        [ 15.8748],\n",
      "        [121.0154],\n",
      "        [ 24.8904],\n",
      "        [ 16.0779],\n",
      "        [ 58.1404],\n",
      "        [  9.5779],\n",
      "        [ 21.8279],\n",
      "        [109.7029],\n",
      "        [ 54.3904],\n",
      "        [ 57.3904],\n",
      "        [ 16.6248],\n",
      "        [ 18.0154],\n",
      "        [ 18.0154],\n",
      "        [  7.6404],\n",
      "        [ 31.1404],\n",
      "        [ 15.9529],\n",
      "        [ 13.2810],\n",
      "        [ 18.3591],\n",
      "        [  7.6404],\n",
      "        [ 16.6404],\n",
      "        [  7.6404],\n",
      "        [171.7654],\n",
      "        [111.2654],\n",
      "        [ 25.6404],\n",
      "        [ 19.2654],\n",
      "        [ 15.9216],\n",
      "        [ 19.6404],\n",
      "        [ 19.3904],\n",
      "        [ 18.0154],\n",
      "        [ 15.7029],\n",
      "        [ 17.0154],\n",
      "        [ 16.6404],\n",
      "        [ 13.2029],\n",
      "        [ 13.6404],\n",
      "        [ 11.2654],\n",
      "        [ 16.6404],\n",
      "        [ 38.1404],\n",
      "        [ 19.8904],\n",
      "        [ 18.8904],\n",
      "        [ 11.3904],\n",
      "        [ 11.1404],\n",
      "        [ 75.0154],\n",
      "        [279.1554],\n",
      "        [ 38.8904]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[223.4221],\n",
      "        [ 16.6404],\n",
      "        [ 56.5046],\n",
      "        [  7.6404],\n",
      "        [107.7654],\n",
      "        [  1.9634],\n",
      "        [ 13.8357],\n",
      "        [ 19.6404],\n",
      "        [ 14.2810],\n",
      "        [ 12.9841],\n",
      "        [ 15.2029],\n",
      "        [ 31.8904],\n",
      "        [205.3596],\n",
      "        [ 73.9684],\n",
      "        [ 18.1404],\n",
      "        [  0.3596],\n",
      "        [  5.1404],\n",
      "        [ 11.4529],\n",
      "        [173.5779],\n",
      "        [ 15.6970],\n",
      "        [ 18.3591],\n",
      "        [ 26.6404],\n",
      "        [ 13.3123],\n",
      "        [ 15.0818],\n",
      "        [  4.8904],\n",
      "        [ 16.0310],\n",
      "        [ 24.3904],\n",
      "        [ 22.2029],\n",
      "        [  7.6404],\n",
      "        [ 24.2654],\n",
      "        [ 15.5779],\n",
      "        [ 16.3435],\n",
      "        [ 20.9529],\n",
      "        [ 25.2654],\n",
      "        [ 26.9529],\n",
      "        [ 19.6638],\n",
      "        [ 14.4529],\n",
      "        [  4.1404],\n",
      "        [ 15.5154],\n",
      "        [ 20.2341],\n",
      "        [ 12.3591],\n",
      "        [ 25.8279],\n",
      "        [ 40.6404],\n",
      "        [ 15.8777],\n",
      "        [ 16.6560],\n",
      "        [  7.6404],\n",
      "        [ 16.3904],\n",
      "        [ 12.8904],\n",
      "        [ 25.0154],\n",
      "        [ 38.6404],\n",
      "        [  7.6404],\n",
      "        [ 17.6404],\n",
      "        [ 13.8083],\n",
      "        [  8.8904],\n",
      "        [ 10.8669],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 19.9841],\n",
      "        [ 17.2263],\n",
      "        [ 17.8933],\n",
      "        [ 17.8914],\n",
      "        [ 20.4373],\n",
      "        [ 19.1130],\n",
      "        [ 36.8904],\n",
      "        [ 13.8435],\n",
      "        [ 11.5154],\n",
      "        [ 16.3279],\n",
      "        [ 15.3435],\n",
      "        [ 16.4529],\n",
      "        [ 22.3904],\n",
      "        [  9.3904],\n",
      "        [ 13.7966],\n",
      "        [ 15.8123],\n",
      "        [ 38.1404],\n",
      "        [ 20.0857],\n",
      "        [ 14.6716],\n",
      "        [ 31.8904],\n",
      "        [ 11.6404],\n",
      "        [205.3596],\n",
      "        [ 10.8123],\n",
      "        [ 15.7151],\n",
      "        [ 10.3904],\n",
      "        [ 19.1904],\n",
      "        [  7.6404],\n",
      "        [ 34.1404],\n",
      "        [  3.7029],\n",
      "        [ 19.3904],\n",
      "        [  8.2263],\n",
      "        [ 77.9874],\n",
      "        [  6.4216],\n",
      "        [  9.9529],\n",
      "        [ 33.8104],\n",
      "        [  7.0310],\n",
      "        [ 50.4846],\n",
      "        [ 17.3279],\n",
      "        [ 11.6404],\n",
      "        [ 22.8904],\n",
      "        [ 10.2904],\n",
      "        [ 21.5110],\n",
      "        [ 25.0002],\n",
      "        [ 18.2346],\n",
      "        [ 21.0471],\n",
      "        [  7.6404],\n",
      "        [ 34.2341],\n",
      "        [  7.6404],\n",
      "        [ 11.4373],\n",
      "        [  7.6404],\n",
      "        [ 17.0588],\n",
      "        [ 14.8396],\n",
      "        [  7.6404],\n",
      "        [ 30.0159],\n",
      "        [ 23.1631],\n",
      "        [ 12.8240],\n",
      "        [ 45.8779],\n",
      "        [  7.6404],\n",
      "        [ 13.1140],\n",
      "        [ 11.4890],\n",
      "        [  9.3899],\n",
      "        [ 12.2956],\n",
      "        [ 26.6565],\n",
      "        [ 37.9065],\n",
      "        [ 27.3596],\n",
      "        [ 38.7034],\n",
      "        [123.8596],\n",
      "        [ 26.5154],\n",
      "        [  9.3904],\n",
      "        [ 30.7029],\n",
      "        [ 30.7029],\n",
      "        [ 17.1404],\n",
      "        [ 36.1404],\n",
      "        [ 45.8284],\n",
      "        [126.3904],\n",
      "        [221.1409],\n",
      "        [ 54.8596],\n",
      "        [  3.8096],\n",
      "        [ 39.2654],\n",
      "        [ 13.1404],\n",
      "        [ 47.4596],\n",
      "        [ 66.3127],\n",
      "        [ 11.1284],\n",
      "        [ 11.1284],\n",
      "        [ 76.6252],\n",
      "        [ 84.9846],\n",
      "        [ 24.8904],\n",
      "        [137.9221],\n",
      "        [ 39.8596],\n",
      "        [ 95.4221],\n",
      "        [ 83.1721],\n",
      "        [109.7029],\n",
      "        [ 59.1096],\n",
      "        [ 63.0396],\n",
      "        [122.3752],\n",
      "        [134.6546],\n",
      "        [134.6546],\n",
      "        [167.8596],\n",
      "        [148.8596],\n",
      "        [ 15.9529],\n",
      "        [ 13.2810],\n",
      "        [171.6409],\n",
      "        [187.3596],\n",
      "        [183.3596],\n",
      "        [220.3596],\n",
      "        [177.2346],\n",
      "        [126.7346],\n",
      "        [ 25.6404],\n",
      "        [ 19.2654],\n",
      "        [ 15.9216],\n",
      "        [157.3596],\n",
      "        [ 19.3904],\n",
      "        [ 18.0154],\n",
      "        [ 15.7029],\n",
      "        [ 17.0154],\n",
      "        [ 16.6404],\n",
      "        [ 13.2029],\n",
      "        [ 13.6404],\n",
      "        [ 11.2654],\n",
      "        [ 16.6404],\n",
      "        [ 23.1404],\n",
      "        [ 19.8904],\n",
      "        [ 18.8904],\n",
      "        [ 11.3904],\n",
      "        [ 11.1404],\n",
      "        [ 75.0154],\n",
      "        [  2.1554],\n",
      "        [248.7796]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4291.4946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 10\n",
      "Number of shrink: 12\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.1296],\n",
      "        [    7.6404],\n",
      "        [  110.0154],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   24.1404],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   43.2654],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   20.8904],\n",
      "        [    7.1404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  176.0154],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   30.1404],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1091],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.1404],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.6404],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.6404],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   29.8904],\n",
      "        [   16.8904],\n",
      "        [   37.8904],\n",
      "        [   58.6404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    9.8904],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.3904],\n",
      "        [   18.8591],\n",
      "        [   12.8904],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   27.3904],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.1404],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   28.3904],\n",
      "        [   19.3904],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   20.1904],\n",
      "        [    7.6404],\n",
      "        [   45.3904],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   40.0604],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.1404],\n",
      "        [   22.6404],\n",
      "        [   17.2904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.3596],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    8.3904],\n",
      "        [   38.6404],\n",
      "        [   38.6404],\n",
      "        [   16.8904],\n",
      "        [   25.1404],\n",
      "        [   42.2659],\n",
      "        [  136.2654],\n",
      "        [  219.6409],\n",
      "        [   44.3596],\n",
      "        [    1.6904],\n",
      "        [   37.1716],\n",
      "        [   10.1404],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8904],\n",
      "        [  134.3596],\n",
      "        [   37.9846],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   49.1096],\n",
      "        [   34.0396],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  179.0471],\n",
      "        [  121.7346],\n",
      "        [   25.8904],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  153.7346],\n",
      "        [   21.1404],\n",
      "        [   21.0154],\n",
      "        [   17.5154],\n",
      "        [   18.1404],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.5154],\n",
      "        [   17.1404],\n",
      "        [   28.6404],\n",
      "        [   21.6404],\n",
      "        [   19.8904],\n",
      "        [   12.8904],\n",
      "        [   13.1404],\n",
      "        [   76.2654],\n",
      "        [    2.7596],\n",
      "        [  220.5296]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 60.55542850494385\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 179\n",
      "剩餘X 資料 torch.Size([24, 10])\n",
      "剩餘Y 資料 torch.Size([24, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (82863.1640625, 13)\n",
      "The second_loss value of k: (93779.640625, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引13，y= tensor([314.])\n",
      "目前模型的Data狀態 torch.Size([187, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 97.3904],\n",
      "        [ 20.0154],\n",
      "        [267.6404],\n",
      "        [  7.6404],\n",
      "        [110.0154],\n",
      "        [ 16.3904],\n",
      "        [ 16.8784],\n",
      "        [ 24.1404],\n",
      "        [ 16.1404],\n",
      "        [ 20.5779],\n",
      "        [ 19.8904],\n",
      "        [ 43.2654],\n",
      "        [ 23.3904],\n",
      "        [ 15.7966],\n",
      "        [ 20.8904],\n",
      "        [  7.1404],\n",
      "        [ 22.6404],\n",
      "        [ 10.1404],\n",
      "        [176.0154],\n",
      "        [ 17.8513],\n",
      "        [ 22.3279],\n",
      "        [ 30.1404],\n",
      "        [ 16.0466],\n",
      "        [ 17.0349],\n",
      "        [ 13.6404],\n",
      "        [ 18.8748],\n",
      "        [ 35.1091],\n",
      "        [ 36.0154],\n",
      "        [  7.6404],\n",
      "        [ 42.1404],\n",
      "        [ 18.7654],\n",
      "        [ 18.1873],\n",
      "        [ 23.0154],\n",
      "        [ 31.6404],\n",
      "        [ 42.7654],\n",
      "        [ 22.6951],\n",
      "        [ 16.1716],\n",
      "        [ 11.6404],\n",
      "        [ 17.6716],\n",
      "        [ 22.2654],\n",
      "        [ 15.0466],\n",
      "        [ 29.2966],\n",
      "        [ 48.6404],\n",
      "        [ 18.1277],\n",
      "        [ 19.1705],\n",
      "        [  7.6404],\n",
      "        [ 29.8904],\n",
      "        [ 16.8904],\n",
      "        [ 37.8904],\n",
      "        [ 58.6404],\n",
      "        [  7.6404],\n",
      "        [ 21.7654],\n",
      "        [ 15.9177],\n",
      "        [  9.8904],\n",
      "        [ 12.3044],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 22.4841],\n",
      "        [ 19.8943],\n",
      "        [ 20.7683],\n",
      "        [ 20.7546],\n",
      "        [ 25.1873],\n",
      "        [ 22.3494],\n",
      "        [ 69.3904],\n",
      "        [ 18.8591],\n",
      "        [ 12.8904],\n",
      "        [ 27.2029],\n",
      "        [ 20.2029],\n",
      "        [ 18.5154],\n",
      "        [ 27.7341],\n",
      "        [ 27.3904],\n",
      "        [ 15.2029],\n",
      "        [ 19.1248],\n",
      "        [ 62.1404],\n",
      "        [ 23.6990],\n",
      "        [ 17.5076],\n",
      "        [ 38.3904],\n",
      "        [ 21.3904],\n",
      "        [ 23.3904],\n",
      "        [ 16.0310],\n",
      "        [ 23.4451],\n",
      "        [ 18.8279],\n",
      "        [ 26.8904],\n",
      "        [  7.6404],\n",
      "        [ 45.3904],\n",
      "        [ 19.5466],\n",
      "        [ 24.1091],\n",
      "        [ 21.8103],\n",
      "        [ 21.0124],\n",
      "        [  3.6091],\n",
      "        [ 10.1716],\n",
      "        [ 65.1404],\n",
      "        [  5.5935],\n",
      "        [ 17.9529],\n",
      "        [ 21.6404],\n",
      "        [  9.1404],\n",
      "        [ 22.6404],\n",
      "        [ 49.8904],\n",
      "        [ 13.0437],\n",
      "        [  9.3748],\n",
      "        [ 20.4529],\n",
      "        [ 20.0232],\n",
      "        [  7.6404],\n",
      "        [ 31.2966],\n",
      "        [  7.6404],\n",
      "        [ 12.3591],\n",
      "        [  7.6404],\n",
      "        [ 19.6980],\n",
      "        [ 16.7302],\n",
      "        [  7.6404],\n",
      "        [ 12.9216],\n",
      "        [ 43.8367],\n",
      "        [ 14.5271],\n",
      "        [148.3279],\n",
      "        [  7.6404],\n",
      "        [ 14.6970],\n",
      "        [ 12.8074],\n",
      "        [  9.3897],\n",
      "        [ 12.2954],\n",
      "        [ 20.1091],\n",
      "        [ 15.7810],\n",
      "        [ 43.6404],\n",
      "        [ 20.1560],\n",
      "        [ 25.3904],\n",
      "        [ 25.3904],\n",
      "        [  8.3904],\n",
      "        [ 38.6404],\n",
      "        [ 38.6404],\n",
      "        [ 40.3904],\n",
      "        [ 29.1404],\n",
      "        [ 22.2341],\n",
      "        [136.2654],\n",
      "        [ 16.3591],\n",
      "        [ 26.6404],\n",
      "        [ 80.8904],\n",
      "        [ 37.1716],\n",
      "        [ 10.1404],\n",
      "        [ 67.1404],\n",
      "        [ 24.7810],\n",
      "        [ 13.0779],\n",
      "        [ 13.0779],\n",
      "        [ 17.2498],\n",
      "        [122.8279],\n",
      "        [ 35.8904],\n",
      "        [ 19.6404],\n",
      "        [ 60.0154],\n",
      "        [  8.3904],\n",
      "        [ 30.3904],\n",
      "        [104.9529],\n",
      "        [ 64.3904],\n",
      "        [ 86.3904],\n",
      "        [ 19.9685],\n",
      "        [ 27.1404],\n",
      "        [ 27.1404],\n",
      "        [  7.6404],\n",
      "        [ 30.6404],\n",
      "        [ 17.7341],\n",
      "        [ 14.3123],\n",
      "        [ 23.2341],\n",
      "        [  7.6404],\n",
      "        [ 19.6716],\n",
      "        [  7.6404],\n",
      "        [169.9529],\n",
      "        [116.2654],\n",
      "        [ 25.8904],\n",
      "        [ 21.8904],\n",
      "        [ 17.7341],\n",
      "        [ 23.2654],\n",
      "        [ 21.1404],\n",
      "        [ 21.0154],\n",
      "        [ 17.5154],\n",
      "        [ 18.1404],\n",
      "        [ 17.8904],\n",
      "        [ 14.0154],\n",
      "        [ 13.3904],\n",
      "        [ 10.5154],\n",
      "        [ 17.1404],\n",
      "        [ 43.6404],\n",
      "        [ 21.6404],\n",
      "        [ 19.8904],\n",
      "        [ 12.8904],\n",
      "        [ 13.1404],\n",
      "        [ 76.2654],\n",
      "        [279.7596],\n",
      "        [ 67.1404],\n",
      "        [ 26.3904]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.1296],\n",
      "        [    7.6404],\n",
      "        [  110.0154],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   24.1404],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   43.2654],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   20.8904],\n",
      "        [    7.1404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  176.0154],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   30.1404],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1091],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.1404],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.6404],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.6404],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   29.8904],\n",
      "        [   16.8904],\n",
      "        [   37.8904],\n",
      "        [   58.6404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    9.8904],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.3904],\n",
      "        [   18.8591],\n",
      "        [   12.8904],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   27.3904],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.1404],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   28.3904],\n",
      "        [   19.3904],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   20.1904],\n",
      "        [    7.6404],\n",
      "        [   45.3904],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   40.0604],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.1404],\n",
      "        [   22.6404],\n",
      "        [   17.2904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.3596],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    8.3904],\n",
      "        [   38.6404],\n",
      "        [   38.6404],\n",
      "        [   16.8904],\n",
      "        [   25.1404],\n",
      "        [   42.2659],\n",
      "        [  136.2654],\n",
      "        [  219.6409],\n",
      "        [   44.3596],\n",
      "        [    1.6904],\n",
      "        [   37.1716],\n",
      "        [   10.1404],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8904],\n",
      "        [  134.3596],\n",
      "        [   37.9846],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   49.1096],\n",
      "        [   34.0396],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  179.0471],\n",
      "        [  121.7346],\n",
      "        [   25.8904],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  153.7346],\n",
      "        [   21.1404],\n",
      "        [   21.0154],\n",
      "        [   17.5154],\n",
      "        [   18.1404],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.5154],\n",
      "        [   17.1404],\n",
      "        [   28.6404],\n",
      "        [   21.6404],\n",
      "        [   19.8904],\n",
      "        [   12.8904],\n",
      "        [   13.1404],\n",
      "        [   76.2654],\n",
      "        [    2.7596],\n",
      "        [  220.5296],\n",
      "        [  287.6096]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4648.5483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 8\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.1296],\n",
      "        [    7.6404],\n",
      "        [  110.0154],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   24.1404],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   43.2654],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   20.8904],\n",
      "        [    7.1404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  176.0154],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   30.1404],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1091],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.1404],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.6404],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.6404],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   29.8904],\n",
      "        [   16.8904],\n",
      "        [   37.8904],\n",
      "        [   58.6404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    9.8904],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.3904],\n",
      "        [   18.8591],\n",
      "        [   12.8904],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   27.3904],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.1404],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   28.3904],\n",
      "        [   19.3904],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   20.1904],\n",
      "        [    7.6404],\n",
      "        [   45.3904],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   40.0604],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.1404],\n",
      "        [   22.6404],\n",
      "        [   17.2904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.3596],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    8.3904],\n",
      "        [   38.6404],\n",
      "        [   38.6404],\n",
      "        [   16.8904],\n",
      "        [   25.1404],\n",
      "        [   42.2659],\n",
      "        [  136.2654],\n",
      "        [  219.6409],\n",
      "        [   44.3596],\n",
      "        [    1.6904],\n",
      "        [   37.1716],\n",
      "        [   10.1404],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8904],\n",
      "        [  134.3596],\n",
      "        [   37.9846],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   49.1096],\n",
      "        [   34.0396],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  179.0471],\n",
      "        [  121.7346],\n",
      "        [   25.8904],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  153.7346],\n",
      "        [   21.1404],\n",
      "        [   21.0154],\n",
      "        [   17.5154],\n",
      "        [   18.1404],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.5154],\n",
      "        [   17.1404],\n",
      "        [   28.6404],\n",
      "        [   21.6404],\n",
      "        [   19.8904],\n",
      "        [   12.8904],\n",
      "        [   13.1404],\n",
      "        [   76.2654],\n",
      "        [    2.7596],\n",
      "        [  220.5296],\n",
      "        [  287.6096]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[186,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.1296],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6404],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.6404],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.6404],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6404],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1091],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.1404],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.6404],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.1404],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6404],\n",
      "        [   37.8904],\n",
      "        [   58.6404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6404],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.3904],\n",
      "        [   18.8591],\n",
      "        [   11.6404],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6404],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.1404],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.6404],\n",
      "        [   19.6404],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5604],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6404],\n",
      "        [   22.6404],\n",
      "        [   15.0404],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.3596],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.6404],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.6404],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.3596],\n",
      "        [    1.4404],\n",
      "        [   37.1716],\n",
      "        [   10.6404],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.7654],\n",
      "        [  134.3596],\n",
      "        [   39.3596],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.8596],\n",
      "        [   16.7896],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6404],\n",
      "        [   11.6404],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  220.0296],\n",
      "        [    0.1031]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 342\n",
      "Number of shrink: 158\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 342\n",
      "Number of shrink: 158\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 7\n",
      "Reorganizing result: The final number of neuro is  7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.1296],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6404],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.6404],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.6404],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6404],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1091],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.1404],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.6404],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.1404],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6404],\n",
      "        [   37.8904],\n",
      "        [   58.6404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6404],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.3904],\n",
      "        [   18.8591],\n",
      "        [   11.6404],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6404],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.1404],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.6404],\n",
      "        [   19.6404],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5604],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6404],\n",
      "        [   22.6404],\n",
      "        [   15.0404],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.3596],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.6404],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.6404],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.3596],\n",
      "        [    1.4404],\n",
      "        [   37.1716],\n",
      "        [   10.6404],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.7654],\n",
      "        [  134.3596],\n",
      "        [   39.3596],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.8596],\n",
      "        [   16.7896],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6404],\n",
      "        [   11.6404],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  220.0296],\n",
      "        [    0.1031]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 7],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 67.4351418018341\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 180\n",
      "剩餘X 資料 torch.Size([23, 10])\n",
      "剩餘Y 資料 torch.Size([23, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (93779.640625, 0)\n",
      "The second_loss value of k: (98370.2890625, 15)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([332.5000])\n",
      "目前模型的Data狀態 torch.Size([188, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 97.3904],\n",
      "        [ 20.0154],\n",
      "        [267.6404],\n",
      "        [  7.6404],\n",
      "        [108.6404],\n",
      "        [ 16.3904],\n",
      "        [ 16.8784],\n",
      "        [ 23.6404],\n",
      "        [ 16.1404],\n",
      "        [ 20.5779],\n",
      "        [ 19.8904],\n",
      "        [ 44.6404],\n",
      "        [ 23.3904],\n",
      "        [ 15.7966],\n",
      "        [ 19.6404],\n",
      "        [  7.6404],\n",
      "        [ 22.6404],\n",
      "        [ 10.1404],\n",
      "        [175.9841],\n",
      "        [ 17.8513],\n",
      "        [ 22.3279],\n",
      "        [ 29.6404],\n",
      "        [ 16.0466],\n",
      "        [ 17.0349],\n",
      "        [ 13.6404],\n",
      "        [ 18.8748],\n",
      "        [ 35.1091],\n",
      "        [ 36.0154],\n",
      "        [  7.6404],\n",
      "        [ 42.1404],\n",
      "        [ 18.7654],\n",
      "        [ 18.1873],\n",
      "        [ 23.0154],\n",
      "        [ 31.6404],\n",
      "        [ 42.7654],\n",
      "        [ 22.6951],\n",
      "        [ 16.1716],\n",
      "        [ 11.6404],\n",
      "        [ 17.6716],\n",
      "        [ 22.2654],\n",
      "        [ 15.0466],\n",
      "        [ 29.2966],\n",
      "        [ 48.1404],\n",
      "        [ 18.1277],\n",
      "        [ 19.1705],\n",
      "        [  7.6404],\n",
      "        [ 31.6404],\n",
      "        [ 16.6404],\n",
      "        [ 37.8904],\n",
      "        [ 58.6404],\n",
      "        [  7.6404],\n",
      "        [ 21.7654],\n",
      "        [ 15.9177],\n",
      "        [  8.6404],\n",
      "        [ 12.3044],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 22.4841],\n",
      "        [ 19.8943],\n",
      "        [ 20.7683],\n",
      "        [ 20.7546],\n",
      "        [ 25.1873],\n",
      "        [ 22.3494],\n",
      "        [ 69.3904],\n",
      "        [ 18.8591],\n",
      "        [ 11.6404],\n",
      "        [ 27.2029],\n",
      "        [ 20.2029],\n",
      "        [ 18.5154],\n",
      "        [ 27.7341],\n",
      "        [ 31.6404],\n",
      "        [ 15.2029],\n",
      "        [ 19.1248],\n",
      "        [ 62.1404],\n",
      "        [ 23.6990],\n",
      "        [ 17.5076],\n",
      "        [ 37.6404],\n",
      "        [ 21.6404],\n",
      "        [ 23.3904],\n",
      "        [ 16.0310],\n",
      "        [ 23.4451],\n",
      "        [ 18.8279],\n",
      "        [ 29.6404],\n",
      "        [  7.6404],\n",
      "        [ 45.6404],\n",
      "        [ 19.5466],\n",
      "        [ 24.1091],\n",
      "        [ 21.8103],\n",
      "        [ 21.0124],\n",
      "        [  3.6091],\n",
      "        [ 10.1716],\n",
      "        [ 63.6404],\n",
      "        [  5.5935],\n",
      "        [ 17.9529],\n",
      "        [ 21.6404],\n",
      "        [  9.6404],\n",
      "        [ 22.6404],\n",
      "        [ 47.6404],\n",
      "        [ 13.0437],\n",
      "        [  9.3748],\n",
      "        [ 20.4529],\n",
      "        [ 20.0232],\n",
      "        [  7.6404],\n",
      "        [ 31.2966],\n",
      "        [  7.6404],\n",
      "        [ 12.3591],\n",
      "        [  7.6404],\n",
      "        [ 19.6980],\n",
      "        [ 16.7302],\n",
      "        [  7.6404],\n",
      "        [ 12.9216],\n",
      "        [ 43.8367],\n",
      "        [ 14.5271],\n",
      "        [148.3279],\n",
      "        [  7.6404],\n",
      "        [ 14.6970],\n",
      "        [ 12.8074],\n",
      "        [  9.3897],\n",
      "        [ 12.2954],\n",
      "        [ 20.1091],\n",
      "        [ 15.7810],\n",
      "        [ 43.6404],\n",
      "        [ 20.1560],\n",
      "        [ 25.3904],\n",
      "        [ 25.5154],\n",
      "        [  7.6404],\n",
      "        [ 38.3904],\n",
      "        [ 38.3904],\n",
      "        [ 39.6404],\n",
      "        [ 35.6404],\n",
      "        [ 22.2341],\n",
      "        [133.6404],\n",
      "        [ 16.3591],\n",
      "        [ 27.6404],\n",
      "        [ 80.6404],\n",
      "        [ 37.1716],\n",
      "        [ 10.6404],\n",
      "        [ 67.1404],\n",
      "        [ 24.7810],\n",
      "        [ 13.0779],\n",
      "        [ 13.0779],\n",
      "        [ 17.2498],\n",
      "        [122.8279],\n",
      "        [ 35.7654],\n",
      "        [ 19.6404],\n",
      "        [ 58.6404],\n",
      "        [  8.3904],\n",
      "        [ 30.3904],\n",
      "        [104.9529],\n",
      "        [ 65.6404],\n",
      "        [103.6404],\n",
      "        [ 19.9685],\n",
      "        [ 27.1404],\n",
      "        [ 27.1404],\n",
      "        [  7.6404],\n",
      "        [ 30.6404],\n",
      "        [ 17.7341],\n",
      "        [ 14.3123],\n",
      "        [ 23.2341],\n",
      "        [  7.6404],\n",
      "        [ 19.6716],\n",
      "        [  7.6404],\n",
      "        [170.6404],\n",
      "        [117.6404],\n",
      "        [ 26.1404],\n",
      "        [ 21.8904],\n",
      "        [ 17.7341],\n",
      "        [ 25.6404],\n",
      "        [ 21.6404],\n",
      "        [ 21.1404],\n",
      "        [ 17.5154],\n",
      "        [ 18.2654],\n",
      "        [ 17.8904],\n",
      "        [ 14.0154],\n",
      "        [ 13.3904],\n",
      "        [ 10.3904],\n",
      "        [ 16.6404],\n",
      "        [ 55.6404],\n",
      "        [ 21.6404],\n",
      "        [ 19.6404],\n",
      "        [ 13.6404],\n",
      "        [ 11.6404],\n",
      "        [ 77.6404],\n",
      "        [279.7596],\n",
      "        [ 67.6404],\n",
      "        [314.1031],\n",
      "        [ 26.2654]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.1296],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6404],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.6404],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.6404],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6404],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1091],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.1404],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.6404],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.1404],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6404],\n",
      "        [   37.8904],\n",
      "        [   58.6404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6404],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.3904],\n",
      "        [   18.8591],\n",
      "        [   11.6404],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6404],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.1404],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.6404],\n",
      "        [   19.6404],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5604],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6404],\n",
      "        [   22.6404],\n",
      "        [   15.0404],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.3596],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.6404],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.6404],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.3596],\n",
      "        [    1.4404],\n",
      "        [   37.1716],\n",
      "        [   10.6404],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.7654],\n",
      "        [  134.3596],\n",
      "        [   39.3596],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.8596],\n",
      "        [   16.7896],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6404],\n",
      "        [   11.6404],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  220.0296],\n",
      "        [    0.1031],\n",
      "        [  306.2346]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4672.1108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.1296],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6404],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.6404],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.6404],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6404],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1091],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.1404],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.6404],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.1404],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6404],\n",
      "        [   37.8904],\n",
      "        [   58.6404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6404],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.3904],\n",
      "        [   18.8591],\n",
      "        [   11.6404],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6404],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.1404],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.6404],\n",
      "        [   19.6404],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5604],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6404],\n",
      "        [   22.6404],\n",
      "        [   15.0404],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.3596],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.6404],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.6404],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.3596],\n",
      "        [    1.4404],\n",
      "        [   37.1716],\n",
      "        [   10.6404],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.7654],\n",
      "        [  134.3596],\n",
      "        [   39.3596],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.8596],\n",
      "        [   16.7896],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6404],\n",
      "        [   11.6404],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  220.0296],\n",
      "        [    0.1031],\n",
      "        [  306.2346]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[187,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.6404],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.3904],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3779],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7896],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.3904],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6482],\n",
      "        [   11.6248],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 342\n",
      "Number of shrink: 158\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.6404],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.3904],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3779],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7896],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.3904],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6482],\n",
      "        [   11.6248],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  4,  4,  7, 10], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 77.42444038391113\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 181\n",
      "剩餘X 資料 torch.Size([22, 10])\n",
      "剩餘Y 資料 torch.Size([22, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (98370.2890625, 14)\n",
      "The second_loss value of k: (100558.5078125, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引14，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([189, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 97.3904],\n",
      "        [ 20.0154],\n",
      "        [267.7654],\n",
      "        [  7.6404],\n",
      "        [108.6404],\n",
      "        [ 16.3904],\n",
      "        [ 16.8784],\n",
      "        [ 23.6091],\n",
      "        [ 16.1404],\n",
      "        [ 20.5779],\n",
      "        [ 19.8904],\n",
      "        [ 44.5779],\n",
      "        [ 23.3904],\n",
      "        [ 15.7966],\n",
      "        [ 19.7029],\n",
      "        [  7.6404],\n",
      "        [ 22.6404],\n",
      "        [ 10.1404],\n",
      "        [175.9841],\n",
      "        [ 17.8513],\n",
      "        [ 22.3279],\n",
      "        [ 29.6716],\n",
      "        [ 16.0466],\n",
      "        [ 17.0349],\n",
      "        [ 13.6404],\n",
      "        [ 18.8748],\n",
      "        [ 35.1248],\n",
      "        [ 36.0154],\n",
      "        [  7.6404],\n",
      "        [ 42.0154],\n",
      "        [ 18.7654],\n",
      "        [ 18.1873],\n",
      "        [ 23.0154],\n",
      "        [ 31.6404],\n",
      "        [ 42.7654],\n",
      "        [ 22.6951],\n",
      "        [ 16.1716],\n",
      "        [ 11.6404],\n",
      "        [ 17.6716],\n",
      "        [ 22.2654],\n",
      "        [ 15.0466],\n",
      "        [ 29.2966],\n",
      "        [ 48.0154],\n",
      "        [ 18.1277],\n",
      "        [ 19.1705],\n",
      "        [  7.6404],\n",
      "        [ 31.6404],\n",
      "        [ 16.6560],\n",
      "        [ 37.9529],\n",
      "        [ 58.3904],\n",
      "        [  7.6404],\n",
      "        [ 21.7654],\n",
      "        [ 15.9177],\n",
      "        [  8.6716],\n",
      "        [ 12.3044],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 22.4841],\n",
      "        [ 19.8943],\n",
      "        [ 20.7683],\n",
      "        [ 20.7546],\n",
      "        [ 25.1873],\n",
      "        [ 22.3494],\n",
      "        [ 69.1404],\n",
      "        [ 18.8591],\n",
      "        [ 11.5154],\n",
      "        [ 27.2029],\n",
      "        [ 20.2029],\n",
      "        [ 18.5154],\n",
      "        [ 27.7341],\n",
      "        [ 31.3904],\n",
      "        [ 15.2029],\n",
      "        [ 19.1248],\n",
      "        [ 62.3904],\n",
      "        [ 23.6990],\n",
      "        [ 17.5076],\n",
      "        [ 37.7654],\n",
      "        [ 21.7029],\n",
      "        [ 23.3904],\n",
      "        [ 16.0310],\n",
      "        [ 23.4451],\n",
      "        [ 18.8279],\n",
      "        [ 29.6404],\n",
      "        [  7.6404],\n",
      "        [ 45.6404],\n",
      "        [ 19.5466],\n",
      "        [ 24.1091],\n",
      "        [ 21.8103],\n",
      "        [ 21.0124],\n",
      "        [  3.6091],\n",
      "        [ 10.1716],\n",
      "        [ 63.6091],\n",
      "        [  5.5935],\n",
      "        [ 17.9529],\n",
      "        [ 21.6404],\n",
      "        [  9.6091],\n",
      "        [ 22.6404],\n",
      "        [ 47.3904],\n",
      "        [ 13.0437],\n",
      "        [  9.3748],\n",
      "        [ 20.4529],\n",
      "        [ 20.0232],\n",
      "        [  7.6404],\n",
      "        [ 31.2966],\n",
      "        [  7.6404],\n",
      "        [ 12.3591],\n",
      "        [  7.6404],\n",
      "        [ 19.6980],\n",
      "        [ 16.7302],\n",
      "        [  7.6404],\n",
      "        [ 12.9216],\n",
      "        [ 43.8367],\n",
      "        [ 14.5271],\n",
      "        [148.3279],\n",
      "        [  7.6404],\n",
      "        [ 14.6970],\n",
      "        [ 12.8074],\n",
      "        [  9.3897],\n",
      "        [ 12.2954],\n",
      "        [ 20.1091],\n",
      "        [ 15.7810],\n",
      "        [ 43.3904],\n",
      "        [ 20.1560],\n",
      "        [ 25.3904],\n",
      "        [ 25.5154],\n",
      "        [  7.8904],\n",
      "        [ 38.3904],\n",
      "        [ 38.3904],\n",
      "        [ 39.6404],\n",
      "        [ 35.8904],\n",
      "        [ 22.2341],\n",
      "        [133.6404],\n",
      "        [ 16.3591],\n",
      "        [ 27.7654],\n",
      "        [ 80.5779],\n",
      "        [ 37.1716],\n",
      "        [ 10.6560],\n",
      "        [ 67.3904],\n",
      "        [ 24.7810],\n",
      "        [ 13.0779],\n",
      "        [ 13.0779],\n",
      "        [ 17.2498],\n",
      "        [122.8279],\n",
      "        [ 35.8279],\n",
      "        [ 19.6404],\n",
      "        [ 58.6248],\n",
      "        [  8.3904],\n",
      "        [ 30.3904],\n",
      "        [104.9529],\n",
      "        [ 65.8904],\n",
      "        [103.6404],\n",
      "        [ 19.9685],\n",
      "        [ 27.1404],\n",
      "        [ 27.1404],\n",
      "        [  7.6404],\n",
      "        [ 30.6404],\n",
      "        [ 17.7341],\n",
      "        [ 14.3123],\n",
      "        [ 23.2341],\n",
      "        [  7.6404],\n",
      "        [ 19.6716],\n",
      "        [  7.6404],\n",
      "        [170.6404],\n",
      "        [117.6404],\n",
      "        [ 26.1404],\n",
      "        [ 21.8904],\n",
      "        [ 17.7341],\n",
      "        [ 25.6404],\n",
      "        [ 21.6404],\n",
      "        [ 21.1404],\n",
      "        [ 17.5154],\n",
      "        [ 18.2654],\n",
      "        [ 17.8904],\n",
      "        [ 14.0154],\n",
      "        [ 13.3904],\n",
      "        [ 10.3904],\n",
      "        [ 16.6404],\n",
      "        [ 55.3904],\n",
      "        [ 21.6404],\n",
      "        [ 19.6404],\n",
      "        [ 13.6482],\n",
      "        [ 11.6248],\n",
      "        [ 77.6404],\n",
      "        [279.7596],\n",
      "        [ 67.8904],\n",
      "        [314.1031],\n",
      "        [332.4933],\n",
      "        [309.6404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.6404],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.3904],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3779],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7896],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.3904],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6482],\n",
      "        [   11.6248],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067],\n",
      "        [  309.6404]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4657.2808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.6404],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.3904],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3779],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7896],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.3904],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6482],\n",
      "        [   11.6248],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067],\n",
      "        [  309.6404]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[188,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6404],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3779],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7584],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6482],\n",
      "        [   11.6248],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067],\n",
      "        [    0.2544]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 13\n",
      "Reorganizing result: The final number of neuro is  13\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6404],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3779],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7584],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6482],\n",
      "        [   11.6248],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067],\n",
      "        [    0.2544]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  4,  4,  7, 10, 13], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 90.74948692321777\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 182\n",
      "剩餘X 資料 torch.Size([21, 10])\n",
      "剩餘Y 資料 torch.Size([21, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (100558.5078125, 3)\n",
      "The second_loss value of k: (123453.578125, 15)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([384.])\n",
      "目前模型的Data狀態 torch.Size([190, 1])\n",
      "<<預測值>>\n",
      "tensor([[   97.3904],\n",
      "        [   20.0154],\n",
      "        [  267.7654],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [   16.3904],\n",
      "        [   16.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   20.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [   23.3904],\n",
      "        [   15.7966],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [   22.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6404],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   37.7654],\n",
      "        [   21.7029],\n",
      "        [   23.3904],\n",
      "        [   16.0310],\n",
      "        [   23.4451],\n",
      "        [   18.8279],\n",
      "        [   29.6404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [   19.5466],\n",
      "        [   24.1091],\n",
      "        [   21.8103],\n",
      "        [   21.0124],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   63.6091],\n",
      "        [    5.5935],\n",
      "        [   17.9529],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   47.3904],\n",
      "        [   13.0437],\n",
      "        [    9.3748],\n",
      "        [   20.4529],\n",
      "        [   20.0232],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   12.9216],\n",
      "        [   43.8367],\n",
      "        [   14.5271],\n",
      "        [  148.3279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   20.1091],\n",
      "        [   15.7810],\n",
      "        [   43.3904],\n",
      "        [   20.1560],\n",
      "        [   25.3904],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   39.6404],\n",
      "        [   35.8904],\n",
      "        [   22.2341],\n",
      "        [  133.6404],\n",
      "        [   16.3591],\n",
      "        [   27.7654],\n",
      "        [   80.5779],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   67.3904],\n",
      "        [   24.7810],\n",
      "        [   13.0779],\n",
      "        [   13.0779],\n",
      "        [   17.2498],\n",
      "        [  122.8279],\n",
      "        [   35.8279],\n",
      "        [   19.6404],\n",
      "        [   58.6248],\n",
      "        [    8.3904],\n",
      "        [   30.3904],\n",
      "        [  104.9529],\n",
      "        [   65.8904],\n",
      "        [  103.6716],\n",
      "        [   19.9685],\n",
      "        [   27.1404],\n",
      "        [   27.1404],\n",
      "        [    7.6404],\n",
      "        [   30.6404],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [   23.2341],\n",
      "        [    7.6404],\n",
      "        [   19.6716],\n",
      "        [    7.6404],\n",
      "        [  170.6404],\n",
      "        [  117.6404],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [   25.6404],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   55.6404],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6482],\n",
      "        [   11.6248],\n",
      "        [   77.6404],\n",
      "        [  279.7596],\n",
      "        [   67.8904],\n",
      "        [  314.1031],\n",
      "        [  332.4933],\n",
      "        [    0.2544],\n",
      "        [   66.8904]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6404],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3779],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7584],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6482],\n",
      "        [   11.6248],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067],\n",
      "        [    0.2544],\n",
      "        [  317.1096]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4657.5771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6404],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6404],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6404],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6404],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6404],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3779],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7584],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6404],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2654],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3904],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6404],\n",
      "        [   19.6404],\n",
      "        [   13.6482],\n",
      "        [   11.6248],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067],\n",
      "        [    0.2544],\n",
      "        [  317.1096]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[189,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6423],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7271],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2659],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067],\n",
      "        [    0.2544],\n",
      "        [    0.0062]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 16\n",
      "Reorganizing result: The final number of neuro is  16\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6423],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7271],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2659],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067],\n",
      "        [    0.2544],\n",
      "        [    0.0062]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  4,  4,  7, 10, 13, 16], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 107.68448495864868\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 183\n",
      "剩餘X 資料 torch.Size([20, 10])\n",
      "剩餘Y 資料 torch.Size([20, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (123453.578125, 14)\n",
      "The second_loss value of k: (138116.578125, 4)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引14，y= tensor([359.])\n",
      "目前模型的Data狀態 torch.Size([191, 1])\n",
      "<<預測值>>\n",
      "tensor([[   97.3904],\n",
      "        [   20.0154],\n",
      "        [  267.7654],\n",
      "        [    7.6404],\n",
      "        [  108.6423],\n",
      "        [   16.3904],\n",
      "        [   16.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   20.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [   23.3904],\n",
      "        [   15.7966],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [   22.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   37.7654],\n",
      "        [   21.7029],\n",
      "        [   23.3904],\n",
      "        [   16.0310],\n",
      "        [   23.4451],\n",
      "        [   18.8279],\n",
      "        [   29.6404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [   19.5466],\n",
      "        [   24.1091],\n",
      "        [   21.8103],\n",
      "        [   21.0124],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   63.6091],\n",
      "        [    5.5935],\n",
      "        [   17.9529],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   47.3904],\n",
      "        [   13.0437],\n",
      "        [    9.3748],\n",
      "        [   20.4529],\n",
      "        [   20.0232],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   12.9216],\n",
      "        [   43.8367],\n",
      "        [   14.5271],\n",
      "        [  148.3279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   20.1091],\n",
      "        [   15.7810],\n",
      "        [   43.3904],\n",
      "        [   20.1560],\n",
      "        [   25.3904],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   39.6404],\n",
      "        [   35.8904],\n",
      "        [   22.2341],\n",
      "        [  133.6716],\n",
      "        [   16.3591],\n",
      "        [   27.7654],\n",
      "        [   80.5769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   67.3904],\n",
      "        [   24.7810],\n",
      "        [   13.0779],\n",
      "        [   13.0779],\n",
      "        [   17.2498],\n",
      "        [  122.8279],\n",
      "        [   35.8279],\n",
      "        [   19.6404],\n",
      "        [   58.6248],\n",
      "        [    8.3904],\n",
      "        [   30.3904],\n",
      "        [  104.9529],\n",
      "        [   65.8904],\n",
      "        [  103.7029],\n",
      "        [   19.9685],\n",
      "        [   27.1404],\n",
      "        [   27.1404],\n",
      "        [    7.6404],\n",
      "        [   30.6404],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [   23.2341],\n",
      "        [    7.6404],\n",
      "        [   19.6716],\n",
      "        [    7.6404],\n",
      "        [  170.6404],\n",
      "        [  117.6404],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [   25.6404],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2659],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   16.6404],\n",
      "        [   55.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [  279.7596],\n",
      "        [   67.8904],\n",
      "        [  314.1031],\n",
      "        [  332.4933],\n",
      "        [    0.2544],\n",
      "        [  383.9938],\n",
      "        [    7.6404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6423],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7271],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2659],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067],\n",
      "        [    0.2544],\n",
      "        [    0.0062],\n",
      "        [  351.3596]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4753.1226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6404],\n",
      "        [  108.6423],\n",
      "        [    0.1304],\n",
      "        [   15.8784],\n",
      "        [   23.6091],\n",
      "        [   16.1404],\n",
      "        [   15.5779],\n",
      "        [   19.8904],\n",
      "        [   44.5779],\n",
      "        [  202.6096],\n",
      "        [   71.5934],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8513],\n",
      "        [   22.3279],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0349],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0154],\n",
      "        [    7.6404],\n",
      "        [   42.0154],\n",
      "        [   18.7654],\n",
      "        [   18.1873],\n",
      "        [   23.0154],\n",
      "        [   31.6404],\n",
      "        [   42.7654],\n",
      "        [   22.6951],\n",
      "        [   16.1716],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2654],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1277],\n",
      "        [   19.1705],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9177],\n",
      "        [    8.6716],\n",
      "        [   12.3044],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.8943],\n",
      "        [   20.7683],\n",
      "        [   20.7546],\n",
      "        [   25.1873],\n",
      "        [   22.3494],\n",
      "        [   69.1404],\n",
      "        [   18.8591],\n",
      "        [   11.5154],\n",
      "        [   27.2029],\n",
      "        [   20.2029],\n",
      "        [   18.5154],\n",
      "        [   27.7341],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1248],\n",
      "        [   62.3904],\n",
      "        [   23.6990],\n",
      "        [   17.5076],\n",
      "        [   27.7654],\n",
      "        [   19.7029],\n",
      "        [  202.6096],\n",
      "        [   12.5310],\n",
      "        [   18.9651],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5466],\n",
      "        [   24.1091],\n",
      "        [   11.3103],\n",
      "        [   77.9876],\n",
      "        [    3.6091],\n",
      "        [   10.1716],\n",
      "        [   38.5291],\n",
      "        [    5.5935],\n",
      "        [   48.5471],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9563],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9768],\n",
      "        [    7.6404],\n",
      "        [   31.2966],\n",
      "        [    7.6404],\n",
      "        [   12.3591],\n",
      "        [    7.6404],\n",
      "        [   19.6980],\n",
      "        [   16.7302],\n",
      "        [    7.6404],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5271],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6970],\n",
      "        [   12.8074],\n",
      "        [    9.3897],\n",
      "        [   12.2954],\n",
      "        [   23.8909],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.5154],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.2096],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.1721],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.9529],\n",
      "        [   47.6096],\n",
      "        [   16.7271],\n",
      "        [  119.0315],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7341],\n",
      "        [   14.3123],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.8904],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.2659],\n",
      "        [   17.8904],\n",
      "        [   14.0154],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   16.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7596],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0067],\n",
      "        [    0.2544],\n",
      "        [    0.0062],\n",
      "        [  351.3596]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[190,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6423],\n",
      "        [  109.6423],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5779],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.8904],\n",
      "        [   18.8279],\n",
      "        [   11.5154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   47.6096],\n",
      "        [   16.7271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.2544],\n",
      "        [    0.0062],\n",
      "        [    0.0003]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 19\n",
      "Reorganizing result: The final number of neuro is  19\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6423],\n",
      "        [  109.6423],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5779],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.8904],\n",
      "        [   18.8279],\n",
      "        [   11.5154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   47.6096],\n",
      "        [   16.7271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.2544],\n",
      "        [    0.0062],\n",
      "        [    0.0003]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  4,  4,  7, 10, 13, 16, 19], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 127.75940203666687\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 184\n",
      "剩餘X 資料 torch.Size([19, 10])\n",
      "剩餘Y 資料 torch.Size([19, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (138116.578125, 4)\n",
      "The second_loss value of k: (144079.734375, 8)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引4，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([192, 1])\n",
      "<<預測值>>\n",
      "tensor([[   97.3904],\n",
      "        [   20.0154],\n",
      "        [  267.7654],\n",
      "        [    7.6423],\n",
      "        [  109.6423],\n",
      "        [   16.3591],\n",
      "        [   16.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   20.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5779],\n",
      "        [   23.4529],\n",
      "        [   15.8279],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [   22.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.8904],\n",
      "        [   18.8279],\n",
      "        [   11.5154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   37.7654],\n",
      "        [   20.7029],\n",
      "        [   23.4529],\n",
      "        [   15.9998],\n",
      "        [   23.4529],\n",
      "        [   18.8279],\n",
      "        [   29.6404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [   19.5779],\n",
      "        [   24.2029],\n",
      "        [   21.8162],\n",
      "        [   21.0115],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   64.6091],\n",
      "        [    5.6091],\n",
      "        [   17.8904],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   47.3904],\n",
      "        [   13.0525],\n",
      "        [    9.3748],\n",
      "        [   20.4529],\n",
      "        [   20.0310],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   12.9216],\n",
      "        [   43.8367],\n",
      "        [   14.5310],\n",
      "        [  148.3279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   20.1169],\n",
      "        [   15.7810],\n",
      "        [   43.3904],\n",
      "        [   20.1560],\n",
      "        [   25.3904],\n",
      "        [   25.3904],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   39.6404],\n",
      "        [   35.8904],\n",
      "        [   22.2341],\n",
      "        [  133.6716],\n",
      "        [   16.3591],\n",
      "        [   27.7654],\n",
      "        [   80.5769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   67.1404],\n",
      "        [   24.7810],\n",
      "        [   13.0779],\n",
      "        [   13.0779],\n",
      "        [   17.2498],\n",
      "        [  122.7654],\n",
      "        [   35.8279],\n",
      "        [   19.6404],\n",
      "        [   58.6248],\n",
      "        [    8.3904],\n",
      "        [   30.3904],\n",
      "        [  104.8904],\n",
      "        [   65.8904],\n",
      "        [  103.7029],\n",
      "        [   19.9373],\n",
      "        [   27.1404],\n",
      "        [   27.1404],\n",
      "        [    7.6404],\n",
      "        [   30.6404],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [   23.2341],\n",
      "        [    7.6404],\n",
      "        [   19.6716],\n",
      "        [    7.6404],\n",
      "        [  170.6404],\n",
      "        [  117.6404],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [   25.6404],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   55.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [  279.7615],\n",
      "        [   67.8904],\n",
      "        [  314.1031],\n",
      "        [  332.5558],\n",
      "        [    0.2544],\n",
      "        [  383.9938],\n",
      "        [  358.9997],\n",
      "        [  373.6404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6423],\n",
      "        [  109.6423],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5779],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.8904],\n",
      "        [   18.8279],\n",
      "        [   11.5154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   47.6096],\n",
      "        [   16.7271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.2544],\n",
      "        [    0.0062],\n",
      "        [    0.0003],\n",
      "        [  373.6404]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4813.5454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6423],\n",
      "        [  109.6423],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5779],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   11.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.8904],\n",
      "        [   18.8279],\n",
      "        [   11.5154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    7.8904],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   31.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   47.6096],\n",
      "        [   16.7271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.2544],\n",
      "        [    0.0062],\n",
      "        [    0.0003],\n",
      "        [  373.6404]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[191,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6423],\n",
      "        [  109.6423],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5779],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.8904],\n",
      "        [   18.8279],\n",
      "        [   11.5154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    0.1096],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   27.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.6096],\n",
      "        [   24.7271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.2544],\n",
      "        [    0.0062],\n",
      "        [    0.0003],\n",
      "        [    0.3596]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 2\n",
      "Number of shrink: 8\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 20 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 21 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 22 / 22\n",
      "Reorganizing result: The final number of neuro is  22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6423],\n",
      "        [  109.6423],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5779],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.8904],\n",
      "        [   18.8279],\n",
      "        [   11.5154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    0.1096],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   27.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.6096],\n",
      "        [   24.7271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.2544],\n",
      "        [    0.0062],\n",
      "        [    0.0003],\n",
      "        [    0.3596]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  4,  4,  7, 10, 13, 16, 19, 22], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 151.2686915397644\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 185\n",
      "剩餘X 資料 torch.Size([18, 10])\n",
      "剩餘Y 資料 torch.Size([18, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (144079.734375, 7)\n",
      "The second_loss value of k: (153278.171875, 11)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引7，y= tensor([403.])\n",
      "目前模型的Data狀態 torch.Size([193, 1])\n",
      "<<預測值>>\n",
      "tensor([[    97.3904],\n",
      "        [    20.0154],\n",
      "        [   267.7654],\n",
      "        [     7.6423],\n",
      "        [   109.6423],\n",
      "        [    16.3591],\n",
      "        [    16.8789],\n",
      "        [    23.6091],\n",
      "        [    16.1560],\n",
      "        [    20.5466],\n",
      "        [    19.9529],\n",
      "        [    44.5779],\n",
      "        [    23.4529],\n",
      "        [    15.8279],\n",
      "        [    19.7029],\n",
      "        [     7.6404],\n",
      "        [    22.6404],\n",
      "        [    10.1404],\n",
      "        [   175.9841],\n",
      "        [    17.8611],\n",
      "        [    22.3591],\n",
      "        [    29.6716],\n",
      "        [    16.0466],\n",
      "        [    17.0466],\n",
      "        [    13.6443],\n",
      "        [    18.8748],\n",
      "        [    35.1248],\n",
      "        [    36.0779],\n",
      "        [     7.6404],\n",
      "        [    42.2654],\n",
      "        [    18.7654],\n",
      "        [    18.2029],\n",
      "        [    22.9529],\n",
      "        [    31.6716],\n",
      "        [    42.8904],\n",
      "        [    22.7029],\n",
      "        [    16.1794],\n",
      "        [    15.5154],\n",
      "        [    17.6716],\n",
      "        [    22.2966],\n",
      "        [    15.0466],\n",
      "        [    29.2966],\n",
      "        [    48.0154],\n",
      "        [    18.1394],\n",
      "        [    19.1700],\n",
      "        [     7.6404],\n",
      "        [    31.6404],\n",
      "        [    16.6560],\n",
      "        [    37.9529],\n",
      "        [    58.3904],\n",
      "        [     7.6404],\n",
      "        [    21.7654],\n",
      "        [    15.9216],\n",
      "        [     8.6716],\n",
      "        [    12.3201],\n",
      "        [     7.6404],\n",
      "        [     7.6404],\n",
      "        [     7.6404],\n",
      "        [    22.4841],\n",
      "        [    19.9021],\n",
      "        [    20.7752],\n",
      "        [    20.7615],\n",
      "        [    25.1873],\n",
      "        [    22.3572],\n",
      "        [    68.8904],\n",
      "        [    18.8279],\n",
      "        [    11.5154],\n",
      "        [    27.2654],\n",
      "        [    20.1716],\n",
      "        [    18.6404],\n",
      "        [    27.6716],\n",
      "        [    31.6716],\n",
      "        [    15.2029],\n",
      "        [    19.1091],\n",
      "        [    62.3904],\n",
      "        [    23.7068],\n",
      "        [    17.4841],\n",
      "        [    37.7654],\n",
      "        [    20.7029],\n",
      "        [    23.4529],\n",
      "        [    15.9998],\n",
      "        [    23.4529],\n",
      "        [    18.8279],\n",
      "        [    29.6404],\n",
      "        [     7.6404],\n",
      "        [    45.6482],\n",
      "        [    19.5779],\n",
      "        [    24.2029],\n",
      "        [    21.8162],\n",
      "        [    21.0115],\n",
      "        [     3.6091],\n",
      "        [    10.2029],\n",
      "        [    64.6091],\n",
      "        [     5.6091],\n",
      "        [    17.8904],\n",
      "        [    21.6404],\n",
      "        [     9.6091],\n",
      "        [    22.6404],\n",
      "        [    47.3904],\n",
      "        [    13.0525],\n",
      "        [     9.3748],\n",
      "        [    20.4529],\n",
      "        [    20.0310],\n",
      "        [     7.6404],\n",
      "        [    31.2654],\n",
      "        [     7.6404],\n",
      "        [    12.3748],\n",
      "        [     7.6404],\n",
      "        [    19.6958],\n",
      "        [    16.7380],\n",
      "        [     7.6414],\n",
      "        [    12.9216],\n",
      "        [    43.8367],\n",
      "        [    14.5310],\n",
      "        [   148.3279],\n",
      "        [     7.6404],\n",
      "        [    14.6892],\n",
      "        [    12.8074],\n",
      "        [     9.3898],\n",
      "        [    12.2952],\n",
      "        [    20.1169],\n",
      "        [    15.7810],\n",
      "        [    43.3904],\n",
      "        [    20.1560],\n",
      "        [    25.3904],\n",
      "        [    25.3904],\n",
      "        [    -0.1096],\n",
      "        [    38.3904],\n",
      "        [    38.3904],\n",
      "        [    39.6404],\n",
      "        [    31.8904],\n",
      "        [    22.2341],\n",
      "        [   133.6716],\n",
      "        [    16.3591],\n",
      "        [    27.7654],\n",
      "        [    80.5769],\n",
      "        [    37.1716],\n",
      "        [    10.6560],\n",
      "        [    67.1404],\n",
      "        [    24.7810],\n",
      "        [    13.0779],\n",
      "        [    13.0779],\n",
      "        [    17.2498],\n",
      "        [   122.7654],\n",
      "        [    35.8279],\n",
      "        [    19.6404],\n",
      "        [    58.6248],\n",
      "        [     8.3904],\n",
      "        [    30.3904],\n",
      "        [   104.8904],\n",
      "        [    67.8904],\n",
      "        [    95.7029],\n",
      "        [    19.9373],\n",
      "        [    27.1404],\n",
      "        [    27.1404],\n",
      "        [     7.6404],\n",
      "        [    30.6404],\n",
      "        [    17.7029],\n",
      "        [    14.2966],\n",
      "        [    23.2341],\n",
      "        [     7.6404],\n",
      "        [    19.6716],\n",
      "        [     7.6404],\n",
      "        [   170.6404],\n",
      "        [   117.6404],\n",
      "        [    26.1404],\n",
      "        [    21.9529],\n",
      "        [    17.7341],\n",
      "        [    25.6404],\n",
      "        [    21.6384],\n",
      "        [    21.1404],\n",
      "        [    17.5154],\n",
      "        [    18.1409],\n",
      "        [    17.9529],\n",
      "        [    14.1404],\n",
      "        [    13.3904],\n",
      "        [    10.3914],\n",
      "        [    15.6404],\n",
      "        [    55.6404],\n",
      "        [    21.6423],\n",
      "        [    19.6716],\n",
      "        [    13.6482],\n",
      "        [    11.6209],\n",
      "        [    77.6404],\n",
      "        [   279.7615],\n",
      "        [    67.8904],\n",
      "        [   314.1031],\n",
      "        [   332.5558],\n",
      "        [     0.2544],\n",
      "        [   383.9938],\n",
      "        [   358.9997],\n",
      "        [    -0.3596],\n",
      "        [    23.3904]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6423],\n",
      "        [  109.6423],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5779],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.8904],\n",
      "        [   18.8279],\n",
      "        [   11.5154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    0.1096],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   27.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.6096],\n",
      "        [   24.7271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.2544],\n",
      "        [    0.0062],\n",
      "        [    0.0003],\n",
      "        [    0.3596],\n",
      "        [  379.6096]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4811.6528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   58.0046],\n",
      "        [    7.6423],\n",
      "        [  109.6423],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5779],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    7.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.6404],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.3904],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.8904],\n",
      "        [   18.8279],\n",
      "        [   11.5154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   45.6482],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.7904],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   11.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    0.1096],\n",
      "        [   38.3904],\n",
      "        [   38.3904],\n",
      "        [   16.1404],\n",
      "        [   27.8904],\n",
      "        [   42.2659],\n",
      "        [  133.6716],\n",
      "        [  219.6409],\n",
      "        [   43.2346],\n",
      "        [    1.3769],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.8279],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.6096],\n",
      "        [   24.7271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.3596],\n",
      "        [  120.3596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.3596],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   40.6404],\n",
      "        [   21.6423],\n",
      "        [   19.6716],\n",
      "        [   13.6482],\n",
      "        [   11.6209],\n",
      "        [   77.6404],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.2544],\n",
      "        [    0.0062],\n",
      "        [    0.0003],\n",
      "        [    0.3596],\n",
      "        [  379.6096]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[192,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8298],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    8.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7654],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.1404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6404],\n",
      "        [   18.8279],\n",
      "        [   11.0154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.4216],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   46.5232],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.5404],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    3.1096],\n",
      "        [   38.4529],\n",
      "        [   38.4529],\n",
      "        [   16.6404],\n",
      "        [   26.6404],\n",
      "        [   42.2659],\n",
      "        [  133.0466],\n",
      "        [  219.6409],\n",
      "        [   43.6096],\n",
      "        [    1.3144],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.7654],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1096],\n",
      "        [   25.2271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.6409],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   43.8904],\n",
      "        [   21.6423],\n",
      "        [   21.4216],\n",
      "        [   13.0310],\n",
      "        [   11.4177],\n",
      "        [   77.7888],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.8794],\n",
      "        [    0.2562],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.3904]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 8\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 20 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 21 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 22 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 23 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 24 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 25 / 25\n",
      "Reorganizing result: The final number of neuro is  25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8298],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    8.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7654],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.1404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6404],\n",
      "        [   18.8279],\n",
      "        [   11.0154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.4216],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   46.5232],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.5404],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    3.1096],\n",
      "        [   38.4529],\n",
      "        [   38.4529],\n",
      "        [   16.6404],\n",
      "        [   26.6404],\n",
      "        [   42.2659],\n",
      "        [  133.0466],\n",
      "        [  219.6409],\n",
      "        [   43.6096],\n",
      "        [    1.3144],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.7654],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1096],\n",
      "        [   25.2271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.6409],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   43.8904],\n",
      "        [   21.6423],\n",
      "        [   21.4216],\n",
      "        [   13.0310],\n",
      "        [   11.4177],\n",
      "        [   77.7888],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.8794],\n",
      "        [    0.2562],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.3904]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  4,  4,  7, 10, 13, 16, 19, 22, 25], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 178.21138525009155\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 186\n",
      "剩餘X 資料 torch.Size([17, 10])\n",
      "剩餘Y 資料 torch.Size([17, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (154160.328125, 10)\n",
      "The second_loss value of k: (159089.0, 9)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引10，y= tensor([0.])\n",
      "目前模型的Data狀態 torch.Size([194, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 97.3904],\n",
      "        [ 20.0154],\n",
      "        [268.6404],\n",
      "        [  7.6423],\n",
      "        [109.8298],\n",
      "        [ 16.3591],\n",
      "        [ 16.8789],\n",
      "        [ 23.6091],\n",
      "        [ 16.1560],\n",
      "        [ 20.5466],\n",
      "        [ 19.9529],\n",
      "        [ 44.5154],\n",
      "        [ 23.4529],\n",
      "        [ 15.8279],\n",
      "        [ 19.7029],\n",
      "        [  8.6404],\n",
      "        [ 22.6404],\n",
      "        [ 10.1404],\n",
      "        [175.9841],\n",
      "        [ 17.8611],\n",
      "        [ 22.3591],\n",
      "        [ 29.6716],\n",
      "        [ 16.0466],\n",
      "        [ 17.0466],\n",
      "        [ 13.6443],\n",
      "        [ 18.8748],\n",
      "        [ 35.1248],\n",
      "        [ 36.0779],\n",
      "        [  7.6404],\n",
      "        [ 42.2654],\n",
      "        [ 18.7654],\n",
      "        [ 18.2029],\n",
      "        [ 22.9529],\n",
      "        [ 31.6716],\n",
      "        [ 42.8904],\n",
      "        [ 22.7029],\n",
      "        [ 16.1794],\n",
      "        [ 15.5154],\n",
      "        [ 17.6716],\n",
      "        [ 22.2966],\n",
      "        [ 15.0466],\n",
      "        [ 29.2966],\n",
      "        [ 48.0154],\n",
      "        [ 18.1394],\n",
      "        [ 19.1700],\n",
      "        [  7.6404],\n",
      "        [ 30.7654],\n",
      "        [ 16.6560],\n",
      "        [ 37.9529],\n",
      "        [ 58.1404],\n",
      "        [  7.6404],\n",
      "        [ 21.7654],\n",
      "        [ 15.9216],\n",
      "        [  8.6716],\n",
      "        [ 12.3201],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 22.4841],\n",
      "        [ 19.9021],\n",
      "        [ 20.7752],\n",
      "        [ 20.7615],\n",
      "        [ 25.1873],\n",
      "        [ 22.3572],\n",
      "        [ 68.6404],\n",
      "        [ 18.8279],\n",
      "        [ 11.0154],\n",
      "        [ 27.2654],\n",
      "        [ 20.1716],\n",
      "        [ 18.6404],\n",
      "        [ 27.6716],\n",
      "        [ 31.4216],\n",
      "        [ 15.2029],\n",
      "        [ 19.1091],\n",
      "        [ 62.3904],\n",
      "        [ 23.7068],\n",
      "        [ 17.4841],\n",
      "        [ 37.7654],\n",
      "        [ 20.7029],\n",
      "        [ 23.4529],\n",
      "        [ 15.9998],\n",
      "        [ 23.4529],\n",
      "        [ 18.8279],\n",
      "        [ 29.6404],\n",
      "        [  7.6404],\n",
      "        [ 46.5232],\n",
      "        [ 19.5779],\n",
      "        [ 24.2029],\n",
      "        [ 21.8162],\n",
      "        [ 21.0115],\n",
      "        [  3.6091],\n",
      "        [ 10.2029],\n",
      "        [ 64.6091],\n",
      "        [  5.6091],\n",
      "        [ 17.8904],\n",
      "        [ 21.6404],\n",
      "        [  9.6091],\n",
      "        [ 22.6404],\n",
      "        [ 47.1404],\n",
      "        [ 13.0525],\n",
      "        [  9.3748],\n",
      "        [ 20.4529],\n",
      "        [ 20.0310],\n",
      "        [  7.6404],\n",
      "        [ 31.2654],\n",
      "        [  7.6404],\n",
      "        [ 12.3748],\n",
      "        [  7.6404],\n",
      "        [ 19.6958],\n",
      "        [ 16.7380],\n",
      "        [  7.6414],\n",
      "        [ 12.9216],\n",
      "        [ 43.8367],\n",
      "        [ 14.5310],\n",
      "        [148.3279],\n",
      "        [  7.6404],\n",
      "        [ 14.6892],\n",
      "        [ 12.8074],\n",
      "        [  9.3898],\n",
      "        [ 12.2952],\n",
      "        [ 20.1169],\n",
      "        [ 15.7810],\n",
      "        [ 44.3904],\n",
      "        [ 20.1560],\n",
      "        [ 25.3904],\n",
      "        [ 25.3904],\n",
      "        [ -3.1096],\n",
      "        [ 38.4529],\n",
      "        [ 38.4529],\n",
      "        [ 40.1404],\n",
      "        [ 30.6404],\n",
      "        [ 22.2341],\n",
      "        [133.0466],\n",
      "        [ 16.3591],\n",
      "        [ 27.3904],\n",
      "        [ 80.5144],\n",
      "        [ 37.1716],\n",
      "        [ 10.6560],\n",
      "        [ 67.1404],\n",
      "        [ 24.7810],\n",
      "        [ 13.0779],\n",
      "        [ 13.0779],\n",
      "        [ 17.2498],\n",
      "        [122.7654],\n",
      "        [ 35.7654],\n",
      "        [ 19.6404],\n",
      "        [ 58.6248],\n",
      "        [  8.3904],\n",
      "        [ 30.3904],\n",
      "        [104.8904],\n",
      "        [ 68.3904],\n",
      "        [ 95.2029],\n",
      "        [ 19.9373],\n",
      "        [ 27.1404],\n",
      "        [ 27.1404],\n",
      "        [  7.6404],\n",
      "        [ 30.6404],\n",
      "        [ 17.7029],\n",
      "        [ 14.2966],\n",
      "        [ 23.2341],\n",
      "        [  7.6404],\n",
      "        [ 19.6716],\n",
      "        [  7.6404],\n",
      "        [170.7966],\n",
      "        [118.1404],\n",
      "        [ 26.1404],\n",
      "        [ 21.9529],\n",
      "        [ 17.7341],\n",
      "        [ 25.3591],\n",
      "        [ 21.6384],\n",
      "        [ 21.1404],\n",
      "        [ 17.5154],\n",
      "        [ 18.1409],\n",
      "        [ 17.9529],\n",
      "        [ 14.1404],\n",
      "        [ 13.3904],\n",
      "        [ 10.3914],\n",
      "        [ 15.6404],\n",
      "        [ 58.8904],\n",
      "        [ 21.6423],\n",
      "        [ 21.4216],\n",
      "        [ 13.0310],\n",
      "        [ 11.4177],\n",
      "        [ 77.7888],\n",
      "        [279.7615],\n",
      "        [ 67.8904],\n",
      "        [314.1031],\n",
      "        [332.5558],\n",
      "        [  0.8794],\n",
      "        [383.7438],\n",
      "        [358.9997],\n",
      "        [ -0.8596],\n",
      "        [403.3904],\n",
      "        [392.5076]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8298],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    8.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7654],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.1404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6404],\n",
      "        [   18.8279],\n",
      "        [   11.0154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.4216],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   46.5232],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.5404],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    3.1096],\n",
      "        [   38.4529],\n",
      "        [   38.4529],\n",
      "        [   16.6404],\n",
      "        [   26.6404],\n",
      "        [   42.2659],\n",
      "        [  133.0466],\n",
      "        [  219.6409],\n",
      "        [   43.6096],\n",
      "        [    1.3144],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.7654],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1096],\n",
      "        [   25.2271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.6409],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   43.8904],\n",
      "        [   21.6423],\n",
      "        [   21.4216],\n",
      "        [   13.0310],\n",
      "        [   11.4177],\n",
      "        [   77.7888],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.8794],\n",
      "        [    0.2562],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.3904],\n",
      "        [  392.5076]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4837.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8298],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [    8.6404],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7654],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.1404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6404],\n",
      "        [   18.8279],\n",
      "        [   11.0154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.4216],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   46.5232],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.5404],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.6096],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    3.1096],\n",
      "        [   38.4529],\n",
      "        [   38.4529],\n",
      "        [   16.6404],\n",
      "        [   26.6404],\n",
      "        [   42.2659],\n",
      "        [  133.0466],\n",
      "        [  219.6409],\n",
      "        [   43.6096],\n",
      "        [    1.3144],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.7654],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1096],\n",
      "        [   25.2271],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.6409],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   43.8904],\n",
      "        [   21.6423],\n",
      "        [   21.4216],\n",
      "        [   13.0310],\n",
      "        [   11.4177],\n",
      "        [   77.7888],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.8794],\n",
      "        [    0.2562],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.3904],\n",
      "        [  392.5076]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[193,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8298],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [   10.1091],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7654],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.1404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6404],\n",
      "        [   18.8279],\n",
      "        [   11.0154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   46.5232],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.5404],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.4846],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    4.3596],\n",
      "        [   38.4529],\n",
      "        [   38.4529],\n",
      "        [   16.6404],\n",
      "        [   26.6404],\n",
      "        [   42.2659],\n",
      "        [  133.0466],\n",
      "        [  219.6409],\n",
      "        [   43.6096],\n",
      "        [    1.3144],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6404],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1096],\n",
      "        [   24.6334],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.6096],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   21.6716],\n",
      "        [   13.0310],\n",
      "        [   11.4177],\n",
      "        [   77.7888],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.8794],\n",
      "        [    0.2562],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.6404],\n",
      "        [    0.0076]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 8\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 329\n",
      "Number of shrink: 171\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 330\n",
      "Number of shrink: 170\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 20 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 21 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 22 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 330\n",
      "Number of shrink: 170\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 23 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 24 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 25 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 26 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 27 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 28 / 28\n",
      "Reorganizing result: The final number of neuro is  28\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8298],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [   10.1091],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7654],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.1404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6404],\n",
      "        [   18.8279],\n",
      "        [   11.0154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   46.5232],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.5404],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.4846],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    4.3596],\n",
      "        [   38.4529],\n",
      "        [   38.4529],\n",
      "        [   16.6404],\n",
      "        [   26.6404],\n",
      "        [   42.2659],\n",
      "        [  133.0466],\n",
      "        [  219.6409],\n",
      "        [   43.6096],\n",
      "        [    1.3144],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6404],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1096],\n",
      "        [   24.6334],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.6096],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   21.6716],\n",
      "        [   13.0310],\n",
      "        [   11.4177],\n",
      "        [   77.7888],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.8794],\n",
      "        [    0.2562],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.6404],\n",
      "        [    0.0076]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  4,  4,  7, 10, 13, 16, 19, 22, 25, 28],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 208.66763710975647\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 187\n",
      "剩餘X 資料 torch.Size([16, 10])\n",
      "剩餘Y 資料 torch.Size([16, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (159089.0, 9)\n",
      "The second_loss value of k: (195019.0625, 11)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引9，y= tensor([420.])\n",
      "目前模型的Data狀態 torch.Size([195, 1])\n",
      "<<預測值>>\n",
      "tensor([[    97.3904],\n",
      "        [    20.0154],\n",
      "        [   268.6404],\n",
      "        [     7.6423],\n",
      "        [   109.8298],\n",
      "        [    16.3591],\n",
      "        [    16.8789],\n",
      "        [    23.6091],\n",
      "        [    16.1560],\n",
      "        [    20.5466],\n",
      "        [    19.9529],\n",
      "        [    44.5154],\n",
      "        [    23.4529],\n",
      "        [    15.8279],\n",
      "        [    19.7029],\n",
      "        [    10.1091],\n",
      "        [    22.6404],\n",
      "        [    10.1404],\n",
      "        [   175.9841],\n",
      "        [    17.8611],\n",
      "        [    22.3591],\n",
      "        [    29.6716],\n",
      "        [    16.0466],\n",
      "        [    17.0466],\n",
      "        [    13.6443],\n",
      "        [    18.8748],\n",
      "        [    35.1248],\n",
      "        [    36.0779],\n",
      "        [     7.6404],\n",
      "        [    42.2654],\n",
      "        [    18.7654],\n",
      "        [    18.2029],\n",
      "        [    22.9529],\n",
      "        [    31.6716],\n",
      "        [    42.8904],\n",
      "        [    22.7029],\n",
      "        [    16.1794],\n",
      "        [    15.5154],\n",
      "        [    17.6716],\n",
      "        [    22.2966],\n",
      "        [    15.0466],\n",
      "        [    29.2966],\n",
      "        [    48.0154],\n",
      "        [    18.1394],\n",
      "        [    19.1700],\n",
      "        [     7.6404],\n",
      "        [    30.7654],\n",
      "        [    16.6560],\n",
      "        [    37.9529],\n",
      "        [    58.1404],\n",
      "        [     7.6404],\n",
      "        [    21.7654],\n",
      "        [    15.9216],\n",
      "        [     8.6716],\n",
      "        [    12.3201],\n",
      "        [     7.6404],\n",
      "        [     7.6404],\n",
      "        [     7.6404],\n",
      "        [    22.4841],\n",
      "        [    19.9021],\n",
      "        [    20.7752],\n",
      "        [    20.7615],\n",
      "        [    25.1873],\n",
      "        [    22.3572],\n",
      "        [    68.6404],\n",
      "        [    18.8279],\n",
      "        [    11.0154],\n",
      "        [    27.2654],\n",
      "        [    20.1716],\n",
      "        [    18.6404],\n",
      "        [    27.6716],\n",
      "        [    31.6716],\n",
      "        [    15.2029],\n",
      "        [    19.1091],\n",
      "        [    62.3904],\n",
      "        [    23.7068],\n",
      "        [    17.4841],\n",
      "        [    37.7654],\n",
      "        [    20.7029],\n",
      "        [    23.4529],\n",
      "        [    15.9998],\n",
      "        [    23.4529],\n",
      "        [    18.8279],\n",
      "        [    29.6404],\n",
      "        [     7.6404],\n",
      "        [    46.5232],\n",
      "        [    19.5779],\n",
      "        [    24.2029],\n",
      "        [    21.8162],\n",
      "        [    21.0115],\n",
      "        [     3.6091],\n",
      "        [    10.2029],\n",
      "        [    64.6091],\n",
      "        [     5.6091],\n",
      "        [    17.8904],\n",
      "        [    21.6404],\n",
      "        [     9.6091],\n",
      "        [    22.6404],\n",
      "        [    47.1404],\n",
      "        [    13.0525],\n",
      "        [     9.3748],\n",
      "        [    20.4529],\n",
      "        [    20.0310],\n",
      "        [     7.6404],\n",
      "        [    31.2654],\n",
      "        [     7.6404],\n",
      "        [    12.3748],\n",
      "        [     7.6404],\n",
      "        [    19.6958],\n",
      "        [    16.7380],\n",
      "        [     7.6414],\n",
      "        [    12.9216],\n",
      "        [    43.8367],\n",
      "        [    14.5310],\n",
      "        [   148.3279],\n",
      "        [     7.6404],\n",
      "        [    14.6892],\n",
      "        [    12.8074],\n",
      "        [     9.3898],\n",
      "        [    12.2952],\n",
      "        [    20.1169],\n",
      "        [    15.7810],\n",
      "        [    44.5154],\n",
      "        [    20.1560],\n",
      "        [    25.3904],\n",
      "        [    25.3904],\n",
      "        [    -4.3596],\n",
      "        [    38.4529],\n",
      "        [    38.4529],\n",
      "        [    40.1404],\n",
      "        [    30.6404],\n",
      "        [    22.2341],\n",
      "        [   133.0466],\n",
      "        [    16.3591],\n",
      "        [    27.3904],\n",
      "        [    80.5144],\n",
      "        [    37.1716],\n",
      "        [    10.6560],\n",
      "        [    67.1404],\n",
      "        [    24.7810],\n",
      "        [    13.0779],\n",
      "        [    13.0779],\n",
      "        [    17.2498],\n",
      "        [   122.7654],\n",
      "        [    35.6404],\n",
      "        [    19.6404],\n",
      "        [    58.6248],\n",
      "        [     8.3904],\n",
      "        [    30.3904],\n",
      "        [   104.8904],\n",
      "        [    68.3904],\n",
      "        [    95.7966],\n",
      "        [    19.9373],\n",
      "        [    27.1404],\n",
      "        [    27.1404],\n",
      "        [     7.6404],\n",
      "        [    30.6404],\n",
      "        [    17.7029],\n",
      "        [    14.2966],\n",
      "        [    23.2341],\n",
      "        [     7.6404],\n",
      "        [    19.6716],\n",
      "        [     7.6404],\n",
      "        [   170.7966],\n",
      "        [   118.1404],\n",
      "        [    26.1404],\n",
      "        [    21.9529],\n",
      "        [    17.7341],\n",
      "        [    25.3904],\n",
      "        [    21.6384],\n",
      "        [    21.1404],\n",
      "        [    17.5154],\n",
      "        [    18.1409],\n",
      "        [    17.9529],\n",
      "        [    14.1404],\n",
      "        [    13.3904],\n",
      "        [    10.3914],\n",
      "        [    15.6404],\n",
      "        [    67.6404],\n",
      "        [    21.6423],\n",
      "        [    21.6716],\n",
      "        [    13.0310],\n",
      "        [    11.4177],\n",
      "        [    77.7888],\n",
      "        [   279.7615],\n",
      "        [    67.8904],\n",
      "        [   314.1031],\n",
      "        [   332.5558],\n",
      "        [     0.8794],\n",
      "        [   383.7438],\n",
      "        [   358.9997],\n",
      "        [    -0.8596],\n",
      "        [   403.6404],\n",
      "        [     0.0076],\n",
      "        [    21.0154]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8298],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [   10.1091],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7654],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.1404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6404],\n",
      "        [   18.8279],\n",
      "        [   11.0154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   46.5232],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.5404],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.4846],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    4.3596],\n",
      "        [   38.4529],\n",
      "        [   38.4529],\n",
      "        [   16.6404],\n",
      "        [   26.6404],\n",
      "        [   42.2659],\n",
      "        [  133.0466],\n",
      "        [  219.6409],\n",
      "        [   43.6096],\n",
      "        [    1.3144],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6404],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1096],\n",
      "        [   24.6334],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.6096],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   21.6716],\n",
      "        [   13.0310],\n",
      "        [   11.4177],\n",
      "        [   77.7888],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.8794],\n",
      "        [    0.2562],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.6404],\n",
      "        [    0.0076],\n",
      "        [  398.9846]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(4843.6763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8298],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6091],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5471],\n",
      "        [   71.5621],\n",
      "        [   19.7029],\n",
      "        [   10.1091],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6443],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2654],\n",
      "        [   18.7654],\n",
      "        [   18.2029],\n",
      "        [   22.9529],\n",
      "        [   31.6716],\n",
      "        [   42.8904],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.5154],\n",
      "        [   17.6716],\n",
      "        [   22.2966],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7654],\n",
      "        [   16.6560],\n",
      "        [   37.9529],\n",
      "        [   58.1404],\n",
      "        [    7.6404],\n",
      "        [   21.7654],\n",
      "        [   15.9216],\n",
      "        [    8.6716],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6404],\n",
      "        [   18.8279],\n",
      "        [   11.0154],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6716],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3904],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7029],\n",
      "        [  202.5471],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3279],\n",
      "        [   22.9404],\n",
      "        [    7.6404],\n",
      "        [   46.5232],\n",
      "        [    9.5779],\n",
      "        [   24.2029],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6096],\n",
      "        [   21.6404],\n",
      "        [    9.6091],\n",
      "        [   22.6404],\n",
      "        [   14.5404],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.4846],\n",
      "        [   34.8440],\n",
      "        [  123.6096],\n",
      "        [   25.3904],\n",
      "        [    4.3596],\n",
      "        [   38.4529],\n",
      "        [   38.4529],\n",
      "        [   16.6404],\n",
      "        [   26.6404],\n",
      "        [   42.2659],\n",
      "        [  133.0466],\n",
      "        [  219.6409],\n",
      "        [   43.6096],\n",
      "        [    1.3144],\n",
      "        [   37.1716],\n",
      "        [   10.6560],\n",
      "        [   18.4596],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6404],\n",
      "        [  134.3596],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1096],\n",
      "        [   24.6334],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3596],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8596],\n",
      "        [   26.1404],\n",
      "        [   21.9529],\n",
      "        [   17.7341],\n",
      "        [  151.6096],\n",
      "        [   21.6384],\n",
      "        [   21.1404],\n",
      "        [   17.5154],\n",
      "        [   18.1409],\n",
      "        [   17.9529],\n",
      "        [   14.1404],\n",
      "        [   13.3904],\n",
      "        [   10.3914],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   21.6716],\n",
      "        [   13.0310],\n",
      "        [   11.4177],\n",
      "        [   77.7888],\n",
      "        [    2.7615],\n",
      "        [  219.7796],\n",
      "        [    0.1031],\n",
      "        [    0.0558],\n",
      "        [    0.8794],\n",
      "        [    0.2562],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.6404],\n",
      "        [    0.0076],\n",
      "        [  398.9846]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[194,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8318],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6248],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5393],\n",
      "        [   71.5621],\n",
      "        [   19.6746],\n",
      "        [   10.0935],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6755],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2732],\n",
      "        [   18.7693],\n",
      "        [   18.2029],\n",
      "        [   22.9373],\n",
      "        [   31.6716],\n",
      "        [   42.8884],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.4529],\n",
      "        [   17.6716],\n",
      "        [   22.2986],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7732],\n",
      "        [   16.6482],\n",
      "        [   37.9509],\n",
      "        [   58.1091],\n",
      "        [    7.6404],\n",
      "        [   21.7655],\n",
      "        [   15.9216],\n",
      "        [    8.6736],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6560],\n",
      "        [   18.8279],\n",
      "        [   11.0115],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6091],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3748],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7009],\n",
      "        [  202.5393],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3318],\n",
      "        [   23.0029],\n",
      "        [    7.6404],\n",
      "        [   46.5154],\n",
      "        [    9.5779],\n",
      "        [   24.2034],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6091],\n",
      "        [   21.6404],\n",
      "        [    9.6052],\n",
      "        [   22.6091],\n",
      "        [   14.5229],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.4690],\n",
      "        [   34.8440],\n",
      "        [  123.5784],\n",
      "        [   25.3904],\n",
      "        [    4.4690],\n",
      "        [   38.4607],\n",
      "        [   38.4607],\n",
      "        [   16.6326],\n",
      "        [   26.3435],\n",
      "        [   42.2659],\n",
      "        [  133.0544],\n",
      "        [  219.6409],\n",
      "        [   43.6174],\n",
      "        [    1.3154],\n",
      "        [   37.1716],\n",
      "        [   10.6716],\n",
      "        [   18.4674],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6335],\n",
      "        [  134.3635],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1721],\n",
      "        [   24.6646],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3909],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8518],\n",
      "        [   26.1716],\n",
      "        [   21.9607],\n",
      "        [   17.7341],\n",
      "        [  151.6096],\n",
      "        [   21.6248],\n",
      "        [   21.1482],\n",
      "        [   17.5134],\n",
      "        [   18.1599],\n",
      "        [   17.9607],\n",
      "        [   14.1404],\n",
      "        [   13.3992],\n",
      "        [   10.3894],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   21.6873],\n",
      "        [   13.0310],\n",
      "        [   11.4255],\n",
      "        [   77.7869],\n",
      "        [    2.7615],\n",
      "        [  219.7660],\n",
      "        [    0.1091],\n",
      "        [    0.0466],\n",
      "        [    0.8767],\n",
      "        [    0.2659],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.6091],\n",
      "        [    0.0002],\n",
      "        [    0.0024]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 8\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 330\n",
      "Number of shrink: 170\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 329\n",
      "Number of shrink: 171\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 20 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 21 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 22 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 23 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 24 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 330\n",
      "Number of shrink: 170\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 25 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 26 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 27 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 28 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 29 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 30 / 31\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 31 / 31\n",
      "Reorganizing result: The final number of neuro is  31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8318],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6248],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5393],\n",
      "        [   71.5621],\n",
      "        [   19.6746],\n",
      "        [   10.0935],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6755],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2732],\n",
      "        [   18.7693],\n",
      "        [   18.2029],\n",
      "        [   22.9373],\n",
      "        [   31.6716],\n",
      "        [   42.8884],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.4529],\n",
      "        [   17.6716],\n",
      "        [   22.2986],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7732],\n",
      "        [   16.6482],\n",
      "        [   37.9509],\n",
      "        [   58.1091],\n",
      "        [    7.6404],\n",
      "        [   21.7655],\n",
      "        [   15.9216],\n",
      "        [    8.6736],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6560],\n",
      "        [   18.8279],\n",
      "        [   11.0115],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6091],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3748],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7009],\n",
      "        [  202.5393],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3318],\n",
      "        [   23.0029],\n",
      "        [    7.6404],\n",
      "        [   46.5154],\n",
      "        [    9.5779],\n",
      "        [   24.2034],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6091],\n",
      "        [   21.6404],\n",
      "        [    9.6052],\n",
      "        [   22.6091],\n",
      "        [   14.5229],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.4690],\n",
      "        [   34.8440],\n",
      "        [  123.5784],\n",
      "        [   25.3904],\n",
      "        [    4.4690],\n",
      "        [   38.4607],\n",
      "        [   38.4607],\n",
      "        [   16.6326],\n",
      "        [   26.3435],\n",
      "        [   42.2659],\n",
      "        [  133.0544],\n",
      "        [  219.6409],\n",
      "        [   43.6174],\n",
      "        [    1.3154],\n",
      "        [   37.1716],\n",
      "        [   10.6716],\n",
      "        [   18.4674],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6335],\n",
      "        [  134.3635],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1721],\n",
      "        [   24.6646],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3909],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8518],\n",
      "        [   26.1716],\n",
      "        [   21.9607],\n",
      "        [   17.7341],\n",
      "        [  151.6096],\n",
      "        [   21.6248],\n",
      "        [   21.1482],\n",
      "        [   17.5134],\n",
      "        [   18.1599],\n",
      "        [   17.9607],\n",
      "        [   14.1404],\n",
      "        [   13.3992],\n",
      "        [   10.3894],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   21.6873],\n",
      "        [   13.0310],\n",
      "        [   11.4255],\n",
      "        [   77.7869],\n",
      "        [    2.7615],\n",
      "        [  219.7660],\n",
      "        [    0.1091],\n",
      "        [    0.0466],\n",
      "        [    0.8767],\n",
      "        [    0.2659],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.6091],\n",
      "        [    0.0002],\n",
      "        [    0.0024]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  4,  4,  7, 10, 13, 16, 19, 22, 25, 28, 31],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 242.2586636543274\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 188\n",
      "剩餘X 資料 torch.Size([15, 10])\n",
      "剩餘Y 資料 torch.Size([15, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (195019.0625, 10)\n",
      "The second_loss value of k: (233027.875, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引10，y= tensor([465.])\n",
      "目前模型的Data狀態 torch.Size([196, 1])\n",
      "<<預測值>>\n",
      "tensor([[    97.3904],\n",
      "        [    20.0154],\n",
      "        [   268.6404],\n",
      "        [     7.6423],\n",
      "        [   109.8318],\n",
      "        [    16.3591],\n",
      "        [    16.8789],\n",
      "        [    23.6248],\n",
      "        [    16.1560],\n",
      "        [    20.5466],\n",
      "        [    19.9529],\n",
      "        [    44.5154],\n",
      "        [    23.4607],\n",
      "        [    15.8279],\n",
      "        [    19.6746],\n",
      "        [    10.0935],\n",
      "        [    22.6404],\n",
      "        [    10.1404],\n",
      "        [   175.9841],\n",
      "        [    17.8611],\n",
      "        [    22.3591],\n",
      "        [    29.6716],\n",
      "        [    16.0466],\n",
      "        [    17.0466],\n",
      "        [    13.6755],\n",
      "        [    18.8748],\n",
      "        [    35.1248],\n",
      "        [    36.0779],\n",
      "        [     7.6404],\n",
      "        [    42.2732],\n",
      "        [    18.7693],\n",
      "        [    18.2029],\n",
      "        [    22.9373],\n",
      "        [    31.6716],\n",
      "        [    42.8884],\n",
      "        [    22.7029],\n",
      "        [    16.1794],\n",
      "        [    15.4529],\n",
      "        [    17.6716],\n",
      "        [    22.2986],\n",
      "        [    15.0466],\n",
      "        [    29.2966],\n",
      "        [    48.0154],\n",
      "        [    18.1394],\n",
      "        [    19.1700],\n",
      "        [     7.6404],\n",
      "        [    30.7732],\n",
      "        [    16.6482],\n",
      "        [    37.9509],\n",
      "        [    58.1091],\n",
      "        [     7.6404],\n",
      "        [    21.7655],\n",
      "        [    15.9216],\n",
      "        [     8.6736],\n",
      "        [    12.3201],\n",
      "        [     7.6404],\n",
      "        [     7.6404],\n",
      "        [     7.6404],\n",
      "        [    22.4841],\n",
      "        [    19.9021],\n",
      "        [    20.7752],\n",
      "        [    20.7615],\n",
      "        [    25.1873],\n",
      "        [    22.3572],\n",
      "        [    68.6560],\n",
      "        [    18.8279],\n",
      "        [    11.0115],\n",
      "        [    27.2654],\n",
      "        [    20.1716],\n",
      "        [    18.6404],\n",
      "        [    27.6716],\n",
      "        [    31.6091],\n",
      "        [    15.2029],\n",
      "        [    19.1091],\n",
      "        [    62.3748],\n",
      "        [    23.7068],\n",
      "        [    17.4841],\n",
      "        [    37.7654],\n",
      "        [    20.7009],\n",
      "        [    23.4607],\n",
      "        [    15.9998],\n",
      "        [    23.4529],\n",
      "        [    18.8318],\n",
      "        [    29.7029],\n",
      "        [     7.6404],\n",
      "        [    46.5154],\n",
      "        [    19.5779],\n",
      "        [    24.2034],\n",
      "        [    21.8162],\n",
      "        [    21.0115],\n",
      "        [     3.6091],\n",
      "        [    10.2029],\n",
      "        [    64.6091],\n",
      "        [     5.6091],\n",
      "        [    17.8909],\n",
      "        [    21.6404],\n",
      "        [     9.6052],\n",
      "        [    22.6091],\n",
      "        [    47.1229],\n",
      "        [    13.0525],\n",
      "        [     9.3748],\n",
      "        [    20.4529],\n",
      "        [    20.0310],\n",
      "        [     7.6404],\n",
      "        [    31.2654],\n",
      "        [     7.6404],\n",
      "        [    12.3748],\n",
      "        [     7.6404],\n",
      "        [    19.6958],\n",
      "        [    16.7380],\n",
      "        [     7.6414],\n",
      "        [    12.9216],\n",
      "        [    43.8367],\n",
      "        [    14.5310],\n",
      "        [   148.3279],\n",
      "        [     7.6404],\n",
      "        [    14.6892],\n",
      "        [    12.8074],\n",
      "        [     9.3898],\n",
      "        [    12.2952],\n",
      "        [    20.1169],\n",
      "        [    15.7810],\n",
      "        [    44.5310],\n",
      "        [    20.1560],\n",
      "        [    25.4216],\n",
      "        [    25.3904],\n",
      "        [    -4.4690],\n",
      "        [    38.4607],\n",
      "        [    38.4607],\n",
      "        [    40.1326],\n",
      "        [    30.3435],\n",
      "        [    22.2341],\n",
      "        [   133.0544],\n",
      "        [    16.3591],\n",
      "        [    27.3826],\n",
      "        [    80.5154],\n",
      "        [    37.1716],\n",
      "        [    10.6716],\n",
      "        [    67.1326],\n",
      "        [    24.7810],\n",
      "        [    13.0779],\n",
      "        [    13.0779],\n",
      "        [    17.2498],\n",
      "        [   122.7654],\n",
      "        [    35.6335],\n",
      "        [    19.6365],\n",
      "        [    58.6248],\n",
      "        [     8.3904],\n",
      "        [    30.3904],\n",
      "        [   104.8904],\n",
      "        [    68.3279],\n",
      "        [    95.7654],\n",
      "        [    19.9373],\n",
      "        [    27.1404],\n",
      "        [    27.1404],\n",
      "        [     7.6404],\n",
      "        [    30.6091],\n",
      "        [    17.7029],\n",
      "        [    14.2966],\n",
      "        [    23.2341],\n",
      "        [     7.6404],\n",
      "        [    19.6716],\n",
      "        [     7.6404],\n",
      "        [   170.7966],\n",
      "        [   118.1482],\n",
      "        [    26.1716],\n",
      "        [    21.9607],\n",
      "        [    17.7341],\n",
      "        [    25.3904],\n",
      "        [    21.6248],\n",
      "        [    21.1482],\n",
      "        [    17.5134],\n",
      "        [    18.1599],\n",
      "        [    17.9607],\n",
      "        [    14.1404],\n",
      "        [    13.3992],\n",
      "        [    10.3894],\n",
      "        [    15.6404],\n",
      "        [    67.6404],\n",
      "        [    21.6423],\n",
      "        [    21.6873],\n",
      "        [    13.0310],\n",
      "        [    11.4255],\n",
      "        [    77.7869],\n",
      "        [   279.7615],\n",
      "        [    67.9041],\n",
      "        [   314.1091],\n",
      "        [   332.5466],\n",
      "        [     0.8767],\n",
      "        [   383.7341],\n",
      "        [   358.9997],\n",
      "        [    -0.8596],\n",
      "        [   403.6091],\n",
      "        [    -0.0002],\n",
      "        [   420.0024],\n",
      "        [    23.3904]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8318],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6248],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5393],\n",
      "        [   71.5621],\n",
      "        [   19.6746],\n",
      "        [   10.0935],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6755],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2732],\n",
      "        [   18.7693],\n",
      "        [   18.2029],\n",
      "        [   22.9373],\n",
      "        [   31.6716],\n",
      "        [   42.8884],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.4529],\n",
      "        [   17.6716],\n",
      "        [   22.2986],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7732],\n",
      "        [   16.6482],\n",
      "        [   37.9509],\n",
      "        [   58.1091],\n",
      "        [    7.6404],\n",
      "        [   21.7655],\n",
      "        [   15.9216],\n",
      "        [    8.6736],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6560],\n",
      "        [   18.8279],\n",
      "        [   11.0115],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6091],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3748],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7009],\n",
      "        [  202.5393],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3318],\n",
      "        [   23.0029],\n",
      "        [    7.6404],\n",
      "        [   46.5154],\n",
      "        [    9.5779],\n",
      "        [   24.2034],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6091],\n",
      "        [   21.6404],\n",
      "        [    9.6052],\n",
      "        [   22.6091],\n",
      "        [   14.5229],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.4690],\n",
      "        [   34.8440],\n",
      "        [  123.5784],\n",
      "        [   25.3904],\n",
      "        [    4.4690],\n",
      "        [   38.4607],\n",
      "        [   38.4607],\n",
      "        [   16.6326],\n",
      "        [   26.3435],\n",
      "        [   42.2659],\n",
      "        [  133.0544],\n",
      "        [  219.6409],\n",
      "        [   43.6174],\n",
      "        [    1.3154],\n",
      "        [   37.1716],\n",
      "        [   10.6716],\n",
      "        [   18.4674],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6335],\n",
      "        [  134.3635],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1721],\n",
      "        [   24.6646],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3909],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8518],\n",
      "        [   26.1716],\n",
      "        [   21.9607],\n",
      "        [   17.7341],\n",
      "        [  151.6096],\n",
      "        [   21.6248],\n",
      "        [   21.1482],\n",
      "        [   17.5134],\n",
      "        [   18.1599],\n",
      "        [   17.9607],\n",
      "        [   14.1404],\n",
      "        [   13.3992],\n",
      "        [   10.3894],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   21.6873],\n",
      "        [   13.0310],\n",
      "        [   11.4255],\n",
      "        [   77.7869],\n",
      "        [    2.7615],\n",
      "        [  219.7660],\n",
      "        [    0.1091],\n",
      "        [    0.0466],\n",
      "        [    0.8767],\n",
      "        [    0.2659],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.6091],\n",
      "        [    0.0002],\n",
      "        [    0.0024],\n",
      "        [  441.6096]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(5001.6650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.1296],\n",
      "        [    7.6423],\n",
      "        [  109.8318],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6248],\n",
      "        [   16.1560],\n",
      "        [   15.5466],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5393],\n",
      "        [   71.5621],\n",
      "        [   19.6746],\n",
      "        [   10.0935],\n",
      "        [    9.6404],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6755],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2732],\n",
      "        [   18.7693],\n",
      "        [   18.2029],\n",
      "        [   22.9373],\n",
      "        [   31.6716],\n",
      "        [   42.8884],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   15.4529],\n",
      "        [   17.6716],\n",
      "        [   22.2986],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   48.0154],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   30.7732],\n",
      "        [   16.6482],\n",
      "        [   37.9509],\n",
      "        [   58.1091],\n",
      "        [    7.6404],\n",
      "        [   21.7655],\n",
      "        [   15.9216],\n",
      "        [    8.6736],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.6560],\n",
      "        [   18.8279],\n",
      "        [   11.0115],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.6404],\n",
      "        [   27.6716],\n",
      "        [   31.6091],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3748],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   27.7654],\n",
      "        [   18.7009],\n",
      "        [  202.5393],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3318],\n",
      "        [   23.0029],\n",
      "        [    7.6404],\n",
      "        [   46.5154],\n",
      "        [    9.5779],\n",
      "        [   24.2034],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6091],\n",
      "        [   21.6404],\n",
      "        [    9.6052],\n",
      "        [   22.6091],\n",
      "        [   14.5229],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1279],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.4690],\n",
      "        [   34.8440],\n",
      "        [  123.5784],\n",
      "        [   25.3904],\n",
      "        [    4.4690],\n",
      "        [   38.4607],\n",
      "        [   38.4607],\n",
      "        [   16.6326],\n",
      "        [   26.3435],\n",
      "        [   42.2659],\n",
      "        [  133.0544],\n",
      "        [  219.6409],\n",
      "        [   43.6174],\n",
      "        [    1.3154],\n",
      "        [   37.1716],\n",
      "        [   10.6716],\n",
      "        [   18.4674],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6335],\n",
      "        [  134.3635],\n",
      "        [   39.3752],\n",
      "        [   96.6096],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   45.1721],\n",
      "        [   24.6646],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3909],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.2034],\n",
      "        [  119.8518],\n",
      "        [   26.1716],\n",
      "        [   21.9607],\n",
      "        [   17.7341],\n",
      "        [  151.6096],\n",
      "        [   21.6248],\n",
      "        [   21.1482],\n",
      "        [   17.5134],\n",
      "        [   18.1599],\n",
      "        [   17.9607],\n",
      "        [   14.1404],\n",
      "        [   13.3992],\n",
      "        [   10.3894],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   21.6873],\n",
      "        [   13.0310],\n",
      "        [   11.4255],\n",
      "        [   77.7869],\n",
      "        [    2.7615],\n",
      "        [  219.7660],\n",
      "        [    0.1091],\n",
      "        [    0.0466],\n",
      "        [    0.8767],\n",
      "        [    0.2659],\n",
      "        [    0.0003],\n",
      "        [    0.8596],\n",
      "        [    0.6091],\n",
      "        [    0.0002],\n",
      "        [    0.0024],\n",
      "        [  441.6096]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[195,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.2390],\n",
      "        [    7.6423],\n",
      "        [  109.5310],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6248],\n",
      "        [   16.1560],\n",
      "        [   15.5726],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5393],\n",
      "        [   71.5621],\n",
      "        [   19.6746],\n",
      "        [   10.5779],\n",
      "        [    9.6794],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6755],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2576],\n",
      "        [   18.7693],\n",
      "        [   18.2029],\n",
      "        [   22.9373],\n",
      "        [   31.6716],\n",
      "        [   42.8884],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   14.6716],\n",
      "        [   17.6716],\n",
      "        [   22.2986],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   47.9060],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.5466],\n",
      "        [   16.6482],\n",
      "        [   37.9509],\n",
      "        [   57.8845],\n",
      "        [    7.6404],\n",
      "        [   21.7986],\n",
      "        [   15.9216],\n",
      "        [    8.5154],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.5037],\n",
      "        [   18.8279],\n",
      "        [    9.9060],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.5857],\n",
      "        [   27.6716],\n",
      "        [   29.7029],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3748],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   28.2498],\n",
      "        [   18.7009],\n",
      "        [  202.5393],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3318],\n",
      "        [   22.7841],\n",
      "        [    7.6404],\n",
      "        [   46.2810],\n",
      "        [    9.5779],\n",
      "        [   24.2034],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6091],\n",
      "        [   21.6404],\n",
      "        [    9.3435],\n",
      "        [   22.5730],\n",
      "        [   16.0248],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1240],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.1565],\n",
      "        [   34.8440],\n",
      "        [  123.5784],\n",
      "        [   25.3904],\n",
      "        [    2.7346],\n",
      "        [   38.4607],\n",
      "        [   38.4607],\n",
      "        [   16.4373],\n",
      "        [   25.2654],\n",
      "        [   42.2659],\n",
      "        [  134.3748],\n",
      "        [  219.6409],\n",
      "        [   43.6174],\n",
      "        [    1.3154],\n",
      "        [   37.1716],\n",
      "        [   10.7966],\n",
      "        [   18.6593],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6335],\n",
      "        [  134.3635],\n",
      "        [   38.9299],\n",
      "        [   96.5823],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   44.9846],\n",
      "        [   22.9146],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3909],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.1721],\n",
      "        [  118.8127],\n",
      "        [   26.1716],\n",
      "        [   21.9607],\n",
      "        [   17.7341],\n",
      "        [  152.1565],\n",
      "        [   21.6248],\n",
      "        [   21.1482],\n",
      "        [   17.5134],\n",
      "        [   18.1599],\n",
      "        [   17.9607],\n",
      "        [   14.1404],\n",
      "        [   13.3992],\n",
      "        [   10.3894],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   20.9841],\n",
      "        [   12.7185],\n",
      "        [   11.4373],\n",
      "        [   77.4685],\n",
      "        [    2.7615],\n",
      "        [  220.0140],\n",
      "        [    0.1091],\n",
      "        [    0.0466],\n",
      "        [    1.7029],\n",
      "        [    0.2659],\n",
      "        [    0.0003],\n",
      "        [    0.5159],\n",
      "        [    2.7029],\n",
      "        [    1.2341],\n",
      "        [    0.0505],\n",
      "        [    0.0038]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 8\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 329\n",
      "Number of shrink: 171\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 329\n",
      "Number of shrink: 171\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 20 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 21 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 22 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 330\n",
      "Number of shrink: 170\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 23 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 24 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 25 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 26 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 27 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 28 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 29 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 30 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 31 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 32 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 33 / 34\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 34 / 34\n",
      "Reorganizing result: The final number of neuro is  34\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.2390],\n",
      "        [    7.6423],\n",
      "        [  109.5310],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6248],\n",
      "        [   16.1560],\n",
      "        [   15.5726],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5393],\n",
      "        [   71.5621],\n",
      "        [   19.6746],\n",
      "        [   10.5779],\n",
      "        [    9.6794],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6755],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2576],\n",
      "        [   18.7693],\n",
      "        [   18.2029],\n",
      "        [   22.9373],\n",
      "        [   31.6716],\n",
      "        [   42.8884],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   14.6716],\n",
      "        [   17.6716],\n",
      "        [   22.2986],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   47.9060],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.5466],\n",
      "        [   16.6482],\n",
      "        [   37.9509],\n",
      "        [   57.8845],\n",
      "        [    7.6404],\n",
      "        [   21.7986],\n",
      "        [   15.9216],\n",
      "        [    8.5154],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.5037],\n",
      "        [   18.8279],\n",
      "        [    9.9060],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.5857],\n",
      "        [   27.6716],\n",
      "        [   29.7029],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3748],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   28.2498],\n",
      "        [   18.7009],\n",
      "        [  202.5393],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3318],\n",
      "        [   22.7841],\n",
      "        [    7.6404],\n",
      "        [   46.2810],\n",
      "        [    9.5779],\n",
      "        [   24.2034],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6091],\n",
      "        [   21.6404],\n",
      "        [    9.3435],\n",
      "        [   22.5730],\n",
      "        [   16.0248],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1240],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.1565],\n",
      "        [   34.8440],\n",
      "        [  123.5784],\n",
      "        [   25.3904],\n",
      "        [    2.7346],\n",
      "        [   38.4607],\n",
      "        [   38.4607],\n",
      "        [   16.4373],\n",
      "        [   25.2654],\n",
      "        [   42.2659],\n",
      "        [  134.3748],\n",
      "        [  219.6409],\n",
      "        [   43.6174],\n",
      "        [    1.3154],\n",
      "        [   37.1716],\n",
      "        [   10.7966],\n",
      "        [   18.6593],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6335],\n",
      "        [  134.3635],\n",
      "        [   38.9299],\n",
      "        [   96.5823],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   44.9846],\n",
      "        [   22.9146],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3909],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.1721],\n",
      "        [  118.8127],\n",
      "        [   26.1716],\n",
      "        [   21.9607],\n",
      "        [   17.7341],\n",
      "        [  152.1565],\n",
      "        [   21.6248],\n",
      "        [   21.1482],\n",
      "        [   17.5134],\n",
      "        [   18.1599],\n",
      "        [   17.9607],\n",
      "        [   14.1404],\n",
      "        [   13.3992],\n",
      "        [   10.3894],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   20.9841],\n",
      "        [   12.7185],\n",
      "        [   11.4373],\n",
      "        [   77.4685],\n",
      "        [    2.7615],\n",
      "        [  220.0140],\n",
      "        [    0.1091],\n",
      "        [    0.0466],\n",
      "        [    1.7029],\n",
      "        [    0.2659],\n",
      "        [    0.0003],\n",
      "        [    0.5159],\n",
      "        [    2.7029],\n",
      "        [    1.2341],\n",
      "        [    0.0505],\n",
      "        [    0.0038]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  4,  4,  7, 10, 13, 16, 19, 22, 25, 28, 31, 34],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 279.4427978992462\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 189\n",
      "剩餘X 資料 torch.Size([14, 10])\n",
      "剩餘Y 資料 torch.Size([14, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (233027.875, 1)\n",
      "The second_loss value of k: (233027.875, 10)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([490.3700])\n",
      "目前模型的Data狀態 torch.Size([197, 1])\n",
      "<<預測值>>\n",
      "tensor([[ 97.3904],\n",
      "        [ 20.0154],\n",
      "        [268.5310],\n",
      "        [  7.6423],\n",
      "        [109.5310],\n",
      "        [ 16.3591],\n",
      "        [ 16.8789],\n",
      "        [ 23.6248],\n",
      "        [ 16.1560],\n",
      "        [ 20.5726],\n",
      "        [ 19.9529],\n",
      "        [ 44.5154],\n",
      "        [ 23.4607],\n",
      "        [ 15.8279],\n",
      "        [ 19.6746],\n",
      "        [ 10.5779],\n",
      "        [ 22.6794],\n",
      "        [ 10.1404],\n",
      "        [175.9841],\n",
      "        [ 17.8611],\n",
      "        [ 22.3591],\n",
      "        [ 29.6716],\n",
      "        [ 16.0466],\n",
      "        [ 17.0466],\n",
      "        [ 13.6755],\n",
      "        [ 18.8748],\n",
      "        [ 35.1248],\n",
      "        [ 36.0779],\n",
      "        [  7.6404],\n",
      "        [ 42.2576],\n",
      "        [ 18.7693],\n",
      "        [ 18.2029],\n",
      "        [ 22.9373],\n",
      "        [ 31.6716],\n",
      "        [ 42.8884],\n",
      "        [ 22.7029],\n",
      "        [ 16.1794],\n",
      "        [ 14.6716],\n",
      "        [ 17.6716],\n",
      "        [ 22.2986],\n",
      "        [ 15.0466],\n",
      "        [ 29.2966],\n",
      "        [ 47.9060],\n",
      "        [ 18.1394],\n",
      "        [ 19.1700],\n",
      "        [  7.6404],\n",
      "        [ 31.5466],\n",
      "        [ 16.6482],\n",
      "        [ 37.9509],\n",
      "        [ 57.8845],\n",
      "        [  7.6404],\n",
      "        [ 21.7986],\n",
      "        [ 15.9216],\n",
      "        [  8.5154],\n",
      "        [ 12.3201],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [  7.6404],\n",
      "        [ 22.4841],\n",
      "        [ 19.9021],\n",
      "        [ 20.7752],\n",
      "        [ 20.7615],\n",
      "        [ 25.1873],\n",
      "        [ 22.3572],\n",
      "        [ 68.5037],\n",
      "        [ 18.8279],\n",
      "        [  9.9060],\n",
      "        [ 27.2654],\n",
      "        [ 20.1716],\n",
      "        [ 18.5857],\n",
      "        [ 27.6716],\n",
      "        [ 29.7029],\n",
      "        [ 15.2029],\n",
      "        [ 19.1091],\n",
      "        [ 62.3748],\n",
      "        [ 23.7068],\n",
      "        [ 17.4841],\n",
      "        [ 38.2498],\n",
      "        [ 20.7009],\n",
      "        [ 23.4607],\n",
      "        [ 15.9998],\n",
      "        [ 23.4529],\n",
      "        [ 18.8318],\n",
      "        [ 29.4841],\n",
      "        [  7.6404],\n",
      "        [ 46.2810],\n",
      "        [ 19.5779],\n",
      "        [ 24.2034],\n",
      "        [ 21.8162],\n",
      "        [ 21.0115],\n",
      "        [  3.6091],\n",
      "        [ 10.2029],\n",
      "        [ 64.6091],\n",
      "        [  5.6091],\n",
      "        [ 17.8909],\n",
      "        [ 21.6404],\n",
      "        [  9.3435],\n",
      "        [ 22.5730],\n",
      "        [ 48.6248],\n",
      "        [ 13.0525],\n",
      "        [  9.3748],\n",
      "        [ 20.4529],\n",
      "        [ 20.0310],\n",
      "        [  7.6404],\n",
      "        [ 31.2654],\n",
      "        [  7.6404],\n",
      "        [ 12.3748],\n",
      "        [  7.6404],\n",
      "        [ 19.6958],\n",
      "        [ 16.7380],\n",
      "        [  7.6414],\n",
      "        [ 12.9216],\n",
      "        [ 43.8367],\n",
      "        [ 14.5310],\n",
      "        [148.3240],\n",
      "        [  7.6404],\n",
      "        [ 14.6892],\n",
      "        [ 12.8074],\n",
      "        [  9.3898],\n",
      "        [ 12.2952],\n",
      "        [ 20.1169],\n",
      "        [ 15.7810],\n",
      "        [ 44.8435],\n",
      "        [ 20.1560],\n",
      "        [ 25.4216],\n",
      "        [ 25.3904],\n",
      "        [ -2.7346],\n",
      "        [ 38.4607],\n",
      "        [ 38.4607],\n",
      "        [ 39.9373],\n",
      "        [ 29.2654],\n",
      "        [ 22.2341],\n",
      "        [134.3748],\n",
      "        [ 16.3591],\n",
      "        [ 27.3826],\n",
      "        [ 80.5154],\n",
      "        [ 37.1716],\n",
      "        [ 10.7966],\n",
      "        [ 66.9407],\n",
      "        [ 24.7810],\n",
      "        [ 13.0779],\n",
      "        [ 13.0779],\n",
      "        [ 17.2498],\n",
      "        [122.7654],\n",
      "        [ 35.6335],\n",
      "        [ 19.6365],\n",
      "        [ 59.0701],\n",
      "        [  8.4177],\n",
      "        [ 30.3904],\n",
      "        [104.8904],\n",
      "        [ 68.5154],\n",
      "        [ 97.5154],\n",
      "        [ 19.9373],\n",
      "        [ 27.1404],\n",
      "        [ 27.1404],\n",
      "        [  7.6404],\n",
      "        [ 30.6091],\n",
      "        [ 17.7029],\n",
      "        [ 14.2966],\n",
      "        [ 23.2341],\n",
      "        [  7.6404],\n",
      "        [ 19.6716],\n",
      "        [  7.6404],\n",
      "        [170.8279],\n",
      "        [119.1873],\n",
      "        [ 26.1716],\n",
      "        [ 21.9607],\n",
      "        [ 17.7341],\n",
      "        [ 24.8435],\n",
      "        [ 21.6248],\n",
      "        [ 21.1482],\n",
      "        [ 17.5134],\n",
      "        [ 18.1599],\n",
      "        [ 17.9607],\n",
      "        [ 14.1404],\n",
      "        [ 13.3992],\n",
      "        [ 10.3894],\n",
      "        [ 15.6404],\n",
      "        [ 67.6404],\n",
      "        [ 21.6423],\n",
      "        [ 20.9841],\n",
      "        [ 12.7185],\n",
      "        [ 11.4373],\n",
      "        [ 77.4685],\n",
      "        [279.7615],\n",
      "        [ 67.6560],\n",
      "        [314.1091],\n",
      "        [332.5466],\n",
      "        [  1.7029],\n",
      "        [383.7341],\n",
      "        [358.9997],\n",
      "        [ -0.5159],\n",
      "        [405.7029],\n",
      "        [  1.2341],\n",
      "        [420.0505],\n",
      "        [465.0038],\n",
      "        [  7.6404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.2390],\n",
      "        [    7.6423],\n",
      "        [  109.5310],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6248],\n",
      "        [   16.1560],\n",
      "        [   15.5726],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5393],\n",
      "        [   71.5621],\n",
      "        [   19.6746],\n",
      "        [   10.5779],\n",
      "        [    9.6794],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6755],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2576],\n",
      "        [   18.7693],\n",
      "        [   18.2029],\n",
      "        [   22.9373],\n",
      "        [   31.6716],\n",
      "        [   42.8884],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   14.6716],\n",
      "        [   17.6716],\n",
      "        [   22.2986],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   47.9060],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.5466],\n",
      "        [   16.6482],\n",
      "        [   37.9509],\n",
      "        [   57.8845],\n",
      "        [    7.6404],\n",
      "        [   21.7986],\n",
      "        [   15.9216],\n",
      "        [    8.5154],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.5037],\n",
      "        [   18.8279],\n",
      "        [    9.9060],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.5857],\n",
      "        [   27.6716],\n",
      "        [   29.7029],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3748],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   28.2498],\n",
      "        [   18.7009],\n",
      "        [  202.5393],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3318],\n",
      "        [   22.7841],\n",
      "        [    7.6404],\n",
      "        [   46.2810],\n",
      "        [    9.5779],\n",
      "        [   24.2034],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6091],\n",
      "        [   21.6404],\n",
      "        [    9.3435],\n",
      "        [   22.5730],\n",
      "        [   16.0248],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1240],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.1565],\n",
      "        [   34.8440],\n",
      "        [  123.5784],\n",
      "        [   25.3904],\n",
      "        [    2.7346],\n",
      "        [   38.4607],\n",
      "        [   38.4607],\n",
      "        [   16.4373],\n",
      "        [   25.2654],\n",
      "        [   42.2659],\n",
      "        [  134.3748],\n",
      "        [  219.6409],\n",
      "        [   43.6174],\n",
      "        [    1.3154],\n",
      "        [   37.1716],\n",
      "        [   10.7966],\n",
      "        [   18.6593],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6335],\n",
      "        [  134.3635],\n",
      "        [   38.9299],\n",
      "        [   96.5823],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   44.9846],\n",
      "        [   22.9146],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3909],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.1721],\n",
      "        [  118.8127],\n",
      "        [   26.1716],\n",
      "        [   21.9607],\n",
      "        [   17.7341],\n",
      "        [  152.1565],\n",
      "        [   21.6248],\n",
      "        [   21.1482],\n",
      "        [   17.5134],\n",
      "        [   18.1599],\n",
      "        [   17.9607],\n",
      "        [   14.1404],\n",
      "        [   13.3992],\n",
      "        [   10.3894],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   20.9841],\n",
      "        [   12.7185],\n",
      "        [   11.4373],\n",
      "        [   77.4685],\n",
      "        [    2.7615],\n",
      "        [  220.0140],\n",
      "        [    0.1091],\n",
      "        [    0.0466],\n",
      "        [    1.7029],\n",
      "        [    0.2659],\n",
      "        [    0.0003],\n",
      "        [    0.5159],\n",
      "        [    2.7029],\n",
      "        [    1.2341],\n",
      "        [    0.0505],\n",
      "        [    0.0038],\n",
      "        [  482.7296]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(5168.6841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 250\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   20.0154],\n",
      "        [   57.2390],\n",
      "        [    7.6423],\n",
      "        [  109.5310],\n",
      "        [    0.0991],\n",
      "        [   15.8789],\n",
      "        [   23.6248],\n",
      "        [   16.1560],\n",
      "        [   15.5726],\n",
      "        [   19.9529],\n",
      "        [   44.5154],\n",
      "        [  202.5393],\n",
      "        [   71.5621],\n",
      "        [   19.6746],\n",
      "        [   10.5779],\n",
      "        [    9.6794],\n",
      "        [   10.1404],\n",
      "        [  175.9841],\n",
      "        [   17.8611],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0466],\n",
      "        [   13.6755],\n",
      "        [   18.8748],\n",
      "        [   35.1248],\n",
      "        [   36.0779],\n",
      "        [    7.6404],\n",
      "        [   42.2576],\n",
      "        [   18.7693],\n",
      "        [   18.2029],\n",
      "        [   22.9373],\n",
      "        [   31.6716],\n",
      "        [   42.8884],\n",
      "        [   22.7029],\n",
      "        [   16.1794],\n",
      "        [   14.6716],\n",
      "        [   17.6716],\n",
      "        [   22.2986],\n",
      "        [   15.0466],\n",
      "        [   29.2966],\n",
      "        [   47.9060],\n",
      "        [   18.1394],\n",
      "        [   19.1700],\n",
      "        [    7.6404],\n",
      "        [   31.5466],\n",
      "        [   16.6482],\n",
      "        [   37.9509],\n",
      "        [   57.8845],\n",
      "        [    7.6404],\n",
      "        [   21.7986],\n",
      "        [   15.9216],\n",
      "        [    8.5154],\n",
      "        [   12.3201],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [    7.6404],\n",
      "        [   22.4841],\n",
      "        [   19.9021],\n",
      "        [   20.7752],\n",
      "        [   20.7615],\n",
      "        [   25.1873],\n",
      "        [   22.3572],\n",
      "        [   68.5037],\n",
      "        [   18.8279],\n",
      "        [    9.9060],\n",
      "        [   27.2654],\n",
      "        [   20.1716],\n",
      "        [   18.5857],\n",
      "        [   27.6716],\n",
      "        [   29.7029],\n",
      "        [   15.2029],\n",
      "        [   19.1091],\n",
      "        [   62.3748],\n",
      "        [   23.7068],\n",
      "        [   17.4841],\n",
      "        [   28.2498],\n",
      "        [   18.7009],\n",
      "        [  202.5393],\n",
      "        [   12.4998],\n",
      "        [   18.9729],\n",
      "        [   14.3318],\n",
      "        [   22.7841],\n",
      "        [    7.6404],\n",
      "        [   46.2810],\n",
      "        [    9.5779],\n",
      "        [   24.2034],\n",
      "        [   11.3162],\n",
      "        [   77.9885],\n",
      "        [    3.6091],\n",
      "        [   10.2029],\n",
      "        [   39.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6091],\n",
      "        [   21.6404],\n",
      "        [    9.3435],\n",
      "        [   22.5730],\n",
      "        [   16.0248],\n",
      "        [   19.9475],\n",
      "        [   24.6252],\n",
      "        [   14.5471],\n",
      "        [   17.9690],\n",
      "        [    7.6404],\n",
      "        [   31.2654],\n",
      "        [    7.6404],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6958],\n",
      "        [   16.7380],\n",
      "        [    7.6414],\n",
      "        [   28.5784],\n",
      "        [   23.1633],\n",
      "        [   14.5310],\n",
      "        [   42.1240],\n",
      "        [    7.6404],\n",
      "        [   14.6892],\n",
      "        [   12.8074],\n",
      "        [    9.3898],\n",
      "        [   12.2952],\n",
      "        [   23.8831],\n",
      "        [   35.2190],\n",
      "        [   10.1565],\n",
      "        [   34.8440],\n",
      "        [  123.5784],\n",
      "        [   25.3904],\n",
      "        [    2.7346],\n",
      "        [   38.4607],\n",
      "        [   38.4607],\n",
      "        [   16.4373],\n",
      "        [   25.2654],\n",
      "        [   42.2659],\n",
      "        [  134.3748],\n",
      "        [  219.6409],\n",
      "        [   43.6174],\n",
      "        [    1.3154],\n",
      "        [   37.1716],\n",
      "        [   10.7966],\n",
      "        [   18.6593],\n",
      "        [   62.2190],\n",
      "        [    9.2221],\n",
      "        [    9.2221],\n",
      "        [   75.2502],\n",
      "        [   83.2346],\n",
      "        [   35.6335],\n",
      "        [  134.3635],\n",
      "        [   38.9299],\n",
      "        [   96.5823],\n",
      "        [   74.6096],\n",
      "        [  104.8904],\n",
      "        [   44.9846],\n",
      "        [   22.9146],\n",
      "        [  119.0627],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8596],\n",
      "        [  149.3909],\n",
      "        [   17.7029],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3284],\n",
      "        [  220.3596],\n",
      "        [  178.1721],\n",
      "        [  118.8127],\n",
      "        [   26.1716],\n",
      "        [   21.9607],\n",
      "        [   17.7341],\n",
      "        [  152.1565],\n",
      "        [   21.6248],\n",
      "        [   21.1482],\n",
      "        [   17.5134],\n",
      "        [   18.1599],\n",
      "        [   17.9607],\n",
      "        [   14.1404],\n",
      "        [   13.3992],\n",
      "        [   10.3894],\n",
      "        [   15.6404],\n",
      "        [   52.6404],\n",
      "        [   21.6423],\n",
      "        [   20.9841],\n",
      "        [   12.7185],\n",
      "        [   11.4373],\n",
      "        [   77.4685],\n",
      "        [    2.7615],\n",
      "        [  220.0140],\n",
      "        [    0.1091],\n",
      "        [    0.0466],\n",
      "        [    1.7029],\n",
      "        [    0.2659],\n",
      "        [    0.0003],\n",
      "        [    0.5159],\n",
      "        [    2.7029],\n",
      "        [    1.2341],\n",
      "        [    0.0505],\n",
      "        [    0.0038],\n",
      "        [  482.7296]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 250\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[196,   0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   19.8904],\n",
      "        [   57.2390],\n",
      "        [    7.6423],\n",
      "        [  109.5310],\n",
      "        [    0.0991],\n",
      "        [   15.8865],\n",
      "        [   24.1248],\n",
      "        [   16.1716],\n",
      "        [   15.5414],\n",
      "        [   19.8279],\n",
      "        [   44.5154],\n",
      "        [  202.4768],\n",
      "        [   71.6246],\n",
      "        [   19.6746],\n",
      "        [   10.5779],\n",
      "        [    9.6794],\n",
      "        [   10.1716],\n",
      "        [  176.0154],\n",
      "        [   17.8669],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0544],\n",
      "        [   13.6755],\n",
      "        [   18.8279],\n",
      "        [   35.0310],\n",
      "        [   36.1404],\n",
      "        [    7.6482],\n",
      "        [   42.0076],\n",
      "        [   18.6443],\n",
      "        [   18.2029],\n",
      "        [   22.8748],\n",
      "        [   31.6716],\n",
      "        [   42.8884],\n",
      "        [   22.7029],\n",
      "        [   16.1716],\n",
      "        [   10.6716],\n",
      "        [   17.5779],\n",
      "        [   22.2986],\n",
      "        [   14.9529],\n",
      "        [   29.2654],\n",
      "        [   47.9060],\n",
      "        [   18.1560],\n",
      "        [   19.1755],\n",
      "        [    7.6404],\n",
      "        [   31.5466],\n",
      "        [   17.6482],\n",
      "        [   37.9509],\n",
      "        [   58.1345],\n",
      "        [    7.6365],\n",
      "        [   21.7986],\n",
      "        [   15.9294],\n",
      "        [    9.5154],\n",
      "        [   12.2966],\n",
      "        [    7.6404],\n",
      "        [    7.6418],\n",
      "        [    7.6326],\n",
      "        [   22.4841],\n",
      "        [   19.8982],\n",
      "        [   20.7810],\n",
      "        [   20.7576],\n",
      "        [   25.1873],\n",
      "        [   22.3513],\n",
      "        [   67.7537],\n",
      "        [   18.7654],\n",
      "        [    9.9060],\n",
      "        [   27.3904],\n",
      "        [   20.2029],\n",
      "        [   18.7107],\n",
      "        [   27.7029],\n",
      "        [   29.7029],\n",
      "        [   15.2029],\n",
      "        [   19.1404],\n",
      "        [   62.6248],\n",
      "        [   23.7146],\n",
      "        [   17.4841],\n",
      "        [   26.2498],\n",
      "        [   19.7009],\n",
      "        [  202.4768],\n",
      "        [   12.5154],\n",
      "        [   18.9729],\n",
      "        [   14.2693],\n",
      "        [   22.7841],\n",
      "        [    7.6404],\n",
      "        [   46.2810],\n",
      "        [    9.5779],\n",
      "        [   24.1409],\n",
      "        [   11.3162],\n",
      "        [   77.9905],\n",
      "        [    3.6091],\n",
      "        [   10.2185],\n",
      "        [   38.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6716],\n",
      "        [   21.5779],\n",
      "        [    9.3435],\n",
      "        [   23.0730],\n",
      "        [   16.0248],\n",
      "        [   19.9534],\n",
      "        [   24.6252],\n",
      "        [   14.6096],\n",
      "        [   17.9534],\n",
      "        [    7.6414],\n",
      "        [   31.2341],\n",
      "        [    7.6399],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6931],\n",
      "        [   16.7185],\n",
      "        [    7.6414],\n",
      "        [   28.6721],\n",
      "        [   23.1636],\n",
      "        [   14.5310],\n",
      "        [   42.0615],\n",
      "        [    7.6414],\n",
      "        [   14.6951],\n",
      "        [   12.8064],\n",
      "        [    9.3899],\n",
      "        [   12.2952],\n",
      "        [   23.8752],\n",
      "        [   35.2659],\n",
      "        [   10.1565],\n",
      "        [   34.9846],\n",
      "        [  123.3284],\n",
      "        [   25.2654],\n",
      "        [    2.7346],\n",
      "        [   38.2107],\n",
      "        [   38.2107],\n",
      "        [   15.4373],\n",
      "        [   25.2654],\n",
      "        [   42.2815],\n",
      "        [  134.3748],\n",
      "        [  219.6721],\n",
      "        [   43.6174],\n",
      "        [    1.3154],\n",
      "        [   37.1404],\n",
      "        [   10.7966],\n",
      "        [   18.6593],\n",
      "        [   62.2034],\n",
      "        [    9.2846],\n",
      "        [    9.2846],\n",
      "        [   75.2346],\n",
      "        [   83.2034],\n",
      "        [   35.6335],\n",
      "        [  134.6135],\n",
      "        [   38.9299],\n",
      "        [   96.6448],\n",
      "        [   74.6096],\n",
      "        [  104.9216],\n",
      "        [   44.9846],\n",
      "        [   22.9146],\n",
      "        [  119.0471],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8577],\n",
      "        [  149.3909],\n",
      "        [   17.6404],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3596],\n",
      "        [  220.3596],\n",
      "        [  178.6721],\n",
      "        [  118.8127],\n",
      "        [   26.1716],\n",
      "        [   21.8982],\n",
      "        [   17.6404],\n",
      "        [  152.1565],\n",
      "        [   21.6248],\n",
      "        [   21.1482],\n",
      "        [   17.5134],\n",
      "        [   18.0349],\n",
      "        [   18.0232],\n",
      "        [   14.1404],\n",
      "        [   13.3992],\n",
      "        [   10.3894],\n",
      "        [   16.6404],\n",
      "        [   52.6404],\n",
      "        [   21.3923],\n",
      "        [   20.9841],\n",
      "        [   12.7185],\n",
      "        [   11.4373],\n",
      "        [   76.4685],\n",
      "        [    2.7615],\n",
      "        [  219.0140],\n",
      "        [    0.1404],\n",
      "        [    0.1409],\n",
      "        [    0.2971],\n",
      "        [    1.2659],\n",
      "        [    0.0017],\n",
      "        [    2.5159],\n",
      "        [    1.2971],\n",
      "        [    1.2341],\n",
      "        [    0.0432],\n",
      "        [    0.0038],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 329\n",
      "Number of shrink: 171\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 329\n",
      "Number of shrink: 171\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 20 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 21 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 22 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 23 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 24 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 331\n",
      "Number of shrink: 169\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 25 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 26 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 27 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 339\n",
      "Number of shrink: 161\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 28 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 29 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 334\n",
      "Number of shrink: 166\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 30 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 31 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 32 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 333\n",
      "Number of shrink: 167\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 33 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 332\n",
      "Number of shrink: 168\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 34 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 35 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 338\n",
      "Number of shrink: 162\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 36 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 37 / 37\n",
      "Reorganizing result: The final number of neuro is  37\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   19.8904],\n",
      "        [   57.2390],\n",
      "        [    7.6423],\n",
      "        [  109.5310],\n",
      "        [    0.0991],\n",
      "        [   15.8865],\n",
      "        [   24.1248],\n",
      "        [   16.1716],\n",
      "        [   15.5414],\n",
      "        [   19.8279],\n",
      "        [   44.5154],\n",
      "        [  202.4768],\n",
      "        [   71.6246],\n",
      "        [   19.6746],\n",
      "        [   10.5779],\n",
      "        [    9.6794],\n",
      "        [   10.1716],\n",
      "        [  176.0154],\n",
      "        [   17.8669],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0544],\n",
      "        [   13.6755],\n",
      "        [   18.8279],\n",
      "        [   35.0310],\n",
      "        [   36.1404],\n",
      "        [    7.6482],\n",
      "        [   42.0076],\n",
      "        [   18.6443],\n",
      "        [   18.2029],\n",
      "        [   22.8748],\n",
      "        [   31.6716],\n",
      "        [   42.8884],\n",
      "        [   22.7029],\n",
      "        [   16.1716],\n",
      "        [   10.6716],\n",
      "        [   17.5779],\n",
      "        [   22.2986],\n",
      "        [   14.9529],\n",
      "        [   29.2654],\n",
      "        [   47.9060],\n",
      "        [   18.1560],\n",
      "        [   19.1755],\n",
      "        [    7.6404],\n",
      "        [   31.5466],\n",
      "        [   17.6482],\n",
      "        [   37.9509],\n",
      "        [   58.1345],\n",
      "        [    7.6365],\n",
      "        [   21.7986],\n",
      "        [   15.9294],\n",
      "        [    9.5154],\n",
      "        [   12.2966],\n",
      "        [    7.6404],\n",
      "        [    7.6418],\n",
      "        [    7.6326],\n",
      "        [   22.4841],\n",
      "        [   19.8982],\n",
      "        [   20.7810],\n",
      "        [   20.7576],\n",
      "        [   25.1873],\n",
      "        [   22.3513],\n",
      "        [   67.7537],\n",
      "        [   18.7654],\n",
      "        [    9.9060],\n",
      "        [   27.3904],\n",
      "        [   20.2029],\n",
      "        [   18.7107],\n",
      "        [   27.7029],\n",
      "        [   29.7029],\n",
      "        [   15.2029],\n",
      "        [   19.1404],\n",
      "        [   62.6248],\n",
      "        [   23.7146],\n",
      "        [   17.4841],\n",
      "        [   26.2498],\n",
      "        [   19.7009],\n",
      "        [  202.4768],\n",
      "        [   12.5154],\n",
      "        [   18.9729],\n",
      "        [   14.2693],\n",
      "        [   22.7841],\n",
      "        [    7.6404],\n",
      "        [   46.2810],\n",
      "        [    9.5779],\n",
      "        [   24.1409],\n",
      "        [   11.3162],\n",
      "        [   77.9905],\n",
      "        [    3.6091],\n",
      "        [   10.2185],\n",
      "        [   38.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6716],\n",
      "        [   21.5779],\n",
      "        [    9.3435],\n",
      "        [   23.0730],\n",
      "        [   16.0248],\n",
      "        [   19.9534],\n",
      "        [   24.6252],\n",
      "        [   14.6096],\n",
      "        [   17.9534],\n",
      "        [    7.6414],\n",
      "        [   31.2341],\n",
      "        [    7.6399],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6931],\n",
      "        [   16.7185],\n",
      "        [    7.6414],\n",
      "        [   28.6721],\n",
      "        [   23.1636],\n",
      "        [   14.5310],\n",
      "        [   42.0615],\n",
      "        [    7.6414],\n",
      "        [   14.6951],\n",
      "        [   12.8064],\n",
      "        [    9.3899],\n",
      "        [   12.2952],\n",
      "        [   23.8752],\n",
      "        [   35.2659],\n",
      "        [   10.1565],\n",
      "        [   34.9846],\n",
      "        [  123.3284],\n",
      "        [   25.2654],\n",
      "        [    2.7346],\n",
      "        [   38.2107],\n",
      "        [   38.2107],\n",
      "        [   15.4373],\n",
      "        [   25.2654],\n",
      "        [   42.2815],\n",
      "        [  134.3748],\n",
      "        [  219.6721],\n",
      "        [   43.6174],\n",
      "        [    1.3154],\n",
      "        [   37.1404],\n",
      "        [   10.7966],\n",
      "        [   18.6593],\n",
      "        [   62.2034],\n",
      "        [    9.2846],\n",
      "        [    9.2846],\n",
      "        [   75.2346],\n",
      "        [   83.2034],\n",
      "        [   35.6335],\n",
      "        [  134.6135],\n",
      "        [   38.9299],\n",
      "        [   96.6448],\n",
      "        [   74.6096],\n",
      "        [  104.9216],\n",
      "        [   44.9846],\n",
      "        [   22.9146],\n",
      "        [  119.0471],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8577],\n",
      "        [  149.3909],\n",
      "        [   17.6404],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3596],\n",
      "        [  220.3596],\n",
      "        [  178.6721],\n",
      "        [  118.8127],\n",
      "        [   26.1716],\n",
      "        [   21.8982],\n",
      "        [   17.6404],\n",
      "        [  152.1565],\n",
      "        [   21.6248],\n",
      "        [   21.1482],\n",
      "        [   17.5134],\n",
      "        [   18.0349],\n",
      "        [   18.0232],\n",
      "        [   14.1404],\n",
      "        [   13.3992],\n",
      "        [   10.3894],\n",
      "        [   16.6404],\n",
      "        [   52.6404],\n",
      "        [   21.3923],\n",
      "        [   20.9841],\n",
      "        [   12.7185],\n",
      "        [   11.4373],\n",
      "        [   76.4685],\n",
      "        [    2.7615],\n",
      "        [  219.0140],\n",
      "        [    0.1404],\n",
      "        [    0.1409],\n",
      "        [    0.2971],\n",
      "        [    1.2659],\n",
      "        [    0.0017],\n",
      "        [    2.5159],\n",
      "        [    1.2971],\n",
      "        [    1.2341],\n",
      "        [    0.0432],\n",
      "        [    0.0038],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  4,  4,  7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 319.9082717895508\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 190\n",
      "剩餘X 資料 torch.Size([13, 10])\n",
      "剩餘Y 資料 torch.Size([13, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0, 9)\n",
      "The second_loss value of k: (289276.15625, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引9，y= tensor([490.3700])\n",
      "目前模型的Data狀態 torch.Size([198, 1])\n",
      "<<預測值>>\n",
      "tensor([[    97.3904],\n",
      "        [    19.8904],\n",
      "        [   268.5310],\n",
      "        [     7.6423],\n",
      "        [   109.5310],\n",
      "        [    16.3591],\n",
      "        [    16.8865],\n",
      "        [    24.1248],\n",
      "        [    16.1716],\n",
      "        [    20.5414],\n",
      "        [    19.8279],\n",
      "        [    44.5154],\n",
      "        [    23.5232],\n",
      "        [    15.7654],\n",
      "        [    19.6746],\n",
      "        [    10.5779],\n",
      "        [    22.6794],\n",
      "        [    10.1716],\n",
      "        [   176.0154],\n",
      "        [    17.8669],\n",
      "        [    22.3591],\n",
      "        [    29.6716],\n",
      "        [    16.0466],\n",
      "        [    17.0544],\n",
      "        [    13.6755],\n",
      "        [    18.8279],\n",
      "        [    35.0310],\n",
      "        [    36.1404],\n",
      "        [     7.6482],\n",
      "        [    42.0076],\n",
      "        [    18.6443],\n",
      "        [    18.2029],\n",
      "        [    22.8748],\n",
      "        [    31.6716],\n",
      "        [    42.8884],\n",
      "        [    22.7029],\n",
      "        [    16.1716],\n",
      "        [    10.6716],\n",
      "        [    17.5779],\n",
      "        [    22.2986],\n",
      "        [    14.9529],\n",
      "        [    29.2654],\n",
      "        [    47.9060],\n",
      "        [    18.1560],\n",
      "        [    19.1755],\n",
      "        [     7.6404],\n",
      "        [    31.5466],\n",
      "        [    17.6482],\n",
      "        [    37.9509],\n",
      "        [    58.1345],\n",
      "        [     7.6365],\n",
      "        [    21.7986],\n",
      "        [    15.9294],\n",
      "        [     9.5154],\n",
      "        [    12.2966],\n",
      "        [     7.6404],\n",
      "        [     7.6418],\n",
      "        [     7.6326],\n",
      "        [    22.4841],\n",
      "        [    19.8982],\n",
      "        [    20.7810],\n",
      "        [    20.7576],\n",
      "        [    25.1873],\n",
      "        [    22.3513],\n",
      "        [    67.7537],\n",
      "        [    18.7654],\n",
      "        [     9.9060],\n",
      "        [    27.3904],\n",
      "        [    20.2029],\n",
      "        [    18.7107],\n",
      "        [    27.7029],\n",
      "        [    29.7029],\n",
      "        [    15.2029],\n",
      "        [    19.1404],\n",
      "        [    62.6248],\n",
      "        [    23.7146],\n",
      "        [    17.4841],\n",
      "        [    36.2498],\n",
      "        [    21.7009],\n",
      "        [    23.5232],\n",
      "        [    16.0154],\n",
      "        [    23.4529],\n",
      "        [    18.7693],\n",
      "        [    29.4841],\n",
      "        [     7.6404],\n",
      "        [    46.2810],\n",
      "        [    19.5779],\n",
      "        [    24.1409],\n",
      "        [    21.8162],\n",
      "        [    21.0095],\n",
      "        [     3.6091],\n",
      "        [    10.2185],\n",
      "        [    63.6091],\n",
      "        [     5.6091],\n",
      "        [    17.8284],\n",
      "        [    21.5779],\n",
      "        [     9.3435],\n",
      "        [    23.0730],\n",
      "        [    48.6248],\n",
      "        [    13.0466],\n",
      "        [     9.3748],\n",
      "        [    20.3904],\n",
      "        [    20.0466],\n",
      "        [     7.6414],\n",
      "        [    31.2341],\n",
      "        [     7.6399],\n",
      "        [    12.3748],\n",
      "        [     7.6404],\n",
      "        [    19.6931],\n",
      "        [    16.7185],\n",
      "        [     7.6414],\n",
      "        [    12.8279],\n",
      "        [    43.8364],\n",
      "        [    14.5310],\n",
      "        [   148.2615],\n",
      "        [     7.6414],\n",
      "        [    14.6951],\n",
      "        [    12.8064],\n",
      "        [     9.3899],\n",
      "        [    12.2952],\n",
      "        [    20.1248],\n",
      "        [    15.7341],\n",
      "        [    44.8435],\n",
      "        [    20.0154],\n",
      "        [    25.6716],\n",
      "        [    25.2654],\n",
      "        [    -2.7346],\n",
      "        [    38.2107],\n",
      "        [    38.2107],\n",
      "        [    38.9373],\n",
      "        [    29.2654],\n",
      "        [    22.2185],\n",
      "        [   134.3748],\n",
      "        [    16.3279],\n",
      "        [    27.3826],\n",
      "        [    80.5154],\n",
      "        [    37.1404],\n",
      "        [    10.7966],\n",
      "        [    66.9407],\n",
      "        [    24.7966],\n",
      "        [    13.0154],\n",
      "        [    13.0154],\n",
      "        [    17.2654],\n",
      "        [   122.7966],\n",
      "        [    35.6335],\n",
      "        [    19.3865],\n",
      "        [    59.0701],\n",
      "        [     8.3552],\n",
      "        [    30.3904],\n",
      "        [   104.9216],\n",
      "        [    68.5154],\n",
      "        [    97.5154],\n",
      "        [    19.9529],\n",
      "        [    27.1404],\n",
      "        [    27.1404],\n",
      "        [     7.6423],\n",
      "        [    30.6091],\n",
      "        [    17.6404],\n",
      "        [    14.2966],\n",
      "        [    23.2341],\n",
      "        [     7.6404],\n",
      "        [    19.6404],\n",
      "        [     7.6404],\n",
      "        [   170.3279],\n",
      "        [   119.1873],\n",
      "        [    26.1716],\n",
      "        [    21.8982],\n",
      "        [    17.6404],\n",
      "        [    24.8435],\n",
      "        [    21.6248],\n",
      "        [    21.1482],\n",
      "        [    17.5134],\n",
      "        [    18.0349],\n",
      "        [    18.0232],\n",
      "        [    14.1404],\n",
      "        [    13.3992],\n",
      "        [    10.3894],\n",
      "        [    16.6404],\n",
      "        [    67.6404],\n",
      "        [    21.3923],\n",
      "        [    20.9841],\n",
      "        [    12.7185],\n",
      "        [    11.4373],\n",
      "        [    76.4685],\n",
      "        [   279.7615],\n",
      "        [    68.6560],\n",
      "        [   314.1404],\n",
      "        [   332.3591],\n",
      "        [    -0.2971],\n",
      "        [   382.7341],\n",
      "        [   359.0017],\n",
      "        [    -2.5159],\n",
      "        [   401.7029],\n",
      "        [     1.2341],\n",
      "        [   419.9568],\n",
      "        [   465.0038],\n",
      "        [   490.3700],\n",
      "        [   490.3700]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[  220.6096],\n",
      "        [   19.8904],\n",
      "        [   57.2390],\n",
      "        [    7.6423],\n",
      "        [  109.5310],\n",
      "        [    0.0991],\n",
      "        [   15.8865],\n",
      "        [   24.1248],\n",
      "        [   16.1716],\n",
      "        [   15.5414],\n",
      "        [   19.8279],\n",
      "        [   44.5154],\n",
      "        [  202.4768],\n",
      "        [   71.6246],\n",
      "        [   19.6746],\n",
      "        [   10.5779],\n",
      "        [    9.6794],\n",
      "        [   10.1716],\n",
      "        [  176.0154],\n",
      "        [   17.8669],\n",
      "        [   22.3591],\n",
      "        [   29.6716],\n",
      "        [   16.0466],\n",
      "        [   17.0544],\n",
      "        [   13.6755],\n",
      "        [   18.8279],\n",
      "        [   35.0310],\n",
      "        [   36.1404],\n",
      "        [    7.6482],\n",
      "        [   42.0076],\n",
      "        [   18.6443],\n",
      "        [   18.2029],\n",
      "        [   22.8748],\n",
      "        [   31.6716],\n",
      "        [   42.8884],\n",
      "        [   22.7029],\n",
      "        [   16.1716],\n",
      "        [   10.6716],\n",
      "        [   17.5779],\n",
      "        [   22.2986],\n",
      "        [   14.9529],\n",
      "        [   29.2654],\n",
      "        [   47.9060],\n",
      "        [   18.1560],\n",
      "        [   19.1755],\n",
      "        [    7.6404],\n",
      "        [   31.5466],\n",
      "        [   17.6482],\n",
      "        [   37.9509],\n",
      "        [   58.1345],\n",
      "        [    7.6365],\n",
      "        [   21.7986],\n",
      "        [   15.9294],\n",
      "        [    9.5154],\n",
      "        [   12.2966],\n",
      "        [    7.6404],\n",
      "        [    7.6418],\n",
      "        [    7.6326],\n",
      "        [   22.4841],\n",
      "        [   19.8982],\n",
      "        [   20.7810],\n",
      "        [   20.7576],\n",
      "        [   25.1873],\n",
      "        [   22.3513],\n",
      "        [   67.7537],\n",
      "        [   18.7654],\n",
      "        [    9.9060],\n",
      "        [   27.3904],\n",
      "        [   20.2029],\n",
      "        [   18.7107],\n",
      "        [   27.7029],\n",
      "        [   29.7029],\n",
      "        [   15.2029],\n",
      "        [   19.1404],\n",
      "        [   62.6248],\n",
      "        [   23.7146],\n",
      "        [   17.4841],\n",
      "        [   26.2498],\n",
      "        [   19.7009],\n",
      "        [  202.4768],\n",
      "        [   12.5154],\n",
      "        [   18.9729],\n",
      "        [   14.2693],\n",
      "        [   22.7841],\n",
      "        [    7.6404],\n",
      "        [   46.2810],\n",
      "        [    9.5779],\n",
      "        [   24.1409],\n",
      "        [   11.3162],\n",
      "        [   77.9905],\n",
      "        [    3.6091],\n",
      "        [   10.2185],\n",
      "        [   38.5291],\n",
      "        [    5.6091],\n",
      "        [   48.6716],\n",
      "        [   21.5779],\n",
      "        [    9.3435],\n",
      "        [   23.0730],\n",
      "        [   16.0248],\n",
      "        [   19.9534],\n",
      "        [   24.6252],\n",
      "        [   14.6096],\n",
      "        [   17.9534],\n",
      "        [    7.6414],\n",
      "        [   31.2341],\n",
      "        [    7.6399],\n",
      "        [   12.3748],\n",
      "        [    7.6404],\n",
      "        [   19.6931],\n",
      "        [   16.7185],\n",
      "        [    7.6414],\n",
      "        [   28.6721],\n",
      "        [   23.1636],\n",
      "        [   14.5310],\n",
      "        [   42.0615],\n",
      "        [    7.6414],\n",
      "        [   14.6951],\n",
      "        [   12.8064],\n",
      "        [    9.3899],\n",
      "        [   12.2952],\n",
      "        [   23.8752],\n",
      "        [   35.2659],\n",
      "        [   10.1565],\n",
      "        [   34.9846],\n",
      "        [  123.3284],\n",
      "        [   25.2654],\n",
      "        [    2.7346],\n",
      "        [   38.2107],\n",
      "        [   38.2107],\n",
      "        [   15.4373],\n",
      "        [   25.2654],\n",
      "        [   42.2815],\n",
      "        [  134.3748],\n",
      "        [  219.6721],\n",
      "        [   43.6174],\n",
      "        [    1.3154],\n",
      "        [   37.1404],\n",
      "        [   10.7966],\n",
      "        [   18.6593],\n",
      "        [   62.2034],\n",
      "        [    9.2846],\n",
      "        [    9.2846],\n",
      "        [   75.2346],\n",
      "        [   83.2034],\n",
      "        [   35.6335],\n",
      "        [  134.6135],\n",
      "        [   38.9299],\n",
      "        [   96.6448],\n",
      "        [   74.6096],\n",
      "        [  104.9216],\n",
      "        [   44.9846],\n",
      "        [   22.9146],\n",
      "        [  119.0471],\n",
      "        [  125.5296],\n",
      "        [  125.5296],\n",
      "        [  167.8577],\n",
      "        [  149.3909],\n",
      "        [   17.6404],\n",
      "        [   14.2966],\n",
      "        [  166.7659],\n",
      "        [  187.3596],\n",
      "        [  180.3596],\n",
      "        [  220.3596],\n",
      "        [  178.6721],\n",
      "        [  118.8127],\n",
      "        [   26.1716],\n",
      "        [   21.8982],\n",
      "        [   17.6404],\n",
      "        [  152.1565],\n",
      "        [   21.6248],\n",
      "        [   21.1482],\n",
      "        [   17.5134],\n",
      "        [   18.0349],\n",
      "        [   18.0232],\n",
      "        [   14.1404],\n",
      "        [   13.3992],\n",
      "        [   10.3894],\n",
      "        [   16.6404],\n",
      "        [   52.6404],\n",
      "        [   21.3923],\n",
      "        [   20.9841],\n",
      "        [   12.7185],\n",
      "        [   11.4373],\n",
      "        [   76.4685],\n",
      "        [    2.7615],\n",
      "        [  219.0140],\n",
      "        [    0.1404],\n",
      "        [    0.1409],\n",
      "        [    0.2971],\n",
      "        [    1.2659],\n",
      "        [    0.0017],\n",
      "        [    2.5159],\n",
      "        [    1.2971],\n",
      "        [    1.2341],\n",
      "        [    0.0432],\n",
      "        [    0.0038],\n",
      "        [    0.0000],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 250\n",
      "Loss值\n",
      "tensor(3962.1736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 250\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 341\n",
      "Number of shrink: 159\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 340\n",
      "Number of shrink: 160\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 337\n",
      "Number of shrink: 163\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 336\n",
      "Number of shrink: 164\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 335\n",
      "Number of shrink: 165\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n",
      "Matching的第500回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 329\n",
      "Number of shrink: 171\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 37\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 250\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-8d796f023f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mnb_step4\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreorganizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<<Reorganizing後看一下差異>>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0myo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-d90f45550235>\u001b[0m in \u001b[0;36mreorganizing\u001b[0;34m(network)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;31m## Using the matching module to adjust the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatching_for_reorganizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"是不是可以不要這個hidden node:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macceptable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-779cb7523337>\u001b[0m in \u001b[0;36mmatching_for_reorganizing\u001b[0;34m(network)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0myo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mnetwork_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mloss_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'xla'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evaluation_table_train = pd.DataFrame(columns=[\"Window_index\",\"Stage\",\"MAE\",\"MAPE\",\"RMSE\",\"Accuracy(2000)\",\"Accuracy(3000)\",\"Step4\",\"Step6.1\",\"Step6.2\",\"Time\",\"Adopted_hidden_node\"])\n",
    "# evaluation_table_test = pd.DataFrame(columns=[\"Window_index\",\"Stage\",\"MAE\",\"MAPE\",\"RMSE\",\"Accuracy(2000)\",\"Accuracy(3000)\",\"Step4\",\"Step6.1\",\"Step6.2\",\"Time\",\"Adopted_hidden_node\"])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i_block in range(len(block_x_train)):\n",
    "# for i_block in range(-2,0,1):\n",
    "# for i_block in range(2):\n",
    "    block_start = time.time()\n",
    "    ## Record the number of each step\n",
    "    nb_step4 = 0\n",
    "    nb_step6_1 = 0\n",
    "    nb_step6_2 = 0\n",
    "    \n",
    "    print(\"The <<%d>> Block\" %(i_block+1))\n",
    "\n",
    "    \n",
    "    x_train = x_sets_train[i_block]\n",
    "    x_test = x_sets_test[i_block]\n",
    "    y_train = y_sets_train[i_block][:,0].reshape(-1,1)\n",
    "    y_test = y_sets_test[i_block][:,0].reshape(-1,1)\n",
    "    \n",
    "    x_train_scaled = torch.FloatTensor(x_train)\n",
    "    x_test_scaled = torch.FloatTensor(x_test)\n",
    "    y_train_scaled = torch.FloatTensor(y_train)\n",
    "\n",
    "\n",
    "#     if i_block == -2:\n",
    "#     if i_block == 0:\n",
    "#         lower = torch.mean(y_train_scaled)-torch.std(y_train_scaled)\n",
    "#         upper = torch.mean(y_train_scaled)+torch.std(y_train_scaled)\n",
    "#         nonoutlier_index = torch.nonzero((y_train_scaled[:,0]>lower)&(y_train_scaled[:,0]<upper)).reshape([-1])\n",
    "        \n",
    "    initial_x = x_train_scaled[:19]\n",
    "    initial_y = y_train_scaled[:19]\n",
    "\n",
    "    x_train_scaled = x_train_scaled[19:]\n",
    "    y_train_scaled = y_train_scaled[19:]\n",
    "#         print(initial_x.shape[0])\n",
    "        \n",
    "    network = Network(1,initial_x,initial_y)\n",
    "        \n",
    "    network.nb_node_acceptable = torch.IntTensor([1 for _ in range(initial_x.shape[0])])\n",
    "    network.threshold_for_error = 250\n",
    "        \n",
    "    initializing(network, initial_x, initial_y)\n",
    "        \n",
    "    print(\"<<Initializing後看一下差異>>\")\n",
    "    yo,loss = network.forward()\n",
    "    print(torch.abs(network.y-yo))\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "#     remainder = int(window_size*0.9624) - initial_x.shape[0]\n",
    "    \n",
    "#     else:\n",
    "# #         print(\"新的Code待驗證\")\n",
    "# #         print(network.state_dict())\n",
    "#         sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "#         restart_index = int(x_train_scaled.shape[0]*0.9624)-step_window\n",
    "#         print(\"其他區塊剛開始選的資料索引：\",sorted_index[:restart_index])\n",
    "#         init_x = x_train_scaled[sorted_index[:int(x_train_scaled.shape[0]*0.9624)-step_window]].reshape(-1,x_train_scaled.shape[1])\n",
    "#         init_y = y_train_scaled[sorted_index[:int(x_train_scaled.shape[0]*0.9624)-step_window]].reshape(-1,1)\n",
    "# #         print(\"取得的x\",init_x.shape)\n",
    "# #         print(\"取得的y\",init_y.shape)\n",
    "# #         print(\"前\")\n",
    "# #         print(network.y.shape)\n",
    "#         network.setData(init_x, init_y)\n",
    "# #         print(\"後\")\n",
    "# #         print(network.y.shape)\n",
    "#         network.nb_node_acceptable = torch.IntTensor([network.linear1.bias.data.shape[0] for _ in range(init_x.shape[0])])\n",
    "#         network.nb_node_pruned = 0\n",
    "        \n",
    "#         print(\"<<其他區塊剛開始時看一下差異>>\")\n",
    "#         yo,loss = network.forward()\n",
    "#         print(torch.abs(network.y-yo))\n",
    "        \n",
    "#         remainder = int(window_size*0.9624) - init_x.shape[0]\n",
    "#         x_train_scaled = np.delete(x_train_scaled, sorted_index[:restart_index], 0)\n",
    "#         y_train_scaled = np.delete(y_train_scaled, sorted_index[:restart_index], 0)\n",
    "        \n",
    "#         print(\"X 資料\",x_train_scaled.shape)\n",
    "#         print(\"Y 資料\",y_train_scaled.shape)\n",
    "#     network.limit = network.linear1.bias.data.shape[0]\n",
    "#     print(\"Limit for node pruned:\",network.limit)\n",
    "    \n",
    "    for i in range(int(x_train_scaled.shape[0])):\n",
    "#     for i in range(2):\n",
    "#     for i in range(remainder):\n",
    "#         if i_block == -2:\n",
    "        if i_block == 0:\n",
    "            print(\"現在訓練到第幾筆資料: %d\"%(i+x_train_scaled.shape[1]+2))\n",
    "        \n",
    "#         else:\n",
    "#             print(\"現在訓練到第幾筆資料: %d\"%(restart_index+i+1))\n",
    "        \n",
    "        print(\"剩餘X 資料\",x_train_scaled.shape)\n",
    "        print(\"剩餘Y 資料\",y_train_scaled.shape)\n",
    "        \n",
    "        sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "        \n",
    "\n",
    "        ## Add new data for training\n",
    "        \n",
    "        print(\"現在要進去模型的數據，索引%d，y=\"%(sorted_index[0]),y_train_scaled[sorted_index[0]].data)        \n",
    "        network.addData(x_train_scaled[sorted_index[0]], y_train_scaled[sorted_index[0]])\n",
    "        print(\"目前模型的Data狀態\",network.y.shape)\n",
    "        x_train_scaled = np.delete(x_train_scaled, sorted_index[0], 0)\n",
    "        y_train_scaled = np.delete(y_train_scaled, sorted_index[0], 0)\n",
    "        \n",
    "        yo,loss = network.forward()\n",
    "        print(\"<<預測值>>\")\n",
    "        print(yo)\n",
    "        print(\"<<差異>>\")\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        print(\"Loss值\")\n",
    "        print(loss)\n",
    "\n",
    "        pre_network = copy.deepcopy(network)\n",
    "        \n",
    "        if not torch.all(torch.abs(network.y-yo)<=network.threshold_for_error):\n",
    "\n",
    "            network.acceptable = False\n",
    "            network = matching(network)\n",
    "            \n",
    "            print(\"<<Matching後看一下差異>>\")\n",
    "            yo,loss = network.forward()\n",
    "            print(torch.abs(yo-network.y))\n",
    "            print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "            \n",
    "            if network.acceptable == False:\n",
    "                \n",
    "                network = copy.deepcopy(pre_network)\n",
    "                cramming(network)\n",
    "\n",
    "                if network.acceptable == False:\n",
    "                    sys.exit(0)  \n",
    "                \n",
    "                print(\"<<Cramming後看一下差異>>\")\n",
    "                yo,loss = network.forward()\n",
    "                print(torch.abs(yo-network.y))\n",
    "                print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "                nb_step6_2 += 1\n",
    "\n",
    "            else:\n",
    "                nb_step6_1 += 1\n",
    "\n",
    "        else:\n",
    "            nb_step4 += 1\n",
    "\n",
    "        network = reorganizing(network)\n",
    "        print(\"<<Reorganizing後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        \n",
    "        network.nb_node_acceptable = torch.cat([network.nb_node_acceptable, torch.IntTensor([network.linear1.bias.data.shape[0]])],0)\n",
    "        print(\"看一下 hidden node\")\n",
    "        print(network.nb_node_acceptable)\n",
    "       \n",
    "        print(\"使用裝置\",(list(network.parameters())[0].device))\n",
    "        print(\"累計時間(s)\",time.time()-start)\n",
    "#         print(network.state_dict())\n",
    "        print(\"-\"*90)\n",
    "\n",
    "    \n",
    "    block_end = time.time()\n",
    "    print(\"到第 %d 個區塊累積花費時間(s)\"%(i_block+1),block_end-block_start)\n",
    "#     print(\"到第 %d 個區塊累積花費時間(s)\"%(len(splits)+i_block+1),block_end-block_start)\n",
    "    print(\"<<The performance of %d block>>\"%(i_block+1))\n",
    "#     print(\"<<The performance of %d block>>\"%(len(splits)+i_block+1))\n",
    "    \n",
    "#     evaluation_table_train, evaluation_table_test = validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test_scaled, y_test, block_start, block_end,i_block+1,evaluation_table_train,evaluation_table_test)\n",
    "\n",
    "#     evaluation_table_train.to_csv(\"evaluation_table_train.csv\",index=False)\n",
    "#     evaluation_table_test.to_csv(\"evaluation_table_inferencing.csv\",index=False)\n",
    "#     validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test_scaled, y_test, block_start, block_end,(len(splits)+i_block+1))\n",
    "end = time.time()\n",
    "print(\"總計時間(s)\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
